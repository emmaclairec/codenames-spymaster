{"id": "9569", "url": "https://en.wikipedia.org/wiki?curid=9569", "title": "Endomorphism", "text": "Endomorphism\n\nIn mathematics, an endomorphism is a morphism from a mathematical object to itself. An endomorphism that is also an isomorphism is an automorphism. For example, an endomorphism of a vector space is a linear map , and an endomorphism of a group is a group homomorphism . In general, we can talk about endomorphisms in any category. In the category of sets, endomorphisms are functions from a set \"S\" to itself.\n\nIn any category, the composition of any two endomorphisms of is again an endomorphism of . It follows that the set of all endomorphisms of forms a monoid, denoted (or to emphasize the category ).\n\nAn invertible endomorphism of is called an automorphism. The set of all automorphisms is a subset of with a group structure, called the automorphism group of and denoted . In the following diagram, the arrows denote implication:\n\nAny two endomorphisms of an abelian group, , can be added together by the rule . Under this addition, and with multiplication being defined as function composition, the endomorphisms of an abelian group form a ring (the endomorphism ring). For example, the set of endomorphisms of is the ring of all matrices with integer entries. The endomorphisms of a vector space or module also form a ring, as do the endomorphisms of any object in a preadditive category. The endomorphisms of a nonabelian group generate an algebraic structure known as a near-ring. Every ring with one is the endomorphism ring of its regular module, and so is a subring of an endomorphism ring of an abelian group; however there are rings that are not the endomorphism ring of any abelian group.\n\nIn any concrete category, especially for vector spaces, endomorphisms are maps from a set into itself, and may be interpreted as unary operators on that set, acting on the elements, and allowing to define the notion of orbits of elements, etc.\n\nDepending on the additional structure defined for the category at hand (topology, metric, ...), such operators can have properties like continuity, boundedness, and so on. More details should be found in the article about operator theory.\n\nAn endofunction is a function whose domain is equal to its codomain. A homomorphic endofunction is an endomorphism.\n\nLet be an arbitrary set. Among endofunctions on one finds permutations of and constant functions associating to every in the same element in . Every permutation of has the codomain equal to its domain and is bijective and invertible. A constant function on , if has more than 1 element, has an image that is a proper subset of its codomain, is not bijective (and non invertible). The function associating to each natural integer the floor of has its image equal to its codomain and is not invertible.\n\nFinite endofunctions are equivalent to directed pseudoforests. For sets of size there are endofunctions on the set.\n\nParticular examples of bijective endofunctions are the involutions; i.e., the functions coinciding with their inverses.\n\nBULLET::::- Adjoint endomorphism\nBULLET::::- Epimorphism (Surjective morphism)\nBULLET::::- Frobenius endomorphism\nBULLET::::- Monomorphism (Injective morphism)\n\n"}
{"id": "9574", "url": "https://en.wikipedia.org/wiki?curid=9574", "title": "Eric Hoffer", "text": "Eric Hoffer\n\nEric Hoffer (July 25, 1898 – May 21, 1983) was an American moral and social philosopher. He was the author of ten books and was awarded the Presidential Medal of Freedom in February 1983. His first book, \"The True Believer\" (1951), was widely recognized as a classic, receiving critical acclaim from both scholars and laymen, although Hoffer believed that \"The Ordeal of Change\" (1963) was his finest work.\n\nHoffer was born in 1898 in The Bronx, New York, to Knut and Elsa (Goebel) Hoffer. His parents were immigrants from Alsace, then part of Imperial Germany. By age five, Hoffer could already read in both English and his parents' native German. When he was five, his mother fell down the stairs with him in her arms. He later recalled, \"I lost my sight at the age of seven. Two years before, my mother and I fell down a flight of stairs. She did not recover and died in that second year after the fall. I lost my sight and, for a time, my memory.\" Hoffer spoke with a pronounced German accent all his life, and spoke the language fluently. He was raised by a live-in relative or servant, a German immigrant named Martha. His eyesight inexplicably returned when he was 15. Fearing he might lose it again, he seized on the opportunity to read as much as he could. His recovery proved permanent, but Hoffer never abandoned his reading habit.\n\nHoffer was a young man when he also lost his father. The cabinetmaker's union paid for Knut Hoffer's funeral and gave Hoffer about $300 insurance money. He took a bus to Los Angeles and spent the next 10 years wandering, as he remembered, “up and down the land, dodging hunger and grieving over the world.” Hoffer eventually landed on Skid Row, reading, occasionally writing, and working at odd jobs.\n\nIn 1931, he considered suicide by drinking a solution of oxalic acid, but he could not bring himself to do it. He left Skid Row and became a migrant worker, following the harvests in California. He acquired a library card where he worked, dividing his time \"between the books and the brothels.\" He also prospected for gold in the mountains. Snowed in for the winter, he read the \"Essays\" by Michel de Montaigne. Montaigne impressed Hoffer deeply, and Hoffer often made reference to him. He also developed a respect for America's underclass, which he said was \"lumpy with talent.\"\n\nHe wrote a novel, \"Four Years in Young Hank's Life,\" and a novella, \"Chance and Mr. Kunze,\" both partly autobiographical. He also penned a long article based on his experiences in a federal work camp, \"Tramps and Pioneers.\" It was never published, but a truncated version appeared in \"Harper's Magazine\" after he became well known.\n\nHoffer tried to enlist in the US Army at age 40 during World War II, but he was rejected due to a hernia. Instead, he began work as a longshoreman on the docks of San Francisco in 1943. At the same time, he began to write seriously.\n\nHoffer left the docks in 1964, and shortly after became an adjunct professor at the University of California, Berkeley. He later retired from public life in 1970. “I'm going to crawl back into my hole where I started,” he said. “I don't want to be a public person or anybody's spokesman... Any man can ride a train. Only a wise man knows when to get off.”In 1970, he endowed the Lili Fabilli and Eric Hoffer Laconic Essay Prize for students, faculty, and staff at the University of California, Berkeley.\n\nHoffer called himself an atheist but had sympathetic views of religion and described it as a positive force.\n\nHe died at his home in San Francisco in 1983 at the age of 84.\n\nHoffer was influenced by his modest roots and working-class surroundings, seeing in it vast human potential. In a letter to Margaret Anderson in 1941, he wrote:\nHe once remarked, \"my writing grows out of my life just as a branch from a tree.\" When he was called an intellectual, he insisted that he simply was a longshoreman. Hoffer has been dubbed by some authors a \"longshoreman philosopher.\"\n\nHoffer, who was an only child, never married. He fathered a child with Lili Fabilli Osborne, named Eric Osborne, who was born in 1955 and raised by Lili Osborne and her husband, Selden Osborne. Lili Fabilli Osborne had become acquainted with Hoffer through her husband, a fellow longshoreman and acquaintance of Hoffer's. Despite the affair and Lili Osborne later co-habitating with Hoffer, Selden Osborne and Hoffer remained on good terms.\n\nHoffer referred to Eric Osborne as his son or godson. Lili Fabilli Osborne died in 2010 at the age of 93. Prior to her death, Osborne was the executor of Hoffer's estate, and vigorously controlled the rights to his intellectual property.\n\nIn his 2012 book \"Eric Hoffer: The Longshoreman Philosopher,\" journalist Tom Bethell revealed doubts about Hoffer's account of his early life. Although Hoffer claimed his parents were from Alsace-Lorraine, Hoffer himself spoke with a pronounced Bavarian accent. He claimed to have been born and raised in the Bronx but had no Bronx accent. His lover and executor Lili Fabilli stated that she always thought Hoffer was an immigrant. Her son, Eric Fabilli, said that Hoffer's life may have been comparable to that of B. Traven and considered hiring a genealogist to investigate Hoffer's early life, to which Hoffer reportedly replied, \"Are you \"sure\" you want to know?\" Pescadero land-owner Joe Gladstone, a family friend of the Fabilli's who also knew Hoffer, said of Hoffer's account of his early life: \"I don't believe a word of it.\" To this day, no one ever has claimed to have known Hoffer in his youth, and no records apparently exist of his parents, nor indeed of Hoffer himself until he was about forty, when his name appeared in a census.\n\nHoffer came to public attention with the 1951 publication of his first book, \"The True Believer: Thoughts on the Nature of Mass Movements\", which consists of a preface and 125 sections, which are divided into 18 chapters. Hoffer analyzes the phenomenon of \"mass movements,\" a general term that he applies to revolutionary parties, nationalistic movements, and religious movements. He summarizes his thesis in §113: \"A movement is pioneered by men of words, materialized by fanatics and consolidated by men of actions.\"\n\nHoffer argues that fanatical and extremist cultural movements, whether religious, social, or national, arise when large numbers of frustrated people, believing their own individual lives to be worthless or spoiled, join a movement demanding radical change. But the real attraction for this population is an escape from the self, not a realization of individual hopes: \"A mass movement attracts and holds a following not because it can satisfy the desire for self-advancement, but because it can satisfy the passion for self-renunciation.\"\n\nHoffer consequently argues that the appeal of mass movements is interchangeable: in the Germany of the 1920s and the 1930s, for example, the Communists and National Socialists were ostensibly enemies, but sometimes enlisted each other's members, since they competed for the same kind of marginalized, angry, frustrated people. For the \"true believer,\" Hoffer argues that particular beliefs are less important than escaping from the burden of the autonomous self.\n\nHarvard historian Arthur M. Schlesinger Jr. said of \"The True Believer\": \"This brilliant and original inquiry into the nature of mass movements is a genuine contribution to our social thought.\"\n\nSubsequent to the publication of \"The True Believer\" (1951), Eric Hoffer touched upon Asia and American interventionism in several of his essays. In \"The Awakening of Asia\" (1954), published in \"The Reporter\" and later his book \"The Ordeal of Change\" (1963), Hoffer discusses the reasons for unrest on the continent. In particular, he argues that the root cause of social discontent in Asia was not government corruption, \"communist agitation,\" or the legacy of European colonial \"oppression and exploitation,\" but rather that a \"craving for pride\" was the central problem in Asia, suggesting a problem that could not be relieved through typical American intervention.\n\nFor centuries, Hoffer notes, Asia had \"submitted to one conqueror after another.\" Throughout these centuries, Asia had \"been misruled, looted, and bled by both foreign and native oppressors without\" so much as \"a peep\" from the general population. Though not without negative effect, corrupt governments and the legacy of European imperialism represented nothing new under the sun. Indeed, the European colonial authorities had been \"fairly beneficent\" in Asia.\n\nTo be sure, Communism exerted an appeal of sorts. For the Asian \"pseudo-intellectual,\" it promised elite status and the phony complexities of \"doctrinaire double talk.\" For the ordinary Asian, it promised partnership with the seemingly emergent Soviet Union in a \"tremendous, unprecedented undertaking\" to build a better tomorrow.\n\nAccording to Hoffer, however, Communism in Asia was dwarfed by the desire for pride. To satisfy such desire, Asians would willingly and irrationally sacrifice their economic well-being and their lives as well.\n\nUnintentionally, the West had created this appetite, causing \"revolutionary unrest\" in Asia. The West had done so by eroding the traditional communal bonds that once had woven the individual to the patriarchal family, clan, tribe, \"cohesive rural or urban unit,\" and \"religious or political body.\"\n\nWithout the security and spiritual meaning produced by such bonds, Asians had been liberated from tradition only to find themselves now atomized, isolated, exposed, and abandoned, \"left orphaned and empty in a cold world.\"\n\nCertainly, Europe had undergone a similar destruction of tradition, but it had occurred centuries earlier at the end of the medieval period and produced better results thanks to different circumstances.\n\nFor the Asians of the 1950s, the circumstances differed markedly. Most were illiterate and impoverished, living in a world that included no expansive physical or intellectual vistas. Dangerously, the \"articulate minority\" of the Asian population inevitably disconnected themselves from the ordinary people, thereby failing to acquire \"a sense of usefulness and of worth\" that came by \"taking part in the world's work.\" As a result, they were \"condemned to the life of chattering posturing pseudo-intellectuals\" and coveted \"the illusion of weight and importance.\"\n\nMost significantly, Hoffer asserts that the disruptive awakening of Asia came about as a result of an unbearable sense of weakness. Indeed, Hoffer discusses the problem of weakness, asserting that while \"power corrupts the few... weakness corrupts the many.\"\n\nHoffer notes that \" the resentment of the weak does not spring from any injustice done them but from the sense of their inadequacy and impotence.\" In short, the weak \"hate not wickedness\" but themselves for being weak. Consequently, self-loathing produces explosive effects that cannot be mitigated through social engineering schemes, such as programs of wealth redistribution. In fact, American \"generosity\" is counterproductive, perceived in Asia simply as an example of Western \"oppression.\"\n\nIn the wake of the Korean War, Hoffer does not recommend exporting at gunpoint either American political institutions or mass democracy. In fact, Hoffer advances the possibility that winning over the multitudes of Asia may not even be desirable. If on the other hand, necessity truly dictates that for \"survival\" the United States must persuade the \"weak\" of Asia to \"our side,\" Hoffer suggests the wisest course of action would be to master \"the art or technique of sharing hope, pride, and as a last resort, hatred with others.\"\n\nDuring the Vietnam War, despite his objections to the antiwar movement and acceptance of the notion that the war was somehow necessary to prevent a third world war, Hoffer remained skeptical concerning American interventionism, specifically the intelligence with which the war was being conducted in Southeast Asia. After the United States became involved in the war, Hoffer wished to avoid defeat in Vietnam because of his fear that such a defeat would transform American society for ill, opening the door to those who would preach a stab-in-the-back myth and allow for the rise of an American version of Hitler.\n\nIn \"The Temper of Our Time\" (1967), Hoffer implies that the United States as a rule should avoid interventions in the first place: \"the better part of statesmanship might be to know clearly and precisely what not to do, and leave action to the improvisation of chance.\" In fact, Hoffer indicates that \"it might be wise to wait for enemies to defeat themselves,\" as they might fall upon each other with the United States out of the picture. The view was somewhat borne out with the Cambodian-Vietnamese War and Chinese-Vietnamese War of the late 1970s.\n\nIn May 1968, about a year after the Six-Day War, he wrote an article for the \"Los Angeles Times\" titled \"Israel's Peculiar Position:\"\nHoffer asks why \"everyone expects the Jews to be the only real Christians in this world\" and why Israel should sue for peace after its victory.\n\nHoffer believed that rapid change is not necessarily a positive thing for a society and that too rapid change can cause a regression in maturity for those who were brought up in a different society. He noted that in America in the 1960s, many young adults were still living in extended adolescence. Seeking to explain the attraction of the New Left protest movements, he characterized them as the result of widespread affluence, which \"is robbing a modern society of whatever it has left of puberty rites to routinize the attainment of manhood.\" He saw the puberty rites as essential for self-esteem and noted that mass movements and juvenile mindsets tend to go together, to the point that anyone, no matter what age, who joins a mass movement immediately begins to exhibit juvenile behavior.\n\nHoffer further noted that working-class Americans rarely joined protest movements and subcultures since they had entry into meaningful labor as an effective rite of passage out of adolescence while both the very poor who lived on welfare and the affluent were, in his words, \"prevented from having a share in the world's work, and of proving their manhood by doing a man's work and getting a man's pay\" and thus remained in a state of extended adolescence. Lacking in necessary self-esteem, they were prone to joining mass movements as a form of compensation. Hoffer suggested that the need for meaningful work as a rite of passage into adulthood could be fulfilled with a two-year civilian national service program (like programs during the Great Depression such as the Civilian Conservation Corps): \"The routinization of the passage from boyhood to manhood would contribute to the solution of many of our pressing problems. I cannot think of any other undertaking that would dovetail so many of our present difficulties into opportunities for growth.\"\n\nHoffer appeared on public television in 1964 and then in two one-hour conversations on CBS with Eric Sevareid in the late 1960s.\n\nHoffer's papers, including 131 of the notebooks he carried in his pockets, were acquired in 2000 by the Hoover Institution Archives. The papers fill of shelf space. Because Hoffer cultivated an aphoristic style, the unpublished notebooks (dated from 1949 to 1977) contain very significant work. Although available for scholarly study since at least 2003, little of their contents has been published. A selection of fifty aphorisms, focusing on the development of unrealized human talents through the creative process, appeared in the July 2005 issue of \"Harper's Magazine\".\n\nBULLET::::- \"Conversations with Eric Hoffer\", twelve-part television interview by James Day of KQED, San Franscisco, 1963.\nBULLET::::- \"Eric Hoffer: The Passionate State of Mind\" with Eric Sevareid, CBS, September 19, 1967 (re-broadcast on November 14, due to popular demand).\nBULLET::::- \"The Savage Heart: A Conversation with Eric Hoffer,\" with Eric Sevareid, CBS, January 28, 1969.\n\nBULLET::::- 1971, May - Honorary Doctorate; Stonehill College\nBULLET::::- 1971, June - Honorary Doctorate; Michigan Technological University\nBULLET::::- 1978 – Bust of Eric Hoffer by sculptor Jonathan Hirschfeld; commissioned by Charles Kittrell and placed in Bartlesville, Oklahoma.\nBULLET::::- 1983, February 13 – Presidential Medal of Freedom awarded by Ronald Reagan.\nBULLET::::- 1985, September 17 – Skygate unveiling in San Francisco; dedication speech by Eric Sevareid.\n\nOn 1 January 2001, the Eric Hoffer Award for books and prose was launched internationally in his honor. In 2005, the Eric Hoffer Estate granted its permission for the award, and Christopher Klim became the award's Chairperson.\n\nAustralian foreign minister Julie Bishop extensively referred to Hoffer's book \"The True Believer\" when in a 2015 speech she closely compared the psychological underpinnings of ISIS with that of Nazism.\n\nBULLET::::- American philosophy\nBULLET::::- List of American philosophers\nBULLET::::- Eric Voegelin\nBULLET::::- Ivan Ilyin\n\nBULLET::::- \"American Iconoclast: The Life and Times of Eric Hoffer\", Shachtman, Tom, Titusville, NJ, Hopewell Publications, 2011. .\nBULLET::::- \"Eric Hoffer; an American Odyssey\" Tomkins, Calvin, New York, E.P. Dutton & Co., 1968 Part of Twayne's United States authors series\nBULLET::::- \"Hoffer's America\", Koerner, James D., La Salle, Ill., Library Press, 1973\nBULLET::::- \"Eric Hoffer\", Baker, James Thomas. Boston : Twayne, 1982 Twayne's United States authors series\nBULLET::::- \"Eric Hoffer: The Longshoreman Philosopher\", Bethell, Thomas, Stanford, Calif., Hoover Institution Press, 2012\n\nBULLET::::- The Eric Hoffer Project, preserving the legacy of Eric Hoffer\n"}
{"id": "9577", "url": "https://en.wikipedia.org/wiki?curid=9577", "title": "European Coal and Steel Community", "text": "European Coal and Steel Community\n\nThe European Coal and Steel Community (ECSC) was an organisation of six European countries created after World War II to regulate their industrial production under a centralised authority. It was formally established in 1951 by the Treaty of Paris, signed by Belgium, France, Italy, Luxembourg, the Netherlands, and West Germany. The ECSC was the first international organisation to be based on the principles of supranationalism, and started the process of formal integration which ultimately led to the European Union.\n\nThe ECSC was first proposed by French foreign minister Robert Schuman on 9 May 1950 as a way to prevent further war between France and Germany. He declared his aim was to \"make war not only unthinkable but materially impossible\" which was to be achieved by regional integration, of which the ECSC was the first step. The Treaty would create a common market for coal and steel among its member states which served to neutralise competition between European nations over natural resources, particularly in the Ruhr.\n\nThe ECSC was overseen by four institutions: a High Authority composed of independent appointees, a Common Assembly composed of national parliamentarians, a Special Council composed of national ministers, and a Court of Justice. These would ultimately form the blueprint for today's European Commission, European Parliament, the Council of the European Union and the European Court of Justice.\n\nThe ECSC stood as a model for the communities set up after it by the Treaty of Rome in 1957, the European Economic Community and European Atomic Energy Community, with whom it shared its membership and some institutions. The 1967 Merger (Brussels) Treaty led all of ECSC's institutions to merge into the European Economic Community, but the ECSC retained its own independent legal personality. In 2002, the Treaty of Paris expired and the ECSC ceased to exist in any form, its activities fully absorbed by the European Community under the framework of the Amsterdam and Nice treaties.\n\nAs Prime Minister and Foreign Minister, Schuman was instrumental in turning French policy away from the Gaullist policy of permanent occupation or control of parts of German territory such as the Ruhr or the Saar. Despite stiff ultra-nationalist, Gaullist and communist opposition, the French Assembly voted a number of resolutions in favour of his new policy of integrating Germany into a community. The International Authority for the Ruhr changed in consequence.\n\nThe Schuman Declaration of 9 May 1950 (in 1985 declared \"Europe Day\" by the European Communities) occurred after two Cabinet meetings, when the proposal became French government policy. France was thus the first government to agree to surrender sovereignty in a supranational Community. That decision was based on a text, written and edited by Schuman's friend and colleague, the Foreign Ministry lawyer, professor Paul Reuter with the assistance of economist Jean Monnet and Schuman's Directeur de Cabinet, Bernard Clappier. It laid out a plan for a European Community to pool the coal and steel of its members in a common market.\n\nSchuman proposed that \"Franco-German production of coal and steel as a whole be placed under a common High Authority, within the framework of an organisation open to the participation of the other countries of Europe\". Such an act was intended to help economic growth and cement peace between France and Germany, who were historic enemies. Coal and steel were vital resources needed for a country to wage war, so pooling those resources between two such enemies was seen as more than symbolic. Schuman saw the decision of the French government on his proposal as the first example of a democratic and supranational Community, a new development in world history. The plan was also seen by some, like Monnet, who crossed out Reuter's mention of \"supranational\" in the draft and inserted \"federation\", as a first step to a \"European federation\".\nThe Schuman Declaration that created the ECSC had several distinct aims:\nBULLET::::- It would mark the birth of a united Europe.\nBULLET::::- It would make war between member states impossible.\nBULLET::::- It would encourage world peace.\nBULLET::::- It would transform Europe in a \"step by step\" process (building through sectoral supranational communities) leading to the unification of Europe democratically, unifying two political blocks separated by the Iron Curtain.\nBULLET::::- It would create the world's first supranational institution.\nBULLET::::- It would create the world's first international anti-cartel agency.\nBULLET::::- It would create a common market across the Community.\nBULLET::::- It would, starting with the coal and steel sector, revitalise the whole European economy by similar community processes.\nBULLET::::- It would improve the world economy and the developing countries, such as those in Africa.\n\nFirstly, it was intended to prevent further war between France and Germany and other states by tackling the root cause of war. The ECSC was primarily conceived with France and Germany in mind: \"The coming together of the nations of Europe requires the elimination of the age-old opposition of France and Germany. Any action taken must in the first place concern these two countries.\" The coal and steel industries being essential for the production of munitions, Schuman believed that by uniting these two industries across France and Germany under an innovative supranational system that also included a European anti-cartel agency, he could \"make war not only unthinkable but materially impossible\". Schuman had another aim: \"With increased resources Europe will be able to pursue the achievement of one of its essential tasks, namely, the development of the African continent.\" Industrial cartels tended to impose \"restrictive practices\" on national markets, whereas the ECSC would ensure the increased production necessary for their ambitions in Africa.\n\nIn West Germany, Schuman kept the closest contacts with the new generation of democratic politicians. Karl Arnold, the Minister President of North Rhine-Westphalia, the state that included the coal and steel producing Ruhr, was initially spokesman for German foreign affairs. He gave a number of speeches and broadcasts on a supranational coal and steel community at the same time as Robert Schuman began to propose this Community in 1948 and 1949. The Social Democratic Party of Germany (, SPD), in spite of support from unions and other socialists in Europe, decided it would oppose the Schuman plan. Kurt Schumacher's personal distrust of France, capitalism, and Konrad Adenauer aside, he claimed that a focus on integrating with a \"Little Europe of the Six\" would override the SPD's prime objective of German reunification and thus empower ultra-nationalist and Communist movements in democratic countries. He also thought the ECSC would end any hopes of nationalising the steel industry and lock in a Europe of \"cartels, clerics and conservatives\". Younger members of the party like Carlo Schmid, were, however, in favor of the Community and pointed to the long socialist support for the supranational idea.\n\nIn France, Schuman had gained strong political and intellectual support from all sections of the nation and many non-communist parties. Notable amongst these were ministerial colleague Andre Philip, president of the Foreign Relations Committee Edouard Bonnefous, and former prime minister, Paul Reynaud. Projects for a coal and steel authority and other supranational communities were formulated in specialist subcommittees of the Council of Europe in the period before it became French government policy. Charles de Gaulle, who was then out of power, had been an early supporter of \"linkages\" between economies, on French terms, and had spoken in 1945 of a \"European confederation\" that would exploit the resources of the Ruhr. However, he opposed the ECSC as a \"faux\" (false) pooling (\"\"le pool, ce faux semblant\"\") because he considered it an unsatisfactory \"piecemeal approach\" to European unity and because he considered the French government \"too weak\" to dominate the ECSC as he thought proper. De Gaulle also felt that the ECSC had insufficient supranational authority because the Assembly was not ratified by a European referendum and he did not accept Raymond Aron's contention that the ECSC was intended as a movement away from United States domination. Consequently, de Gaulle and his followers in the RPF voted against ratification in the lower house of the French Parliament.\n\nDespite these attacks and those from the extreme left, the ECSC found substantial public support, and so it was established. It gained strong majority votes in all eleven chambers of the parliaments of the Six, as well as approval among associations and European public opinion. In 1950, many had thought another war was inevitable. The steel and coal interests, however, were quite vocal in their opposition. The Council of Europe, created by a proposal of Schuman's first government in May 1948, helped articulate European public opinion and gave the Community idea positive support.\n\nThe 100-article Treaty of Paris, which established the ECSC, was signed on 18 April 1951 by \"the inner six\": France, West Germany, Italy, Belgium, the Netherlands and Luxembourg (Benelux). The ECSC was the first international organisation to be based on supranational principles and was, through the establishment of a common market for coal and steel, intended to expand the economies, increase employment, and raise the standard of living within the Community. The market was also intended to progressively rationalise the distribution of high level production whilst ensuring stability and employment. The common market for coal was opened on 10 February 1953, and for steel on 1 May 1953. Upon taking effect, the ECSC gradually replaced the International Authority for the Ruhr.\n\nOn 11 August 1952, the United States was the first non-ECSC member to recognise the Community and stated it would now deal with the ECSC on coal and steel matters, establishing its delegation in Brussels. Monnet responded by choosing Washington, D.C. as the site of the ECSC's first external presence. The headline of the delegation's first bulletin read \"Towards a Federal Government of Europe\".\n\nSix years after the Treaty of Paris, the Treaties of Rome were signed by the six ECSC members, creating the European Economic Community (EEC) and the European Atomic Energy Community (EAEC or Euratom). These Communities were based, with some adjustments, on the ECSC. The Treaties of Rome were to be in force indefinitely, unlike the Treaty of Paris, which was to expire after fifty years. These two new Communities worked on the creation of a customs union and nuclear power community respectively. The Rome treaties were hurried through just before de Gaulle was given emergency powers and proclaimed the Fifth Republic. Despite his efforts to \"chloroform\" the Communities, their fields rapidly expanded and the EEC became the most important tool for political unification, overshadowing the ECSC.\n\nDespite being separate legal entities, the ECSC, EEC and Euratom initially shared the Common Assembly and the European Court of Justice, although the Councils and the High Authority/Commissions remained separate. To avoid duplication, the Merger Treaty merged these separate bodies of the ECSC and Euratom with the EEC. The EEC later became one of the three pillars of the present day European Union.\n\nThe Treaty of Paris was frequently amended as the EC and EU evolved and expanded. With the treaty due to expire in 2002, debate began at the beginning of the 1990s on what to do with it. It was eventually decided that it should be left to expire. The areas covered by the ECSC's treaty were transferred to the Treaty of Rome and the financial loose ends and the ECSC research fund were dealt with via a protocol of the Treaty of Nice. The treaty finally expired on 23 July 2002. That day, the ECSC flag was lowered for the final time outside the European Commission in Brussels and replaced with the EU flag.\n\nThe institutions of the ECSC were the High Authority, the Common Assembly, the Special Council of Ministers and the Court of Justice. A Consultative Committee was established alongside the High Authority, as a fifth institution representing civil society. This was the first international representation of consumers in history. These institutions were merged in 1967 with those of the European Community, which then governed the ECSC, except for the Committee, which continued to be independent until the expiration of the Treaty of Paris in 2002.\n\nThe Treaty stated that the location of the institutions would be decided by common accord of the members, yet the issue was hotly contested. As a temporary compromise, the institutions were provisionally located in the City of Luxembourg, despite the Assembly being based in Strasbourg.\n\nThe High Authority (the predecessor to the European Commission) was a nine-member executive body which governed the Community. The Authority consisted of nine members in office for a term of six years. Eight of these members were appointed by the governments of the six signatories. These eight members then themselves appointed a ninth person to be President of the High Authority.\n\nDespite being appointed by agreement of national governments acting together, the members were to pledge not to represent their national interest, but rather took an oath to defend the general interests of the Community as a whole. Their independence was aided by members being barred from having any occupation outside the Authority or having any business interests (paid or unpaid) during their tenure and for three years after they left office. To further ensure impartiality, one third of the membership was to be renewed every two years (article 10).\n\nThe Authority's principal innovation was its supranational character. It had a broad area of competence to ensure the objectives of the treaty were met and that the common market functioned smoothly. The High Authority could issue three types of legal instruments: Decisions, which were entirely binding laws; Recommendations, which had binding aims but the methods were left to member states; and Opinions, which had no legal force.\n\nUp to the merger in 1967, the authority had five Presidents followed by an interim President serving for the final days.\n\nThe Common Assembly (which later became the European Parliament) was composed of 78 representatives and exercised supervisory powers over the executive High Authority. The Common Assembly representatives were to be national MPs delegated each year by their Parliaments to the Assembly or directly elected \"by universal suffrage\" (article 21), though in practice it was the former, as there was no requirement for elections until the Treaties of Rome and no actual election until 1979, as Rome required agreement in the Council on the electoral system first. However, to emphasise that the chamber was not a traditional international organisation composed of representatives of national governments, the Treaty of Paris used the term \"representatives of the peoples\". The Assembly was not originally specified in the Schuman Plan because it was hoped the Community would use the institutions (Assembly, Court) of the Council of Europe. When this became impossible because of British objections, separate institutions had to be created. The Assembly was intended as a democratic counter-weight and check to the High Authority, to advise but also to have power to sack the Authority for incompetence, injustice, corruption or fraud. The first President (akin to a Speaker) was Paul-Henri Spaak.\n\nThe Special Council of Ministers (equivalent to the current Council of the European Union) was composed of representatives of national governments. The Presidency was held by each state for a period of three months, rotating between them in alphabetical order. One of its key aspects was the harmonisation of the work of the High Authority and that of national governments, which were still responsible for the state's general economic policies. The Council was also required to issue opinions on certain areas of work of the High Authority. Issues relating only to coal and steel were in the exclusive domain of the High Authority, and in these areas the Council (unlike the modern Council) could only act as a scrutiny on the Authority. However, areas outside coal and steel required the consent of the Council.\n\nThe Court of Justice was to ensure the observation of ECSC law along with the interpretation and application of the Treaty. The Court was composed of seven judges, appointed by common accord of the national governments for six years. There were no requirements that the judges had to be of a certain nationality, simply that they be qualified and that their independence be beyond doubt. The Court was assisted by two Advocates General.\n\nThe Consultative Committee (similar to the Economic and Social Committee) had between 30 and 50 members equally divided between producers, workers, consumers and dealers in the coal and steel sector. Again, there were no national quotas, and the treaty required representatives of European associations to organise their own democratic procedures. They were to establish rules to make their membership fully representative for democratic organised civil society. Membership were appointed for two years and were not bound by any mandate or instruction of the organisations which appointed them. The Committee had a plenary assembly, bureau and president. Again, the required democratic procedures were not introduced and nomination of these members remained in the hands of national ministers. The High Authority was obliged to consult the Committee in certain cases where it was appropriate and to keep it informed. The Consultative Committee remained separate (despite the merger of the other institutions) until 2002, when the Treaty expired and its duties were taken over by the Economic and Social Committee (ESC). Despite its independence, the Committee did cooperate with the ESC when they were consulted on the same issue.\n\nIts mission (article 2) was general: to \"contribute to the expansion of the economy, the development of employment and the improvement of the standard of living\" of its citizens. The Community had little effect on coal and steel \"production\", which was influenced more by global trends. Trade between members did increase (tenfold for steel) which saved members' money by not having to import resources from the United States. The High Authority also issued 280 modernization loans to the industry which helped the industry to improve output and reduce costs. Costs were further reduced by the abolition of tariffs at borders.\n\nAmong the ECSC's greatest achievements are those on welfare issues. Some mines, for example, were clearly unsustainable without government subsidies. Some miners had extremely poor housing. Over 15 years it financed 112,500 flats for workers, paying US$1,770 per flat, enabling workers to buy a home they could not have otherwise afforded. The ECSC also paid half the occupational redeployment costs of those workers who have lost their jobs as coal and steel facilities began to close down. Combined with regional redevelopment aid the ECSC spent $150 million creating 100,000 jobs, a third of which were for unemployed coal and steel workers. The welfare guarantees invented by the ECSC were extended to workers outside the coal and steel sector by some of its members.\n\nFar more important than creating Europe's first social and regional policy, it is argued that the ECSC introduced European peace. It involved the continent's first European tax. This was a flat tax, a levy on production with a maximum rate of one percent. Given that the European Community countries are now experiencing the longest period of peace in more than seventy years, this has been described as the cheapest tax for peace in history. Another world war, or \"world suicide\" as Schuman called this threat in 1949, was avoided. In October 1953 Schuman said that the possibility of another European war had been eliminated. Reasoning had to prevail among member states.\n\nHowever the ECSC failed to achieve several fundamental aims of the Treaty of Paris. It was hoped the ECSC would prevent a resurgence of large coal and steel groups such as the \"Konzerne\", which helped Adolf Hitler rise to power. In the Cold War trade-offs, the cartels and major companies re-emerged, leading to apparent price fixing (another element that was meant to be tackled). With a democratic supervisory system the worst aspects of past abuse were avoided with the anti-cartel powers of the Authority, the first international anti-cartel agency in the world. Efficient firms were allowed to expand into a European market without undue domination. Oil, gas, electricity became natural competitors to coal and also broke cartel powers. Furthermore, with the move to oil, the Community failed to define a proper energy policy. The Euratom treaty was largely stifled by de Gaulle and the European governments refused the suggestion of an Energy Community involving electricity and other vectors that was suggested at Messina in 1955. In a time of high inflation and monetary instability ECSC also fell short of ensuring an upward equalisation of pay of workers within the market. These failures could be put down to overambition in a short period of time, or that the goals were merely political posturing to be ignored. It has been argued that the greatest achievements of the European Coal and Steel Community lie in its revolutionary democratic concepts of a supranational Community.\n\nBULLET::::- Energy Community\nBULLET::::- Energy policy of the European Union\nBULLET::::- Flag of the European Coal and Steel Community\nBULLET::::- History of the European Union\nBULLET::::- History of the Ruhr District\nBULLET::::- Industrial plans for Germany\nBULLET::::- Monnet plan\nBULLET::::- Schuman Declaration\nBULLET::::- Supranationalism\nBULLET::::- Supranational union\n\n\nBULLET::::- Documents of the European Coal and Steel Community are consultable at the Historical Archives of the EU in Florence\nBULLET::::- rtsp://rtsppress.cec.eu.int/Archive/video/mpeg/i000679/i000679.rm (insert address into RealPlayer) Common Destiny, a period film explaining the Coal and Steel Community, Europa (web portal)\nBULLET::::- Treaty constituting the European Coal and Steel Community, CVCE\nBULLET::::- Schuman info\nBULLET::::- The institutions of the European Coal and Steel Community, CVCE\nBULLET::::- France, Germany and the Struggle for the War-making Natural Resources of the Rhineland, American University\nBULLET::::- Ruhr Delegation of the United States of America, Council of Foreign Ministers American Embassy Moscow, 24 March 1947, Truman Library\n"}
{"id": "9578", "url": "https://en.wikipedia.org/wiki?curid=9578", "title": "European Economic Community", "text": "European Economic Community\n\nThe European Economic Community (EEC) was a regional organisation that aimed to bring about economic integration among its member states. It was created by the Treaty of Rome of 1957. Upon the formation of the European Union (EU) in 1993, the EEC was incorporated and renamed the European Community (EC). In 2009, the EC's institutions were absorbed into the EU's wider framework and the community ceased to exist.\n\nThe Community's initial aim was to bring about economic integration, including a common market and customs union, among its six founding members: Belgium, France, Italy, Luxembourg, the Netherlands and West Germany. It gained a common set of institutions along with the European Coal and Steel Community (ECSC) and the European Atomic Energy Community (EURATOM) as one of the European Communities under the 1965 Merger Treaty (Treaty of Brussels). In 1993 a complete single market was achieved, known as the internal market, which allowed for the free movement of goods, capital, services, and people within the EEC. In 1994 the internal market was formalised by the EEA agreement. This agreement also extended the internal market to include most of the member states of the European Free Trade Association, forming the European Economic Area, which encompasses 15 countries.\n\nUpon the entry into force of the Maastricht Treaty in 1993, the EEC was renamed the European Community to reflect that it covered a wider range than economic policy. This was also when the three European Communities, including the EC, were collectively made to constitute the first of the three pillars of the European Union, which the treaty also founded. The EC existed in this form until it was abolished by the 2009 Treaty of Lisbon, which incorporated the EC's institutions into the EU's wider framework and provided that the EU would \"replace and succeed the European Community\".\n\nThe EEC was also known as the Common Market in the English-speaking countries and sometimes referred to as the European Community even before it was officially renamed as such in 1993.\n\nIn 1951, the Treaty of Paris was signed, creating the European Coal and Steel Community (ECSC). This was an international community based on supranationalism and international law, designed to help the economy of Europe and prevent future war by integrating its members.\n\nIn the aim of creating a federal Europe two further communities were proposed: a European Defence Community and a European Political Community. While the treaty for the latter was being drawn up by the Common Assembly, the ECSC parliamentary chamber, the proposed defense community was rejected by the French Parliament. ECSC President Jean Monnet, a leading figure behind the communities, resigned from the High Authority in protest and began work on alternative communities, based on economic integration rather than political integration. After the Messina Conference in 1955, Paul Henri Spaak was given the task to prepare a report on the idea of a customs union. The so-called Spaak Report of the Spaak Committee formed the cornerstone of the intergovernmental negotiations at Val Duchesse conference centre in 1956. Together with the Ohlin Report the Spaak Report would provide the basis for the Treaty of Rome.\n\nIn 1956, Paul Henri Spaak led the Intergovernmental Conference on the Common Market and Euratom at the Val Duchesse conference centre, which prepared for the Treaty of Rome in 1957. The conference led to the signature, on 25 March 1957, of the Treaty of Rome establishing a European Economic Community.\n\nThe resulting communities were the European Economic Community (EEC) and the European Atomic Energy Community (EURATOM or sometimes EAEC). These were markedly less supranational than the previous communities, due to protests from some countries that their sovereignty was being infringed (however there would still be concerns with the behaviour of the Hallstein Commission). The first formal meeting of the Hallstein Commission was held on 16 January 1958 at the Chateau de Val-Duchesse. The EEC (direct ancestor of the modern Community) was to create a customs union while Euratom would promote co-operation in the nuclear power sphere. The EEC rapidly became the most important of these and expanded its activities. One of the first important accomplishments of the EEC was the establishment (1962) of common price levels for agricultural products. In 1968, internal tariffs (tariffs on trade between member nations) were removed on certain products.\nAnother crisis was triggered in regard to proposals for the financing of the Common Agricultural Policy, which came into force in 1962. The transitional period whereby decisions were made by unanimity had come to an end, and majority-voting in the Council had taken effect. Then-French President Charles de Gaulle's opposition to supranationalism and fear of the other members challenging the CAP led to an \"empty chair policy\" whereby French representatives were withdrawn from the European institutions until the French veto was reinstated. Eventually, a compromise was reached with the Luxembourg compromise on 29 January 1966 whereby a gentlemen's agreement permitted members to use a veto on areas of national interest.\n\nOn 1 July 1967 when the Merger Treaty came into operation, combining the institutions of the ECSC and Euratom into that of the EEC, they already shared a Parliamentary Assembly and Courts. Collectively they were known as the \"European Communities\". The Communities still had independent personalities although were increasingly integrated. Future treaties granted the community new powers beyond simple economic matters which had achieved a high level of integration. As it got closer to the goal of political integration and a peaceful and united Europe, what Mikhail Gorbachev described as a \"Common European Home\".\n\nThe 1960s saw the first attempts at enlargement. In 1961, Denmark, Ireland, Norway and the United Kingdom applied to join the three Communities. However, President Charles de Gaulle saw British membership as a Trojan horse for U.S. influence and vetoed membership, and the applications of all four countries were suspended. Greece became the first country to join the EC in 1961 as an associate member, however its membership was suspended in 1967 after the Colonels' coup d'état.\n\nA year later, in February 1962, Spain attempted to join the European Communities. However, because Francoist Spain was not a democracy, all members rejected the request in 1964.\n\nThe four countries resubmitted their applications on 11 May 1967 and with Georges Pompidou succeeding Charles de Gaulle as French president in 1969, the veto was lifted. Negotiations began in 1970 under the pro-European government of Edward Heath, who had to deal with disagreements relating to the Common Agricultural Policy and the UK's relationship with the Commonwealth of Nations. Nevertheless, two years later the accession treaties were signed so that Denmark, Ireland and the UK joined the Community effective 1 January 1973. The Norwegian people had finally rejected membership in a referendum on 25 September 1972.\n\nThe Treaties of Rome had stated that the European Parliament must be directly elected, however this required the Council to agree on a common voting system first. The Council procrastinated on the issue and the Parliament remained appointed, French President Charles de Gaulle was particularly active in blocking the development of the Parliament, with it only being granted Budgetary powers following his resignation.\n\nParliament pressured for agreement and on 20 September 1976 the Council agreed part of the necessary instruments for election, deferring details on electoral systems which remain varied to this day. During the tenure of President Jenkins, in June 1979, the elections were held in all the then-members (see 1979 European Parliament election). The new Parliament, galvanised by direct election and new powers, started working full-time and became more active than the previous assemblies.\n\nShortly after its election, the Parliament proposed that the Community adopt the flag of Europe design used by the Council of Europe. The European Council in 1984 appointed an \"ad hoc\" committee for this purpose. The European Council in 1985 largely followed the Committee's recommendations, but as the adoption of a flag was strongly reminiscent of a national flag representing statehood, was controversial, the \"flag of Europe\" design was adopted only with the status of a \"logo\" or \"emblem\".\n\nThe European Council, or European summit, had developed since the 1960s as an informal meeting of the Council at the level of heads of state. It had originated from then-French President Charles de Gaulle's resentment at the domination of supranational institutions (e.g. the Commission) over the integration process. It was mentioned in the treaties for the first time in the Single European Act (see below).\n\nGreece re-applied to join the community on 12 June 1975, following the restoration of democracy, and joined on 1 January 1981. Following on from Greece, and after their own democratic restoration, Spain and Portugal applied to the communities in 1977 and joined together on 1 January 1986. In 1987 Turkey formally applied to join the Community and began the longest application process for any country.\n\nWith the prospect of further enlargement, and a desire to increase areas of co-operation, the Single European Act was signed by the foreign ministers on the 17 and 28 February 1986 in Luxembourg and the Hague respectively. In a single document it dealt with reform of institutions, extension of powers, foreign policy cooperation and the single market. It came into force on 1 July 1987. The act was followed by work on what would be the Maastricht Treaty, which was agreed on 10 December 1991, signed the following year and coming into force on 1 November 1993 establishing the European Union, and paving the way for the European Monetary Union.\n\nThe EU absorbed the European Communities as one of its three pillars. The EEC's areas of activities were enlarged and were renamed the \"European Community\", continuing to follow the supranational structure of the EEC. The EEC institutions became those of the EU, however the Court, Parliament and Commission had only limited input in the new pillars, as they worked on a more intergovernmental system than the European Communities. This was reflected in the names of the institutions, the Council was formally the \"Council of the \"European Union\"\" while the Commission was formally the \"Commission of the \"European Communities\"\".\n\nHowever, after the Treaty of Maastricht, Parliament gained a much bigger role. Maastricht brought in the codecision procedure, which gave it equal legislative power with the Council on Community matters. Hence, with the greater powers of the supranational institutions and the operation of Qualified Majority Voting in the Council, the Community pillar could be described as a far more federal method of decision making.\n\nThe Treaty of Amsterdam transferred responsibility for free movement of persons (e.g., visas, illegal immigration, asylum) from the Justice and Home Affairs (JHA) pillar to the European Community (JHA was renamed Police and Judicial Co-operation in Criminal Matters (PJCC) as a result). Both Amsterdam and the Treaty of Nice also extended codecision procedure to nearly all policy areas, giving Parliament equal power to the Council in the Community.\n\nIn 2002, the Treaty of Paris which established the ECSC expired, having reached its 50-year limit (as the first treaty, it was the only one with a limit). No attempt was made to renew its mandate; instead, the Treaty of Nice transferred certain of its elements to the Treaty of Rome and hence its work continued as part of the EC area of the European Community's remit.\n\nAfter the entry into force of the Treaty of Lisbon in 2009 the pillar structure ceased to exist. The European Community, together with its legal personality, was absorbed into the newly consolidated European Union which merged in the other two pillars (however Euratom remained distinct). This was originally proposed under the European Constitution but that treaty failed ratification in 2005.\n\nThe main aim of the EEC, as stated in its preamble, was to \"preserve peace and liberty and to lay the foundations of an ever closer union among the peoples of Europe\". Calling for balanced economic growth, this was to be accomplished through:\n\nBULLET::::1. The establishment of a customs union with a common external tariff\nBULLET::::2. Common policies for agriculture, transport and trade, including standardization (for example, the CE marking designates standards compliance)\nBULLET::::3. Enlargement of the EEC to the rest of Europe\n\nFor the customs union, the treaty provided for a 10% reduction in custom duties and up to 20% of global import quotas. Progress on the customs union proceeded much faster than the twelve years planned. However, France faced some setbacks due to their war with Algeria.\n\nThe six states that founded the EEC and the other two Communities were known as the \"inner six\" (the \"outer seven\" were those countries who formed the European Free Trade Association). The six were France, West Germany, Italy and the three Benelux countries: Belgium, the Netherlands and Luxembourg. The first enlargement was in 1973, with the accession of Denmark, Ireland and the United Kingdom. Greece, Spain and Portugal joined in the 1980s. The former East Germany became part of the EEC upon German reunification in 1990. Following the creation of the EU in 1993, it has enlarged to include an additional sixteen countries by 2013.\n\n! class=\"unsortable\"  Flag\n! State\n! Accession\n! class=\"unsortable\"  Language(s)\n! Currency\n! Population(1990)\n\nMember states are represented in some form in each institution. The Council is also composed of one national minister who represents their national government. Each state also has a right to one European Commissioner each, although in the European Commission they are not supposed to represent their national interest but that of the Community. Prior to 2004, the larger members (France, Germany, Italy and the United Kingdom) have had two Commissioners. In the European Parliament, members are allocated a set number seats related to their population, however these (since 1979) have been directly elected and they sit according to political allegiance, not national origin. Most other institutions, including the European Court of Justice, have some form of national division of its members.\n\nThere were three political institutions which held the executive and legislative power of the EEC, plus one judicial institution and a fifth body created in 1975. These institutions (except for the auditors) were created in 1957 by the EEC but from 1967 onwards they applied to all three Communities. The Council represents governments, the Parliament represents citizens and the Commission represents the European interest. Essentially, the Council, Parliament or another party place a request for legislation to the Commission. The Commission then drafts this and presents it to the Council for approval and the Parliament for an opinion (in some cases it had a veto, depending upon the legislative procedure in use). The Commission's duty is to ensure it is implemented by dealing with the day-to-day running of the Union and taking others to Court if they fail to comply. After the Maastricht Treaty in 1993, these institutions became those of the European Union, though limited in some areas due to the pillar structure. Despite this, Parliament in particular has gained more power over legislation and security of the Commission. The Court was the highest authority in the law, settling legal disputes in the Community, while the Auditors had no power but to investigate.\n\nThe EEC inherited some of the Institutions of the ECSC in that the Common Assembly and Court of Justice of the ECSC had their authority extended to the EEC and Euratom in the same role. However the EEC, and Euratom, had different executive bodies to the ECSC. In place of the ECSC's Council of Ministers was the Council of the European Economic Community, and in place of the High Authority was the Commission of the European Communities.\n\nThere was greater difference between these than name: the French government of the day had grown suspicious of the supranational power of the High Authority and sought to curb its powers in favour of the intergovernmental style Council. Hence the Council had a greater executive role in the running of the EEC than was the situation in the ECSC. By virtue of the Merger Treaty in 1967, the executives of the ECSC and Euratom were merged with that of the EEC, creating a single institutional structure governing the three separate Communities. From here on, the term \"European Communities\" were used for the institutions (for example, from \"Commission of the European Economic Community\" to the \"Commission of the European Communities\").\n\nThe Council of the European Communities was a body holding legislative and executive powers and was thus the main decision making body of the Community. Its Presidency rotated between the member states every six months and it is related to the European Council, which was an informal gathering of national leaders (started in 1961) on the same basis as the Council.\n\nThe Council was composed of one national minister from each member state. However the Council met in various forms depending upon the topic. For example, if agriculture was being discussed, the Council would be composed of each national minister for agriculture. They represented their governments and were accountable to their national political systems. Votes were taken either by majority (with votes allocated according to population) or unanimity. In these various forms they share some legislative and budgetary power of the Parliament. Since the 1960s the Council also began to meet informally at the level of national leaders; these European summits followed the same presidency system and secretariat as the Council but was not a formal formation of it.\n\nThe Commission of the European Communities was the executive arm of the community, drafting Community law, dealing with the day to running of the Community and upholding the treaties. It was designed to be independent, representing the Community interest, but was composed of national representatives (two from each of the larger states, one from the smaller states). One of its members was the President, appointed by the Council, who chaired the body and represented it.\n\nUnder the Community, the European Parliament (formerly the European Parliamentary Assembly) had an advisory role to the Council and Commission. There were a number of Community legislative procedures, at first there was only the consultation procedure, which meant Parliament had to be consulted, although it was often ignored. The Single European Act gave Parliament more power, with the assent procedure giving it a right to veto proposals and the cooperation procedure giving it equal power with the Council if the Council was not unanimous.\n\nIn 1970 and 1975, the Budgetary treaties gave Parliament power over the Community budget. The Parliament's members, up-until 1980 were national MPs serving part-time in the Parliament. The Treaties of Rome had required elections to be held once the Council had decided on a voting system, but this did not happen and elections were delayed until 1979 (see 1979 European Parliament election). After that, Parliament was elected every five years. In the following 20 years, it gradually won co-decision powers with the Council over the adoption of legislation, the right to approve or reject the appointment of the Commission President and the Commission as a whole, and the right to approve or reject international agreements entered into by the Community.\n\nThe Court of Justice of the European Communities was the highest court of on matters of Community law and was composed of one judge per state with a president elected from among them. Its role was to ensure that Community law was applied in the same way across all states and to settle legal disputes between institutions or states. It became a powerful institution as Community law overrides national law.\n\nThe fifth institution is the \"European Court of Auditors\", which despite its name had no judicial powers like the Court of Justice. Instead, it ensured that taxpayer funds from the Community budget have been correctly spent. The court provided an audit report for each financial year to the Council and Parliament and gives opinions and proposals on financial legislation and anti-fraud actions. It is the only institution not mentioned in the original treaties, having been set up in 1975.\n\nAt the time of its abolition, the European Community pillar covered the following areas;\n\nBULLET::::- Asylum policy\nBULLET::::- Border control\nBULLET::::- Common Agricultural Policy\nBULLET::::- Common Fisheries Policy\nBULLET::::- Competition\nBULLET::::- Consumer protection\nBULLET::::- Customs Union and Single market\n valign=top \nBULLET::::- Economic and monetary union\nBULLET::::- Education and Culture\nBULLET::::- Employment\nBULLET::::- Environmental law\nBULLET::::- EU Citizenship\nBULLET::::- Healthcare\n valign=top \nBULLET::::- Immigration policy\nBULLET::::- Research\nBULLET::::- Schengen treaty\nBULLET::::- Social policy\nBULLET::::- Trade policy\nBULLET::::- Trans-European Networks\n\nBULLET::::- Economy of the European Union\nBULLET::::- Brussels and the European Union\nBULLET::::- Delors Commission\nBULLET::::- European Commission\nBULLET::::- European Customs Information Portal (ECIP)\nBULLET::::- European Institutions in Strasbourg\nBULLET::::- History of the European Communities (1958-1972)\nBULLET::::- History of the European Communities (1973-1993)\nBULLET::::- Location of European Union institutions\nBULLET::::- Snake in the tunnel\n\nBULLET::::- Acocella, Nicola (1992), ‘\"Trade and direct investment within the EC: The impact of strategic considerations\"’, in: Cantwell, John (ed.), ‘\"Multinational investment in modern Europe\"’, E. Elgar, Cheltenham, .\nBULLET::::- Balassa, Bela (1962). \"The Theory of Economic Integration\"\nBULLET::::- Hallstein, Walter (1962). \"A New Path to Peaceful Union\"\nBULLET::::- Milward, Alan S. (1992). \"The European Rescue of the Nation-State\"\nBULLET::::- Monnet, Jean (1959). \"Prospect for a New Europe\"\nBULLET::::- Moravcsik, Andrew (1998). \"The Choice for Europe. Social Purpose and State Power from Messina to Maastricht\"\nBULLET::::- Ludlow, N. Piers (2006). \"The European Community and the Crises of the 1960s. Negotiating the Gaullist Challenge\"\nBULLET::::- Spaak, Paul-Henri (1971). \"The Continuing Battle: Memories of a European\"\nBULLET::::- Warlouzet, Laurent (2018). \"Governing Europe in a Globalizing World. Neoliberalism and its Alternatives following the 1973 Oil Crisis\"\n\nBULLET::::- European Union website\nBULLET::::- Documents of the European Economic Community are consultable at the Historical Archives of the EU in Florence\nBULLET::::- Treaty establishing the European Economic Community on CVCE website\nBULLET::::- History of the Rome Treaties on CVCE website\nBULLET::::- Papers of J. Robert Schaetzel, ambassador to European Economic Community, 1966–1972, Dwight D. Eisenhower Presidential Library\nBULLET::::- European Customs Information Portal (ECIP)\nBULLET::::- The history of the European Union\n"}
{"id": "9579", "url": "https://en.wikipedia.org/wiki?curid=9579", "title": "EFTA (disambiguation)", "text": "EFTA (disambiguation)\n\nEFTA is the European Free Trade Association, a trade organisation and free trade area.\n\nEFTA may also refer to:\n\nBULLET::::- European Fair Trade Association, an association of eleven fair trade importers\nBULLET::::- European Federation of Taiwanese Associations\nBULLET::::- Free trade areas in Europe\n"}
{"id": "9580", "url": "https://en.wikipedia.org/wiki?curid=9580", "title": "European Free Trade Association", "text": "European Free Trade Association\n\nThe European Free Trade Association (EFTA) is a regional trade organization and free trade area consisting of four European states: Iceland, Liechtenstein, Norway, and Switzerland. The organization operates in parallel with the European Union (EU), and all four member states participate in the European Single Market and are part of the Schengen Area. They are not, however, party to the European Union Customs Union.\n\nEFTA was historically one of the two dominant western European trade blocs, but is now much smaller and closely associated with its historical competitor, the European Union. It was established on 3 May 1960 to serve as an alternative trade bloc for those European states that were unable or unwilling to join the then European Economic Community (EEC), which subsequently became the European Union. The Stockholm Convention (1960), to establish the EFTA, was signed on 4 January 1960 in the Swedish capital by seven countries (known as the \"outer seven\": Austria, Denmark, Norway, Portugal, Sweden, Switzerland and the United Kingdom). A revised Convention, the Vaduz Convention, was signed on 21 June 2001 and entered into force on 1 June 2002. \n\nSince 1995, only two founding members remain, namely Norway and Switzerland. The other five, Austria, Denmark, Portugal, Sweden and the United Kingdom, have joined the EU in the intervening years. The initial Stockholm Convention was superseded by the Vaduz Convention, which aimed to provide a successful framework for continuing the expansion and liberalization of trade, both among the organization's member states and with the rest of the world.\n\nWhilst the EFTA is not a customs union and member states have full rights to enter into bilateral third-country trade arrangements, it does have a coordinated trade policy. As a result, its member states have jointly concluded free trade agreements with the EU and a number of other countries. To participate in the EU's single market, Iceland, Liechtenstein, and Norway are parties to the Agreement on a European Economic Area (EEA), with compliances regulated by the EFTA Surveillance Authority and the EFTA Court. Switzerland has a set of bilateral agreements with the EU instead.\n\nOn 12 January 1960, the Treaty on the European Free Trade Association was initiated in the Golden Hall of the Prince's Palace of Stockholm. This established the progressive elimination of customs duties on industrial products, but did not affect agricultural or fisheries products.\n\nThe main difference between the early EEC and the EFTA was that the latter did not operate common external customs tariffs unlike the former: each EFTA member was free to establish its individual customs duties against, or its individual free trade agreements with, non-EFTA countries.\n\nThe founding members of the EFTA were: Austria, Denmark, Norway, Portugal, Sweden, Switzerland, and the United Kingdom. During the 1960s, these countries were often referred to as the \"Outer Seven\", as opposed to the Inner Six of the then European Economic Community (EEC).\n\nFinland became an associate member in 1961 and a full member in 1986, and Iceland joined in 1970. The United Kingdom and Denmark joined the EEC in 1973 and hence ceased to be EFTA members. Portugal also left EFTA for the European Community in 1986. Liechtenstein joined the EFTA in 1991 (previously its interests had been represented by Switzerland). Austria, Sweden, and Finland joined the EU in 1995 and thus ceased to be EFTA members.\n\nTwice, in 1973 and in 1995, the Norwegian government had tried to join the EU (still the EEC, in 1973) and by doing so, leave the EFTA. However, both the times, the membership of the EU was rejected in national referenda, keeping Norway in the EFTA. Iceland applied for EU membership in 2009 due to the 2008–2011 Icelandic financial crisis, but has since dropped its bid.\n\n! Contracting party\n! Accession\n! Population()\n! Area \n! Capital\n! GDP \n! GDP per capita \n\n!State\n!Accession\n!Left EFTA and joined EU/EEC\n\n1960\n1995\n\n1960\n1973\n\n1986\n1995\n\n1960\n1986\n\n1960\n1995\n\n1960\n1973\n\nBetween 1994 and 2011, EFTA memberships for Andorra, San Marino, Monaco, the Isle of Man, Turkey, Israel, Morocco, and other European Neighbourhood Policy partners were discussed.\n\nIn November 2012, after the Council of the European Union had called for an evaluation of the EU's relations with Monaco, Andorra and San Marino, which they described as \"fragmented\", the European Commission published a report outlining the options for their further integration into the EU. Unlike Liechtenstein, which is a member of the EEA via the EFTA and the Schengen Agreement, relations with these three states are based on a collection of agreements covering specific issues. The report examined four alternatives to the current situation: \nBULLET::::1. A Sectoral Approach with separate agreements with each state covering an entire policy area.\nBULLET::::2. A comprehensive, multilateral Framework Association Agreement (FAA) with the three states.\nBULLET::::3. EEA membership, and\nBULLET::::4. EU membership.\nHowever, the Commission argued that the sectoral approach did not address the major issues and was still needlessly complicated, while EU membership was dismissed in the near future because \"the EU institutions are currently not adapted to the accession of such small-sized countries\". The remaining options, EEA membership and a FAA with the states, were found to be viable and were recommended by the Commission. In response, the Council requested that negotiations with the three microstates on further integration continue, and that a report be prepared by the end of 2013 detailing the implications of the two viable alternatives and recommendations on how to proceed.\n\nAs the EEA memberships are currently only open to the EFTA or EU members, the consent of the existing EFTA member states is required for the microstates to join the EEA without becoming members of the EU. In 2011, Jonas Gahr Støre, then Foreign Minister of Norway which is an EFTA member state, said that EFTA/EEA membership for the microstates was not the appropriate mechanism for their integration into the internal market due to their different requirements from those of large countries such as Norway, and suggested that a simplified association would be better suited for them. Espen Barth Eide, Støre's successor, responded to the Commission's report in late 2012 by questioning whether the microstates have sufficient administrative capabilities to meet the obligations of EEA membership. However, he stated that Norway was open to the possibility of EFTA membership for the microstates if they decide to submit an application, and that the country had not made a final decision on the matter. Pascal Schafhauser, the Counsellor of the Liechtenstein Mission to the EU, said that Liechtenstein, another EFTA member state, was willing to discuss EEA membership for the microstates provided their joining, did not impede the functioning of the organization. However, he suggested that the option direct membership in the EEA for the microstates, outside of both the EFTA and the EU, should be considered. On 18 November 2013, the EU Commission concluded that \"the participation of the small-sized countries in the EEA is not judged to be a viable option at present due to the political and institutional reasons,\" and that, Association Agreements were a more feasible mechanism to integrate the microstates into the internal market.\n\nThe Norwegian electorate had rejected treaties of accession to the EU in two referendums. At the time of the first referendum in 1972, their neighbour, Denmark joined. Since the second referendum in 1994, two other Nordic neighbours, Sweden and Finland, have joined the EU. The last two governments of Norway have not advanced the question, as they have both been coalition governments consisting of proponents and opponents of EU membership.\n\nSince Switzerland rejected the EEA membership in a referendum in 1992, more referendums on EU membership have been initiated, the last time being in 2001. These were all rejected. Switzerland has been in a customs union with fellow EFTA member state and neighbour Liechtenstein since 1924.\n\nOn 16 July 2009, the government of Iceland formally applied for the EU membership, but the negotiation process had been suspended since mid-2013, and in 2015 the foreign ministers wrote to withdraw its application.\n\nIn mid-2005, representatives of the Faroe Islands raised the possibility of their territory joining the EFTA. According to Article 56 of the EFTA Convention, only states may become members of the EFTA. The Faroes are a constituent country of the Kingdom of Denmark, and not a sovereign state in their own right. Consequently, they considered the possibility that the \"Kingdom of Denmark in respect of the Faroes\" could join the EFTA, though the Danish Government has stated that this mechanism would not allow the Faroes to become a separate member of the EEA because Denmark was already a party to the EEA Agreement.\n\nThe Faroes already have an extensive bilateral free trade agreement with Iceland, known as the Hoyvík Agreement.\n\nThe United Kingdom was a co-founder of EFTA in 1960, but ceased to be a member upon joining the European Economic Community. The country held a referendum in 2016 on withdrawing from the EU (popularly referred to as \"Brexit\"), resulting in a 51.9% vote in favour of withdrawing. A 2013 research paper presented to the Parliament of the United Kingdom proposed a number of alternatives to EU membership which would continue to allow it access to the EU's internal market, including continuing EEA membership as an EFTA member state, or the Swiss model of a number of bilateral treaties covering the provisions of the single market.\n\nIn the first meeting since the Brexit vote, EFTA reacted by saying both that they were open to a UK return, and that Britain has many issues to work through. The president of Switzerland Johann Schneider-Ammann stated that its return would strengthen the association. However, in August 2016 the Norwegian Government expressed reservations. Norway's European affairs minister, Elisabeth Vik Aspaker, told the \"Aftenposten\" newspaper: \"It’s not certain that it would be a good idea to let a big country into this organization. It would shift the balance, which is not necessarily in Norway’s interests.\"\n\nIn late 2016, the Scottish First Minister said that her priority was to keep the whole of the UK in the European single market but that taking Scotland alone into the EEA was an option being \"looked at\". However, other EFTA states have stated that only sovereign states are eligible for membership, so it could only join if it became independent from the UK, unless the solution scouted for the Faroes in 2005 were to be adopted (see above).\n\nIn early 2018, British MPs Antoinette Sandbach, Stephen Kinnock and Stephen Hammond all called for the UK to rejoin EFTA.\n\nEFTA is governed by the EFTA Council and serviced by the EFTA Secretariat. In addition, in connection with the EEA Agreement of 1992, two other EFTA organisations were established, the EFTA Surveillance Authority and the EFTA Court.\n\nThe EFTA Council is the highest governing body of EFTA. The Council usually meets eight times a year at the ambassadorial level (heads of permanent delegations to EFTA) and twice a year at Ministerial level. In the Council meetings, the delegations consult with one another, negotiate and decide on policy issues regarding EFTA. Each Member State is represented and has one vote, though decisions are usually reached through consensus.\n\nThe Council discusses substantive matters, especially relating to the development of EFTA relations with third countries and the management of free trade agreements, and keeps under general review relations with the EU third-country policy and administration. It has a broad mandate to consider possible policies to promote the overall objectives of the Association and to facilitate the development of links with other states, unions of states or international organisations. The Council also manages relations between the EFTA States under the EFTA Convention. Questions relating to the EEA are dealt with by the Standing Committee in Brussels.\n\nThe day-to-day running of the Secretariat is headed by the Secretary-General, Henri Gétaz, who is assisted by two Deputy Secretaries-General, one based in Geneva and the other in Brussels. The three posts are shared between the Member States. The division of the Secretariat reflects the division of EFTA's activities. The Secretariat employs approximately 100 staff members, of whom a third are based in Geneva and two thirds in Brussels and Luxembourg.\n\nThe Headquarters in Geneva deals with the management and negotiation of free trade agreements with non-EU countries, and provides support to the EFTA Council.\n\nIn Brussels, the Secretariat provides support for the management of the EEA Agreement and assists the Member States in the preparation of new legislation for integration into the EEA Agreement. The Secretariat also assists the Member States in the elaboration of input to EU decision making.\n\nThe two duty stations work together closely to implement the Vaduz Convention's stipulations on the intra-EFTA Free Trade Area.\n\nThe EFTA Statistical Office in Luxembourg contributes to the development of a broad and integrated European Statistical System. The EFTA Statistical Office (ESO) is located in the premises of Eurostat, the Statistical Office of the European Union in Luxembourg, and functions as a liaison office between Eurostat and the EFTA National Statistical Institutes. ESO's main objective is to promote the full inclusion of the EFTA States in the European Statistical System, thus providing harmonised and comparable statistics to support the general cooperation process between EFTA and the EU within and outside the EEA Agreement. The cooperation also entails technical cooperation programmes with third countries and training of European statisticians.\n\nThe EFTA Secretariat is headquartered in Geneva, Switzerland, but also has duty stations in Brussels, Belgium and Luxembourg City, Luxembourg. The EFTA Surveillance Authority has its headquarters in Brussels, Belgium (the same location as the headquarters of the European Commission), while the EFTA Court has its headquarters in Luxembourg City (the same location as the headquarters of the European Court of Justice).\n\nIn 1992, the EFTA and the EU signed the European Economic Area Agreement in Oporto, Portugal. However, the proposal that Switzerland ratify its participation was rejected by referendum. (Nevertheless, Switzerland has multiple bilateral treaties with the EU that allow it to participate in the European Single Market, the Schengen Agreement and other programmes). Thus, except for Switzerland, the EFTA members are also members of the European Economic Area (EEA). The EEA comprises three member states of the European Free Trade Association (EFTA) and 28 member states of the European Union (EU), including Croatia which is provisionally applying the agreement pending its ratification by all EEA countries. It was established on 1 January 1994 following an agreement with the European Community (which had become the EU two months earlier). It allows the EFTA-EEA states to participate in the EU's Internal Market without being members of the EU. They adopt almost all EU legislation related to the single market, except laws on agriculture and fisheries. However, they also contribute to and influence the formation of new EEA relevant policies and legislation at an early stage as part of a formal decision-shaping process. One EFTA member, Switzerland, has not joined the EEA but has a series of bilateral agreements, including a free trade agreement, with the EU.\n\nThe following table summarises the various components of EU laws applied in the EFTA countries and their sovereign territories. Some territories of EU member states also have a special status in regard to EU laws applied as is the case with some European microstates.\n\n!colspan=\"2\"  and territories\n! Application \n! EURATOM\n! European Defence Agency\n! Schengen area\n! EU VAT area\n! EU Customs Union\n! EU single market\n! Eurozone\n\n, ISK\n\n, VAT area\n, customs territory\n, CHF\n\n, NOK\n\n, VAT free\n\n, NOK\n\n, NOK\n\n, NOK\n\n, NOK\n\n, VAT area\n, customs territory\n, CHF\n\n, VAT free\n, customs territory\n, CHF\n\nA Joint Committee consisting of the EEA-EFTA States plus the European Commission (representing the EU) has the function of extending relevant EU law to the non EU members. An EEA Council meets twice yearly to govern the overall relationship between the EEA members.\n\nRather than setting up pan-EEA institutions, the activities of the EEA are regulated by the EFTA Surveillance Authority and the EFTA Court. The EFTA Surveillance Authority and the EFTA Court regulate the activities of the EFTA members in respect of their obligations in the European Economic Area (EEA). Since Switzerland is not an EEA member, it does not participate in these institutions.\n\nThe EFTA Surveillance Authority performs a role for EFTA members that is equivalent to that of the European Commission for the EU, as \"guardian of the treaties\" and the EFTA Court performs the European Court of Justice-equivalent role.\n\nThe original plan for the EEA lacked the EFTA Court or the EFTA Surveillance Authority: the European Court of Justice and the European Commission were to exercise those roles. However, during the negotiations for the EEA agreement, the European Court of Justice informed the Council of the European Union by way of letter that it considered that it would be a violation of the treaties to give to the EU institutions these powers with respect to non-EU member states. Therefore, the current arrangement was developed instead.\n\nThe EEA and Norway Grants are the financial contributions of Iceland, Liechtenstein and Norway to reduce social and economic disparities in Europe. They were established in conjunction with the 2004 enlargement of the European Economic Area (EEA), which brought together the EU, Iceland, Liechtenstein and Norway in the Internal Market. In the period from 2004 to 2009, €1.3 billion of project funding was made available for project funding in the 15 beneficiary states in Central and Southern Europe. The EEA and Norway Grants are administered by the Financial Mechanism Office, which is affiliated to the EFTA Secretariat in Brussels.\n\nEFTA also originated the Hallmarking Convention and the Pharmaceutical Inspection Convention, both of which are open to non-EFTA states.\n\nEFTA has several free trade agreements with non-EU countries as well as declarations on cooperation and joint workgroups to improve trade. Currently, the EFTA States have established preferential trade relations with 24 states and territories, in addition to the 28 member states of the European Union.\n\nEFTA's interactive Free Trade Map gives an overview of the partners worldwide.\n\nBULLET::::- Albania\nBULLET::::- Bosnia and Herzegovina\nBULLET::::- Canada (Canada-European Free Trade Association Free Trade Agreement)\nBULLET::::- Central American States (Costa Rica, Guatemala, Panama)\nBULLET::::- Chile\nBULLET::::- Colombia\nBULLET::::- Ecuador\nBULLET::::- Egypt\nBULLET::::- Georgia\nBULLET::::- Gulf Co-operation Council (Bahrain, Kuwait, Oman, Qatar, Saudi Arabia, United Arab Emirates)\nBULLET::::- Hong Kong\nBULLET::::- Israel\nBULLET::::- Japan\nBULLET::::- Jordan\nBULLET::::- South Korea\nBULLET::::- Lebanon\nBULLET::::- Mexico\nBULLET::::- Montenegro\nBULLET::::- Morocco (excluding Western Sahara)\nBULLET::::- North Macedonia\nBULLET::::- Palestinian National Authority\nBULLET::::- Peru\nBULLET::::- Philippines\nBULLET::::- Serbia\nBULLET::::- Singapore\nBULLET::::- Southern African Customs Union (Botswana, Lesotho, Namibia, South Africa, Swaziland)\nBULLET::::- Tunisia\nBULLET::::- Turkey\nBULLET::::- Ukraine\n\nBULLET::::- Algeria\nBULLET::::- Central American States (Honduras)\nBULLET::::- India\nBULLET::::- Indonesia\nBULLET::::- Malaysia\nBULLET::::- MERCOSUR (Argentina, Brazil, Paraguay and Uruguay)\nBULLET::::- Thailand\nBULLET::::- Vietnam\n\nBULLET::::- Mauritius\nBULLET::::- MERCOSUR (Argentina, Brazil, Paraguay and Uruguay)\nBULLET::::- Mongolia\nBULLET::::- Myanmar\nBULLET::::- Pakistan\n\nBULLET::::- Moldova\n\nEFTA member states' citizens enjoy freedom of movement in each other's territories in accordance with the EFTA convention. EFTA nationals also enjoy freedom of movement in the European Union (EU). EFTA nationals and EU citizens are not only visa-exempt but are legally entitled to enter and reside in each other's countries. The Citizens’ Rights Directive (also sometimes called the \"Free Movement Directive\") defines the right of free movement for citizens of the European Economic Area (EEA), which includes the three EFTA members Iceland, Norway and Liechtenstein plus the member states of the EU. Switzerland, which is a member of EFTA but not of the EEA, is not bound by the Directive but rather has a separate bilateral agreement on free movement with the EU.\n\nAs a result a citizen of an EFTA country can live and work in all the other EFTA countries and in all the EU countries, and a citizen of an EU country can live and work in all the EFTA countries (but for voting and working in sensitive fields, such as government / police / military, citizenship is often required, and non-citizens may not have the same rights to welfare and unemployment benefits as citizens).\n\nSince each EFTA and EU country can make its own citizenship laws, dual citizenship is not always possible. Of the EFTA countries, Iceland and Switzerland allow it (in Switzerland, the conditions for the naturalization of immigrants vary regionally), but Norway only in exceptional cases, and Liechtenstein only for citizens by descent, but not for foreigners wanting to naturalize.\n\nSome non-EFTA/non-EU countries do not allow dual citizenship either, so immigrants wanting to naturalize must sometimes renounce their old citizenship.\n\nSee also multiple citizenship and the nationality laws of the countries in question for more details.\n\n!State\n!Name\n!Year\n\nFrank Figgures\n1960–1965\n\nJohn Coulson\n1965–1972\n\nBengt Rabaeus\n1972–1975\n\nCharles Müller\n1976–1981\n\nPer Kleppe\n1981–1988\n\nGeorg Reisch\n1988–1994\n\nKjartan Jóhannsson\n1994–2000\n\nWilliam Rossier\n2000–2006\n\nKåre Bryn\n2006-2012\n\nKristinn F. Árnason\n2012–2018\n\nHenri Gétaz\n2018–present\n\nThe Portugal Fund came into operation in February 1977 when Portugal was still a member of EFTA. It was to provide funding for the development of Portugal after the Carnation Revolution and the consequential restoration of democracy and the decolonization of the country's overseas possessions. This followed a period of economic sanctions by most of the international community, which left Portugal economically underdeveloped compared to the rest of the western Europe. When Portugal left EFTA in 1985 in order to join the EEC, the remaining EFTA members decided to continue the Portugal Fund so that Portugal would continue to benefit from it. The Fund originally took the form of a low-interest loan from the EFTA member states to the value of US$100 million. Repayment was originally to commence in 1988, however, EFTA then decided to postpone the start of repayments until 1998. The Portugal Fund has now been dissolved.\n\nBULLET::::- Central European Free Trade Agreement\nBULLET::::- Euro-Mediterranean free trade area\nBULLET::::- European Union Association Agreement\nBULLET::::- European Union free trade agreements\nBULLET::::- Free trade areas in Europe\n\nBULLET::::- Official website\n"}
{"id": "9581", "url": "https://en.wikipedia.org/wiki?curid=9581", "title": "European Parliament", "text": "European Parliament\n\nThe European Parliament (EP) is the legislative branch of the European Union and one of its seven institutions. Together with the Council of the European Union, it adopts European legislation, normally on a proposal from the European Commission. The Parliament is composed of 751 members (MEPs), intended to become 705 starting from the 2019–2024 legislature because of specific provisions adopted about Brexit. The Parliament represents the second-largest democratic electorate in the world (after the Parliament of India) and the largest trans-national democratic electorate in the world (375 million eligible voters in 2009).\n\nSince 1979, it has been directly elected every five years by European Union citizens, using universal suffrage. Voter turnout for parliamentary elections has decreased at each election after 1979 until 2019, when the voter turnout increased by 8 percentage points and went above 50% for the first time since 1994. Voting age is 18 in all member states except Malta and Austria, where it is 16, and Greece, where it is 17.\n\nAlthough the European Parliament has legislative power, as does the Council, it does not formally possess legislative initiative (which is the prerogative of the European Commission), as most national parliaments of European Union member states do. The Parliament is the \"first institution\" of the EU (mentioned first in the treaties, having ceremonial precedence over all authority at the European level), and shares equal legislative and budgetary powers with the Council (except in a few areas where the special legislative procedures apply). It likewise has equal control over the EU budget. Finally, the European Commission, the executive body of the EU (it exercises executive powers, but no legislative ones other than legislative initiative), is accountable to Parliament. In particular, Parliament can decide whether or not to approve the European Council's nominee for the President of the Commission, and it is further tasked with approving (or rejecting) the appointment of the Commission as a whole. It can subsequently force the Commission as a body to resign by adopting a motion of censure.\n\nThe President of the European Parliament (Parliament's speaker) is David Sassoli (PD), elected in July 2019. He presides over a multi-party chamber, the five largest groups being the European People's Party group (EPP), the Progressive Alliance of Socialists and Democrats (S&D), Renew Europe (previously ALDE), the Greens/European Free Alliance (Greens–EFA) and Identity and Democracy (ID). The last union-wide elections were the 2019 elections.\n\nThe European Parliament has three places of work – Brussels (Belgium), Luxembourg City (Luxembourg) and Strasbourg (France).\nLuxembourg City is home to the administrative offices (the \"General Secretariat\"). Meetings of the whole Parliament (\"plenary sessions\") take place in Strasbourg and in Brussels. Committee meetings are held in Brussels.\n\nThe Parliament, like the other institutions, was not designed in its current form when it first met on 10 September 1952. One of the oldest common institutions, it began as the \"Common Assembly\" of the European Coal and Steel Community (ECSC). It was a consultative assembly of 78 appointed parliamentarians drawn from the national parliaments of member states, having no legislative powers. The change since its foundation was highlighted by Professor David Farrell of the University of Manchester: \"For much of its life, the European Parliament could have been justly labelled a 'multi-lingual talking shop'.\"\n\nIts development since its foundation shows how the European Union's structures have evolved without a clear ‘master plan’. Some, such as Tom Reid of the \"Washington Post\", said of the union: \"nobody would have deliberately designed a government as complex and as redundant as the EU\". Even the Parliament's two seats, which have switched several times, are a result of various agreements or lack of agreements. Although most MEPs would prefer to be based just in Brussels, at John Major's 1992 Edinburgh summit, France engineered a treaty amendment to maintain Parliament's plenary seat permanently at Strasbourg.\n\nThe body was not mentioned in the original Schuman Declaration. It was assumed or hoped that difficulties with the British would be resolved to allow the Council of Europe's Assembly to perform the task. A separate Assembly was introduced during negotiations on the Treaty as an institution which would counterbalance and monitor the executive while providing democratic legitimacy. The wording of the ECSC Treaty demonstrated the leaders' desire for more than a normal consultative assembly by using the term \"representatives of the people\" and allowed for direct election. Its early importance was highlighted when the Assembly was given the task of drawing up the draft treaty to establish a European Political Community. By this document, the Ad Hoc Assembly was established on 13 September 1952 with extra members, but after the failure of the proposed European Defence Community the project was dropped. \n\nDespite this, the European Economic Community and Euratom were established in 1958 by the Treaties of Rome. The Common Assembly was shared by all three communities (which had separate executives) and it renamed itself the \"European Parliamentary Assembly\". The first meeting was held on 19 March 1958 having been set up in Luxembourg City, it elected Schuman as its president and on 13 May it rearranged itself to sit according to political ideology rather than nationality. This is seen as the birth of the modern European Parliament, with Parliament's 50 years celebrations being held in March 2008 rather than 2002.\n\nThe three communities merged their remaining organs as the European Communities in 1967, and the body's name was changed to the current \"European Parliament\" in 1962. In 1970 the Parliament was granted power over areas of the Communities' budget, which were expanded to the whole budget in 1975. Under the Rome Treaties, the Parliament should have become elected. However, the Council was required to agree a uniform voting system beforehand, which it failed to do. The Parliament threatened to take the Council to the European Court of Justice; this led to a compromise whereby the Council would agree to elections, but the issue of voting systems would be put off until a later date.\n\nIn 1979, its members were directly elected for the first time. This sets it apart from similar institutions such as those of the Parliamentary Assembly of the Council of Europe or Pan-African Parliament which are appointed. After that first election, the parliament held its first session on 11 July 1979, electing Simone Veil MEP as its president. Veil was also the first female president of the Parliament since it was formed as the Common Assembly.\n\nAs an elected body, the Parliament began to draft proposals addressing the functioning of the EU. For example, in 1984, inspired by its previous work on the Political Community, it drafted the \"draft Treaty establishing the European Union\" (also known as the 'Spinelli Plan' after its rapporteur Altiero Spinelli MEP). Although it was not adopted, many ideas were later implemented by other treaties. Furthermore, the Parliament began holding votes on proposed Commission Presidents from the 1980s, before it was given any formal right to veto.\n\nSince it became an elected body, the membership of the European Parliament has simply expanded whenever new nations have joined (the membership was also adjusted upwards in 1994 after German reunification). Following this, the Treaty of Nice imposed a cap on the number of members to be elected, 732. \n\nLike the other institutions, the Parliament's seat was not yet fixed. The provisional arrangements placed Parliament in Strasbourg, while the Commission and Council had their seats in Brussels. In 1985 the Parliament, wishing to be closer to these institutions, built a second chamber in Brussels and moved some of its work there despite protests from some states. A final agreement was eventually reached by the European Council in 1992. It stated the Parliament would retain its formal seat in Strasbourg, where twelve sessions a year would be held, but with all other parliamentary activity in Brussels. This two-seat arrangement was contested by the Parliament, but was later enshrined in the Treaty of Amsterdam. To this day the institution's locations are a source of contention.\n\nThe Parliament gained more powers from successive treaties, namely through the extension of the ordinary legislative procedure (then called the codecision procedure), and in 1999, the Parliament forced the resignation of the Santer Commission. The Parliament had refused to approve the Community budget over allegations of fraud and mis-management in the Commission. The two main parties took on a government-opposition dynamic for the first time during the crisis which ended in the Commission resigning en masse, the first of any forced resignation, in the face of an impending censure from the Parliament.\n\nIn 2004, following the largest trans-national election in history, despite the European Council choosing a President from the largest political group (the EPP), the Parliament again exerted pressure on the Commission. During the Parliament's hearings of the proposed Commissioners MEPs raised doubts about some nominees with the Civil Liberties committee rejecting Rocco Buttiglione from the post of Commissioner for Justice, Freedom and Security over his views on homosexuality. That was the first time the Parliament had ever voted against an incoming Commissioner and despite Barroso's insistence upon Buttiglione the Parliament forced Buttiglione to be withdrawn. A number of other Commissioners also had to be withdrawn or reassigned before Parliament allowed the Barroso Commission to take office.\nAlong with the extension of the ordinary legislative procedure, the Parliament's democratic mandate has given it greater control over legislation against the other institutions. In voting on the Bolkestein directive in 2006, the Parliament voted by a large majority for over 400 amendments that changed the fundamental principle of the law. The \"Financial Times\" described it in the following terms:\nIn 2007, for the first time, Justice Commissioner Franco Frattini included Parliament in talks on the second Schengen Information System even though MEPs only needed to be consulted on parts of the package. After that experiment, Frattini indicated he would like to include Parliament in all justice and criminal matters, informally pre-empting the new powers they could gain as part of the Treaty of Lisbon. Between 2007 and 2009, a special working group on parliamentary reform implemented a series of changes to modernise the institution such as more speaking time for rapporteurs, increase committee co-operation and other efficiency reforms.\n\nThe Lisbon Treaty finally came into force on 1 December 2009, granting Parliament powers over the entire EU budget, making Parliament's legislative powers equal to the Council's in nearly all areas and linking the appointment of the Commission President to Parliament's own elections. Despite some calls for the parties to put forward candidates beforehand, only the EPP (which had re-secured their position as largest party) had one in re-endorsing Barroso.\n\nBarroso gained the support of the European Council for a second term and secured majority support from the Parliament in September 2009. Parliament voted 382 votes in favour and 219 votes against (117 abstentions ) with support of the European People's Party, European Conservatives and Reformists and the Alliance of Liberals and Democrats for Europe. The liberals gave support after Barroso gave them a number of concessions; the liberals previously joined the socialists' call for a delayed vote (the EPP had wanted to approve Barroso in July of that year).\n\nOnce Barroso put forward the candidates for his next Commission, another opportunity to gain concessions arose. Bulgarian nominee Rumiana Jeleva was forced to step down by Parliament due to concerns over her experience and financial interests. She only had the support of the EPP which began to retaliate on left wing candidates before Jeleva gave in and was replaced (setting back the final vote further).\n\nBefore the final vote, Parliament demanded a number of concessions as part of a future working agreement under the new Lisbon Treaty. The deal includes that Parliament's President will attend high level Commission meetings. Parliament will have a seat in the EU's Commission-led international negotiations and have a right to information on agreements. However, Parliament secured only an observer seat. Parliament also did not secure a say over the appointment of delegation heads and special representatives for foreign policy. Although they will appear before parliament after they have been appointed by the High Representative. One major internal power was that Parliament wanted a pledge from the Commission that it would put forward legislation when parliament requests. Barroso considered this an infringement on the Commission's powers but did agree to respond within three months. Most requests are already responded to positively.\n\nDuring the setting up of the European External Action Service (EEAS), Parliament used its control over the EU budget to influence the shape of the EEAS. MEPs had aimed at getting greater oversight over the EEAS by linking it to the Commission and having political deputies to the High Representative. MEPs didn't manage to get everything they demanded. However, they got broader financial control over the new body.\nIn January 2019, Conservative MEPs supported proposals to boost opportunities for women and tackle sexual harassment in the European Parliament.\n\nThe Parliament and Council have been compared to the two chambers of a bicameral legislature. However, there are some differences from national legislatures; for example, neither the Parliament nor the Council have the power of legislative initiative (except for the fact that the Council has the power in some intergovernmental matters). In Community matters, this is a power uniquely reserved for the European Commission (the executive). Therefore, while Parliament can amend and reject legislation, to make a proposal for legislation, it needs the Commission to draft a bill before anything can become law. The value of such a power has been questioned by noting that in the national legislatures of the member states 85% of initiatives introduced without executive support fail to become law. Yet it has been argued by former Parliament president Hans-Gert Pöttering that as the Parliament does have the right to ask the Commission to draft such legislation, and as the Commission is following Parliament's proposals more and more Parliament does have a \"de facto\" right of legislative initiative.\n\nThe Parliament also has a great deal of indirect influence, through non-binding resolutions and committee hearings, as a \"pan-European soapbox\" with the ear of thousands of Brussels-based journalists. There is also an indirect effect on foreign policy; the Parliament must approve all development grants, including those overseas. For example, the support for post-war Iraq reconstruction, or incentives for the cessation of Iranian nuclear development, must be supported by the Parliament. Parliamentary support was also required for the transatlantic passenger data-sharing deal with the United States. Finally, Parliament holds a non-binding vote on new EU treaties but cannot veto it. However, when Parliament threatened to vote down the Nice Treaty, the Belgian and Italian Parliaments said they would veto the treaty on the European Parliament's behalf.\n\nWith each new treaty, the powers of the Parliament, in terms of its role in the Union's legislative procedures, have expanded. The procedure which has slowly become dominant is the \"ordinary legislative procedure\" (previously named \"codecision procedure\"), which provides an equal footing between Parliament and Council. In particular, under the procedure, the Commission presents a proposal to Parliament and the Council which can only become law if both agree on a text, which they do (or not) through successive readings up to a maximum of three. In its first reading, Parliament may send amendments to the Council which can either adopt the text with those amendments or send back a \"common position\". That position may either be approved by Parliament, or it may reject the text by an absolute majority, causing it to fail, or it may adopt further amendments, also by an absolute majority. If the Council does not approve these, then a \"Conciliation Committee\" is formed. The Committee is composed of the Council members plus an equal number of MEPs who seek to agree a compromise. Once a position is agreed, it has to be approved by Parliament, by a simple majority. This is also aided by Parliament's mandate as the only directly democratic institution, which has given it leeway to have greater control over legislation than other institutions, for example over its changes to the Bolkestein directive in 2006.\n\nThe few other areas that operate the \"special legislative procedures\" are justice and home affairs, budget and taxation, and certain aspects of other policy areas, such as the fiscal aspects of environmental policy. In these areas, the Council or Parliament decide law alone. The procedure also depends upon which type of institutional act is being used. The strongest act is a regulation, an act or law which is directly applicable in its entirety. Then there are directives which bind member states to certain goals which they must achieve. They do this through their own laws and hence have room to manoeuvre in deciding upon them. A decision is an instrument which is focused at a particular person or group and is directly applicable. Institutions may also issue recommendations and opinions which are merely non-binding, declarations. There is a further document which does not follow normal procedures, this is a \"written declaration\" which is similar to an early day motion used in the Westminster system. It is a document proposed by up to five MEPs on a matter within the EU's activities used to launch a debate on that subject. Having been posted outside the entrance to the hemicycle, members can sign the declaration and if a majority do so it is forwarded to the President and announced to the plenary before being forwarded to the other institutions and formally noted in the minutes.\n\nThe legislative branch officially holds the Union's budgetary authority with powers gained through the Budgetary Treaties of the 1970s and the Lisbon Treaty. The EU budget is subject to a form of the ordinary legislative procedure with a single reading giving Parliament power over the entire budget (before 2009, its influence was limited to certain areas) on an equal footing to the Council. If there is a disagreement between them, it is taken to a conciliation committee as it is for legislative proposals. If the joint conciliation text is not approved, the Parliament may adopt the budget definitively.\n\nThe Parliament is also responsible for discharging the implementation of previous budgets based on the annual report of the European Court of Auditors. It has refused to approve the budget only twice, in 1984 and in 1998. On the latter occasion it led to the resignation of the Santer Commission; highlighting how the budgetary power gives Parliament a great deal of power over the Commission. Parliament also makes extensive use of its budgetary, and other powers, elsewhere; for example in the setting up of the European External Action Service, Parliament has a de facto veto over its design as it has to approve the budgetary and staff changes.\n\nThe President of the European Commission is proposed by the European Council on the basis of the European elections to Parliament. That proposal has to be approved by the Parliament (by a simple majority) who \"elect\" the President according to the treaties. Following the approval of the Commission President, the members of the Commission are proposed by the President in accord with the member states. Each Commissioner comes before a relevant parliamentary committee hearing covering the proposed portfolio. They are then, as a body, approved or rejected by the Parliament.\n\nIn practice, the Parliament has never voted against a President or his Commission, but it did seem likely when the Barroso Commission was put forward. The resulting pressure forced the proposal to be withdrawn and changed to be more acceptable to parliament. That pressure was seen as an important sign by some of the evolving nature of the Parliament and its ability to make the Commission accountable, rather than being a rubber stamp for candidates. Furthermore, in voting on the Commission, MEPs also voted along party lines, rather than national lines, despite frequent pressure from national governments on their MEPs. This cohesion and willingness to use the Parliament's power ensured greater attention from national leaders, other institutions and the public who previously gave the lowest ever turnout for the Parliament's elections.\n\nThe Parliament also has the power to censure the Commission if they have a two-thirds majority which will force the resignation of the entire Commission from office. As with approval, this power has never been used but it was threatened to the Santer Commission, who subsequently resigned of their own accord. There are a few other controls, such as: the requirement of Commission to submit reports to the Parliament and answer questions from MEPs; the requirement of the President-in-office of the Council to present its programme at the start of their presidency; the obligation on the President of the European Council to report to Parliament after each of its meetings; the right of MEPs to make requests for legislation and policy to the Commission; and the right to question members of those institutions (e.g. \"Commission Question Time\" every Tuesday). At present, MEPs may ask a question on any topic whatsoever, but in July 2008 MEPs voted to limit questions to those within the EU's mandate and ban offensive or personal questions.\n\nThe Parliament also has other powers of general supervision, mainly granted by the Maastricht Treaty. The Parliament has the power to set up a Committee of Inquiry, for example over mad cow disease or CIA detention flights the former led to the creation of the European veterinary agency. The Parliament can call other institutions to answer questions and if necessary to take them to court if they break EU law or treaties. Furthermore, it has powers over the appointment of the members of the Court of Auditors and the president and executive board of the European Central Bank. The ECB president is also obliged to present an annual report to the parliament.\n\nThe European Ombudsman is elected by the Parliament, who deals with public complaints against all institutions. Petitions can also be brought forward by any EU citizen on a matter within the EU's sphere of activities. The Committee on Petitions hears cases, some 1500 each year, sometimes presented by the citizen themselves at the Parliament. While the Parliament attempts to resolve the issue as a mediator they do resort to legal proceedings if it is necessary to resolve the citizens dispute.\n\nThe parliamentarians are known in English as Members of the European Parliament (MEPs). They are elected every five years by universal adult suffrage and sit according to political allegiance; about a third are women. Before 1979 they were appointed by their national parliaments. In 2017, an estimated 17 MEPs were not white. Of these, three were black; if the numbers were proportionate to the EU population, then 22 would be black.\n\nUnder the Lisbon Treaty, seats are allocated to each state according to population and the maximum number of members is set at 751 (however, as the President cannot vote while in the chair there will only be 750 voting members at any one time).\n\nRepresentation is currently limited to a maximum of 96 seats and a minimum of 6 seats per state and the seats are distributed according to \"degressive proportionality\", i.e., the larger the state, the more citizens are represented per MEP. As a result, Maltese and Luxembourgish voters have roughly 10x more influence per voter than citizens of the six large countries.\n\n, Germany (80.9 million inhabitants) has 96 seats (previously 99 seats), i.e. one seat for 843,000 inhabitants. Malta (0.4 million inhabitants) has 6 seats, i.e. one seat for 70,000 inhabitants.\n\nThe new system implemented under the Lisbon Treaty, including revising the seating well before elections, was intended to avoid political horse trading when the allocations have to be revised to reflect demographic changes.\n\nPursuant to this apportionment, the constituencies are formed. In five EU member states (Belgium, Ireland, Italy, Poland, and the United Kingdom), the national territory is divided into a number of constituencies. In the remaining member states, the whole country forms a single constituency. All member states hold elections to the European Parliament using various forms of proportional representation.\n\nDue to the delay in ratifying the Lisbon Treaty, the seventh parliament was elected under the lower Nice Treaty cap. A small scale treaty amendment was ratified on 29 November 2011. This amendment brought in transitional provisions to allow the 18 additional MEPs created under the Lisbon Treaty to be elected or appointed before the 2014 election. Under the Lisbon Treaty reforms, Germany was the only state to lose members from 99 to 96. However, these seats were not removed until the 2014 election.\n\nBefore 2009, members received the same salary as members of their national parliament. However, from 2009 a new members statute came into force, after years of attempts, which gave all members an equal monthly pay, of €8,484.05 each in 2016, subject to a European Union tax and which can also be taxed nationally. MEPs are entitled to a pension, paid by Parliament, from the age of 63. Members are also entitled to allowances for office costs and subsistence, and travelling expenses, based on actual cost. Besides their pay, members are granted a number of privileges and immunities. To ensure their free movement to and from the Parliament, they are accorded by their own states the facilities accorded to senior officials travelling abroad and, by other state governments, the status of visiting foreign representatives. When in their own state, they have all the immunities accorded to national parliamentarians, and, in other states, they have immunity from detention and legal proceedings. However, immunity cannot be claimed when a member is found committing a criminal offence and the Parliament also has the right to strip a member of their immunity.\n\nMEPs in Parliament are organised into eight different parliamentary groups, including thirty non-attached members known as \"non-inscrits\". The two largest groups are the European People's Party (EPP) and the Socialists & Democrats (S&D). These two groups have dominated the Parliament for much of its life, continuously holding between 50 and 70 percent of the seats between them. No single group has ever held a majority in Parliament. As a result of being broad alliances of national parties, European group parties are very decentralised and hence have more in common with parties in federal states like Germany or the United States than unitary states like the majority of the EU states. Nevertheless, the European groups were actually more cohesive than their US counterparts between 2004 and 2009.\n\nGroups are often based on a single European political party such as the European People's Party. However, they can, like the liberal group, include more than one European party as well as national parties and independents. For a group to be recognised, it needs 25 MEPs from seven different countries. Once recognised, groups receive financial subsidies from the parliament and guaranteed seats on committees, creating an incentive for the formation of groups. However, some controversy occurred with the establishment of the short-lived Identity, Tradition, Sovereignty (ITS) due to its ideology; the members of the group were far-right, so there were concerns about public funds going towards such a group. There were attempts to change the rules to block the formation of ITS, but they never came to fruition. The group was, however, blocked from gaining leading positions on committees traditionally (by agreement, not a rule) shared among all parties. When this group engaged in infighting, leading to the withdrawal of some members, its size fell below the threshold for recognition causing its collapse.\n\nGiven that the Parliament does not form the government in the traditional sense of a Parliamentary system, its politics have developed along more consensual lines rather than majority rule of competing parties and coalitions. Indeed, for much of its life it has been dominated by a grand coalition of the European People's Party and the Party of European Socialists. The two major parties tend to co-operate to find a compromise between their two groups leading to proposals endorsed by huge majorities. However, this does not always produce agreement, and each may instead try to build other alliances, the EPP normally with other centre-right or right wing Groups and the PES with centre-left or left wing groups. Sometimes, the Liberal Group is then in the pivotal position. There are also occasions where very sharp party political divisions have emerged, for example over the resignation of the Santer Commission.\n\nWhen the initial allegations against the Commission emerged, they were directed primarily against Édith Cresson and Manuel Marín, both socialist members. When the parliament was considering refusing to discharge the Community budget, President Jacques Santer stated that a no vote would be tantamount to a vote of no confidence. The Socialist group supported the Commission and saw the issue as an attempt by the EPP to discredit their party ahead of the 1999 elections. Socialist leader, Pauline Green MEP, attempted a vote of confidence and the EPP put forward counter motions. During this period the two parties took on similar roles to a government-opposition dynamic, with the Socialists supporting the executive and EPP renouncing its previous coalition support and voting it down. Politicisation such as this has been increasing, in 2007 Simon Hix of the London School of Economics noted that:\nDuring the fifth term, 1999 to 2004, there was a break in the grand coalition resulting in a centre-right coalition between the Liberal and People's parties. This was reflected in the Presidency of the Parliament with the terms being shared between the EPP and the ELDR, rather than the EPP and Socialists. In the following term the liberal group grew to hold 88 seats, the largest number of seats held by any third party in Parliament.\n\nElections have taken place, directly in every member state, every five years since 1979. there have been nine elections. When a nation joins mid-term, a by-election will be held to elect their representatives. This has happened six times, most recently when Croatia joined in 2013. Elections take place across four days according to local custom and, apart from having to be proportional, the electoral system is chosen by the member state. This includes allocation of sub-national constituencies; while most members have a national list, some, like the UK and Poland, divide their allocation between regions. Seats are allocated to member states according to their population, since 2014 with no state having more than 96, but no fewer than 6, to maintain proportionality.\n\nThe most recent Union-wide elections to the European Parliament were the European elections of 2019, held from 23 to 26 May 2019. They were the largest simultaneous transnational elections ever held anywhere in the world.\nThe first session of the ninth parliament started 2 July 2019\n\nThe proportion of female MEPs elected in 2009 was 35%; in 1979 it was just 16.5%.\n\nEuropean political parties have the exclusive right to campaign during the European elections (as opposed to their corresponding EP groups). There have been a number of proposals designed to attract greater public attention to the elections. One such innovation in the 2014 elections was that the pan-European political parties fielded \"candidates\" for president of the Commission, the so-called \"Spitzenkandidaten\" (German, \"leading candidates\" or \"top candidates\"). However, European Union governance is based on a mixture of intergovernmental and supranational features: the President of the European Commission is nominated by the European Council, representing the governments of the member states, and there is no obligation for them to nominate the successful \"candidate\". The Lisbon Treaty merely states that they should take account of the results of the elections when choosing whom to nominate. The so-called \"Spitzenkandidaten\" were Jean-Claude Juncker for the European People's Party, Martin Schulz for the Party of European Socialists, Guy Verhofstadt for the Alliance of Liberals and Democrats for Europe Party, Ska Keller and José Bové jointly for the European Green Party and Alexis Tsipras for the Party of the European Left.\n\nTurnout has dropped consistently every year since the first election, and from 1999 it has been below 50%. In 2007 both Bulgaria and Romania elected their MEPs in by-elections, having joined at the beginning of 2007. The Bulgarian and Romanian elections saw two of the lowest turnouts for European elections, just 28.6% and 28.3% respectively.\n\nIn England, Scotland and Wales, EP elections were originally held for a constituency MEP on a first-past-the-post basis. In 1999 the system was changed to a form of PR where a large group of candidates stand for a post within a very large regional constituency. One can vote for a party, but not a candidate (unless that party has a single candidate).\n\nEach year the activities of the Parliament cycle between committee weeks where reports are discussed in committees and interparliamentary delegations meet, political group weeks for members to discuss work within their political groups and session weeks where members spend 3½ days in Strasbourg for part-sessions. In addition six 2-day part-sessions are organised in Brussels throughout the year. Four weeks are allocated as constituency week to allow members to do exclusively constituency work. Finally there are no meetings planned during the summer weeks. The Parliament has the power to meet without being convened by another authority. Its meetings are partly controlled by the treaties but are otherwise up to Parliament according to its own \"Rules of Procedure\" (the regulations governing the parliament).\n\nDuring sessions, members may speak after being called on by the President. Members of the Council or Commission may also attend and speak in debates. Partly due to the need for translation, and the politics of consensus in the chamber, debates tend to be calmer and more polite than, say, the Westminster system. Voting is conducted primarily by a show of hands, that may be checked on request by electronic voting. Votes of MEPs are not recorded in either case, however; that only occurs when there is a roll-call ballot. This is required for the final votes on legislation and also whenever a political group or 30 MEPs request it. The number of roll-call votes has increased with time. Votes can also be a completely secret ballot (for example, when the president is elected). All recorded votes, along with minutes and legislation, are recorded in the \"Official Journal of the European Union\" and can be accessed online. Votes usually do not follow a debate, but rather they are grouped with other due votes on specific occasions, usually at noon on Tuesdays, Wednesdays or Thursdays. This is because the length of the vote is unpredictable and if it continues for longer than allocated it can disrupt other debates and meetings later in the day.\n\nMembers are arranged in a hemicycle according to their political groups (in the Common Assembly, prior to 1958, members sat alphabetically) who are ordered mainly by left to right, but some smaller groups are placed towards the outer ring of the Parliament. All desks are equipped with microphones, headphones for translation and electronic voting equipment. The leaders of the groups sit on the front benches at the centre, and in the very centre is a podium for guest speakers. The remaining half of the circular chamber is primarily composed of the raised area where the President and staff sit. Further benches are provided between the sides of this area and the MEPs, these are taken up by the Council on the far left and the Commission on the far right. Both the Brussels and Strasbourg hemicycle roughly follow this layout with only minor differences. The hemicycle design is a compromise between the different Parliamentary systems. The British-based system has the different groups directly facing each other while the French-based system is a semicircle (and the traditional German system had all members in rows facing a rostrum for speeches). Although the design is mainly based on a semicircle, the opposite ends of the spectrum do still face each other. With access to the chamber limited, entrance is controlled by ushers who aid MEPs in the chamber (for example in delivering documents). The ushers can also occasionally act as a form of police in enforcing the President, for example in ejecting an MEP who is disrupting the session (although this is rare). The first head of protocol in the Parliament was French, so many of the duties in the Parliament are based on the French model first developed following the French Revolution. The 180 ushers are highly visible in the Parliament, dressed in black tails and wearing a silver chain, and are recruited in the same manner as the European civil service. The President is allocated a personal usher.\n\nThe President is essentially the speaker of the Parliament and presides over the plenary when it is in session. The President's signature is required for all acts adopted by co-decision, including the EU budget. The President is also responsible for representing the Parliament externally, including in legal matters, and for the application of the rules of procedure. He or she is elected for two-and-a-half-year terms, meaning two elections per parliamentary term. The President is currently David Sassoli (S&D).\n\nIn most countries, the protocol of the head of state comes before all others; however, in the EU the Parliament is listed as the first institution, and hence the protocol of its president comes before any other European, or national, protocol. The gifts given to numerous visiting dignitaries depend upon the President. President Josep Borrell MEP of Spain gave his counterparts a crystal cup created by an artist from Barcelona who had engraved upon it parts of the Charter of Fundamental Rights among other things.\n\nA number of notable figures have been President of the Parliament and its predecessors. The first President was Paul-Henri Spaak MEP, one of the founding fathers of the Union. Other founding fathers include Alcide de Gasperi MEP and Robert Schuman MEP. The two female Presidents were Simone Veil MEP in 1979 (first President of the elected Parliament) and Nicole Fontaine MEP in 1999, both Frenchwomen. The previous president, Jerzy Buzek was the first East-Central European to lead an EU institution, a former Prime Minister of Poland who rose out of the Solidarity movement in Poland that helped overthrow communism in the Eastern Bloc.\n\nDuring the election of a President, the previous President (or, if unable to, one of the previous Vice-Presidents) presides over the chamber. Prior to 2009, the oldest member fulfilled this role but the rule was changed to prevent far-right French MEP Jean-Marie Le Pen taking the chair.\n\nBelow the President, there are 14 Vice-Presidents who chair debates when the President is not in the chamber. There are a number of other bodies and posts responsible for the running of parliament besides these speakers. The two main bodies are the Bureau, which is responsible for budgetary and administration issues, and the Conference of Presidents which is a governing body composed of the presidents of each of the parliament's political groups. Looking after the financial and administrative interests of members are five Quaestors.\n\n, the European Parliament budget was EUR 1.756 billion. A 2008 report on the Parliament's finances highlighted certain overspending and miss-payments. Despite some MEPs calling for the report to be published, Parliamentary authorities had refused until an MEP broke confidentiality and leaked it.\n\nThe Parliament has 20 Standing Committees consisting of 25 to 73 MEPs each (reflecting the political make-up of the whole Parliament) including a chair, a bureau and secretariat. They meet twice a month in public to draw up, amend to adopt legislative proposals and reports to be presented to the plenary. The rapporteurs for a committee are supposed to present the view of the committee, although notably this has not always been the case. In the events leading to the resignation of the Santer Commission, the rapporteur went against the Budgetary Control Committee's narrow vote to discharge the budget, and urged the Parliament to reject it.\n\nCommittees can also set up sub-committees (e.g. the Subcommittee on Human Rights) and temporary committees to deal with a specific topic (e.g. on extraordinary rendition). The chairs of the Committees co-ordinate their work through the \"Conference of Committee Chairmen\". When co-decision was introduced it increased the Parliament's powers in a number of areas, but most notably those covered by the Committee on the Environment, Public Health and Food Safety. Previously this committee was considered by MEPs as a \"Cinderella committee\"; however, as it gained a new importance, it became more professional and rigorous, attracting increasing attention to its work.\nThe nature of the committees differ from their national counterparts as, although smaller in comparison to those of the United States Congress, the European Parliament's committees are unusually large by European standards with between eight and twelve dedicated members of staff and three to four support staff. Considerable administration, archives and research resources are also at the disposal of the whole Parliament when needed.\n\nDelegations of the Parliament are formed in a similar manner and are responsible for relations with Parliaments outside the EU. There are 34 delegations made up of around 15 MEPs, chairpersons of the delegations also cooperate in a conference like the committee chairs do. They include \"Interparliamentary delegations\" (maintain relations with Parliament outside the EU), \"joint parliamentary committees\" (maintaining relations with parliaments of states which are candidates or associates of the EU), the delegation to the ACP EU Joint Parliamentary Assembly and the delegation to the Euro-Mediterranean Parliamentary Assembly. MEPs also participate in other international activities such as the Euro-Latin American Parliamentary Assembly, the Transatlantic Legislators' Dialogue and through election observation in third countries.\n\nThe Intergroups in the European Parliament are informal fora which gather MEPs from various political groups around any topic. They do not express the view of the European Parliament. They serve a double purpose: to address a topic which is transversal to several committees and in a less formal manner. Their daily secretariat can be run either through the office of MEPs or through interest groups, be them corporate lobbies or NGOs. The favored access to MEPs which the organization running the secretariat enjoys can be one explanation to the multiplication of Intergroups in the 1990s. They are now strictly regulated and financial support, direct or otherwise (via Secretariat staff, for example) must be officially specified in a declaration of financial interests. Also Intergroups are established or renewed at the beginning of each legislature through a specific process. Indeed, the proposal for the constitution or renewal of an Intergroup must be supported by at least 3 political groups whose support is limited to a specific number of proposals in proportion to their size (for example, for the legislature 2014-2019, the EPP or S&D political groups could support 22 proposals whereas the Greens/EFA or the EFDD political groups only 7).\n\nSpeakers in the European Parliament are entitled to speak in any of the 24 official languages of the European Union, ranging from French and German to Maltese and Irish. Simultaneous interpreting is offered in all plenary sessions, and all final texts of legislation are translated. With twenty-four languages, the European Parliament is the most multilingual parliament in the world and the biggest employer of interpreters in the world (employing 350 full-time and 400 free-lancers when there is higher demand). Citizens may also address the Parliament in Basque, Catalan/Valencian and Galician.\n\nUsually a language is translated from a foreign tongue into a translator's native tongue. Due to the large number of languages, some being minor ones, since 1995 interpreting is sometimes done the opposite way, out of an interpreter's native tongue (the \"retour\" system). In addition, a speech in a minor language may be interpreted through a third language for lack of interpreters (\"relay\" interpreting) for example, when interpreting out of Estonian into Maltese. Due to the complexity of the issues, interpretation is not word for word. Instead, interpreters have to convey the political meaning of a speech, regardless of their own views. This requires detailed understanding of the politics and terms of the Parliament, involving a great deal of preparation beforehand (e.g. reading the documents in question). Difficulty can often arise when MEPs use profanities, jokes and word play or speak too fast.\n\nWhile some see speaking their native language as an important part of their identity, and can speak more fluently in debates, interpretation and its cost has been criticised by some. A 2006 report by Alexander Stubb MEP highlighted that by only using English, French and German costs could be reduced from €118,000 per day (for 21 languages then Romanian, Bulgarian and Croatian having not yet been included) to €8,900 per day. There has also been a small-scale campaign to make French the reference language for all legal texts, on the basis of an argument that it is more clear and precise for legal purposes.\n\nBecause the proceedings are translated into all of the official EU languages, they have been used to make a multilingual corpus known as Europarl. It is widely used to train statistical machine translation systems.\n\nAccording to the European Parliament website, the annual parliament budget for 2016 was €1.838 billion. The main cost categories were:\n\nBULLET::::- 34% staff, interpretation and translation costs\nBULLET::::- 24% information policy, IT, telecommunications\nBULLET::::- 23% MEPs' salaries, expenses, travel, offices and staff\nBULLET::::- 13% buildings\nBULLET::::- 6% political group activities\n\nAccording to a European Parliament study prepared in 2013, the Strasbourg seat costs an extra €103 million over maintaining a single location and according to the Court of Auditors an additional €5 million is related to travel expenses caused by having two seats.\n\nAs a comparison, the German lower house of parliament (Bundestag) is estimated to cost €517 million in total for 2018, for a parliament with 709 members. The British House of Commons reported total annual costs in 2016-2017 of £249 million (€279 million). It had 650 seats.\n\nAccording to \"The Economist\", the European Parliament costs more than the British, French and German parliaments combined. A quarter of the costs is estimated to be related to translation and interpretation costs (c. €460 million) and the double seats are estimated to add an additional €180 million a year. For a like-for-like comparison, these two cost blocks can be excluded.\n\nOn 2 July 2018, MEPs rejected proposals to tighten the rules around the General Expenditure Allowance (GEA), which \"is a controversial €4,416 per month payment that MEPs are given to cover office and other expenses, but they are not required to provide any evidence of how the money is spent\".\n\nThe Parliament is based in three different cities with numerous buildings. A protocol attached to the Treaty of Amsterdam requires that 12 plenary sessions be held in Strasbourg (none in August but two in September), which is the Parliament's official seat, while extra part sessions as well as committee meetings are held in Brussels. Luxembourg City hosts the Secretariat of the European Parliament. The European Parliament is one of at least two assemblies in the world with more than one meeting place (another being the parliament of the Isle of Man, Tynwald) and one of the few that does not have the power to decide its own location.\n\nThe Strasbourg seat is seen as a symbol of reconciliation between France and Germany, the Strasbourg region having been fought over by the two countries in the past. However, the cost and inconvenience of having two seats is questioned. While Strasbourg is the official seat, and sits alongside the Council of Europe, Brussels is home to nearly all other major EU institutions, with the majority of Parliament's work being carried out there. Critics have described the two-seat arrangement as a \"travelling circus\", and there is a strong movement to establish Brussels as the sole seat. This is because the other political institutions (the Commission, Council and European Council) are located there, and hence Brussels is treated as the 'capital' of the EU. This movement has received strong backing from numerous figures, including Margot Wallström, Commission First-Vice President from 2004 to 2010, who stated that \"something that was once a very positive symbol of the EU reuniting France and Germany has now become a negative symbol of wasting money, bureaucracy and the insanity of the Brussels institutions\". The Green Party has also noted the environmental cost in a study led by Jean Lambert MEP and Caroline Lucas MEP; in addition to the extra 200 million euro spent on the extra seat, there are over 20,268 tonnes of additional carbon dioxide, undermining any environmental stance of the institution and the Union. The campaign is further backed by a million-strong online petition started by Cecilia Malmström MEP. In August 2014, an assessment by the European Court of Auditors calculated that relocating the Strasbourg seat of the European Parliament to Brussels would save €113.8 million per year. In 2006, there were allegations of irregularities in the charges made by the city of Strasbourg on buildings the Parliament rented, thus further harming the case for the Strasbourg seat.\n\nMost MEPs prefer Brussels as a single base. A poll of MEPs found 89% of the respondents wanting a single seat, and 81% preferring Brussels. Another, more academic, survey found 68% support. In July 2011, an absolute majority of MEPs voted in favour of a single seat. In early 2011, the Parliament voted to scrap one of the Strasbourg sessions by holding two within a single week. The mayor of Strasbourg officially reacted by stating \"we will counter-attack by upturning the adversary's strength to our own profit, as a judoka would do.\" However, as Parliament's seat is now fixed by the treaties, it can only be changed by the Council acting unanimously, meaning that France could veto any move. The former French President Nicolas Sarkozy has stated that the Strasbourg seat is \"non-negotiable\", and that France has no intention of surrendering the only EU Institution on French soil. Given France's declared intention to veto any relocation to Brussels, some MEPs have advocated civil disobedience by refusing to take part in the monthly exodus to Strasbourg.\n\nOver the last few years, European institutions have committed to promoting transparency, openness, and the availability of information about their work. In particular, transparency is regarded as pivotal to the action of European institutions and a general principle of EU law, to be applied to the activities of EU institutions in order to strengthen the Union's democratic foundation. The general principles of openness and transparency are reaffirmed in the articles 8 A, point 3 and 10.3 of the Treaty of Lisbon and the Maastricht Treaty respectively, stating that \"every citizen shall have the right to participate in the democratic life of the Union. Decisions shall be taken as openly and as closely as possible to the citizen\". Furthermore, both treaties acknowledge the value of dialogue between citizens, representative associations, civil society, and European institutions.\n\nArticle 17 of the Treaty on the Functioning of the European Union (TFEU) lays the juridical foundation for an open, transparent dialogue between European institutions and churches, religious associations, and non-confessional and philosophical organisations. In July 2014, in the beginning of the 8th term, then President of the European Parliament Martin Schulz tasked Antonio Tajani, then Vice-President, with implementing the dialogue with the religious and confessional organisations included in article 17. In this framework, the European Parliament hosts high-level conferences on inter-religious dialogue, also with focus on current issues and in relation with parliamentary works.\n\nThe chair of European Parliament Mediator for International Parental Child Abduction was established in 1987 by initiative of British MEP Charles Henry Plumb, with the goal of helping minor children of international couples victim of parental abduction. The Mediator finds negotiated solutions in the higher interest of the minor when said minor is abducted by a parent following separation of the couple, regardless whether married or unmarried. Since its institution, the chair has been held by Mairead McGuinness (since 2014), Roberta Angelilli (2009-2014), Evelyne Gebhardt (2004-2009), Mary Banotti (1995-2004), and Marie-Claude Vayssade (1987-1994). The Mediator's main task is to assist parents in finding a solution in the minor's best interest through mediation, i.e. a form of controversy resolution alternative to lawsuit. The Mediator is activated by request of a citizen and, after evaluating the request, starts a mediation process aimed at reaching an agreement. Once subscribed by both parties and the Mediator, the agreement is official. The nature of the agreement is that of a private contract between parties. In defining the agreement, the European Parliament offers the parties the juridical support necessary to reach a sound, lawful agreement based on legality and equity. The agreement can be ratified by the competent national courts and can also lay the foundation for consensual separation or divorce.\n\nThe European Parliamentary Research Service (EPRS) is the European Parliament's in-house research department and think tank. It provides Members of the European Parliament and, where appropriate, parliamentary committees with independent, objective and authoritative analysis of, and research on, policy issues relating to the European Union, in order to assist them in their parliamentary work. It is also designed to increase Members' and EP committees' capacity to scrutinise and oversee the European Commission and other EU executive bodies.\n\nEPRS aims to provide a comprehensive range of products and services, backed by specialist internal expertise and knowledge sources in all policy fields, so empowering Members and committees through knowledge and contributing to the Parliament's effectiveness and influence as an institution. In undertaking this work, the EPRS supports and promotes parliamentary outreach to the wider public, including dialogue with relevant stakeholders in the EU’s system of multi-level governance. All publications by EPRS are publicly available on the EP Think Tank platform.\n\nThe European Parliament periodically commissions opinion polls and studies on public opinion trends in Member States to survey perceptions and expectations of citizens about its work and the overall activities of the European Union. Topics include citizens' perception of the European Parliament's role, their knowledge of the institution, their sense of belonging in the European Union, opinions on European elections and European integration, identity, citizenship, political values, but also on current issues such as climate change, current economy and politics, etc.. Eurobarometer analyses seek to provide an overall picture of national situations, regional specificities, socio-demographic cleavages, and historical trends.\n\nAnnually, the European Parliament awards four prizes to individuals and organisations that distinguished themselves in the areas of human rights, film, youth projects, and European participation and citizenship.\n\nWith the Sakharov Prize for Freedom of Thought, created in 1998, the European Parliament supports human rights by awarding individuals that contribute to promoting human rights worldwide, thus raising awareness on human rights violations. Priorities include: protection of human rights and fundamental liberties, with particular focus on freedom of expression; protection of minority rights; compliance with international law; and development of democracy and authentic rule of law.\n\nThe European Charlemagne Youth Prize seeks to encourage youth participation in the European integration process. It is awarded by the European Parliament and the Foundation of the International Charlemagne Prize of Aachen to youth projects aimed at nurturing common European identity and European citizenship.\n\nThe European Citizens' Prize is awarded by the European Parliament to activities and actions carried out by citizens and associations to promote integration between the citizens of EU member states and transnational cooperation projects in the EU.\n\nSince 2007, the LUX Prize is awarded by the European Parliament to films dealing with current topics of public European interest that encourage reflection on Europe and its future. Over time, the Lux Prize has become a prestigious cinema award which supports European film and production also outside the EU.\n\nBULLET::::- Parlamentarium\nBULLET::::- Parliamentwatch\nBULLET::::- State of the Union address (European Union)\nBULLET::::- Rules of Procedure of the European Parliament\n\nBULLET::::- The same three co-authors have written every edition since the first in 1990.\nBULLET::::- (draft version on-line)\nBULLET::::- Lodge, Juliet, ed. \"The 2009 Elections to the European Parliament\" (Palgrave Macmillan; 2011) 327 pages\nBULLET::::- Sabbati, Giulio (2015). \" European Parliament: Facts and Figures'. European Parliament – European Parliamentary Research Service (EPRS).\nBULLET::::- Dick Toornstra; Christian Meseth (2012). \"Inside the European Parliament: A guide to its parliamentary and administrative structures\". European Parliament – Office for Promotion of Parliamentary Democracy (OPPD).\n\nBULLET::::- European Parliamentary Research Service (EPRS)\nBULLET::::- European Parliament’s Think Tank\nBULLET::::- Historical Archives of the European Parliament\nBULLET::::- Historical Archives of the European Union\nBULLET::::- BBC – European Parliament guide\nBULLET::::- 360° tour of European Parliament Brussels\n"}
{"id": "9582", "url": "https://en.wikipedia.org/wiki?curid=9582", "title": "European Council", "text": "European Council\n\nThe European Council (\"informally\" EUCO) is a collective body that defines the European Union's overall political direction and priorities. It comprises the heads of state or government of the EU member states, along with the President of the European Council and the President of the European Commission. The High Representative of the Union for Foreign Affairs and Security Policy also takes part in its meetings. Established as an informal summit in 1975, the European Council was formalised as an institution in 2009 upon the entry into force of the Treaty of Lisbon. Its current president is Charles Michel, former Prime Minister of Belgium.\n\nWhile the European Council has no legislative power, it is a strategic (and crisis-solving) body that provides the union with general political directions and priorities, and acts as a collective presidency. The European Commission remains the sole initiator of legislation, but the European Council is able to provide an impetus to guide legislative policy.\n\nThe meetings of the European Council, still commonly referred to as EU summits, are chaired by its president and take place at least twice every six months; usually in the Europa building in Brussels. Decisions of the European Council are taken by consensus, except where the Treaties provide otherwise.\n\nThe European Council officially gained the status of an EU institution after the Treaty of Lisbon in 2007, distinct from the Council of the European Union (Council of Ministers). Before that, the first summits of EU heads of state or government were held in February and July 1961 (in Paris and Bonn respectively). They were informal summits of the leaders of the European Community, and were started due to then-French President Charles de Gaulle's resentment at the domination of supranational institutions (notably the European Commission) over the integration process, but petered out. The first influential summit held, after the departure of de Gaulle, was the Hague summit of 1969, which reached an agreement on the admittance of the United Kingdom into the Community and initiated foreign policy cooperation (the European Political Cooperation) taking integration beyond economics.\n\nThe summits were only formalised in the period between 1974 and 1988. At the December summit in Paris in 1974, following a proposal from then-French president Valéry Giscard d'Estaing, it was agreed that more high level, political input was needed following the \"empty chair crisis\" and economic problems. The inaugural \"European Council\", as it became known, was held in Dublin on 10 and 11 March 1975 during Ireland's first Presidency of the Council of Ministers. In 1987, it was included in the treaties for the first time (the Single European Act) and had a defined role for the first time in the Maastricht Treaty. At first only a minimum of two meetings per year were required, which resulted in an average of three meetings per year being held for the 1975-1995 period. Since 1996, the number of meetings were required to be minimum four per year. For the latest 2008-2014 period, this minimum was well exceeded, by an average of seven meetings being held per year. The seat of the Council was formalised in 2002, basing it in Brussels. Three types of European Councils exist: Informal, Scheduled and Extraordinary. While the informal meetings are also scheduled 1½ years in advance, they differ from the scheduled ordinary meetings by not ending with official \"Council conclusions\", as they instead end by more broad political \"Statements\" on some cherry picked policy matters. The extraordinary meetings always end with official \"Council conclusions\" - but differs from the scheduled meetings by not being scheduled more than a year in advance, as for example in 2001 when the European Council gathered to lead the European Union's response to the 11 September attacks.\nSome meetings of the European Council—and, before the European Council was formalised, meetings of the heads of government—are seen by some as turning points in the history of the European Union. For example:\nBULLET::::- 1969, \"The Hague\": Foreign policy and enlargement.\nBULLET::::- 1974, \"Paris\": Creation of the Council.\nBULLET::::- 1985, \"Milan\": Initiate IGC leading to the Single European Act.\nBULLET::::- 1991, \"Maastricht\": Agreement on the Maastricht Treaty.\nBULLET::::- 1992, \"Edinburgh\": Agreement (by treaty provision) to retain at Strasbourg the plenary seat of the European Parliament.\nBULLET::::- 1993, \"Copenhagen\": Leading to the definition of the Copenhagen Criteria.\nBULLET::::- 1997, \"Amsterdam\": Agreement on the Amsterdam Treaty.\nBULLET::::- 1998, \"Brussels\": Selected member states to adopt the euro.\nBULLET::::- 1999; \"Cologne\": Declaration on military forces.\nBULLET::::- 1999, \"Tampere\": Institutional reform\nBULLET::::- 2000, \"Lisbon\": Lisbon Strategy\nBULLET::::- 2002, \"Copenhagen\": Agreement for May 2004 enlargement.\nBULLET::::- 2007, \"Lisbon\": Agreement on the Lisbon Treaty.\nBULLET::::- 2009, \"Brussels\": Appointment of first president and merged High Representative.\nBULLET::::- 2010, European Financial Stability Facility\n\nAs such, the European Council had already existed before it gained the status as an institution of the European Union with the entering into force of the Treaty of Lisbon, but even after it had been mentioned in the treaties (since the Single European Act) it could only take political decisions, not formal legal acts. However, when necessary, the Heads of State or Government could also meet as the Council of Ministers and take formal decisions in that role. Sometimes, this was even compulsory, e.g. Article 214(2) of the Treaty establishing the European Community provided (before it was amended by the Treaty of Lisbon) that ‘the Council, meeting \"in the composition of Heads of State or Government\" and acting by a qualified majority, shall nominate the person it intends to appoint as President of the Commission’ (emphasis added); the same rule applied in some monetary policy provisions introduced by the Maastricht Treaty (e.g. Article 109j TEC). In that case, what was politically part of a European Council meeting was legally a meeting of the Council of Ministers. When the European Council, already introduced into the treaties by the Single European Act, became an institution by virtue of the Treaty of Lisbon, this was no longer necessary, and the \"Council [of the European Union] meeting in the composition of the Heads of State or Government\", was replaced in these instances by the European Council now taking formal legally binding decisions in these cases ().\n\nThe Treaty of Lisbon made the European Council a formal institution distinct from the (ordinary) Council of the EU, and created the present longer term and full-time presidency. As an outgrowth of the Council of the EU, the European Council had previously followed the same Presidency, rotating between each member state. While the Council of the EU retains that system, the European Council established, with no change in powers, a system of appointing an individual (without them being a national leader) for a two-and-a-half-year term—which can be renewed for the same person only once. Following the ratification of the treaty in December 2009, the European Council elected the then-Prime Minister of Belgium Herman Van Rompuy as its first permanent president (resigning from Belgian Prime Minister).\n\nThe European Council is an official institution of the EU, mentioned by the Lisbon Treaty as a body which \"shall provide the Union with the necessary impetus for its development\". Essentially it defines the EU's policy agenda and has thus been considered to be the motor of European integration. Beyond the need to provide \"impetus\", the Council has developed further roles: to \"settle issues outstanding from discussions at a lower level\", to lead in foreign policy — acting externally as a \"collective Head of State\", \"formal ratification of important documents\" and \"involvement in the negotiation of the treaty changes\".\n\nSince the institution is composed of national leaders, it gathers the executive power of the member states and has thus a great influence in high-profile policy areas as for example foreign policy. It also exercises powers of appointment, such as appointment of its own President, the High Representative of the Union for Foreign Affairs and Security Policy, and the President of the European Central Bank. It proposes, to the European Parliament, a candidate for President of the European Commission. Moreover, the European Council influences police and justice planning, the composition of the Commission, matters relating to the organisation of the rotating Council presidency, the suspension of membership rights, and changing the voting systems through the Passerelle Clause. Although the European Council has no direct legislative power, under the \"emergency brake\" procedure, a state outvoted in the Council of Ministers may refer contentious legislation to the European Council. However, the state may still be outvoted in the European Council. Hence with powers over the supranational executive of the EU, in addition to its other powers, the European Council has been described by some as the Union's \"supreme political authority\".\n\nThe European Council consists of the heads of state or government of the member states, alongside its own President and the Commission President (both non-voting). The meetings used to be regularly attended by the national foreign minister as well, and the Commission President likewise accompanied by another member of the Commission. However, since the Treaty of Lisbon, this has been discontinued, as the size of the body had become somewhat large following successive accessions of new Member States to the Union.\n\nMeetings can also include other invitees, such as the President of the European Central Bank, as required. The Secretary-General of the Council attends, and is responsible for organisational matters, including minutes. The President of the European Parliament also attends to give an opening speech outlining the European Parliament's position before talks begin.\n\nAdditionally, the negotiations involve a large number of other people working behind the scenes. Most of those people, however, are not allowed to the conference room, except for two delegates per state to relay messages. At the push of a button members can also call for advice from a Permanent Representative via the \"Antici Group\" in an adjacent room. The group is composed of diplomats and assistants who convey information and requests. Interpreters are also required for meetings as members are permitted to speak in their own languages.\nAs the composition is not precisely defined, some states which have a considerable division of executive power can find it difficult to decide who should attend the meetings. While an MEP, Alexander Stubb argued that there was no need for the President of Finland to attend Council meetings with or instead of the Prime Minister of Finland (who was head of European foreign policy). In 2008, having become Finnish Foreign Minister, Stubb was forced out of the Finnish delegation to the emergency council meeting on the Georgian crisis because the President wanted to attend the high-profile summit as well as the Prime Minister (only two people from each country could attend the meetings). This was despite Stubb being Chair-in-Office of the Organisation for Security and Co-operation in Europe at the time which was heavily involved in the crisis. Problems also occurred in Poland where the President of Poland and the Prime Minister of Poland were of different parties and had a different foreign policy response to the crisis. A similar situation arose in Romania between President Traian Băsescu and Prime Minister Călin Popescu-Tăriceanu in 2007–2008 and again in 2012 with Prime Minister Victor Ponta, who both opposed the president.\n\nA number of ad hoc meetings of Heads of State or Government of the Euro area countries were held in 2010 and 2011 to discuss the Sovereign Debt crisis. It was agreed in October 2011 that they should meet regularly twice a year (with extra meetings if needed). This will normally be at the end of a European Council meeting and according to the same format (chaired by the President of the European Council and including the President of the Commission), but usually restricted to the (currently 19) Heads of State or Government of countries whose currency is the euro.\n\nThe President of the European Council is elected by the European Council by a qualified majority for a once-renewable term of two and a half years. The President must report to the European Parliament after each European Council meeting.\n\nThe post was created by the Treaty of Lisbon and was subject to a debate over its exact role. Prior to Lisbon, the Presidency rotated in accordance with the Presidency of the Council of the European Union. The role of that President-in-Office was in no sense (other than protocol) equivalent to an office of a head of state, merely a \"primus inter pares\" (first among equals) role among other European heads of government. The President-in-Office was primarily responsible for preparing and chairing the Council meetings, and had no executive powers other than the task of representing the Union externally. Now the leader of the Council Presidency country can still act as president when the permanent president is absent.\n\n (9 + 1 non-voting from the EU institution)\n\nAlmost all members of the European Council are members of a political party at national level, and most of these are members of a European-level political party. These frequently hold pre-meetings of their European Council members, prior to its meetings. However, the European Council is composed to represent the EU's states rather than political parties and decisions are generally made on these lines, though ideological alignment can colour their political agreements and their choice of appointments (such as their president).\n\nThe table below outlines the number of leaders affiliated to each party and their total voting weight. The map to the right indicates the alignment of each individual country.\n\nThe European Council is required by Article 15.3 TEU to meet at least twice every six months, but convenes more frequently in practice. Despite efforts to contain business, meetings typically last for at least two days, and run long into the night.\n\nUntil 2002, the venue for European Council summits was the member state that held the rotating Presidency of the Council of the European Union. However, European leaders agreed during ratification of the Nice Treaty to forego this arrangement at such a time as the total membership of the European Union surpassed 18 member states. An advanced implementation of this agreement occurred in 2002, with certain states agreeing to waive their right to host meetings, favouring Brussels as the location. Following the growth of the EU to 25 member states, with the 2004 enlargement, all subsequent official summits of the European Council have been in Brussels, with the exception of punctuated ad hoc meetings, such as the 2017 informal European Council in Malta. The logistical, environmental, financial and security arrangements of hosting large summits are usually cited as the primary factors in the decision by EU leaders to move towards a permanent seat for the European Council. Additionally, some scholars argue that the move, when coupled with the formalisation of the European Council in the Lisbon Treaty, represents an institutionalisation of an ad hoc EU organ that had its origins in Luxembourg compromise, with national leaders reasserting their dominance as the EU's \"supreme political authority\".\n\nOriginally, both the European Council and the Council of the European Union utilised the Justus Lipsius building as their Brussels venue. In order to make room for additional meeting space a number of renovations were made, including the conversion of an underground carpark into additional press briefing rooms. However, in 2004 leaders decided the logistical problems created by the outdated facilities warranted the construction of a new purpose built seat able to cope with the nearly 6,000 meetings, working groups, and summits per year. This resulted in the Europa building, which opened its doors in 2017. The focal point of the new building, the distinctive multi-storey \"lantern-shaped\" structure in which the main meeting room is located, is utilised in both the European Council's and Council of the European Union's official logos.\n\nBULLET::::- Laeken indicators\nBULLET::::- Euro summit\nBULLET::::- Presidency of the Council of the European Union\n\nBULLET::::- Official website\nBULLET::::- Archive of European Integration – Summit Guide\nBULLET::::- European Council Collection of documents - CVCE\nBULLET::::- Reflection Group established by the European Council\n"}
{"id": "9587", "url": "https://en.wikipedia.org/wiki?curid=9587", "title": "Euthanasia", "text": "Euthanasia\n\nEuthanasia (from ; \"good death\": εὖ, \"eu\"; \"well\" or \"good\" + θάνατος, \"thanatos\"; \"death\") is the practice of intentionally ending a life to relieve pain and suffering.\n\nDifferent countries have different euthanasia laws. The British House of Lords Select Committee on Medical Ethics defines euthanasia as \"a deliberate intervention undertaken with the express intention of ending a life, to relieve intractable suffering\". In the Netherlands and Belgium, euthanasia is understood as \"termination of life by a doctor at the request of a patient\". The Dutch law however, does not use the term 'euthanasia' but includes the concept under the broader definition of \"assisted suicide and termination of life on request\".\n\nEuthanasia is categorized in different ways, which include voluntary, non-voluntary, or involuntary:\n\nBULLET::::- Voluntary euthanasia is legal in some countries.\nBULLET::::- Non-voluntary euthanasia (patient's consent unavailable) is illegal in all countries.\nBULLET::::- Involuntary euthanasia (without asking consent or against the patient's will) is also illegal in all countries and is usually considered murder.\n\nIn some countries divisive public controversy occurs over the moral, ethical, and legal issues associated with euthanasia. Passive euthanasia (known as \"pulling the plug\") is legal under some circumstances in many countries. Active euthanasia, however, is legal or \"de facto\" legal in only a handful of countries (for example: Belgium, Canada and Switzerland), which limit it to specific circumstances and require the approval of counselors and doctors or other specialists. In some countries - such as Nigeria, Saudi Arabia and Pakistan - support for active euthanasia is almost non-existent.\n\nLike other terms borrowed from history, \"euthanasia\" has had different meanings depending on usage. The first apparent usage of the term \"euthanasia\" belongs to the historian Suetonius, who described how the Emperor Augustus, \"dying quickly and without suffering in the arms of his wife, Livia, experienced the 'euthanasia' he had wished for.\" The word \"euthanasia\" was first used in a medical context by Francis Bacon in the 17th century, to refer to an easy, painless, happy death, during which it was a \"physician's responsibility to alleviate the 'physical sufferings' of the body.\" Bacon referred to an \"outward euthanasia\"—the term \"outward\" he used to distinguish from a spiritual concept—the euthanasia \"which regards the preparation of the soul.\"\n\nIn current usage, euthanasia has been defined as the \"painless inducement of a quick death\". However, it is argued that this approach fails to properly define euthanasia, as it leaves open a number of possible actions which would meet the requirements of the definition, but would not be seen as euthanasia. In particular, these include situations where a person kills another, painlessly, but for no reason beyond that of personal gain; or accidental deaths that are quick and painless, but not intentional.\n\nAnother approach incorporates the notion of suffering into the definition. The definition offered by the Oxford English Dictionary incorporates suffering as a necessary condition, with \"the painless killing of a patient suffering from an incurable and painful disease or in an irreversible coma\", This approach is included in Marvin Khol and Paul Kurtz's definition of it as \"a mode or act of inducing or permitting death painlessly as a relief from suffering\". Counterexamples can be given: such definitions may encompass killing a person suffering from an incurable disease for personal gain (such as to claim an inheritance), and commentators such as Tom Beauchamp and Arnold Davidson have argued that doing so would constitute \"murder simpliciter\" rather than euthanasia.\n\nThe third element incorporated into many definitions is that of intentionality – the death must be intended, rather than being accidental, and the intent of the action must be a \"merciful death\". Michael Wreen argued that \"the principal thing that distinguishes euthanasia from intentional killing simpliciter is the agent's motive: it must be a good motive insofar as the good of the person killed is concerned.\" Likewise, James Field argued that euthanasia entails a sense of compassion towards the patient, in contrast to the diverse non-compassionate motives of serial killers who work in health care professions. Similarly, Heather Draper speaks to the importance of motive, arguing that \"the motive forms a crucial part of arguments for euthanasia, because it must be in the best interests of the person on the receiving end.\" Definitions such as that offered by the House of Lords Select Committee on Medical Ethics take this path, where euthanasia is defined as \"a deliberate intervention undertaken with the express intention of ending a life, to relieve intractable suffering.\" Beauchamp and Davidson also highlight Baruch Brody's \"an act of euthanasia is one in which one person ... (A) kills another person (B) for the benefit of the second person, who actually does benefit from being killed\".\n\nDraper argued that any definition of euthanasia must incorporate four elements: an agent and a subject; an intention; a causal proximity, such that the actions of the agent lead to the outcome; and an outcome. Based on this, she offered a definition incorporating those elements, stating that euthanasia \"must be defined as death that results from the intention of one person to kill another person, using the most gentle and painless means possible, that is motivated solely by the best interests of the person who dies.\" Prior to Draper, Beauchamp and Davidson had also offered a definition that includes these elements. Their definition specifically discounts fetuses to distinguish between abortions and euthanasia:\n\nWreen, in part responding to Beauchamp and Davidson, offered a six-part definition:\n\nWreen also considered a seventh requirement: \"(7) The good specified in (6) is, or at least includes, the avoidance of evil\", although as Wreen noted in the paper, he was not convinced that the restriction was required.\n\nIn discussing his definition, Wreen noted the difficulty of justifying euthanasia when faced with the notion of the subject's \"right to life\". In response, Wreen argued that euthanasia has to be voluntary, and that \"involuntary euthanasia is, as such, a great wrong\". Other commentators incorporate consent more directly into their definitions. For example, in a discussion of euthanasia presented in 2003 by the European Association of Palliative Care (EPAC) Ethics Task Force, the authors offered: \"Medicalized killing of a person without the person's consent, whether nonvoluntary (where the person is unable to consent) or involuntary (against the person's will) is not euthanasia: it is murder. Hence, euthanasia can be voluntary only.\" Although the EPAC Ethics Task Force argued that both non-voluntary and involuntary euthanasia could not be included in the definition of euthanasia, there is discussion in the literature about excluding one but not the other.\n\nEuthanasia may be classified into three types, according to whether a person gives informed consent: voluntary, non-voluntary and involuntary.\n\nThere is a debate within the medical and bioethics literature about whether or not the non-voluntary (and by extension, involuntary) killing of patients can be regarded as euthanasia, irrespective of intent or the patient's circumstances. In the definitions offered by Beauchamp and Davidson and, later, by Wreen, consent on the part of the patient was not considered as one of their criteria, although it may have been required to justify euthanasia. However, others see consent as essential.\n\nVoluntary euthanasia is conducted with the consent of the patient. Active voluntary euthanasia is legal in Belgium, Luxembourg and the Netherlands. Passive voluntary euthanasia is legal throughout the US per \"Cruzan v. Director, Missouri Department of Health\". When the patient brings about his or her own death with the assistance of a physician, the term assisted suicide is often used instead. Assisted suicide is legal in Switzerland and the U.S. states of California, Oregon, Washington, Montana and Vermont.\n\nNon-voluntary euthanasia is conducted when the consent of the patient is unavailable. Examples include child euthanasia, which is illegal worldwide but decriminalised under certain specific circumstances in the Netherlands under the Groningen Protocol.\n\nInvoluntary euthanasia is conducted against the will of the patient.\n\nVoluntary, non-voluntary and involuntary types can be further divided into passive or active variants. Passive euthanasia entails the withholding treatment necessary for the continuance of life. Active euthanasia entails the use of lethal substances or forces (such as administering a lethal injection), and is the more controversial. While some authors consider these terms to be misleading and unhelpful, they are nonetheless commonly used. In some cases, such as the administration of increasingly necessary, but toxic doses of painkillers, there is a debate whether or not to regard the practice as active or passive.\n\nEuthanasia was practiced in Ancient Greece and Rome: for example, hemlock was employed as a means of hastening death on the island of Kea, a technique also employed in Marseilles. Euthanasia, in the sense of the deliberate hastening of a person's death, was supported by Socrates, Plato and Seneca the Elder in the ancient world, although Hippocrates appears to have spoken against the practice, writing \"I will not prescribe a deadly drug to please someone, nor give advice that may cause his death\" (noting there is some debate in the literature about whether or not this was intended to encompass euthanasia).\n\nThe term \"euthanasia\" in the earlier sense of supporting someone as they died, was used for the first time by Francis Bacon. In his work, \"Euthanasia medica\", he chose this ancient Greek word and, in doing so, distinguished between \"euthanasia interior\", the preparation of the soul for death, and \"euthanasia exterior\", which was intended to make the end of life easier and painless, in exceptional circumstances by shortening life. That the ancient meaning of an easy death came to the fore again in the early modern period can be seen from its definition in the 18th century \"Zedlers Universallexikon\":\n\nEuthanasia: a very gentle and quiet death, which happens without painful convulsions. The word comes from ευ, \"bene\", well, and θανατος, \"mors\", death.\n\nThe concept of euthanasia in the sense of alleviating the process of death goes back to the medical historian, Karl Friedrich Heinrich Marx, who drew on Bacon's philosophical ideas. According to Marx, a doctor had a moral duty to ease the suffering of death through encouragement, support and mitigation using medication. Such an \"alleviation of death\" reflected the contemporary \"zeitgeist\", but was brought into the medical canon of responsibility for the first time by Marx. Marx also stressed the distinction between the theological care of the soul of sick people from the physical care and medical treatment by doctors.\n\nEuthanasia in its modern sense has always been strongly opposed in the Judeo-Christian tradition. Thomas Aquinas opposed both and argued that the practice of euthanasia contradicted our natural human instincts of survival, as did Francois Ranchin (1565–1641), a French physician and professor of medicine, and Michael Boudewijns (1601–1681), a physician and teacher. Other voices argued for euthanasia, such as John Donne in 1624, and euthanasia continued to be practised. In 1678, the publication of Caspar Questel's \"De pulvinari morientibus non-subtrahend\", (\"\"On the pillow of which the dying should not be deprived\"\"), initiated debate on the topic. Questel described various customs which were employed at the time to hasten the death of the dying, (including the sudden removal of a pillow, which was believed to accelerate death), and argued against their use, as doing so was \"against the laws of God and Nature\". This view was shared by others who followed, including Philipp Jakob Spener, Veit Riedlin and Johann Georg Krünitz. Despite opposition, euthanasia continued to be practised, involving techniques such as bleeding, suffocation, and removing people from their beds to be placed on the cold ground.\n\nSuicide and euthanasia became more accepted during the Age of Enlightenment. Thomas More wrote of euthanasia in \"Utopia\", although it is not clear if More was intending to endorse the practice. Other cultures have taken different approaches: for example, in Japan suicide has not traditionally been viewed as a sin, as it is used in cases of honor, and accordingly, the perceptions of euthanasia are different from those in other parts of the world.\n\nIn the mid-1800s, the use of morphine to treat \"the pains of death\" emerged, with John Warren recommending its use in 1848. A similar use of chloroform was revealed by Joseph Bullar in 1866. However, in neither case was it recommended that the use should be to hasten death. In 1870 Samuel Williams, a schoolteacher, initiated the contemporary euthanasia debate through a speech given at the Birmingham Speculative Club in England, which was subsequently published in a one-off publication entitled \"Essays of the Birmingham Speculative Club\", the collected works of a number of members of an amateur philosophical society. Williams' proposal was to use chloroform to deliberately hasten the death of terminally ill patients:\n\nThe essay was favourably reviewed in \"The Saturday Review\", but an editorial against the essay appeared in \"The Spectator\". From there it proved to be influential, and other writers came out in support of such views: Lionel Tollemache wrote in favour of euthanasia, as did Annie Besant, the essayist and reformer who later became involved with the National Secular Society, considering it a duty to society to \"die voluntarily and painlessly\" when one reaches the point of becoming a 'burden'. \"Popular Science\" analyzed the issue in May 1873, assessing both sides of the argument. Kemp notes that at the time, medical doctors did not participate in the discussion; it was \"essentially a philosophical enterprise ... tied inextricably to a number of objections to the Christian doctrine of the sanctity of human life\".\n\nThe rise of the euthanasia movement in the United States coincided with the so-called Gilded Age, a time of social and technological change that encompassed an \"individualistic conservatism that praised laissez-faire economics, scientific method, and rationalism\", along with major depressions, industrialisation and conflict between corporations and labour unions. It was also the period in which the modern hospital system was developed, which has been seen as a factor in the emergence of the euthanasia debate.\n\nRobert Ingersoll argued for euthanasia, stating in 1894 that where someone is suffering from a terminal illness, such as terminal cancer, they should have a right to end their pain through suicide. Felix Adler offered a similar approach, although, unlike Ingersoll, Adler did not reject religion. In fact, he argued from an Ethical Culture framework. In 1891, Adler argued that those suffering from overwhelming pain should have the right to commit suicide, and, furthermore, that it should be permissible for a doctor to assist – thus making Adler the first \"prominent American\" to argue for suicide in cases where people were suffering from chronic illness. Both Ingersoll and Adler argued for voluntary euthanasia of adults suffering from terminal ailments. Dowbiggin argues that by breaking down prior moral objections to euthanasia and suicide, Ingersoll and Adler enabled others to stretch the definition of euthanasia.\n\nThe first attempt to legalise euthanasia took place in the United States, when Henry Hunt introduced legislation into the General Assembly of Ohio in 1906. Hunt did so at the behest of Anna Sophina Hall, a wealthy heiress who was a major figure in the euthanasia movement during the early 20th century in the United States. Hall had watched her mother die after an extended battle with liver cancer, and had dedicated herself to ensuring that others would not have to endure the same suffering. Towards this end she engaged in an extensive letter writing campaign, recruited Lurana Sheldon and Maud Ballington Booth, and organised a debate on euthanasia at the annual meeting of the American Humane Association in 1905 – described by Jacob Appel as the first significant public debate on the topic in the 20th century.\n\nHunt's bill called for the administration of an anesthetic to bring about a patient's death, so long as the person is of lawful age and sound mind, and was suffering from a fatal injury, an irrevocable illness, or great physical pain. It also required that the case be heard by a physician, required informed consent in front of three witnesses, and required the attendance of three physicians who had to agree that the patient's recovery was impossible. A motion to reject the bill outright was voted down, but the bill failed to pass, 79 to 23.\n\nAlong with the Ohio euthanasia proposal, in 1906 Assemblyman Ross Gregory introduced a proposal to permit euthanasia to the Iowa legislature. However, the Iowa legislation was broader in scope than that offered in Ohio. It allowed for the death of any person of at least ten years of age who suffered from an ailment that would prove fatal and cause extreme pain, should they be of sound mind and express a desire to artificially hasten their death. In addition, it allowed for infants to be euthanised if they were sufficiently deformed, and permitted guardians to request euthanasia on behalf of their wards. The proposed legislation also imposed penalties on physicians who refused to perform euthanasia when requested: a 6–12 month prison term and a fine of between $200 and $1,000. The proposal proved to be controversial. It engendered considerable debate and failed to pass, having been withdrawn from consideration after being passed to the Committee on Public Health.\n\nAfter 1906 the euthanasia debate reduced in intensity, resurfacing periodically, but not returning to the same level of debate until the 1930s in the United Kingdom.\n\nEuthanasia opponent Ian Dowbiggin argues that the early membership of the Euthanasia Society of America (ESA) reflected how many perceived euthanasia at the time, often seeing it as a eugenics matter rather than an issue concerning individual rights. Dowbiggin argues that not every eugenist joined the ESA \"solely for eugenic reasons\", but he postulates that there were clear ideological connections between the eugenics and euthanasia movements.\n\nThe Voluntary Euthanasia Legalisation Society was founded in 1935 by Charles Killick Millard (now called Dignity in Dying). The movement campaigned for the legalisation of euthanasia in Great Britain.\n\nIn January 1936, King George V was given a fatal dose of morphine and cocaine to hasten his death. At the time he was suffering from cardio-respiratory failure, and the decision to end his life was made by his physician, Lord Dawson. Although this event was kept a secret for over 50 years, the death of George V coincided with proposed legislation in the House of Lords to legalise euthanasia.\n\nA 24 July 1939 killing of a severely disabled infant in Nazi Germany was described in a BBC \"Genocide Under the Nazis Timeline\" as the first \"state-sponsored euthanasia\". Parties that consented to the killing included Hitler's office, the parents, and the Reich Committee for the Scientific Registration of Serious and Congenitally Based Illnesses. \"The Telegraph\" noted that the killing of the disabled infant—whose name was Gerhard Kretschmar, born blind, with missing limbs, subject to convulsions, and reportedly \"an idiot\"— provided \"the rationale for a secret Nazi decree that led to 'mercy killings' of almost 300,000 mentally and physically handicapped people\". While Kretchmar's killing received parental consent, most of the 5,000 to 8,000 children killed afterwards were forcibly taken from their parents.\n\nThe \"euthanasia campaign\" of mass murder gathered momentum on 14 January 1940 when the \"handicapped\" were killed with gas vans and killing centres, eventually leading to the deaths of 70,000 adult Germans. Professor Robert Jay Lifton, author of \"The Nazi Doctors\" and a leading authority on the T4 program, contrasts this program with what he considers to be a genuine euthanasia. He explains that the Nazi version of \"euthanasia\" was based on the work of Adolf Jost, who published \"The Right to Death\" (Das Recht auf den Tod) in 1895. Lifton writes: \n\nJost argued that control over the death of the individual must ultimately belong to the social organism, the state. This concept is in direct opposition to the Anglo-American concept of euthanasia, which emphasizes the \"individual's\" 'right to die' or 'right to death' or 'right to his or her own death,' as the ultimate human claim. In contrast, Jost was pointing to the state's right to kill. ... Ultimately the argument was biological: 'The rights to death [are] the key to the fitness of life.' The state must own death—must kill—in order to keep the social organism alive and healthy.\n\nIn modern terms, the use of \"euthanasia\" in the context of Action T4 is seen to be a euphemism to disguise a program of genocide, in which people were killed on the grounds of \"disabilities, religious beliefs, and discordant individual values\". Compared to the discussions of euthanasia that emerged post-war, the Nazi program may have been worded in terms that appear similar to the modern use of \"euthanasia\", but there was no \"mercy\" and the patients were not necessarily terminally ill. Despite these differences, historian and euthanasia opponent Ian Dowbiggin writes that \"the origins of Nazi euthanasia, like those of the American euthanasia movement, predate the Third Reich and were intertwined with the history of eugenics and Social Darwinism, and with efforts to discredit traditional morality and ethics.\"\n\nOn 6 January 1949, the Euthanasia Society of America presented to the New York State Legislature a petition to legalize euthanasia, signed by 379 leading Protestant and Jewish ministers, the largest group of religious leaders ever to have taken this stance. A similar petition had been sent to the New York Legislature in 1947, signed by approximately 1,000 New York physicians. Roman Catholic religious leaders criticized the petition, saying that such a bill would \"legalize a suicide-murder pact\" and a \"rationalization of the fifth commandment of God, 'Thou Shalt Not Kill.'\" The Right Reverend Robert E. McCormick stated that\n\nThe petition brought tensions between the American Euthanasia Society and the Catholic Church to a head that contributed to a climate of anti-Catholic sentiment generally, regarding issues such as birth control, eugenics, and population control. However, the petition did not result in any legal changes.\n\nHistorically, the euthanasia debate has tended to focus on a number of key concerns. According to euthanasia opponent Ezekiel Emanuel, proponents of euthanasia have presented four main arguments: a) that people have a right to self-determination, and thus should be allowed to choose their own fate; b) assisting a subject to die might be a better choice than requiring that they continue to suffer; c) the distinction between passive euthanasia, which is often permitted, and active euthanasia, which is not substantive (or that the underlying principle–the doctrine of double effect–is unreasonable or unsound); and d) permitting euthanasia will not necessarily lead to unacceptable consequences. Pro-euthanasia activists often point to countries like the Netherlands and Belgium, and states like Oregon, where euthanasia has been legalized, to argue that it is mostly unproblematic.\n\nSimilarly, Emanuel argues that there are four major arguments presented by opponents of euthanasia: a) not all deaths are painful; b) alternatives, such as cessation of active treatment, combined with the use of effective pain relief, are available; c) the distinction between active and passive euthanasia is morally significant; and d) legalising euthanasia will place society on a slippery slope, which will lead to unacceptable consequences. In fact, in Oregon, in 2013, pain wasn't one of the top five reasons people sought euthanasia. Top reasons were a loss of dignity, and a fear of burdening others.\n\nIn the United States in 2013, 47% nationwide supported doctor-assisted suicide. This included 32% of Latinos, 29% of African-Americans, and almost nobody with disabilities.\n\nA 2015 Populus poll in the United Kingdom found broad public support for assisted dying. 82% of people supported the introduction of assisted dying laws, including 86% of people with disabilities.\n\nOne concern is that euthanasia might undermine filial responsibility. In some countries, adult children of impoverished parents are legally entitled to support payments under filial responsibility laws. Thirty out of the fifty United States as well as France, Germany, Singapore, and Taiwan have filial responsibility laws.\n\nWest's \"Encyclopedia of American Law\" states that \"a 'mercy killing' or euthanasia is generally considered to be a criminal homicide\" and is normally used as a synonym of homicide committed at a request made by the patient.\n\nThe judicial sense of the term \"homicide\" includes any intervention undertaken with the express intention of ending a life, even to relieve intractable suffering. Not all homicide is unlawful. Two designations of homicide that carry no criminal punishment are justifiable and excusable homicide. In most countries this is not the status of euthanasia. The term \"euthanasia\" is usually confined to the active variety; the University of Washington website states that \"euthanasia generally means that the physician would act directly, for instance by giving a lethal injection, to end the patient's life\". Physician-assisted suicide is thus not classified as euthanasia by the US State of Oregon, where it is legal under the Oregon Death with Dignity Act, and despite its name, it is not legally classified as suicide either. Unlike physician-assisted suicide, withholding or withdrawing life-sustaining treatments with patient consent (voluntary) is almost unanimously considered, at least in the United States, to be legal. The use of pain medication to relieve suffering, even if it hastens death, has been held as legal in several court decisions.\n\nSome governments around the world have legalized voluntary euthanasia but most commonly it is still considered to be criminal homicide. In the Netherlands and Belgium, where euthanasia has been legalized, it still remains homicide although it is not prosecuted and not punishable if the perpetrator (the doctor) meets certain legal conditions.\n\nIn a historic judgment, the Supreme court of India legalized passive euthanasia. The apex court remarked in the judgment that the Constitution of India values liberty, dignity, autonomy, and privacy. A bench headed by Chief Justice Dipak Misra delivered a unanimous judgment.\n\nA 2010 survey in the United States of more than 10,000 physicians found that 16.3% of physicians would consider halting life-sustaining therapy because the family demanded it, even if they believed that it was premature. Approximately 54.5% would not, and the remaining 29.2% responded \"it depends\". The study also found that 45.8% of physicians agreed that physician-assisted suicide should be allowed in some cases; 40.7% did not, and the remaining 13.5% felt it depended.\n\nIn the United Kingdom, the assisted dying campaign group Dignity in Dying cites research in which 54% of General Practitioners support or are neutral towards a law change on assisted dying. Similarly, a 2017 Doctors.net.uk poll reported in the British Medical Journal stated that 55% of doctors believe assisted dying, in defined circumstances, should be legalised in the UK.\n\nOne concern among healthcare professionals is the possibility of being asked to participate in euthanasia in a situation where they personally believe it to be wrong. In a 1996 study of 852 nurses in adult ICUs, 19% admitted to participating in euthanasia. 30% of those who admitted to it also believed that euthanasia is unethical.\n\nThe Roman Catholic Church condemns euthanasia and assisted suicide as morally wrong. It states that, \"intentional euthanasia, whatever its forms or motives, is murder. It is gravely contrary to the dignity of the human person and to the respect due to the living God, his Creator\". Because of this, the practice is unacceptable within the Church. The Orthodox Church in America, along with other Eastern Orthodox Churches, also opposes euthanasia stating that it must be condemned as murder stating that, \"Euthanasia is the deliberate cessation to end human life.\"\n\nMany non-Catholic churches in the United States take a stance against euthanasia. Among Protestant denominations, the Episcopal Church passed a resolution in 1991 opposing euthanasia and assisted suicide stating that it is \"morally wrong and unacceptable to take a human life to relieve the suffering caused by incurable illnesses.\" Other Protestant churches which oppose euthanasia include:\nBULLET::::- Assemblies of God\nBULLET::::- Church of Jesus Christ of Latter Day Saints\nBULLET::::- Church of the Nazarene\nBULLET::::- Evangelical Lutheran Church in America\nBULLET::::- Presbyterian Church in America\nBULLET::::- Lutheran Church–Missouri Synod\nBULLET::::- Reformed Church in America\nBULLET::::- Salvation Army\nBULLET::::- Seventh-day Adventist Church\nBULLET::::- Southern Baptist Convention\nBULLET::::- United Methodist Church\nThe Church of England accepts passive euthanasia under some circumstances, but is strongly against active euthanasia, and has led opposition against recent attempt to legalise it. The United Church of Canada accepts passive euthanasia under some circumstances, but is in general against active euthanasia, with growing acceptance now that active euthanasia has been partly legalised in Canada..\n\nEuthanasia is a complex issue in Islamic theology; however, in general it is considered contrary to Islamic law and holy texts. Among interpretations of the Koran and Hadith, the early termination of life is a crime, be it by suicide or helping one commit suicide. The various positions on the cessation of medical treatment are mixed and considered a different class of action than direct termination of life, especially if the patient is suffering. Suicide and euthanasia are both crimes in almost all Muslim majority countries.\n\nThere is much debate on the topic of euthanasia in Judaic theology, ethics, and general opinion (especially in Israel and the United States). Passive euthanasia was declared legal by Israel's highest court under certain conditions and has reached some level of acceptance. Active euthanasia remains illegal, however the topic is actively under debate with no clear consensus through legal, ethical, theological and spiritual perspectives.\n\n\nBULLET::::- Physician assisted death from \"The Hastings Center\"\n"}
{"id": "9588", "url": "https://en.wikipedia.org/wiki?curid=9588", "title": "Extraterrestrial life", "text": "Extraterrestrial life\n\nExtraterrestrial life is hypothetical life which may occur outside of Earth and which did not originate on Earth. Such life might range from simple prokaryotes (or comparable life forms) to beings with civilizations far more advanced than humanity. The Drake equation speculates about the existence of intelligent life elsewhere in the universe. The science of extraterrestrial life in all its forms is known as astrobiology.\n\nSince the mid-20th century, active ongoing research has taken place to look for signs of extraterrestrial life. This encompasses a search for current and historic extraterrestrial life, and a narrower search for extraterrestrial intelligent life. Depending on the category of search, methods range from the analysis of telescope and specimen data to radios used to detect and send communication signals.\n\nThe concept of extraterrestrial life, and particularly extraterrestrial intelligence, has had a major cultural impact, chiefly in works of science fiction. Over the years, science fiction has introduced a number of theoretical ideas, each having a wide range of possibilities. Many have piqued public interest in the possibilities of extraterrestrial life. One particular concern is the wisdom of attempting communication with extraterrestrial intelligence. Some encourage aggressive methods to make contact with intelligent extraterrestrial life. Others argue to do so may give away the location of Earth, making an invasion possible in the future.\n\nAlien life, such as microorganisms, has been hypothesized to exist in the Solar System and throughout the universe. This hypothesis relies on the vast size and consistent physical laws of the observable universe. According to this argument, made by scientists such as Carl Sagan and Stephen Hawking, as well as notable personalities such as Winston Churchill, it would be improbable for life \"not\" to exist somewhere other than Earth. This argument is embodied in the Copernican principle, which states that Earth does not occupy a unique position in the Universe, and the mediocrity principle, which states that there is nothing special about life on Earth. The chemistry of life may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the universe was only 10–17 million years old. Life may have emerged independently at many places throughout the universe. Alternatively, life may have formed less frequently, then spread—by meteoroids, for example—between habitable planets in a process called panspermia. In any case, complex organic molecules may have formed in the protoplanetary disk of dust grains surrounding the Sun before the formation of Earth. According to these studies, this process may occur outside Earth on several planets and moons of the Solar System and on planets of other stars.\n\nSince the 1950s, astronomers have proposed that \"habitable zones\" around stars are the most likely places for life to exist. Numerous discoveries of such zones since 2007 have generated numerical estimates of many billions of planets with Earth-like compositions. , only a few planets had been discovered in these zones. Nonetheless, on 4 November 2013, astronomers reported, based on \"Kepler\" space mission data, that there could be as many as 40 billion Earth-sized planets orbiting in the habitable zones of Sun-like stars and red dwarfs in the Milky Way, 11 billion of which may be orbiting Sun-like stars. The nearest such planet may be 12 light-years away, according to the scientists. Astrobiologists have also considered a \"follow the energy\" view of potential habitats.\n\nA study published in 2017 suggests that due to how complexity evolved in species on Earth, the level of predictability for alien evolution elsewhere would make them look similar to life on our planet. One of the study authors, Sam Levin, notes \"Like humans, we predict that they are made-up of a hierarchy of entities, which all cooperate to produce an alien. At each level of the organism there will be mechanisms in place to eliminate conflict, maintain cooperation, and keep the organism functioning. We can even offer some examples of what these mechanisms will be.\" There is also research in assessing the capacity of life for developing intelligence. It has been suggested that this capacity arises with the number of potential niches a planet contains, and that the complexity of life itself is reflected in the information density of planetary environments, which in turn can be computed from its niches.\n\nLife on Earth requires water as a solvent in which biochemical reactions take place. Sufficient quantities of carbon and other elements, along with water, might enable the formation of living organisms on terrestrial planets with a chemical make-up and temperature range similar to that of Earth. Life based on ammonia (rather than water) has been suggested as an alternative, though this solvent appears less suitable than water. It is also conceivable that there are forms of life whose solvent is a liquid hydrocarbon, such as methane, ethane or propane.\n\nAbout 29 chemical elements play active roles in living organisms on Earth. About 95% of living matter is built upon only six elements: carbon, hydrogen, nitrogen, oxygen, phosphorus and sulfur. These six elements form the basic building blocks of virtually all life on Earth, whereas most of the remaining elements are found only in trace amounts. The unique characteristics of carbon make it unlikely that it could be replaced, even on another planet, to generate the biochemistry necessary for life. The carbon atom has the unique ability to make four strong chemical bonds with other atoms, including other carbon atoms. These covalent bonds have a direction in space, so that carbon atoms can form the skeletons of complex 3-dimensional structures with definite architectures such as nucleic acids and proteins. Carbon forms more compounds than all other elements combined. The great versatility of the carbon atom, and its abundance in the visible universe, makes it the element most likely to provide the bases—even exotic ones—for the chemical composition of life on other planets.\n\nSome bodies in the Solar System have the potential for an environment in which extraterrestrial life can exist, particularly those with possible subsurface oceans. Should life be discovered elsewhere in the Solar System, astrobiologists suggest that it will more likely be in the form of extremophile microorganisms. According to NASA's 2015 Astrobiology Strategy, \"Life on other worlds is most likely to include microbes, and any complex living system elsewhere is likely to have arisen from and be founded upon microbial life. Important insights on the limits of microbial life can be gleaned from studies of microbes on modern Earth, as well as their ubiquity and ancestral characteristics.\" Researchers found a stunning array of subterranean organisms, mostly microbial, deep underground and estimate that approximately 70 percent of the total number of Earth's bacteria and archaea organisms live within the Earth's crust. Rick Colwell, a member of the Deep Carbon Observatory team from Oregon State University, told the BBC: \"I think it’s probably reasonable to assume that the subsurface of other planets and their moons are habitable, especially since we’ve seen here on Earth that organisms can function far away from sunlight using the energy provided directly from the rocks deep underground\".\n\nMars may have niche subsurface environments where microbial life might exist. A subsurface marine environment on Jupiter's moon Europa might be the most likely habitat in the Solar System, outside Earth, for extremophile microorganisms.\n\nThe panspermia hypothesis proposes that life elsewhere in the Solar System may have a common origin. If extraterrestrial life was found on another body in the Solar System, it could have originated from Earth just as life on Earth could have been seeded from elsewhere (exogenesis). The first known mention of the term 'panspermia' was in the writings of the 5th century BC Greek philosopher Anaxagoras. In the 19th century it was again revived in modern form by several scientists, including Jöns Jacob Berzelius (1834), Kelvin (1871), Hermann von Helmholtz (1879) and, somewhat later, by Svante Arrhenius (1903).\nSir Fred Hoyle (1915–2001) and Chandra Wickramasinghe (born 1939) are important proponents of the hypothesis who further contended that life forms continue to enter Earth's atmosphere, and may be responsible for epidemic outbreaks, new diseases, and the genetic novelty necessary for macroevolution.\n\nDirected panspermia concerns the deliberate transport of microorganisms in space, sent to Earth to start life here, or sent from Earth to seed new stellar systems with life.\nThe Nobel prize winner Francis Crick, along with Leslie Orgel proposed that seeds of life may have been purposely spread by an advanced extraterrestrial civilization, but considering an early \"RNA world\" Crick noted later that life may have originated on Earth.\n\nIn the early 20th century, Venus was often thought to be similar to Earth in terms of habitability, but observations since the beginning of the Space Age have revealed that Venus's surface is inhospitable to Earth-like life. However, between the altitudes of 50 and 65 kilometers, the pressure and temperature are Earth-like, and it has been speculated that thermoacidophilic extremophile microorganisms might exist in the acidic upper layers of the Venusian atmosphere. Furthermore, Venus likely had liquid water on its surface for at least a few million years after its formation.\n\nLife on Mars has been long speculated. Liquid water is widely thought to have existed on Mars in the past, and now can occasionally be found as low-volume liquid brines in shallow Martian soil. The origin of the potential biosignature of methane observed in Mars' atmosphere is unexplained, although hypotheses not involving life have also been proposed.\n\nThere is evidence that Mars had a warmer and wetter past: dried-up river beds, polar ice caps, volcanoes, and minerals that form in the presence of water have all been found. Nevertheless, present conditions on Mars' subsurface may support life. Evidence obtained by the \"Curiosity\" rover studying Aeolis Palus, Gale Crater in 2013 strongly suggests an ancient freshwater lake that could have been a hospitable environment for microbial life.\n\nCurrent studies on Mars by the \"Curiosity\" and \"Opportunity\" rovers are searching for evidence of ancient life, including a biosphere based on autotrophic, chemotrophic and/or chemolithoautotrophic microorganisms, as well as ancient water, including fluvio-lacustrine environments (plains related to ancient rivers or lakes) that may have been habitable. The search for evidence of habitability, taphonomy (related to fossils), and organic carbon on Mars is now a primary NASA objective.\n\nCeres, the only dwarf planet in the asteroid belt, has a thin water-vapor atmosphere. Frost on the surface may also have been detected in the form of bright spots. The presence of water on Ceres had led to speculation that life may be possible there.\n\nCarl Sagan and others in the 1960s and 1970s computed conditions for hypothetical microorganisms living in the atmosphere of Jupiter. The intense radiation and other conditions, however, do not appear to permit encapsulation and molecular biochemistry, so life there is thought unlikely. In contrast, some of Jupiter's moons may have habitats capable of sustaining life. Scientists have indications that heated subsurface oceans of liquid water may exist deep under the crusts of the three outer Galilean moons—Europa, Ganymede, and Callisto. The EJSM/Laplace mission is planned to determine the habitability of these environments.\n\nJupiter's moon Europa has been subject to speculation about the existence of life due to the strong possibility of a liquid water ocean beneath its ice surface. Hydrothermal vents on the bottom of the ocean, if they exist, may warm the water and could be capable of supporting nutrients and energy to microorganisms. It is also possible that Europa could support aerobic macrofauna using oxygen created by cosmic rays impacting its surface ice.\n\nThe case for life on Europa was greatly enhanced in 2011 when it was discovered that vast lakes exist within Europa's thick, icy shell. Scientists found that ice shelves surrounding the lakes appear to be collapsing into them, thereby providing a mechanism through which life-forming chemicals created in sunlit areas on Europa's surface could be transferred to its interior.\n\nOn 11 December 2013, NASA reported the detection of \"clay-like minerals\" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa. The presence of the minerals may have been the result of a collision with an asteroid or comet according to the scientists. The \"Europa Clipper\", which would assess the habitability of Europa, is planned for launch in 2025. Europa's subsurface ocean is considered the best target for the discovery of life.\n\nLike Jupiter, Saturn is not likely to host life. However, Titan and Enceladus have been speculated to have possible habitats supportive of life.\n\nEnceladus, a moon of Saturn, has some of the conditions for life, including geothermal activity and water vapor, as well as possible under-ice oceans heated by tidal effects. The \"Cassini–Huygens\" probe detected carbon, hydrogen, nitrogen and oxygen—all key elements for supporting life—during its 2005 flyby through one of Enceladus's geysers spewing ice and gas. The temperature and density of the plumes indicate a warmer, watery source beneath the surface.\n\nTitan, the largest moon of Saturn, is the only known moon in the Solar System with a significant atmosphere. Data from the \"Cassini–Huygens\" mission refuted the hypothesis of a global hydrocarbon ocean, but later demonstrated the existence of liquid hydrocarbon lakes in the polar regions—the first stable bodies of surface liquid discovered outside Earth. Analysis of data from the mission has uncovered aspects of atmospheric chemistry near the surface that are consistent with—but do not prove—the hypothesis that organisms there if present, could be consuming hydrogen, acetylene and ethane, and producing methane.\n\nSmall Solar System bodies have also been speculated to host habitats for extremophiles. Fred Hoyle and Chandra Wickramasinghe have proposed that microbial life might exist on comets and asteroids.\n\nModels of heat retention and heating via radioactive decay in smaller icy Solar System bodies suggest that Rhea, Titania, Oberon, Triton, Pluto, Eris, Sedna, and Orcus may have oceans underneath solid icy crusts approximately 100 km thick. Of particular interest in these cases is the fact that the models indicate that the liquid layers are in direct contact with the rocky core, which allows efficient mixing of minerals and salts into the water. This is in contrast with the oceans that may be inside larger icy satellites like Ganymede, Callisto, or Titan, where layers of high-pressure phases of ice are thought to underlie the liquid water layer.\n\nHydrogen sulfide has been proposed as a hypothetical solvent for life and is quite plentiful on Jupiter's moon Io, and may be in liquid form a short distance below the surface.\n\nThe scientific search for extraterrestrial life is being carried out both directly and indirectly. , 3,667 exoplanets in 2,747 systems have been identified, and other planets and moons in our own solar system hold the potential for hosting primitive life such as microorganisms.\n\nScientists search for biosignatures within the Solar System by studying planetary surfaces and examining meteorites. Some claim to have identified evidence that microbial life has existed on Mars. An experiment on the two Viking Mars landers reported gas emissions from heated Martian soil samples that some scientists argue are consistent with the presence of living microorganisms. Lack of corroborating evidence from other experiments on the same samples suggests that a non-biological reaction is a more likely hypothesis. In 1996, a controversial report stated that structures resembling nanobacteria were discovered in a meteorite, ALH84001, formed of rock ejected from Mars.\n\nIn February 2005 NASA scientists reported they may have found some evidence of present life on Mars. The two scientists, Carol Stoker and Larry Lemke of NASA's Ames Research Center, based their claim on methane signatures found in Mars's atmosphere resembling the methane production of some forms of primitive life on Earth, as well as on their own study of primitive life near the Rio Tinto river in Spain. NASA officials soon distanced NASA from the scientists' claims, and Stoker herself backed off from her initial assertions. Though such methane findings are still debated, support among some scientists for the existence of life on Mars exists.\n\nIn November 2011 NASA launched the Mars Science Laboratory that landed the \"Curiosity\" rover on Mars. It is designed to assess the past and present habitability on Mars using a variety of scientific instruments. The rover landed on Mars at Gale Crater in August 2012.\n\nThe Gaia hypothesis stipulates that any planet with a robust population of life will have an atmosphere in chemical disequilibrium, which is relatively easy to determine from a distance by spectroscopy. However, significant advances in the ability to find and resolve light from smaller rocky worlds near their star are necessary before such spectroscopic methods can be used to analyze extrasolar planets. To that effect, the Carl Sagan Institute was founded in 2014 and is dedicated to the atmospheric characterization of exoplanets in circumstellar habitable zones. Planetary spectroscopic data will be obtained from telescopes like WFIRST and ELT.\n\nIn August 2011, findings by NASA, based on studies of meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules), building blocks for life as we know it, may be formed extraterrestrially in outer space. In October 2011, scientists reported that cosmic dust contains complex organic matter (\"amorphous organic solids with a mixed aromatic-aliphatic structure\") that could be created naturally, and rapidly, by stars. One of the scientists suggested that these compounds may have been related to the development of life on Earth and said that, \"If this is the case, life on Earth may have had an easier time getting started as these organics can serve as basic ingredients for life.\"\n\nIn August 2012, and in a world first, astronomers at Copenhagen University reported the detection of a specific sugar molecule, glycolaldehyde, in a distant star system. The molecule was found around the protostellar binary \"IRAS 16293-2422\", which is located 400 light years from Earth. Glycolaldehyde is needed to form ribonucleic acid, or RNA, which is similar in function to DNA. This finding suggests that complex organic molecules may form in stellar systems prior to the formation of planets, eventually arriving on young planets early in their formation.\n\nProjects such as SETI are monitoring the galaxy for electromagnetic interstellar communications from civilizations on other worlds. If there is an advanced extraterrestrial civilization, there is no guarantee that it is transmitting radio communications in the direction of Earth or that this information could be interpreted as such by humans. The length of time required for a signal to travel across the vastness of space means that any signal detected would come from the distant past.\n\nThe presence of heavy elements in a star's light-spectrum is another potential biosignature; such elements would (in theory) be found if the star was being used as an incinerator/repository for nuclear waste products.\n\nSome astronomers search for extrasolar planets that may be conducive to life, narrowing the search to terrestrial planets within the habitable zone of their star. Since 1992 over two thousand exoplanets have been discovered ( planets in planetary systems including multiple planetary systems as of ).\nThe extrasolar planets so far discovered range in size from that of terrestrial planets similar to Earth's size to that of gas giants larger than Jupiter. The number of observed exoplanets is expected to increase greatly in the coming years.\n\nThe \"Kepler\" space telescope has also detected a few thousand candidate planets, of which about 11% may be false positives.\n\nThere is at least one planet on average per star. About 1 in 5 Sun-like stars have an \"Earth-sized\" planet in the habitable zone, with the nearest expected to be within 12 light-years distance from Earth. Assuming 200 billion stars in the Milky Way, that would be 11 billion potentially habitable Earth-sized planets in the Milky Way, rising to 40 billion if red dwarfs are included. The rogue planets in the Milky Way possibly number in the trillions.\n\nThe nearest known exoplanet is Proxima Centauri b, located from Earth in the southern constellation of Centaurus.\n\n, the least massive planet known is PSR B1257+12 A, which is about twice the mass of the Moon. The most massive planet listed on the NASA Exoplanet Archive is DENIS-P J082303.1-491201 b, about 29 times the mass of Jupiter, although according to most definitions of a planet, it is too massive to be a planet and may be a brown dwarf instead. Almost all of the planets detected so far are within the Milky Way, but there have also been a few possible detections of extragalactic planets. The study of planetary habitability also considers a wide range of other factors in determining the suitability of a planet for hosting life.\n\nOne sign that a planet probably already contains life is the presence of an atmosphere with significant amounts of oxygen, since that gas is highly reactive and generally would not last long without constant replenishment. This replenishment occurs on Earth through photosynthetic organisms. One way to analyze the atmosphere of an exoplanet is through spectrography when it transits its star, though this might only be feasible with dim stars like white dwarfs.\n\nThe science of astrobiology considers life on Earth as well, and in the broader astronomical context. In 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia, when the young Earth was about 400 million years old. According to one of the researchers, \"If life arose relatively quickly on Earth, then it could be common in the universe.\"\n\nIn 1961, University of California, Santa Cruz, astronomer and astrophysicist Frank Drake devised the Drake equation as a way to stimulate scientific dialogue at a meeting on the search for extraterrestrial intelligence (SETI). The Drake equation is a probabilistic argument used to estimate the number of active, communicative extraterrestrial civilizations in the Milky Way galaxy. The equation is best understood not as an equation in the strictly mathematical sense, but to summarize all the various concepts which scientists must contemplate when considering the question of life elsewhere. The Drake equation is:\nwhere:\n\nand\n\nDrake's proposed estimates are as follows, but numbers on the right side of the equation are agreed as speculative and open to substitution:\n\nformula_2\n\nThe Drake equation has proved controversial since several of its factors are uncertain and based on conjecture, not allowing conclusions to be made. This has led critics to label the equation a guesstimate, or even meaningless.\n\nBased on observations from the \"Hubble Space Telescope\", there are between 125 and 250 billion galaxies in the observable universe. It is estimated that at least ten percent of all Sun-like stars have a system of planets, i.e. there are stars with planets orbiting them in the observable universe. Even if it is assumed that only one out of a billion of these stars has planets supporting life, there would be some 6.25 billion life-supporting planetary systems in the observable universe.\n\nA 2013 study based on results from the \"Kepler\" spacecraft estimated that the Milky Way contains at least as many planets as it does stars, resulting in 100–400 billion exoplanets. Also based on \"Kepler\" data, scientists estimate that at least one in six stars has an Earth-sized planet.\n\nThe apparent contradiction between high estimates of the probability of the existence of extraterrestrial civilizations and the lack of evidence for such civilizations is known as the Fermi paradox.\n\nCosmic pluralism, the plurality of worlds, or simply pluralism, describes the philosophical belief in numerous \"worlds\" in addition to Earth, which might harbor extraterrestrial life. Before the development of the heliocentric theory and a recognition that the Sun is just one of many stars, the notion of pluralism was largely mythological and philosophical. The earliest recorded assertion of extraterrestrial human life is found in ancient scriptures of Jainism. There are multiple \"worlds\" mentioned in Jain scriptures, that support human life. These include \"Bharat Kshetra\", \"Mahavideh Kshetra\", \"Airavat Kshetra\", \"Hari kshetra\", etc. Medieval Muslim writers like Fakhr al-Din al-Razi and Muhammad al-Baqir supported cosmic pluralism on the basis of the Qur'an.\n\nWith the scientific and Copernican revolutions, and later, during the Enlightenment, cosmic pluralism became a mainstream notion, supported by the likes of Bernard le Bovier de Fontenelle in his 1686 work \"Entretiens sur la pluralité des mondes\". Pluralism was also championed by philosophers such as John Locke, Giordano Bruno and astronomers such as William Herschel. The astronomer Camille Flammarion promoted the notion of cosmic pluralism in his 1862 book \"La pluralité des mondes habités\". None of these notions of pluralism were based on any specific observation or scientific information.\n\nThere was a dramatic shift in thinking initiated by the invention of the telescope and the Copernican assault on geocentric cosmology. Once it became clear that Earth was merely one planet amongst countless bodies in the universe, the theory of extraterrestrial life started to become a topic in the scientific community. The best known early-modern proponent of such ideas was the Italian philosopher Giordano Bruno, who argued in the 16th century for an infinite universe in which every star is surrounded by its own planetary system. Bruno wrote that other worlds \"have no less virtue nor a nature different to that of our earth\" and, like Earth, \"contain animals and inhabitants\".\n\nIn the early 17th century, the Czech astronomer Anton Maria Schyrleus of Rheita mused that \"if Jupiter has (...) inhabitants (...) they must be larger and more beautiful than the inhabitants of Earth, in proportion to the [characteristics] of the two spheres\".\n\nIn Baroque literature such as \"The Other World: The Societies and Governments of the Moon\" by Cyrano de Bergerac, extraterrestrial societies are presented as humoristic or ironic parodies of earthly society.\nThe didactic poet Henry More took up the classical theme of the Greek Democritus in \"Democritus Platonissans, or an Essay Upon the Infinity of Worlds\" (1647).\nIn \"The Creation: a Philosophical Poem in Seven Books\" (1712), Sir Richard Blackmore observed: \"We may pronounce each orb sustains a race / Of living things adapted to the place\". With the new relative viewpoint that the Copernican revolution had wrought, he suggested \"our world's sunne / Becomes a starre elsewhere\". Fontanelle's \"Conversations on the Plurality of Worlds\" (translated into English in 1686) offered similar excursions on the possibility of extraterrestrial life, expanding, rather than denying, the creative sphere of a Maker.\n\nThe possibility of extraterrestrials remained a widespread speculation as scientific discovery accelerated. William Herschel, the discoverer of Uranus, was one of many 18th–19th-century astronomers who believed that the Solar System is populated by alien life. Other luminaries of the period who championed \"cosmic pluralism\" included Immanuel Kant and Benjamin Franklin. At the height of the Enlightenment, even the Sun and Moon were considered candidates for extraterrestrial inhabitants.\n\nSpeculation about life on Mars increased in the late 19th century, following telescopic observation of apparent Martian canals—which soon, however, turned out to be optical illusions. Despite this, in 1895, American astronomer Percival Lowell published his book \"Mars,\" followed by \"Mars and its Canals\" in 1906, proposing that the canals were the work of a long-gone civilization. The idea of life on Mars led British writer H. G. Wells to write the novel \"The War of the Worlds\" in 1897, telling of an invasion by aliens from Mars who were fleeing the planet's desiccation.\n\nSpectroscopic analysis of Mars's atmosphere began in earnest in 1894, when U.S. astronomer William Wallace Campbell showed that neither water nor oxygen was present in the Martian atmosphere.\nBy 1909 better telescopes and the best perihelic opposition of Mars since 1877 conclusively put an end to the canal hypothesis.\n\nThe science fiction genre, although not so named during the time, developed during the late 19th century. Jules Verne's \"Around the Moon\" (1870) features a discussion of the possibility of life on the Moon, but with the conclusion that it is barren.\nStories involving extraterrestrials are found in e.g. Garrett P. Serviss's \"Edison's Conquest of Mars\" (1898), an unauthorized sequel to\n\"The War of the Worlds\" by H. G. Wells was published in 1897 which stands at the beginning of the popular idea of the \"Martian invasion\" of Earth prominent in 20th-century pop culture.\n\nMost unidentified flying objects or UFO sightings can be readily explained as sightings of Earth-based aircraft, known astronomical objects, or as hoaxes. Nonetheless, a certain fraction of the public believe that UFOs might actually be of extraterrestrial origin, and, indeed, the notion has had influence on popular culture.\n\nThe possibility of extraterrestrial life on the Moon was ruled out in the 1960s, and during the 1970s it became clear that most of the other bodies of the Solar System do not harbor highly developed life, although the question of primitive life on bodies in the Solar System remains open.\n\nThe failure so far of the SETI program to detect an intelligent radio signal after decades of effort has at least partially dimmed the prevailing optimism of the beginning of the space age. Notwithstanding, belief in extraterrestrial beings continues to be voiced in pseudoscience, conspiracy theories, and in popular folklore, notably \"Area 51\" and legends. It has become a pop culture trope given less-than-serious treatment in popular entertainment.\n\nIn the words of SETI's Frank Drake, \"All we know for sure is that the sky is not littered with powerful microwave transmitters\". Drake noted that it is entirely possible that advanced technology results in communication being carried out in some way other than conventional radio transmission. At the same time, the data returned by space probes, and giant strides in detection methods, have allowed science to begin delineating habitability criteria on other worlds, and to confirm that at least other planets are plentiful, though aliens remain a question mark. The Wow! signal, detected in 1977 by a SETI project, remains a subject of speculative debate.\n\nIn 2000, geologist and paleontologist Peter Ward and astrobiologist Donald Brownlee published a book entitled \"Rare Earth: Why Complex Life is Uncommon in the Universe\". In it, they discussed the Rare Earth hypothesis, in which they claim that Earth-like life is rare in the universe, whereas microbial life is common. Ward and Brownlee are open to the idea of evolution on other planets that is not based on essential Earth-like characteristics (such as DNA and carbon).\n\nTheoretical physicist Stephen Hawking in 2010 warned that humans should not try to contact alien life forms. He warned that aliens might pillage Earth for resources. \"If aliens visit us, the outcome would be much as when Columbus landed in America, which didn't turn out well for the Native Americans\", he said. Jared Diamond had earlier expressed similar concerns.\n\nIn November 2011, the White House released an official response to two petitions asking the U.S. government to acknowledge formally that aliens have visited Earth and to disclose any intentional withholding of government interactions with extraterrestrial beings. According to the response, \"The U.S. government has no evidence that any life exists outside our planet, or that an extraterrestrial presence has contacted or engaged any member of the human race.\" Also, according to the response, there is \"no credible information to suggest that any evidence is being hidden from the public's eye.\" The response noted \"odds are pretty high\" that there may be life on other planets but \"the odds of us making contact with any of them—especially any intelligent ones—are extremely small, given the distances involved.\"\n\nIn 2013, the exoplanet Kepler-62f was discovered, along with Kepler-62e and Kepler-62c. A related special issue of the journal \"Science\", published earlier, described the discovery of the exoplanets.\n\nOn 17 April 2014, the discovery of the Earth-size exoplanet Kepler-186f, 500 light-years from Earth, was publicly announced; it is the first Earth-size planet to be discovered in the habitable zone and it has been hypothesized that there may be liquid water on its surface.\n\nOn 13 February 2015, scientists (including Geoffrey Marcy, Seth Shostak, Frank Drake and David Brin) at a convention of the American Association for the Advancement of Science, discussed Active SETI and whether transmitting a message to possible intelligent extraterrestrials in the Cosmos was a good idea; one result was a statement, signed by many, that a \"worldwide scientific, political and humanitarian discussion must occur before any message is sent\".\n\nOn 20 July 2015, British physicist Stephen Hawking and Russian billionaire Yuri Milner, along with the SETI Institute, announced a well-funded effort, called the Breakthrough Initiatives, to expand efforts to search for extraterrestrial life. The group contracted the services of the 100-meter Robert C. Byrd Green Bank Telescope in West Virginia in the United States and the 64-meter Parkes Telescope in New South Wales, Australia.\n\nBULLET::::- Speciesism\nBULLET::::- Sentientism\nBULLET::::- First contact (anthropology)\nBULLET::::- First contact (science fiction)\n\n\nBULLET::::- Winston Churchill's essay on Alien Life (c.1939)\n"}
{"id": "9589", "url": "https://en.wikipedia.org/wiki?curid=9589", "title": "European Strategic Program on Research in Information Technology", "text": "European Strategic Program on Research in Information Technology\n\nEuropean Strategic Programme on Research in Information Technology (ESPRIT) was a series of integrated programmes of information technology research and development projects and industrial technology transfer measures. It was a European Union initiative managed by the Directorate General for Industry (DG III) of the European Commission.\n\nFive ESPRIT programmes (ESPRIT 0 to ESPRIT 4) ran consecutively from 1983 to 1998. ESPRIT 4 was succeeded by the Information Society Technologies (IST) programme in 1999.\n\nSome of the projects and products supported by ESPRIT were: \n\nBULLET::::- BBC Domesday Project, a partnership between Acorn Computers Ltd, Philips, Logica and the BBC with some funding from the European Commission's ESPRIT programme, to mark the 900th anniversary of the original Domesday Book, an 11th-century census of England. It is frequently cited as an example of digital obsolescence on account of the physical medium used for data storage.\nBULLET::::- CGAL, the Computational Geometry Algorithms Library (CGAL) is a software library that aims to provide easy access to efficient and reliable algorithms in computational geometry. While primarily written in C++, Python bindings are also available. The original funding for the project came from the ESPRIT project.\nBULLET::::- Eurocoop & Eurocode: ESPRIT III projects to develop systems for supporting distributed collaborative working.\nBULLET::::- Open Document Architecture, a free and open international standard document file format maintained by the ITU-T to replace all proprietary document file formats. In 1985 ESPRIT financed a pilot implementation of the ODA concept, involving, among others, Bull corporation, Olivetti, ICL and Siemens AG.\nBULLET::::- Paradise: A sub-project of the ESPRIT I project, COSINE which established a pan-European computer-based network infrastructure that enabled research workers to communicate with each other using OSI. Paradise implemented a distributed X.500 directory across the academic community.\nBULLET::::- Password: Part of the ESPRIT III VALUE project, developed secure applications based on the X.509 standard for use in the academic community.\nBULLET::::- ProCoS I Project (1989–1991), ProCoS II Project (1992–1995), and ProCoS-WG Working Group (1994–1997) on Provably Correct Systems, under ESPRIT II.\nBULLET::::- REDO Project (1989–1992) on software maintenance, under ESPRIT II.\nBULLET::::- RAISE, Rigorous Approach to Industrial Software Engineering, was developed as part of the European ESPRIT II LaCoS project in the 1990s, led by Dines Bjørner.\nBULLET::::- REMORA methodology is an event-driven approach for designing information systems, developed by Colette Rolland. This methodology integrates behavioral and temporal aspects with concepts for modelling the structural aspects of an information system. In the ESPRIT I project TODOS, which has led to the development of an integrated environment for the design of office information systems (OISs),\nBULLET::::- SAMPA: The Speech Assessment Methods Phonetic Alphabet (SAMPA) is a computer-readable phonetic script originally developed in the late 1980s.\nBULLET::::- SCOPES: The Systematic Concurrent design of Products, Equipments and Control Systems project was a 3-year project launched in July, 1992, with the aim of specifying integrated computer-aided (CAD) tools for design and control of flexible assembly lines.\nBULLET::::- SIP (Advanced Algorithms and Architectures for Speech and Image Processing), a partnership between Thomson-CSF, AEG, CSELT and ENSPS (ESPRIT P26), to develop the algorithmic and architectural techniques required for recognizing and understanding spoken or visual signals and to demonstrate these techniques in suitable applications.\nBULLET::::- StatLog: \"ESPRIT project 5170. Comparative testing and evaluation of statistical and logical learning algorithms on large-scale applications to classification, prediction and control\"\nBULLET::::- SUNDIAL (Speech UNderstanding DIALgue) started in September 1988 with Logica Ltd. as prime contractor, together with Erlangen University, CSELT, Daimler-Benz, Capgemini, Politecnico di Torino. Followed the Esprit P.26 to implement and evaluate dialogue systems to be used in telephone industry. The final results were 4 prototypes in 4 languages, involving speech and understanding technologies, and some criteria for evaluation were also reported.\nBULLET::::- Web for Schools, an ESPRIT IV project that introduced the World Wide Web in secondary schools in Europe. Teachers created more than 70 international collaborative educational projects that resulted in an exponential growth of teacher communities and educational activities using the World Wide Web\n\nBULLET::::- ESPRIT home page\n"}
{"id": "9591", "url": "https://en.wikipedia.org/wiki?curid=9591", "title": "E. E. Cummings", "text": "E. E. Cummings\n\nEdward Estlin \"E. E.\" Cummings (October 14, 1894 – September 3, 1962), often styled as e e cummings, as he is attributed in many of his published works, was an American poet, painter, essayist, author, and playwright. He wrote approximately 2,900 poems, two autobiographical novels, four plays, and several essays. He is often regarded as one of the most important American poets of the 20th century.\n\nCummings is associated with modernist free-form poetry. Much of his work has idiosyncratic syntax and uses lower case spellings for poetic expression. His use of lower case extended to rendering even the personal pronoun \"I\" as \"i\", as in the phrase \"i shall go.”\n\nEdward Estlin Cummings was born on October 14, 1894 in Cambridge, Massachusetts to Edward Cummings and the former Rebecca Haswell Clarke, a well-known Unitarian couple in the city. His father was a professor at Harvard University who later became nationally known as the minister of South Congregational Church (Unitarian) in Boston, Massachusetts. His mother, who loved to spend time with her children, played games with Cummings and his sister, Elizabeth. From an early age, Cummings' parents supported his creative gifts. Cummings wrote poems and drew as a child, and he often played outdoors with the many other children who lived in his neighborhood. He grew up in the company of such family friends as the philosophers William James and Josiah Royce. Many of Cummings' summers were spent on Silver Lake in Madison, New Hampshire, where his father had built two houses along the eastern shore. The family ultimately purchased the nearby Joy Farm where Cummings had his primary summer residence.\n\nHe expressed transcendental leanings his entire life. As he matured, Cummings moved to an \"I, Thou\" relationship with God. His journals are replete with references to \"\"le bon Dieu\"\", as well as prayers for inspiration in his poetry and artwork (such as \"Bon Dieu! may i some day do something truly great. amen.\"). Cummings \"also prayed for strength to be his essential self ('may I be I is the only prayer—not may I be great or good or beautiful or wise or strong'), and for relief of spirit in times of depression ('almighty God! I thank thee for my soul; & may I never die spiritually into a mere mind through disease of loneliness').\"\n\nCummings wanted to be a poet from childhood and wrote poetry daily from age 8 to 22, exploring assorted forms. He graduated from Harvard University with a Bachelor of Arts degree \"magna cum laude\" and Phi Beta Kappa in 1915 and received a Master of Arts degree from the university in 1916. In his studies at Harvard, he developed an interest in modern poetry, which ignored conventional grammar and syntax, while aiming for a dynamic use of language. Upon graduating, he worked for a book dealer.\nIn 1917, with the First World War ongoing in Europe, Cummings enlisted in the Norton-Harjes Ambulance Corps. On the boat to France, he met William Slater Brown. They became fast friends. Due to an administrative mix-up, Cummings and Brown were not assigned to an ambulance unit for five weeks, during which time the two of them explored Paris. Cummings fell in love with the city, to which he would return throughout his life.\n\nDuring their service in the ambulance corps, the two young writers sent letters home that drew the attention of the military censors. They were known to prefer the company of French soldiers over fellow ambulance drivers. The two openly expressed anti-war views; Cummings spoke of his lack of hatred for the Germans. On September 21, 1917, five months after starting his belated assignment, Cummings and William Slater Brown were arrested by the French military on suspicion of espionage and undesirable activities. They were held for three and a half months in a military detention camp at the \"Dépôt de Triage\", in La Ferté-Macé, Orne, Normandy.\n\nThey were imprisoned with other detainees in a large room. Cummings' father failed to obtain his son's release through diplomatic channels, and in December 1917 he wrote a letter to President Woodrow Wilson. Cummings was released on December 19, 1917, and Brown was released two months later. Cummings used his prison experience as the basis for his novel, \"The Enormous Room\" (1922), about which F. Scott Fitzgerald said, \"Of all the work by young men who have sprung up since 1920 one book survives—\"The Enormous Room\" by e e cummings... Those few who cause books to live have not been able to endure the thought of its mortality.\" \n\nCummings returned to the United States on New Year's Day 1918. Later in 1918 he was drafted into the army. He served in the 12th Division at Camp Devens, Massachusetts, until November 1918.\n\nCummings returned to Paris in 1921 and lived there for two years before returning to New York. His collection \"Tulips and Chimneys\" was published in 1923 and his inventive use of grammar and syntax is evident. The book was heavily cut by his editor. \"XLI Poems\" was published in 1925. With these collections, Cummings made his reputation as an avant garde poet.\n\nDuring the rest of the 1920s and 1930s, Cummings returned to Paris a number of times, and traveled throughout Europe, meeting, among others, artist Pablo Picasso. In 1931 Cummings traveled to the Soviet Union, recounting his experiences in \"Eimi\", published two years later. During these years Cummings also traveled to Northern Africa and Mexico. He worked as an essayist and portrait artist for \"Vanity Fair\" magazine (1924–1927).\n\nIn 1926, Cummings' parents were in a car crash; only his mother survived, although she was severely injured. Cummings later described the crash in the following passage from his \"i: six nonlectures\" series given at Harvard (as part of the Charles Eliot Norton Lectures) in 1952 and 1953:\nA locomotive cut the car in half, killing my father instantly. When two brakemen jumped from the halted train, they saw a woman standing – dazed but erect – beside a mangled machine; with blood spouting (as the older said to me) out of her head. One of her hands (the younger added) kept feeling her dress, as if trying to discover why it was wet. These men took my sixty-six-year old mother by the arms and tried to lead her toward a nearby farmhouse; but she threw them off, strode straight to my father's body, and directed a group of scared spectators to cover him. When this had been done (and only then) she let them lead her away.\nHis father's death had a profound effect on Cummings, who entered a new period in his artistic life. He began to focus on more important aspects of life in his poetry. He started this new period by paying homage to his father in the poem \"my father moved through dooms of love\".\n\nIn the 1930s Samuel Aiwaz Jacobs was Cummings' publisher; he had started the Golden Eagle Press after working as a typographer and publisher.\n\nIn 1952, his alma mater, Harvard University, awarded Cummings an honorary seat as a guest professor. The Charles Eliot Norton Lectures he gave in 1952 and 1955 were later collected as \"i: six nonlectures\".\nCummings spent the last decade of his life traveling, fulfilling speaking engagements, and spending time at his summer home, Joy Farm, in Silver Lake, New Hampshire. He died of a stroke on September 3, 1962, at the age of 67 in North Conway, New Hampshire at the Memorial Hospital. Cummings was buried at Forest Hills Cemetery in Boston, Massachusetts. At the time of his death, Cummings was recognized as the second most read poet in the United States, behind Robert Frost.\n\nCummings' papers are held at the Houghton Library at Harvard University and the Harry Ransom Center at the University of Texas at Austin.\n\nCummings was married briefly twice, first to Elaine Orr, then to Anne Minnerly Barton. His longest relationship lasted more than three decades, a common-law marriage to Marion Morehouse.\n\nCummings' first marriage, to Elaine Orr, began as a love affair in 1918 while she was still married to Scofield Thayer, one of Cummings' friends from Harvard. During this time he wrote a good deal of his erotic poetry. After divorcing Thayer, Orr married Cummings on March 19, 1924. The couple had a daughter together out of wedlock. However, the couple separated after two months of marriage and divorced less than nine months later.\n\nCummings married his second wife Anne Minnerly Barton on May 1, 1929, and they separated three years later in 1932. That same year, Minnerly obtained a Mexican divorce; it was not officially recognized in the United States until August 1934. Anne died in 1970 aged 72.\n\nIn 1934, after his separation from his second wife, Cummings met Marion Morehouse, a fashion model and photographer. Although it is not clear whether the two were ever formally married, Morehouse lived with Cummings in a common-law marriage until his death in 1962. She died on May 18, 1969, while living at 4 Patchin Place, Greenwich Village, New York City, where Cummings had resided since September 1924.\n\nAccording to his testimony in \"EIMI\", Cummings had little interest in politics until his trip to the Soviet Union in 1931. He subsequently shifted rightward on many political and social issues. Despite his radical and bohemian public image, he was a Republican, and later, an ardent supporter of Joseph McCarthy.\n\nDespite Cummings' familiarity with avant-garde styles (likely affected by the \"Calligrammes\" of French poet Apollinaire, according to a contemporary observation), much of his work is quite traditional. Many of his poems are sonnets, albeit often with a modern twist. He occasionally used the blues form and acrostics. Cummings' poetry often deals with themes of love and nature, as well as the relationship of the individual to the masses and to the world. His poems are also often rife with satire.\n\nWhile his poetic forms and themes share an affinity with the Romantic tradition, Cummings' work universally shows a particular idiosyncrasy of syntax, or way of arranging individual words into larger phrases and sentences. Many of his most striking poems do not involve any typographical or punctuation innovations at all, but purely syntactic ones.\n\nAs well as being influenced by notable modernists, including Gertrude Stein and Ezra Pound, Cummings in his early work drew upon the imagist experiments of Amy Lowell. Later, his visits to Paris exposed him to Dada and Surrealism, which he reflected in his work. He began to rely on symbolism and allegory, where he once had used simile and metaphor. In his later work, he rarely used comparisons that required objects that were not previously mentioned in the poem, choosing to use a symbol instead. Due to this, his later poetry is \"frequently more lucid, more moving, and more profound than his earlier.\" Cummings also liked to incorporate imagery of nature and death into much of his poetry.\n\nWhile some of his poetry is free verse (with no concern for rhyme or meter), many have a recognizable sonnet structure of 14 lines, with an intricate rhyme scheme. A number of his poems feature a typographically exuberant style, with words, parts of words, or punctuation symbols scattered across the page, often making little sense until read aloud, at which point the meaning and emotion become clear. Cummings, who was also a painter, understood the importance of presentation, and used typography to \"paint a picture\" with some of his poems.\n\nThe seeds of Cummings' unconventional style appear well established even in his earliest work. At age six, he wrote to his father:\n\nFollowing his autobiographical novel, \"The Enormous Room\", Cummings' first published work was a collection of poems titled \"Tulips and Chimneys\" (1923). This work was the public's first encounter with his characteristic eccentric use of grammar and punctuation.\n\nSome of Cummings' most famous poems do not involve much, if any, odd typography or punctuation, but still carry his unmistakable style, particularly in unusual and impressionistic word order.\n\nCummings' work often does not proceed in accordance with the conventional combinatorial rules that generate typical English sentences (for example, \"they sowed their isn't\"). In addition, a number of Cummings' poems feature, in part or in whole, intentional misspellings, and several incorporate phonetic spellings intended to represent particular dialects. Cummings also made use of inventive formations of compound words, as in \"in Just\" which features words such as \"mud-luscious\", \"puddle-wonderful\", and \"eddieandbill.\" This poem is part of a sequence of poems titled \"Chansons Innocentes\"; it has many references comparing the \"balloonman\" to Pan, the mythical creature that is half-goat and half-man. Literary critic R.P. Blackmur has commented that this use of language is \"frequently unintelligible because [Cummings] disregards the historical accumulation of meaning in words in favour of merely private and personal associations.\"\n\nFellow poet Edna St. Vincent Millay, in her equivocal letter recommending Cummings for the Guggenheim Fellowship he was awarded in 1934, expressed her frustration at his opaque symbolism. \"[I]f he prints and offers for sale poetry which he is quite content should be, after hours of sweating concentration, inexplicable from any point of view to a person as intelligent as myself, then he does so with a motive which is frivolous from the point of view of art, and should not be helped or encouraged by any serious person or group of persons... there is fine writing and powerful writing (as well as some of the most pompous nonsense I ever let slip to the floor with a wide yawn)... What I propose, then, is this: that you give Mr. Cummings enough rope. He may hang himself; or he may lasso a unicorn.\"\n\nMany of Cummings' poems are satirical and address social issues but have an equal or even stronger bias toward romanticism: time and again his poems celebrate love, sex, and the season of rebirth.\n\nCummings also wrote children's books and novels. A notable example of his versatility is an introduction he wrote for a collection of the comic strip \"Krazy Kat\".\n\nCummings is known for controversial subject matter, as he wrote numerous erotic poems. He also sometimes included ethnic slurs in his writing. For instance, in his 1950 collection \"Xaipe: Seventy-One Poems\", Cummings published two poems containing words that caused outrage in some quarters.\n\n</poem>\n\nand\n\n<poem>\n</poem>\n\nCummings biographer Catherine Reef notes of the controversy:\n\nFriends begged Cummings to reconsider publishing these poems, and the book's editor pleaded with him to withdraw them, but he insisted that they stay. All the fuss perplexed him. The poems were commenting on prejudice, he pointed out, and not condoning it. He intended to show how derogatory words cause people to see others in terms of stereotypes rather than as individuals. \"America (which turns Hungarian into 'hunky' & Irishman into 'mick' and Norwegian into 'square- head') is to blame for 'kike,'\" he said.\nWilliam Carlos Williams spoke out in his defense.\n\nDuring his lifetime, Cummings published four plays. \"HIM\", a three-act play, was first produced in 1928 by the Provincetown Players in New York City. The production was directed by James Light. The play's main characters are \"Him\", a playwright, portrayed by William Johnstone, and \"Me\", his girlfriend, portrayed by Erin O'Brien-Moore.\n\nCummings said of the unorthodox play:\nRelax and give the play a chance to strut its stuff—relax, stop wondering what it is all 'about'—like many strange and familiar things, Life included, this play isn't 'about,' it simply is. . . . Don't try to enjoy it, let it try to enjoy you. \"\n\n\"Anthropos, or the Future of Art\" is a short, one-act play that Cummings contributed to the anthology \"Whither, Whither or After Sex, What? A Symposium to End Symposium\". The play consists of dialogue between Man, the main character, and three \"infrahumans\", or inferior beings. The word \"anthropos\" is the Greek word for \"man\", in the sense of \"mankind\".\n\n\"Tom, A Ballet\" is a ballet based on \"Uncle Tom's Cabin\". The ballet is detailed in a \"synopsis\" as well as descriptions of four \"episodes\", which were published by Cummings in 1935. It has never been performed.\n\n\"\" was probably Cummings' most successful play. It is an allegorical Christmas fantasy presented in one act of five scenes. The play was inspired by his daughter Nancy, with whom he was reunited in 1946. It was first published in the Harvard College magazine, \"Wake\". The play's main characters are Santa Claus, his family (Woman and Child), Death, and Mob. At the outset of the play, Santa Claus' family has disintegrated due to their lust for knowledge (Science). After a series of events, however, Santa Claus' faith in love and his rejection of the materialism and disappointment he associates with Science are reaffirmed, and he is reunited with Woman and Child.\n\nCummings' publishers and others have often echoed the unconventional orthography in his poetry by writing his name in lowercase and without periods (full stops), but normal orthography for his name (uppercase and periods) is supported by scholarship and preferred by publishers today. Cummings himself used both the lowercase and capitalized versions, though he most often signed his name with capitals.\n\nThe use of lowercase for his initials was popularized in part by the title of some books, particularly in the 1960s, printing his name in lower case on the cover and spine. In the preface to \"E. E. Cummings: The Growth of a Writer\" by Norman Friedman, critic Harry T. Moore notes Cummings \"had his name put legally into lower case, and in his later books the titles and his name were always in lower case.\" According to Cummings' widow, however, this is incorrect. She wrote to Friedman: \"You should not have allowed H. Moore to make such a stupid & childish statement about Cummings & his signature.\" On February 27, 1951, Cummings wrote to his French translator D. Jon Grossman that he preferred the use of upper case for the particular edition they were working on. One Cummings scholar believes that on the rare occasions that Cummings signed his name in all lowercase, he may have intended it as a gesture of humility, not as an indication that it was the preferred orthography for others to use. Additionally, the \"Chicago Manual of Style\", which prescribes favoring non-standard capitalization of names in accordance with the bearer's strongly stated preference, notes \"E. E. Cummings can be safely capitalized; it was one of his publishers, not he himself, who lowercased his name.\"\n\nIn 1943, modern dancer and choreographer Jean Erdman presented \"The Transformations of Medusa, Forever and Sunsmell\" with a commissioned score by John Cage and a spoken text from the title poem by E. E. Cummings, sponsored by the Arts Club of Chicago. Erdman also choreographed \"Twenty Poems\" (1960), a cycle of E. E. Cummings' poems for eight dancers and one actor, with a commissioned score by Teiji Ito. It was performed in the round at the Circle in the Square Theatre in Greenwich Village.\n\nNumerous composers have set Cummings' poems to music:\nBULLET::::- In 1961, Pierre Boulez composed \"Cummings ist der dichter\" from poems by E. E. Cummings.\nBULLET::::- Aribert Reimann set Cummings to music in \"Impression IV\" (1961) for soprano and piano.\nBULLET::::- Morton Feldman (1926-1987) in 1951 composed \"4 Songs to e.e. cummings\" for soprano, piano and cello, using material from Cummings' \"50 poems\" of 1940: \"!Blac\", \"Air\", \"(Sitting In A Tree-)\" and \"(Moan)\".\nBULLET::::- The Icelandic singer Björk used lines from Cummings's poem \"I Will Wade Out\" for the lyrics of \"Sun in My Mouth\" on her 2001 album \"Vespertine.\" On her next album, \"Medúlla\" (2004), Björk used his poem \"It May Not Always Be So\" as the lyrics for the song \"Sonnets/Unrealities XI.\"\nBULLET::::- The American composer Eric Whitacre wrote a cycle of works for choir titled \"The City and the Sea\", which consists of five poems by Cummings set to music.\nBULLET::::- Others who have composed settings for his poems include Dominic Argento, William Bergsma, Leonard Bernstein, Marc Blitzstein, John Cage, Romeo Cascarino, Aaron Copland, Serge de Gastyne, David Diamond, John Duke, Margaret Garwood, Daron Hagen, Michael Hedges, Richard Hundley, Barbara Kolb, Leonard Lehrman, Robert Manno, Salvatore Martirano, William Mayer, John Musto, Paul Nordoff, Tobias Picker, Vincent Persichetti, Ned Rorem, Peter Schickele, Elie Siegmeister, Aki Takase, Hugo Weisgall, Dan Welcher, and James Yannatos, among many others.\n\nDuring his lifetime, Cummings received numerous awards in recognition of his work, including:\nBULLET::::- Dial Award (1925)\nBULLET::::- Guggenheim Fellowship (1933)\nBULLET::::- Shelley Memorial Award for Poetry (1945)\nBULLET::::- Harriet Monroe Prize from \"Poetry\" magazine (1950)\nBULLET::::- Fellowship of American Academy of Poets (1950)\nBULLET::::- Guggenheim Fellowship (1951)\nBULLET::::- Charles Eliot Norton Professorship at Harvard (1952–1953)\nBULLET::::- Special citation from the National Book Award Committee for his \"Poems, 1923–1954\" (1957)\nBULLET::::- Bollingen Prize in Poetry (1958)\nBULLET::::- Boston Arts Festival Award (1957)\nBULLET::::- Two-year Ford Foundation grant of $15,000 (1959)\n\nBULLET::::- \"The Enormous Room\" (1922)\nBULLET::::- \"Tulips and Chimneys\" (1923)\nBULLET::::- \"&\" (1925) (self-published)\nBULLET::::- \"XLI Poems\" (1925)\nBULLET::::- \"is 5\" (1926)\nBULLET::::- \"HIM\" (1927) (a play)\nBULLET::::- \"ViVa\" (1931)\nBULLET::::- \"CIOPW\" (1931) (art works)\nBULLET::::- \"EIMI\" (1933) (Soviet travelogue)\nBULLET::::- \"No Thanks\" (1935)\nBULLET::::- \"Collected Poems\" (1938)\nBULLET::::- \"50 Poems\" (1940)\nBULLET::::- \"1 × 1\" (1944)\nBULLET::::- \"\" (1946)\nBULLET::::- \"XAIPE: Seventy-One Poems\" (1950)\nBULLET::::- \"i—six nonlectures\" (1953) Harvard University Press\nBULLET::::- \"Poems, 1923–1954\" (1954)\nBULLET::::- \"95 Poems\" (1958)\nBULLET::::- \"73 Poems\" (1963) (posthumous)\nBULLET::::- \"Fairy Tales\" (1965)\nBULLET::::- \"Etcetera: The Unpublished Poems\" (1983)\nBULLET::::- \"Complete Poems, 1904–1962\", edited by George James Firmage, Liveright 2008\n\nBULLET::::- Bloom, Harold, \"Twentieth-century American Literature\", New York : Chelsea House Publishers, 1985–1988. .\nBULLET::::- Friedman, Norman (editor), \"E. E. Cummings: A Collection of Critical Essays\".\nBULLET::::- Friedman, Norman, \"E. E. Cummings: The Art of his Poetry\".\nBULLET::::- Galgano, Andrea, \"La furiosa ricerca di Edward E. Cummings\", in \"Mosaico\", Roma, Aracne, 2013, pp. 441–44\nBULLET::::- Heusser, Martin. \"I Am My Writing: The Poetry of E.E. Cummings.\" Tübingen: Stauffenburg, 1997.\nBULLET::::- Hutchinson, Hazel. \"The War That Used Up Words: American Writers and the First World War.\" New Haven, CT: Yale University Press, 2015.\nBULLET::::- James, George, \"E. E. Cummings: A Bibliography\".\nBULLET::::- McBride, Katharine, \"A Concordance to the Complete Poems of E.E.Cummings\".\nBULLET::::- Mott, Christopher. \"The Cummings Line on Race\", \"Spring: The Journal of the E. E. Cummings Society,\" vol. 4, pp. 71–75, Fall 1995.\nBULLET::::- Norman, Charles, \"E. E. Cummings: The Magic-Maker\", Boston, Little Brown, 1972.\nBULLET::::- Sawyer-Lauçanno, Christopher, \"E. E. Cummings: A Biography\", Sourcebooks, Inc. (2004) .\n\nBULLET::::- E. E. Cummings, Lifelong Unitarian Biography of Cummings and his relationship with Unitarianism\nBULLET::::- E.E. Cummings Personal Library at LibraryThing\nBULLET::::- Papers of E. E. Cummings at the Houghton Library at Harvard University\nBULLET::::- E. E. Cummings Collection at the Harry Ransom Center at the University of Texas at Austin\nBULLET::::- Poems by E. E. Cummings at PoetryFoundation.org\nBULLET::::- Jonathan Yardley, \"E. E. Cummings: A Biography\", Sunday, October 17, 2004, Page BW02, \"The Washington Post Book Review\"\nBULLET::::- \"SPRING\":The Journal of the E. E. Cummings Society\nBULLET::::- Modern American Poetry\nBULLET::::- E. E. Cummings at Library of Congress Authorities – with 202 catalog records\nBULLET::::- Biography and poems of E. E. Cummings at Poets.org\n"}
{"id": "9592", "url": "https://en.wikipedia.org/wiki?curid=9592", "title": "East River", "text": "East River\n\nThe East River is a salt water tidal estuary in New York City. The waterway, which is actually not a river despite its name, connects Upper New York Bay on its south end to Long Island Sound on its north end. It separates the borough of Queens on Long Island from the Bronx on the North American mainland, and also divides Manhattan from Queens and Brooklyn, which is also on Long Island. Because of its connection to Long Island Sound, it was once also known as the \"Sound River\". The tidal strait changes its direction of flow frequently, and is subject to strong fluctuations in its current, which are accentuated by its narrowness and variety of depths. The waterway is navigable for its entire length of , and was historically the center of maritime activities in the city, although that is no longer the case.\n\nTechnically a drowned valley, like the other waterways around New York City, the strait was formed approximately 11,000 years ago at the end of the Wisconsin glaciation. The distinct change in the shape of the strait between the lower and upper portions is evidence of this glacial activity. The upper portion (from Long Island Sound to Hell Gate), running largely perpendicular to the glacial motion, is wide, meandering, and has deep narrow bays on both banks, scoured out by the glacier's movement. The lower portion (from Hell Gate to New York Bay) runs north-south, parallel to the glacial motion. It is much narrower, with straight banks. The bays that exist, as well as those that used to exist before being filled in by human activity, are largely wide and shallow.\n\nThe section known as \"Hell Gate\" – from the Dutch name \"Hellegat\" meaning either \"bright strait\" or \"clear opening, given to the entire river in 1614 by explorer Adriaen Block when he passed through it in his ship \"Tyger\" – is a narrow, turbulent, and particularly treacherous stretch of the river. Tides from the Long Island Sound, New York Harbor and the Harlem River meet there, making it difficult to navigate, especially because of the number of rocky islets which once dotted it, with names such as \"Frying Pan\", \"Pot, Bread and Cheese\", \"Hen and Chicken\", \"Nigger Head\", \"Heel Top\"; \"Flood\"; and \"Gridiron\", roughly 12 islets and reefs in all, all of which led to a number of shipwrecks, including HMS \"Hussar\", a British frigate which sank in 1780 while carrying gold and silver intended to pay British troops. The stretch has since been cleared of rocks and widened. Washington Irving wrote of Hell Gate that the current sounded \"like a bull bellowing for more drink\" at half tide, while at full tide it slept \"as soundly as an alderman after dinner.\" He said it was like \"a peaceable fellow enough when he has no liquor at all, or when he has a skinful, but who, when half-seas over, plays the very devil.\" The tidal regime is complex, with the two major tides – from the Long Island Sound and from the Atlantic Ocean – separated by about two hours; and this is without consideration of the tidal influence of the Harlem River, all of which creates a \"dangerous cataract\", as one ship's captain put it.\n\nThe river is navigable for its entire length of . In 1939 it was reported that the stretch from The Battery to the former Brooklyn Navy Yard near Wallabout Bay, a run of about , was deep, the long section from there, running to the west of Roosevelt Island, through Hell Gate and to Throg's Neck was at least deep, and then eastward from there the river was, at mean low tide, deep.\n\nThe broadness of the river's channel south of Roosevelt Island is caused by the dipping of the hardy Fordham gneiss which underlies the island under the less strong Inwood marble which lies under the river bed. Why the river turns to the east as it approaches the three lower Manhattan bridges is currently geologically unknown.\n\nRoosevelt Island, a long () and narrow () landmass, lies in the stretch of the river between Manhattan Island and the borough of Queens roughly paralleling Manhattan's East 46th-86th Streets. The abrupt termination of the island on its north end is due to an extension of the 125th Street Fault. Politically, the island's constitute part of the borough of Manhattan. It is connected to Queens by the Roosevelt Island Bridge, to Manhattan by the Roosevelt Island Tramway, and to both boroughs by a subway station served by the F train. The Queensboro Bridge also runs across Roosevelt Island, and an elevator allowing both pedestrian and vehicular access to the island was added to the bridge in 1930, but elevator service was discontinued in 1955 following the opening of the Roosevelt Island Bridge, and the elevator was demolished in 1970. The island, which was formerly known as Blackwell's Island and Welfare Island before being renamed in honor of US President Franklin Delano Roosevelt, historically served as the site of a penitentiary and a number of hospitals; today, it is dominated by residential neighborhoods consisting of large apartment buildings and park land (much of which is dotted with the ruins of older structures).\n\nThe largest land mass in the River south of Roosevelt Island is U Thant Island, an artificial islet created during the construction of the Steinway Tunnel (which currently serves the subway's 7 and <7> lines). Officially named Belmont Island after one of the tunnel's financiers, the landmass's owes its popular name (after U Thant, former Secretary-General of the United Nations) to the efforts of a group associated with the guru Sri Chinmoy that held mediation meetings on the island in the 1970s. Today, the island is owned by New York State and serves as a migratory bird sanctuary that is closed to visitors. \n\nProceeding north and east from Roosevelt Island, the River's principal islands include Manhattan's Mill Rock, an 8.6 acre island located about 1000 feet from Manhattan's East 96th Street; Manhattan's 520 acre Randalls and Wards Islands, two formerly separate islands joined together by landfill that are home to a large public park, a number of public institutions, and the supports for the Triborough and the Hell Gate Bridges; the Bronx's Rikers Island, once under but now over following extensive landfill expansion after the island's 1884 purchase by the city as a prison farm and still home to New York City's massive and controversial primary jail complex, and North and South Brother Islands, both of which also constitute part of the Bronx.\n\nThe Bronx River drains into the East River in the northern section of the strait, and the Flushing River, historically known as \"Flushing Creek\" empties into it near LaGuardia Airport via Flushing Bay.\n\nNorth of Randalls Island, it is joined by the Bronx Kill. Along the east of Wards Island, at approximately the strait's midpoint, it narrows into a channel called Hell Gate, which is spanned by both the Robert F. Kennedy Bridge (formerly the Triborough), and the Hell Gate Bridge. On the south side of Wards Island, it is joined by the Harlem River.\n\nNewtown Creek on Long Island drains into the East River, and forms part of the boundary between Queens and Brooklyn. The Gowanus Canal was built from Gowanus Creek, which emptied into the river. Historically, there were other small streams which emptied into the river – including the Harlem Creek, one of the most significant tributaries originating in Manhattan – but these and their associated wetlands have been filled in and built over.\n\nPrior to the arrival of Europeans, the land north of the East River was occupied by the Siwanoys, one of many groups of Algonquin-speaking Lenapes in the area. Those of the Lenapes who lived in the northern part of Manhattan Island in a campsite known as Konaande Kongh used a landing at around the current location of East 119th street to paddle into the river in canoes fashioned from tree-trunk in order to fish.\n\nDutch settlement of what became New Amsterdam began in 1623. Some of the earliest of the small settlements in the area were along the west bank of the East River on sites that had previously been Native American settlements. As with the Native Americans, the river was central to their lives for transportation for trading and for fishing. They gathered marsh grass to feed their cattle, and the East River's tides helped to power mills which ground grain to flour. By 1642 there was a ferry running on the river between Manhattan island and what is now Brooklyn, and the first pier on the river was built in 1647 at Pearl and Broad Streets. After the British took over the colony in 1664, and was renamed \"New York\", the development of the waterfront continued, and a shipbuilding industry grew up once New York started exporting flour. By the end of the 17th century, the Great Dock, located at Corlear's Hook on the East River, had been built.\n\nHistorically, the lower portion of the strait, which separates Manhattan from Brooklyn, was one of the busiest and most important channels in the world, particularly during the first three centuries of New York City's history. Because the water along the lower Manhattan shoreline was too shallow for large boats to tie up and unload their goods, from 1686 on – after the signing of the Dongan Charter, which allowed intertidal land to be owned and sold – the shoreline was \"wharfed out\" to the high-water mark by building retaining walls that were filled in with every conceivable kind of landfill: excrement, dead animals, ships deliberately sunk in place, ship ballast, and muck dredged from the bottom of the river. On the new land were built warehouses and other structures necessary for the burgeoning sea trade. Many of the \"water-lot\" grants went to the rich and powerful families of the merchant class, although some went to tradesmen. By 1700, the Manhattan bank of the river has been \"wharfed-out\" up to around Whitehall Street, narrowing the strait of the river.\n\nAfter the signing of the Montgomerie Charter in the late 1720s, another 127 acres of land along the Manhattan shore of the East River was authorized to be filled-in, this time to a point 400 feet beyond the low-water mark; the parts that had already been expanded to the low water mark – much of which had been devastated by a coastal storm in the early 1720s and a nor'easter in 1723 – were also expanded, narrowing the channel even further. What had been quiet beach land was to become new streets and buildings, and the core of the city's sea-borne trade. This infilling went as far north as Corlear's Hook. In addition, the city was given control of the western shore of the river from Wallabout Bay south.\n\nExpansion of the waterfront halted during the American Revolution, in which the East River played an important role early in the conflict. On August 28, 1776, while British and Hessian troops rested after besting the Americans at the Battle of Long Island, General George Washington was rounding up all the boats on the east shore of the river, in what is now Brooklyn, and used them to successfully move his troops across the river – under cover of night, rain, and fog – to Manhattan island, before the British could press their advantage. Thus, though the battle was a victory for the British, the failure of Sir William Howe to destroy the Continental Army when he had the opportunity allowed the Americans to continue fighting. Without the stealthy withdrawal across the East River, the American Revolution might have ended much earlier.\n\nWallabout Bay on the River was the site of most of the British prison ships – most notoriously – where thousands of American prisoners of war were held in terrible conditions. These prisoners had come into the hands of the British after the fall of New York City on September 15, 1776, after the American loss at the Battle of Long Island and the loss of Fort Washington on November 16. Prisoners began to be housed on the broken-down warships and transports in December; about 24 ships were used in total, but generally only 5 or 6 at a time. Almost twice as many Americans died from neglect in these ships than did from all the battles in the war: as many as 12,000 soldiers, sailors and civilians. The bodies were thrown overboard or were buried in shallow graves on the riverbanks, but their bones – some of which were collected when they washed ashore – were later relocated and are now inside the Prison Ship Martyrs' Monument in nearby Fort Greene Park. The existence of the ships and the conditions the men were held in was widely known at the time through letters, diaries and memoirs, and was a factor not only in the attitude of Americans toward the British, but in the negotiations to formally end the war.\n\nAfter the war, East River waterfront development continued once more. New York State legislation which in 1807 authorized what would become the Commissioners Plan of 1811 also authorized the creation of new land out to 400 feet from the low water mark into the river, and with the advent of gridded streets along the new waterline – Joseph Mangin had laid out such a grid in 1803 in his \"A Plan and Regulation of the City of New York\", which was rejected by the city, but established the concept – the coastline become regularized at the same time that the strait became even narrower.\n\nOne result of the narrowing of the East River along the shoreline of Manhattan and, later, Brooklyn – which continued until the mid-19th century when the state put a stop to it – was an increase in the speed of its current. Buttermilk Channel, the strait that divides Governors Island from Red Hook in Brooklyn, and which is located directly south of the \"mouth\" of the East River, was in the early 17th century a fordable waterway across which cattle could be driven. Further investigation by Colonel Jonathan Williams determined that the channel was by 1776 three fathoms deep (), five fathoms deep () in the same spot by 1798, and when surveyed by Williams in 1807 had deepened to 7 fathoms () at low tide. What had been almost a bridge between two landforms which were once connected had become a fully navigable channel, thanks to the constriction of the East River and the increased flow it caused. Soon, the current in the East River had become so strong that larger ships had to use auxiliary steam power in order to turn. The continued narrowing of the channel on both side may have been the reasoning behind the suggestion of one New York State Senator, who wanted to fill in the East River and annex Brooklyn, with the cost of doing so being covered by selling the newly made land. Others proposed a dam at Roosevelt Island (then Blackwell's Island) to create a wet basin for shipping.\n\nFilling in part of the river was also proposed in 1867 by engineer James E. Serrell, later a city surveyor, but with emphasis on solving the problem of Hell Gate. Serrell proposed filling in Hell Gate and build a \"New East River\" through Queens with an extension to Westchester County. Serrell's plan – which he publicized with maps, essay and lectures as well as presentations to the city, state and federal governments – would have filled in the river from 14th Street to 125th Street. The New East River through Queens would be about three times the average width of the existing one at an even throughout, and would run as straight as an arrow for five miles. The new land, and the portions of Queens which would become part of Manhattan, adding , would be covered with an extension of the existing street grid of Manhattan.\n\nVariations on Serrell's plan would be floated over the years. A pseudonymous \"Terra Firma\" brought up filling in the East River again in the \"Evening Post\" and \"Scientific American\" in 1904, and Thomas Alva Edison took it up in 1906. Then Thomas Kennard Thompson, a bridge and railway engineer, proposed in 1913 to fill in the river from Hell Gate to the tip of Manhattan and, as Serrell had suggested, make a new canalized East River, only this time from Flushing Bay to Jamaica Bay. He would also expand Brooklyn into the Upper Harbor, put up a dam from Brooklyn to Staten Island, and make extensive landfill in the Lower Bay. At around the same time, in the 1920s, Dr. John A. Harriss, New York City's chief traffic engineer, who had developed the first traffic signals in the city, also had plans for the river. Harriss wanted to dam the East River at Hell Gate and the Williamsburg Bridge, then remove the water, put a roof over it on stilts, and build boulevards and pedestrian lanes on the roof along with \"majestic structures\", with transportation services below. The East River's course would, once again, be shifted to run through Queens, and this time Brooklyn as well, to channel it to the Harbor.\n\nPeriodically, merchants and other interested parties would try to get something done about the difficulty of navigating through Hell Gate. In 1832, the New York State legislature was presented with a petition for a canal to be built through nearby Hallet's Point, thus avoiding Hell Gate altogether. Instead, the legislature responded by providing ships with pilots trained to navigate the shoals for the next 15 years.\n\nIn 1849, a French engineer whose specialty was underwater blasting, Benjamin Maillefert, had cleared some of the rocks which, along with the mix of tides, made the Hell Gate stretch of the river so dangerous to navigate. Ebenezer Meriam had organized a subscription to pay Maillefert $6,000 to, for instance, reduce \"Pot Rock\" to provide of depth at low-mean water. While ships continued to run aground (in the 1850s about 2% of ships did so) and petitions continued to call for action, the federal government undertook surveys of the area which ended in 1851 with a detailed and accurate map. By then Maillefert had cleared the rock \"Baldheaded Billy\", and it was reported that Pot Rock had been reduced to , which encouraged the United States Congress to appropriate $20,000 for further clearing of the strait. However, a more accurate survey showed that the depth of Pot Rock was actually a little more than , and eventually Congress withdrew its funding.\n\nWith the main shipping channels through The Narrows into the harbor silting up with sand due to littoral drift, thus providing ships with less depth, and a new generation of larger ships coming online – epitomized by Isambard Kingdom Brunel's SS \"Great Eastern\", popularly known as \"Leviathan\" – New York began to be concerned that it would start to lose its status as a great port if a \"back door\" entrance into the harbor was not created. In the 1850s the depth continued to lessen – the harbor commission said in 1850 that the mean water low was and the extreme water low was – while the draft required by the new ships continued to increase, meaning it was only safe for them to enter the harbor at high tide.\n\nThe U.S. Congress, realizing that the problem needed to be addressed, appropriated $20,000 for the Army Corps of Engineers to continue Maillefert's work, but the money was soon spent without appreciable change in the hazards of navigating the strait. An advisory council recommended in 1856 that the strait be cleared of all obstacles, but nothing was done, and the Civil War soon broke out.\n\nIn the late 1860s, after the Civil War, Congress realized the military importance of having easily navigable waterways, and charged the Army Corps of Engineers with clearing Hell Gate of the rocks there that caused a danger to navigation. The Corps' Colonel James Newton estimated that the project would cost $1 million, as compared to the approximate annual loss in shipping of $2 million. Initial forays floundered, and Newton, by that time a general, took over direct control of the project. In 1868 Newton decided, with the support of both New York's mercantile class and local real estate interests, to focus on the Hallert's Point Reef off of Queens. The project would involve of tunnels equipped with trains to haul debris out as the reef was eviscerated, creating a reef structured like \"swiss cheese\" which Newton would then blow up. After seven years of digging seven thousand holes, and filling four thousand of them with of dynamite, on September 24, 1876, in front of an audience of people including the inhabitants of the insane asylum on Wards Island, but not the prisoners of Roosevelt Island – then called Blackwell's Island – who remained in their cells, Newton's daughter set off the explosion. The effect was immediate in decreased turbulence through the strait, and fewer accidents and shipwrecks. The city's Chamber of Commerce commented that \"The Centennial year will be for ever known in the annals of commerce for this destruction of one of the terrors of navigation.\" Clearing out the debris from the explosion took until 1891.\n\nThen, in 1885, Flood Rock, a reef that Newton had begun to undermine even before starting on Hallert's Rock, removing of rock from the reef, was blown up as well, with Civil War General Philip Sheridan and abolitionist Henry Ward Beecher among those in attendance, and Newton's daughter once more setting off the blast, the biggest ever to that date, and reportedly the largest man-made explosion until the advent of the atomic bomb although the detonation at the Battle of Messines in 1917 was several times larger. Two years later, plans were in place to dredge Hell Gate to a consistent depth of .\n\nAt the same time that Hell Gate was being cleared, the Harlem River Ship Canal was being planned. When it was completed in 1895, the \"back door\" to New York's center of ship-borne trade in the docks and warehouses of the East River was open from two directions, through the cleared East River, and from the Hudson River through the Harlem River to the East River. Ironically, though, while both forks of the northern shipping entrance to the city were now open, modern dredging techniques had cut through the sandbars of the Atlantic Ocean entrance, allowing new, even larger ships to use that traditional passage into New York's docks.\n\nAt the beginning of the 19th century, the East River was the center of New York's shipping industry, but by the end of the century, much of it had moved to the Hudson River, leaving the East River wharves and slips to begin a long process of decay, until the area was finally rehabilitated in the mid-1960s, and the South Street Seaport Museum was opened in 1967.\n\nBy 1870, the condition of the Port of New York along both the East and Hudson Rivers had so deteriorated that the New York State legislature created the Department of Docks to renovate the port and keep New York competitive with other ports on the American East Coast. The Department of Docks was given the task of creating the master plan for the waterfront, and General George B. McClellan was engaged to head the project. McClellan held public hearings and invited plans to be submitted, ultimately receiving 70 of them, although in the end he and his successors put his own plan into effect. That plan called for the building of a seawall around Manhattan island from West 61st Street on the Hudson, around The Battery, and up to East 51st Street on the East River. The area behind the masonry wall (mostly concrete but in some parts granite blocks) would be filled in with landfill, and wide streets would be laid down on the new land. In this way, a new edge for the island (or at least the part of it used as a commercial port) would be created.\n\nThe Department had surveyed of shoreline by 1878, as well as documenting the currents and tides. By 1900, had been surveyed and core samples had been taken to inform the builders of how deep the bedrock was. The work was completed just as World War I began, allowing the Port of New York to be a major point of embarkation for troops and materiel.\n\nThe new seawall helps protect Manhattan island from storm surges, although it is only above the mean sea level, so that particularly dangerous storms, such as the nor'easter of 1992 and Hurricane Sandy in 2012, which hit the city in a way to create surges which are much higher, can still do significant damage. (The Hurricane of September 3, 1831 created the biggest storm surge on record in New York City: a rise of in one hour at the Battery, flooding all of lower Manhattan up to Canal Street.) Still, the new seawall begun in 1871 gave the island a firmer edge, improved the quality of the port, and continues to protect Manhattan from normal storm surges.\n\nThe Brooklyn Bridge, completed in 1883, was the first bridge to span the East River, connecting the cities of New York and Brooklyn, and all but replacing the frequent ferry service between them, which did not return until the late 20th century. The bridge offered cable car service across the span. The Brooklyn Bridge was followed by the Williamsburg Bridge (1903), the Queensboro Bridge (1909), the Manhattan Bridge (1912) and the Hell Gate Railroad Bridge (1916). Later would come the Triborough Bridge (1936), the Bronx-Whitestone Bridge (1939), the Throgs Neck Bridge (1961) and the Rikers Island Bridge (1966). In addition, numerous rail tunnels pass under the East River – most of them part of the New York City Subway system – as does the Brooklyn-Battery Tunnel and the Queens-Midtown Tunnel. (See Crossings below for details.) Also under the river is Water Tunnel #1 of the New York City water supply system, built in 1917 to extend the Manhattan portion of the tunnel to Brooklyn, and via City Tunnel #2 (1936) to Queens; these boroughs became part of New York City after the city's consolidation in 1898. City Tunnel #3 will also run under the river, under the northern tip of Roosevelt Island, and is expected to be completed by 2018; the Manhattan portion of the tunnel went into service in 2013.\n\nPhilanthropist John D. Rockefeller founded what is now Rockefeller University in 1901, between 63rd and 64th Streets on the river side of York Avenue, overlooking the river. The university is a research university for doctoral and post-doctoral scholars, primarily in the fields of medicine and biological science. North of it is one of the major medical centers in the city, NewYork Presbyterian / Weill Cornell Medical Center, which is associated with the medical schools of both Columbia University and Cornell University. Although it can trace its history back to 1771, the center on York Avenue, much of which overlooks the river, was built in 1932.\n\nThe East River was the site of one of the greatest disasters in the history of New York City when, in June 1904, the PS \"General Slocum\" sank near North Brother Island due to a fire. It was carrying 1,400 German-Americans to a picnic site on Long Island for an annual outing. There were only 321 survivors of the disaster, one of the worst losses of life in the city's long history, and a devastating blow to the Little Germany neighborhood on the Lower East Side. The captain of the ship and the managers of the company that owned it were indicted, but only the captain was convicted; he spent 3 and a half years of his 10-year sentence at Sing Sing Prison before being released by a Federal parole board, and then pardoned by President William Howard Taft.\n\nBeginning in 1934, and then again from 1948–1966, the Manhattan shore of the river became the location for the limited-access East River Drive, which was later renamed after Franklin Delano Roosevelt, and is universally known by New Yorkers as the \"FDR Drive\". The road is sometimes at grade, sometimes runs under locations such as the site of the Headquarters of the United Nations and Carl Schurz Park and Gracie Mansion – the mayor's official residence, and is at time double-decked, because Hell Gate provides no room for more landfill. It begins at Battery Park, runs past the Brooklyn, Manhattan, Williamsburg and Queensboro Bridges, and the Ward's Island Footbridge, and terminates just before the Robert F. Kennedy Triboro Bridge when it connects to the Harlem River Drive. Between most of the FDR Drive and the River is the East River Greenway, part of the Manhattan Waterfront Greenway. The East River Greenway was primarily built in connection with the building of the FDR Drive, although some portions were built as recently as 2002, and other sections are still incomplete.\n\nIn 1963, Con Edison built the Ravenswood Generating Station on the Long Island City shore of the river, on land some of which was once stone quarries which provided granite and marble slabs for Manhattan's buildings. The plant has since been owned by KeySpan. National Grid and TransCanada, the result of deregulation of the electrical power industry. The station, which can generate about 20% of the electrical needs of New York City – approximately 2,500 megawatts – receives some of its fuel by oil barge.\n\nNorth of the power plant can be found Socrates Sculpture Park, an illegal dumpsite and abandoned landfill that in 1986 was turned into an outdoor museum, exhibition space for artists, and public park by sculptor Mark di Suvero and local activists. The area also contains Rainey Park, which honors Thomas C. Rainey, who attempted for 40 years to get a bridge built in that location from Manhattan to Queens. The Queensboro Bridge was eventually built south of this location.\n\nIn 2011, NY Waterway started operating its East River Ferry line. The route was a 7-stop East River service that runs in a loop between East 34th Street and Hunters Point, making two intermediate stops in Brooklyn and three in Queens. The ferry, an alternative to the New York City Subway, cost $4 per one-way ticket. It was instantly popular: from June to November 2011, the ferry saw 350,000 riders, over 250% of the initial ridership forecast of 134,000 riders. In December 2016, in preparation for the start of NYC Ferry service the next year, Hornblower Cruises purchased the rights to operate the East River Ferry. NYC Ferry started service on May 1, 2017, with the East River Ferry as part of the system.\n\nIn February 2012 the federal government announced an agreement with Verdant Power to install 30 tidal turbines in the channel of the East River. The turbines were projected to begin operations in 2015 and are supposed to produce 1.05 megawatts of power. The strength of the current foiled an earlier effort in 2007 to tap the river for tidal power.\n\nOn May 7, 2017, the catastrophic failure of a Con Edison substation in Brooklyn caused a spill into the river of over of dielectric fluid, a synthetic mineral oil used to cool electrical equipment and prevent electrical discharges. (See below.)\n\nThroughout most of the history of New York City, and New Amsterdam before it, the East River has been the receptacle for the city's garbage and sewage. \"Night men\" who collected \"night soil\" from outdoor privies would dump their loads into the river, and even after the construction of the Croton Aqueduct (1842) and then the New Croton Aqueduct (1890) gave rise to indoor plumbing, the waste that was flushed away into the sewers, where it mixed with ground runoff, ran directly into the river, untreated. The sewers terminated at the slips where ships docked, until the waste began to build up, preventing dockage, after which the outfalls were moved to the end of the piers. The \"landfill\" which created new land along the shoreline when the river was \"wharfed out\" by the sale of \"water lots\" was largely garbage such as bones, offal, and even whole dead animals, along with excrement – human and animal. The result was that by the 1850s, if not before, the East River, like the other waterways around the city, was undergoing the process of eutrophication where the increase in nitrogen from excrement and other sources led to a decrease in free oxygen, which in turn led to an increase in phytoplankton such as algae and a decrease in other life forms, breaking the area's established food chain. The East River became very polluted, and its animal life decreased drastically.\n\nIn an earlier time, one person had described the transparency of the water: \"I remember the time, gentlemen, when you could go in twelve feet of water and you could see the pebbles on the bottom of this river.\" As the water got more polluted, it darkened, underwater vegetation (such as photosynthesizing seagrass) began dying, and as the seagrass beds declined, the many associated species of their ecosystems declined as well, contributing to the decline of the river. Also harmful was the general destruction of the once plentiful oyster beds in the waters around the city, and the over-fishing of menhaden, or mossbunker, a small silvery fish which had been used since the time of the Native Americans for fertilizing crops – however it took 8,000 of these schooling fish to fertilize a single acre, so mechanized fishing using the purse seine was developed, and eventually the menhaden population collapsed. Menhaden feed on phytoplankton, helping to keep them in check, and are also a vital step in the food chain, as bluefish, striped bass and other fish species which do not eat phytoplankton feed on the menhaden. The oyster is another filter feeder: oysters purify 10 to 100 gallons a day, while each menhaden filters four gallons in a minute, and their schools were immense: one report had a farmer collecting 20 oxcarts worth of menhaden using simple fishing nets deployed from the shore. The combination of more sewage, due to the availability of more potable water – New York's water consumption \"per capita\" was twice that of Europe – indoor plumbing, the destruction of filter feeders, and the collapse of the food chain, damaged the ecosystem of the waters around New York, including the East River, almost beyond repair.\n\nBecause of these changes to the ecosystem, by 1909, the level of dissolved-oxygen in the lower part of the river had declined to less than 65%, where 55% of saturation is the point at which the amount of fish and the number of their species begins to be affected. Only 17 years later, by 1926, the level of dissolved oxygen in the river had fallen to 13%, below the point at which most fish species can survive.\n\nDue to heavy pollution, the East River is dangerous to people who fall in or attempt to swim in it, although as of mid-2007 the water was cleaner than it had been in decades. , the New York City Department of Environmental Protection (DEP) categorizes the East River as Use Classification I, meaning it is safe for secondary contact activities such as boating and fishing. According to the marine sciences section of the DEP, the channel is swift, with water moving as fast as four knots, just as it does in the Hudson River on the other side of Manhattan. That speed can push casual swimmers out to sea. A few people drown in the waters around New York City each year.\n\n, it was reported that the level of bacteria in the river was below Federal guidelines for swimming on most days, although the readings may vary significantly, so that the outflow from Newtown Creek or the Gowanus Canal can be tens or hundreds of times higher than recommended, according to Riverkeeper, a non-profit environmentalist advocacy group. The counts are also higher along the shores of the strait than they are in the middle of its flow. Nevertheless, the \"Brooklyn Bridge Swim\" is an annual event where swimmers cross the channel from Brooklyn Bridge Park to Manhattan.\n\nStill, thanks to reductions in pollution, cleanups, the restriction of development, and other environmental controls, the East River along Manhattan is one of the areas of New York's waterways – including the Hudson-Raritan Estuary and both shores of Long Island – which have shown signs of the return of biodiversity. On the other hand, the river is also under attack from hardy, competitive, alien critters, such as the European green crab, which is considered to be one of the world's ten worst invasive species, and is present in the river.\n\nOn May 7, 2017, the catastrophic failure of Con Edison's Farragut Substation at 89 John Street in Dumbo, Brooklyn, caused a spill of dielectric fluid – an insoluble synthetic mineral oil, considered non-toxic by New York state, used to cool electrical equipment and prevent electrical discharges – into the East River from a tank. The National Response Center received a report of the spill at 1:30pm that day, although the public did not learn of the spill for two days, and then only from tweets from NYC Ferry. A \"safety zone\" was established, extending from a line drawn between Dupont Street in Greenpoint, Brooklyn, to East 25th Street in Kips Bay, Manhattan, south to Buttermilk Channel. Recreational and human-powered vehicles such as kayaks and paddleboards were banned from the zone while the oil was being cleaned up, and the speed of commercial vehicles restricted so as not to spread the oil in their wakes, causing delays in NYC Ferry service. The clean-up efforts were being undertaken by Con Edison personnel and private environmental contractors, the U.S. Coast Guard, and the New York State Department of Environmental Conservation, with the assistance of NYC Emergency Management.\n\nThe loss of the sub-station caused a voltage dip in the power provided by Con Ed to the Metropolitan Transportation Authority's New York City Subway system, which disrupted its signals.\n\nThe Coast Guard estimated that of oil spilled into the water, with the remainder soaking into the soil at the substation. In the past the Coast Guard has on average been able to recover about 10% of oil spilled, however the complex tides in the river make the recovery much more difficult, with the turbulent water caused by the river's change of tides pushing contaminated water over the containment booms, where it is then carried out to sea and cannot be recovered. By Friday May 12, officials from Con Edison reported that almost had been taken out of the water.\n\nEnvironmental damage to wildlife is expected to be less than if the spill was of petroleum-based oil, but the oil can still block the sunlight necessary for the river's fish and other organisms to live. Nesting birds are also in possible danger from the oil contaminating their nests and potentially poisoning the birds or their eggs. Water from the East River was reported to have tested positive for low levels of PCB, a known carcinogen.\n\nPutting the spill into perspective, John Lipscomb, the vice president of advocacy for Riverkeepers said that the chronic release after heavy rains of overflow from city's wastewater treatment system was \"a bigger problem for the harbor than this accident.\" The state Department of Environmental Conservation is investigating the spill. It was later reported that according to DEC data which dates back to 1978, the substation involved had spilled 179 times previously, more than any other Con Ed facility. The spills have included 8,400 gallons of dielectric oil, hydraulic oil, and antifreeze which leaked at various times into the soil around the substation, the sewers, and the East River.\n\nOn June 22, Con Edison used non-toxic green dye and divers in the river to find the source of the leak. As a result, a hole was plugged. The utility continued to believe that the bulk of the spill went into the ground around the substation, and excavated and removed several hundred cubic yards of soil from the area. They estimated that about went into the river, of which were recovered. Con Edison said that it installed a new transformer, and intended to add new barrier around the facility to help guard against future spills propagating into the river.\n\n! Crossing\n! Carries\n! Location\n! Coordinates\n!Year<br>opened\n!colspan=5Manhattan — Manhattan (Roosevelt Island)\nRoosevelt Island Tramway\npedestrians, bicycles (aerial tramway)\n\n1976\n!colspan=5Manhattan — Brooklyn\nCity Tunnel #1\nwater\n\n1917\nBrooklyn-Battery Tunnel \n\n1950\nJoralemon Street Tunnel\n\n1908\nMontague Street Tunnel\n\n1920\nClark Street Tunnel\n\n1919\nCranberry Street Tunnel\n\n1932\nBrooklyn Bridge\nvehicles, pedestrians, bicycles\n\n1883\nManhattan Bridge\n, vehicles, pedestrians, bicycles\n\n1909\nRutgers Street Tunnel\n\n1936\nWilliamsburg Bridge\n, vehicles, pedestrians, bicycles\n\n1903\n13th Street Pumping Station tunnel\nwastewater\n\n14th Street Tunnel\n\n1924\n!colspan=5Manhattan — Queens\nEast River Tunnels\nAmtrak Northeast Corridor<br> Long Island Rail Road\n\n1910\nQueens Midtown Tunnel \n\n1940\nSteinway Tunnel\n\n1915\n53rd Street Tunnel\n\n1933\nEd Koch Queensboro Bridge (59th Street Bridge)\n, pedestrians, bicycles\n\n1909\n60th Street Tunnel\n\n1920\n63rd Street Tunnel\n\n1989\nRoosevelt Island Bridge\nvehicles, pedestrians, bicycles to Roosevelt Island\n\n1955\nCity Tunnel #3\nwater\n\n2018 (proj.)\nRobert F. Kennedy Triborough Bridge (East River Suspension Span)\n, pedestrians, bicycles\n\n1936\nHell Gate Bridge\nAmtrak Northeast Corridor<br>CSX Transportation Fremont Secondary<br>Providence & Worcester Railroad\n\n1916\n!colspan=5The Bronx — Queens\nRikers Island Bridge\nvehicles to Rikers Island\n\n1966\nBronx-Whitestone Bridge\n\n1939\nThrogs Neck Bridge\n\n1961\n\nMusic\nBULLET::::- Edward Harrigan's 1874 comic song \"Muldoon, the Solid Man\" mentions \"the enchanting East River air\"\nBULLET::::- The Brecker Brothers performed a song named after the river that is featured on their album \"Heavy Metal Be-Bop\" (1978)\nBULLET::::- According to its author, Yasushi Akimoto, the noted Japanese song \"Kawa no Nagare no Yō ni\" – the \"swan song\" of the noted singer Hibari Misora – was inspired by the East River.\nBULLET::::- Prurient's song \"Greenpoint\" mentions that \"the East River isn't romantic anymore; it's where the suicides go\"\n\nTelevision\nBULLET::::- The character Cosmo Kramer decided to swim in the East River for exercise in the American TV series \"Seinfeld\" episode \"The Nap\"\nBULLET::::- In \"The Simpsons\" episode, \"The City of New York vs. Homer Simpson\", Homer receives a letter stating that his vehicle is illegally parked between the World Trade Center Towers and that if he doesn't fix the issue his car will be \"crushed into a cube and thrown into the East River at your expense.\"\n\nGames\nBULLET::::- In the video game \"\", the Russian Navy had taken control of the river as part of their invasion of the East Coast of the United States in the fictitious Russo-American War.\n\nLiterature\n\nBULLET::::- In the final \"Percy Jackson and the Olympians\" novel, \"The Last Olympian\", the East River appears as a river spirit in the form of a telkhine. The East River Spirit is a rival to the Hudson River Spirit, but assists the Demigods in the Battle of Manhattan by sinking the Titan's ships.\n\nBULLET::::- List of New York rivers\nBULLET::::- Lists of crossings of the East River\nBULLET::::- Geography and environment of New York City\nBULLET::::- Geography of New York Harbor\n\nInformational notes\nCitations\nBibliography\n\nBULLET::::- East River NYC from the Greater Astoria Historical Society\nBULLET::::- LIC Community Boathouse site for free paddling on the East River\nBULLET::::- Western Queens waterfront information page\n"}
{"id": "9593", "url": "https://en.wikipedia.org/wiki?curid=9593", "title": "Existentialism", "text": "Existentialism\n\nExistentialism () is a tradition of philosophical enquiry which takes as its starting point the experience of the human subject—not merely the thinking subject, but the acting, feeling, living human individual. It is associated mainly with certain 19th- and 20th-century European philosophers who, despite profound doctrinal differences, shared the belief in that beginning of philosophical thinking.\n\nWhile the predominant value of existentialist thought is commonly acknowledged to be freedom, its primary virtue is authenticity. In the view of the existentialist, the individual's starting point is characterized by what has been called \"the existential angst\" (or variably, existential attitude, dread, etc.), or a sense of disorientation, confusion, or dread in the face of an apparently meaningless or absurd world. Many existentialists have also regarded traditional systematic or academic philosophies, in both style and content, as too abstract and remote from concrete human experience.\n\nSøren Kierkegaard is generally considered to have been the first existentialist philosopher, though he did not use the term existentialism. He proposed that each individual—not society or religion—is solely responsible for giving meaning to life and living it passionately and sincerely, or \"authentically\".\n\nExistentialism became popular in the years following World War II, thanks to Sartre who read Heidegger while in a POW camp, and strongly influenced many disciplines besides philosophy, including theology, drama, art, literature, and psychology.\n\nThe term \"existentialism\" (French: \"L'existentialisme\") was coined by the French Catholic philosopher Gabriel Marcel in the mid-1940s. At first, when Marcel applied the term to Jean-Paul Sartre at a colloquium in 1945, Sartre rejected it. Sartre subsequently changed his mind and, on October 29, 1945, publicly adopted the existentialist label in a lecture to the \"Club Maintenant\" in Paris. The lecture was published as \"L'existentialisme est un humanisme\" (\"Existentialism is a Humanism\"), a short book that did much to popularize existentialist thought. Marcel later came to reject the label himself in favour of the term Neo-Socratic, in honor of Kierkegaard's essay \"On The Concept of Irony\".\n\nSome scholars argue that the term should be used only to refer to the cultural movement in Europe in the 1940s and 1950s associated with the works of the philosophers Sartre, Simone de Beauvoir, Maurice Merleau-Ponty, and Albert Camus. Other scholars extend the term to Kierkegaard, and yet others extend it as far back as Socrates. However, the term is often identified with the philosophical views of Sartre.\n\nThe labels \"existentialism\" and \"existentialist\" are often seen as historical conveniences in as much as they were first applied to many philosophers in hindsight, long after they had died. In fact, while existentialism is generally considered to have originated with Kierkegaard, the first prominent existentialist philosopher to adopt the term as a self-description was Jean-Paul Sartre. Sartre posits the idea that \"what all existentialists have in common is the fundamental doctrine that existence precedes essence\", as scholar Frederick Copleston explains. According to philosopher Steven Crowell, defining existentialism has been relatively difficult, and he argues that it is better understood as a general approach used to reject certain systematic philosophies rather than as a systematic philosophy itself. Sartre himself, in a lecture delivered in 1945, described existentialism as \"the attempt to draw all the consequences from a position of consistent atheism\".\n\nAlthough many outside Scandinavia consider the term existentialism to have originated from Kierkegaard himself, it is more likely that Kierkegaard adopted this term (or at least the term \"existential\" as a description of his philosophy) from the Norwegian poet and literary critic Johan Sebastian Cammermeyer Welhaven. This assertion comes from two sources. The Norwegian philosopher Erik Lundestad refers to the Danish philosopher Fredrik Christian Sibbern. Sibbern is supposed to have had two conversations in 1841, the first with Welhaven and the second with Kierkegaard. It is in the first conversation that it is believed that Welhaven came up with \"a word that he said covered a certain thinking, which had a close and positive attitude to life, a relationship he described as existential\". This was then brought to Kierkegaard by Sibbern.\n\nThe second claim comes from the Norwegian historian Rune Slagstad, who claims to prove that Kierkegaard himself said the term \"existential\" was borrowed from the poet. He strongly believes that it was Kierkegaard himself who said that \"Hegelians do not study philosophy 'existentially'; to use a phrase by Welhaven from one time when I spoke with him about philosophy\".\n\nSartre argued that a central proposition of existentialism is that \"existence precedes essence\", which means that the most important consideration for individuals is that they are individuals—independently acting and responsible, conscious beings (\"existence\")—rather than what labels, roles, stereotypes, definitions, or other preconceived categories the individuals fit (\"essence\"). The actual life of the individuals is what constitutes what could be called their \"true essence\" instead of there being an arbitrarily attributed essence others use to define them. Thus, human beings, through their own consciousness, create their own values and determine a meaning to their life. Although it was Sartre who explicitly coined the phrase, similar notions can be found in the thought of existentialist philosophers such as Heidegger, and Kierkegaard:\n\nSome interpret the imperative to define oneself as meaning that anyone can wish to be anything. However, an existentialist philosopher would say such a wish constitutes an inauthentic existence – what Sartre would call 'bad faith'. Instead, the phrase should be taken to say that people are (1) defined only insofar as they act and (2) that they are responsible for their actions. For example, someone who acts cruelly towards other people is, by that act, defined as a cruel person. Furthermore, by this action of cruelty, such persons are themselves responsible for their new identity (cruel persons). This is as opposed to their genes, or \"human nature\", bearing the blame.\n\nAs Sartre says in his lecture \"Existentialism is a Humanism\": \"... man first of all exists, encounters himself, surges up in the world—and defines himself afterwards\". The more positive, therapeutic aspect of this is also implied: a person can choose to act in a different way, and to be a good person instead of a cruel person.\n\nSartre's definition of existentialism was based on Heidegger's magnum opus \"Being and Time\". In the correspondence with Jean Beaufret later published as the \"Letter on Humanism\", Heidegger implies that Sartre misunderstood him for his own purposes of subjectivism, and that he did not mean that actions take precedence over being so long as those actions were not reflected upon. Heidegger commented that \"the reversal of a metaphysical statement remains a metaphysical statement\", meaning that he thought Sartre had simply switched the roles traditionally attributed to essence and existence without interrogating these concepts and their history in the way that Heidegger claimed to have done.\n\nThe notion of the absurd contains the idea that there is no meaning in the world beyond what meaning we give it. This meaninglessness also encompasses the amorality or \"unfairness\" of the world. This conceptualization can be highlighted in the way it opposes the traditional Abrahamic religious perspective, which establishes that life's purpose is about the fulfillment of God's commandments. Such a purpose is what gives meaning to people's lives. To live the life of the absurd means rejecting a life that finds or pursues specific meaning for man's existence since there is nothing to be discovered. According to Albert Camus, the world or the human being is not in itself absurd. The concept only emerges through the juxtaposition of the two, where life becomes absurd due to the incompatibility between human beings and the world they inhabit. This view constitutes one of the two interpretations of the absurd in existentialist literature. The second view, which was first elaborated by Søren Kierkegaard, holds that absurdity is limited to actions and choices of human beings. These are considered absurd since they issue from human freedom, undermining their foundation outside of themselves.\n\nThe notion of the absurd in existentialism contrasts with the claim that \"bad things don't happen to good people\"; to the world, metaphorically speaking, there is no such thing as a good person or a bad person; what happens happens, and it may just as well happen to a \"good\" person as to a \"bad\" person. Because of the world's absurdity, at any point in time, anything can happen to anyone, and a tragic event could plummet someone into direct confrontation with the Absurd. The notion of the Absurd has been prominent in literature throughout history. Many of the literary works of Søren Kierkegaard, Samuel Beckett, Franz Kafka, Fyodor Dostoyevsky, Eugène Ionesco, Miguel de Unamuno, Luigi Pirandello, Jean-Paul Sartre, Joseph Heller and Albert Camus contain descriptions of people who encounter the absurdity of the world.\n\nIt is in relation to the concept of the devastating awareness of meaninglessness that Albert Camus claimed that \"there is only one truly serious philosophical problem, and that is suicide\" in his \"The Myth of Sisyphus\". Although \"prescriptions\" against the possibly deleterious consequences of these kinds of encounters vary, from Kierkegaard's religious \"stage\" to Camus' insistence on persevering in spite of absurdity, the concern with helping people avoid living their lives in ways that put them in the perpetual danger of having everything meaningful break down is common to most existentialist philosophers. The possibility of having everything meaningful break down poses a threat of quietism, which is inherently against the existentialist philosophy. It has been said that the possibility of suicide makes all humans existentialists. The ultimate hero of absurdism lives without meaning and faces suicide without succumbing to it.\n\nFacticity is a concept defined by Sartre in \"Being and Nothingness\" as the \"in-itself\", which delineates for humans the modalities of being and not being. This can be more easily understood when considering facticity in relation to the temporal dimension of our past: one's past is what one is, in the sense that it co-constitutes oneself. However, to say that one is only one's past would be to ignore a significant part of reality (the present and the future), while saying that one's past is only what one was, would entirely detach it from oneself now. A denial of one's own concrete past constitutes an inauthentic lifestyle, and the same goes for all other kinds of facticity (having a human body—e.g., one that does not allow a person to run faster than the speed of sound—identity, values, etc.).\n\nFacticity is both a limitation and a condition of freedom. It is a limitation in that a large part of one's facticity consists of things one could not have chosen (birthplace, etc.), but a condition of freedom in the sense that one's values most likely depend on it. However, even though one's facticity is \"set in stone\" (as being past, for instance), it cannot determine a person: the value ascribed to one's facticity is still ascribed to it freely by that person. As an example, consider two men, one of whom has no memory of his past and the other who remembers everything. They both have committed many crimes, but the first man, knowing nothing about this, leads a rather normal life while the second man, feeling trapped by his own past, continues a life of crime, blaming his own past for \"trapping\" him in this life. There is nothing essential about his committing crimes, but he ascribes this meaning to his past.\n\nHowever, to disregard one's facticity when, in the continual process of self-making, one projects oneself into the future, that would be to put oneself in denial of oneself, and thus would be inauthentic. In other words, the origin of one's projection must still be one's facticity, though in the mode of not being it (essentially). An example of one focusing solely on one's possible projects without reflecting on one's current facticity: if one continually thinks about future possibilities related to being rich (e.g. a better car, bigger house, better quality of life, etc.) without considering the facticity of \"not currently having the financial means to do so\". In this example, considering both facticity and transcendence, an authentic mode of being would be considering future projects that might improve one's current finances (e.g. putting in extra hours, or investing savings) in order to arrive at a \"future-facticity\" of a modest pay rise, further leading to purchase of an affordable car.\n\nAnother aspect of facticity is that it entails angst, both in the sense that freedom \"produces\" angst when limited by facticity, and in the sense that the lack of the possibility of having facticity to \"step in\" for one to take responsibility for something one has done, also produces angst.\n\nAnother aspect of existential freedom is that one can change one's values. Thus, one is responsible for one's values, regardless of society's values. The focus on freedom in existentialism is related to the limits of the responsibility one bears, as a result of one's freedom: the relationship between freedom and responsibility is one of interdependency, and a clarification of freedom also clarifies that for which one is responsible.\n\nMany noted existentialist writers consider the theme of authentic existence important. Authentic existence involves the idea that one has to \"create oneself\" and then live in accordance with this self. What is meant by authenticity is that in acting, one should act as oneself, not as \"one's acts\" or as \"one's genes\" or any other essence requires. The authentic act is one that is in accordance with one's freedom. As a condition of freedom is facticity, this includes one's facticity, but not to the degree that this facticity can in any way determine one's transcendent choices (in the sense that one could then blame one's background [facticity] for making the choice one made [chosen project, from one's transcendence]). The role of facticity in relation to authenticity involves letting one's actual values come into play when one makes a choice (instead of, like Kierkegaard's Aesthete, \"choosing\" randomly), so that one also takes responsibility for the act instead of choosing either-or without allowing the options to have different values.\n\nIn contrast to this, the inauthentic is the denial to live in accordance with one's freedom. This can take many forms, from pretending choices are meaningless or random, through convincing oneself that some form of determinism is true, to a sort of \"mimicry\" where one acts as \"one should\".\n\nHow \"one should\" act is often determined by an image one has, of how one such as oneself (say, a bank manager, lion tamer, prostitute, etc.) acts. In \"Being and Nothingness\", Sartre relates an example of a \"waiter\" in \"bad faith\": he merely takes part in the \"act\" of being a typical waiter, albeit very convincingly. This image usually corresponds to some sort of social norm, but this does not mean that all acting in accordance with social norms is inauthentic: The main point is the attitude one takes to one's own freedom and responsibility, and the extent to which one acts in accordance with this freedom.\n\nThe Other (when written with a capital \"O\") is a concept more properly belonging to phenomenology and its account of intersubjectivity. However, the concept has seen widespread use in existentialist writings, and the conclusions drawn from it differ slightly from the phenomenological accounts. The experience of the Other is the experience of another free subject who inhabits the same world as a person does. In its most basic form, it is this experience of the Other that constitutes intersubjectivity and objectivity. To clarify, when one experiences someone else, and this Other person experiences the world (the same world that a person experiences)—only from \"over there\"—the world itself is constituted as objective in that it is something that is \"there\" as identical for both of the subjects; a person experiences the other person as experiencing the same things. This experience of the Other's look is what is termed the Look (sometimes the Gaze).\n\nWhile this experience, in its basic phenomenological sense, constitutes the world as objective, and oneself as objectively existing subjectivity (one experiences oneself as seen in the Other's Look in precisely the same way that one experiences the Other as seen by him, as subjectivity), in existentialism, it also acts as a kind of limitation of freedom. This is because the Look tends to objectify what it sees. As such, when one experiences oneself in the Look, one doesn't experience oneself as nothing (no thing), but as something. Sartre's own example of a man peeping at someone through a keyhole can help clarify this: at first, this man is entirely caught up in the situation he is in; he is in a pre-reflexive state where his entire consciousness is directed at what goes on in the room. Suddenly, he hears a creaking floorboard behind him, and he becomes aware of himself as seen by the Other. He is thus filled with shame for he perceives himself as he would perceive someone else doing what he was doing, as a Peeping Tom. For Sartre, this phenomenological experience of shame establishes a proof for the existence of other minds and defeats the problem of solipsism. For the conscious state of shame to be experienced, one has to become aware of oneself as an object of another look, proving a priori, that other minds exist. The Look is then co-constitutive of one's facticity.\n\nAnother characteristic feature of the Look is that no Other really needs to have been there: It is quite possible that the creaking floorboard was nothing but the movement of an old house; the Look is not some kind of mystical telepathic experience of the actual way the other sees one (there may also have been someone there, but he could have not noticed that the person was there). It is only one's perception of the way another might perceive him.\n\n\"Existential angst\", sometimes called existential dread, anxiety, or anguish, is a term that is common to many existentialist thinkers. It is generally held to be a negative feeling arising from the experience of human freedom and responsibility. The archetypical example is the experience one has when standing on a cliff where one not only fears falling off it, but also dreads the possibility of throwing oneself off. In this experience that \"nothing is holding me back\", one senses the lack of anything that predetermines one to either throw oneself off or to stand still, and one experiences one's own freedom.\n\nIt can also be seen in relation to the previous point how angst is before nothing, and this is what sets it apart from fear that has an object. While in the case of fear, one can take definitive measures to remove the object of fear, in the case of angst, no such \"constructive\" measures are possible. The use of the word \"nothing\" in this context relates both to the inherent insecurity about the consequences of one's actions, and to the fact that, in experiencing freedom as angst, one also realizes that one is fully responsible for these consequences. There is nothing in people (genetically, for instance) that acts in their stead—that they can blame if something goes wrong. Therefore, not every choice is perceived as having dreadful possible consequences (and, it can be claimed, human lives would be unbearable if every choice facilitated dread). However, this doesn't change the fact that freedom remains a condition of every action.\n\nDespair is generally defined as a loss of hope. In existentialism, it is more specifically a loss of hope in reaction to a breakdown in one or more of the defining qualities of one's self or identity. If a person is invested in being a particular thing, such as a bus driver or an upstanding citizen, and then finds their being-thing compromised, they would normally be found in a state of despair—a hopeless state. For example, a singer who loses the ability to sing may despair if they have nothing else to fall back on—nothing to rely on for their identity. They find themselves unable to be what defined their being.\n\nWhat sets the existentialist notion of despair apart from the conventional definition is that existentialist despair is a state one is in even when they are not overtly in despair. So long as a person's identity depends on qualities that can crumble, they are in perpetual despair—and as there is, in Sartrean terms, no human essence found in conventional reality on which to constitute the individual's sense of identity, despair is a universal human condition. As Kierkegaard defines it in \"Either/Or\": \"Let each one learn what he can; both of us can learn that a person’s unhappiness never lies in his lack of control over external conditions, since this would only make him completely unhappy.\" In \"Works of Love\", he says: \n\nExistentialists oppose definitions of human beings as primarily rational, and, therefore, oppose positivism and rationalism. Existentialism asserts that people actually make decisions based on subjective meaning rather than pure rationality. The rejection of reason as the source of meaning is a common theme of existentialist thought, as is the focus on the feelings of anxiety and dread that we feel in the face of our own radical freedom and our awareness of death. Kierkegaard advocated rationality as a means to interact with the objective world (e.g., in the natural sciences), but when it comes to existential problems, reason is insufficient: \"Human reason has boundaries\".\n\nLike Kierkegaard, Sartre saw problems with rationality, calling it a form of \"bad faith\", an attempt by the self to impose structure on a world of phenomena—\"the Other\"—that is fundamentally irrational and random. According to Sartre, rationality and other forms of bad faith hinder people from finding meaning in freedom. To try to suppress their feelings of anxiety and dread, people confine themselves within everyday experience, Sartre asserts, thereby relinquishing their freedom and acquiescing to being possessed in one form or another by \"the Look\" of \"the Other\" (i.e., possessed by another person—or at least one's idea of that other person).\n\nAn existentialist reading of the Bible would demand that the reader recognize that they are an existing subject studying the words more as a recollection of events. This is in contrast to looking at a collection of \"truths\" that are outside and unrelated to the reader, but may develop a sense of reality/God. Such a reader is not obligated to follow the commandments as if an external agent is forcing these commandments upon them, but as though they are inside them and guiding them from inside. This is the task Kierkegaard takes up when he asks: \"Who has the more difficult task: the teacher who lectures on earnest things a meteor's distance from everyday life—or the learner who should put it to use?\"\n\nAlthough nihilism and existentialism are distinct philosophies, they are often confused with one another as both are rooted in the human experience of anguish and confusion stemming from the apparent meaninglessness of a world in which humans are compelled to find or create meaning. A primary cause of confusion is that Friedrich Nietzsche is an important philosopher in both fields. Existentialist philosophers often stress the importance of Angst as signifying the absolute lack of any objective ground for action, a move that is often reduced to a moral or an existential nihilism. A pervasive theme in the works of existentialist philosophy, however, is to persist through encounters with the absurd, as seen in Camus' \"The Myth of Sisyphus\" (\"One must imagine Sisyphus happy\"), and it is only very rarely that existentialist philosophers dismiss morality or one's self-created meaning: Kierkegaard regained a sort of morality in the religious (although he wouldn't himself agree that it was ethical; the religious suspends the ethical), and Sartre's final words in \"Being and Nothingness\" are \"All these questions, which refer us to a pure and not an accessory (or impure) reflection, can find their reply only on the ethical plane. We shall devote to them a future work.\"\n\nSøren Kierkegaard and Friedrich Nietzsche were two of the first philosophers considered fundamental to the existentialist movement, though neither used the term \"existentialism\" and it is unclear whether they would have supported the existentialism of the 20th century. They focused on subjective human experience rather than the objective truths of mathematics and science, which they believed were too detached or observational to truly get at the human experience. Like Pascal, they were interested in people's quiet struggle with the apparent meaninglessness of life and the use of diversion to escape from boredom. Unlike Pascal, Kierkegaard and Nietzsche also considered the role of making free choices, particularly regarding fundamental values and beliefs, and how such choices change the nature and identity of the chooser. Kierkegaard's knight of faith and Nietzsche's Übermensch are representative of people who exhibit Freedom, in that they define the nature of their own existence. Nietzsche's idealized individual invents his own values and creates the very terms they excel under. By contrast, Kierkegaard, opposed to the level of abstraction in Hegel, and not nearly as hostile (actually welcoming) to Christianity as Nietzsche, argues through a pseudonym that the objective certainty of religious truths (specifically Christian) is not only impossible, but even founded on logical paradoxes. Yet he continues to imply that a leap of faith is a possible means for an individual to reach a higher stage of existence that transcends and contains both an aesthetic and ethical value of life. Kierkegaard and Nietzsche were also precursors to other intellectual movements, including postmodernism, and various strands of psychotherapy. However, Kierkegaard believed that individuals should live in accordance with their thinking.\n\nThe first important literary author also important to existentialism was the Russian Fyodor Dostoyevsky. Dostoyevsky's \"Notes from Underground\" portrays a man unable to fit into society and unhappy with the identities he creates for himself. Jean-Paul Sartre, in his book on existentialism \"Existentialism is a Humanism\", quoted Dostoyevsky's \"The Brothers Karamazov\" as an example of existential crisis. Sartre attributes Ivan Karamazov's claim, \"If God did not exist, everything would be permitted\" to Dostoyevsky himself, though this quote does not appear in the novel. However, a similar sentiment is explicitly stated when Alyosha visits Dimitri in prison. Dimitri mentions his conversations with Rakitin in which the idea that \"Then, if He doesn't exist, man is king of the earth, of the universe\" allowing the inference contained in Sartre's attribution to remain a valid idea contested within the novel. Other Dostoyevsky novels covered issues raised in existentialist philosophy while presenting story lines divergent from secular existentialism: for example, in \"Crime and Punishment\", the protagonist Raskolnikov experiences an existential crisis and then moves toward a Christian Orthodox worldview similar to that advocated by Dostoyevsky himself.\n\nIn the first decades of the 20th century, a number of philosophers and writers explored existentialist ideas. The Spanish philosopher Miguel de Unamuno y Jugo, in his 1913 book \"The Tragic Sense of Life in Men and Nations\", emphasized the life of \"flesh and bone\" as opposed to that of abstract rationalism. Unamuno rejected systematic philosophy in favor of the individual's quest for faith. He retained a sense of the tragic, even absurd nature of the quest, symbolized by his enduring interest in Cervantes' fictional character Don Quixote. A novelist, poet and dramatist as well as philosophy professor at the University of Salamanca, Unamuno wrote a short story about a priest's crisis of faith, \"Saint Manuel the Good, Martyr\", which has been collected in anthologies of existentialist fiction. Another Spanish thinker, Ortega y Gasset, writing in 1914, held that human existence must always be defined as the individual person combined with the concrete circumstances of his life: \"\"Yo soy yo y mi circunstancia\"\" (\"I am myself and my circumstances\"). Sartre likewise believed that human existence is not an abstract matter, but is always situated (\"\"en situation\"\").\n\nAlthough Martin Buber wrote his major philosophical works in German, and studied and taught at the Universities of Berlin and Frankfurt, he stands apart from the mainstream of German philosophy. Born into a Jewish family in Vienna in 1878, he was also a scholar of Jewish culture and involved at various times in Zionism and Hasidism. In 1938, he moved permanently to Jerusalem. His best-known philosophical work was the short book \"I and Thou\", published in 1922. For Buber, the fundamental fact of human existence, too readily overlooked by scientific rationalism and abstract philosophical thought, is \"man with man\", a dialogue that takes place in the so-called \"sphere of between\" (\"\"das Zwischenmenschliche\"\").\n\nTwo Russian thinkers, Lev Shestov and Nikolai Berdyaev, became well known as existentialist thinkers during their post-Revolutionary exiles in Paris. Shestov, born into a Ukrainian-Jewish family in Kiev, had launched an attack on rationalism and systematization in philosophy as early as 1905 in his book of aphorisms \"All Things Are Possible\".\n\nBerdyaev, also from Kiev but with a background in the Eastern Orthodox Church, drew a radical distinction between the world of spirit and the everyday world of objects. Human freedom, for Berdyaev, is rooted in the realm of spirit, a realm independent of scientific notions of causation. To the extent the individual human being lives in the objective world, he is estranged from authentic spiritual freedom. \"Man\" is not to be interpreted naturalistically, but as a being created in God's image, an originator of free, creative acts. He published a major work on these themes, \"The Destiny of Man\", in 1931.\n\nGabriel Marcel, long before coining the term \"existentialism\", introduced important existentialist themes to a French audience in his early essay \"Existence and Objectivity\" (1925) and in his \"Metaphysical Journal\" (1927). A dramatist as well as a philosopher, Marcel found his philosophical starting point in a condition of metaphysical alienation: the human individual searching for harmony in a transient life. Harmony, for Marcel, was to be sought through \"secondary reflection\", a \"dialogical\" rather than \"dialectical\" approach to the world, characterized by \"wonder and astonishment\" and open to the \"presence\" of other people and of God rather than merely to \"information\" about them. For Marcel, such presence implied more than simply being there (as one thing might be in the presence of another thing); it connoted \"extravagant\" availability, and the willingness to put oneself at the disposal of the other.\n\nMarcel contrasted \"secondary reflection\" with abstract, scientific-technical \"primary reflection\", which he associated with the activity of the abstract Cartesian ego. For Marcel, philosophy was a concrete activity undertaken by a sensing, feeling human being incarnate—embodied—in a concrete world. Although Jean-Paul Sartre adopted the term \"existentialism\" for his own philosophy in the 1940s, Marcel's thought has been described as \"almost diametrically opposed\" to that of Sartre. Unlike Sartre, Marcel was a Christian, and became a Catholic convert in 1929.\n\nIn Germany, the psychologist and philosopher Karl Jaspers—who later described existentialism as a \"phantom\" created by the public—called his own thought, heavily influenced by Kierkegaard and Nietzsche, \"Existenzphilosophie\". For Jaspers, \"\"Existenz\"-philosophy is the way of thought by means of which man seeks to become himself...This way of thought does not cognize objects, but elucidates and makes actual the being of the thinker\".\n\nJaspers, a professor at the University of Heidelberg, was acquainted with Martin Heidegger, who held a professorship at Marburg before acceding to Husserl's chair at Freiburg in 1928. They held many philosophical discussions, but later became estranged over Heidegger's support of National Socialism (Nazism). They shared an admiration for Kierkegaard, and in the 1930s, Heidegger lectured extensively on Nietzsche. Nevertheless, the extent to which Heidegger should be considered an existentialist is debatable. In \"Being and Time\" he presented a method of rooting philosophical explanations in human existence (\"Dasein\") to be analysed in terms of existential categories (\"existentiale\"); and this has led many commentators to treat him as an important figure in the existentialist movement.\n\nFollowing the Second World War, existentialism became a well-known and significant philosophical and cultural movement, mainly through the public prominence of two French writers, Jean-Paul Sartre and Albert Camus, who wrote best-selling novels, plays and widely read journalism as well as theoretical texts. These years also saw the growing reputation of Heidegger's book \"Being and Time\" outside Germany.\nSartre dealt with existentialist themes in his 1938 novel \"Nausea\" and the short stories in his 1939 collection \"The Wall\", and had published his treatise on existentialism, \"Being and Nothingness\", in 1943, but it was in the two years following the liberation of Paris from the German occupying forces that he and his close associates—Camus, Simone de Beauvoir, Maurice Merleau-Ponty, and others—became internationally famous as the leading figures of a movement known as existentialism. In a very short period of time, Camus and Sartre in particular became the leading public intellectuals of post-war France, achieving by the end of 1945 \"a fame that reached across all audiences.\" Camus was an editor of the most popular leftist (former French Resistance) newspaper \"Combat\"; Sartre launched his journal of leftist thought, \"Les Temps Modernes\", and two weeks later gave the widely reported lecture on existentialism and secular humanism to a packed meeting of the Club Maintenant. Beauvoir wrote that \"not a week passed without the newspapers discussing us\"; existentialism became \"the first media craze of the postwar era.\"\n\nBy the end of 1947, Camus' earlier fiction and plays had been reprinted, his new play \"Caligula\" had been performed and his novel \"The Plague\" published; the first two novels of Sartre's \"The Roads to Freedom\" trilogy had appeared, as had Beauvoir's novel \"The Blood of Others\". Works by Camus and Sartre were already appearing in foreign editions. The Paris-based existentialists had become famous.\n\nSartre had traveled to Germany in 1930 to study the phenomenology of Edmund Husserl and Martin Heidegger, and he included critical comments on their work in his major treatise \"Being and Nothingness\". Heidegger's thought had also become known in French philosophical circles through its use by Alexandre Kojève in explicating Hegel in a series of lectures given in Paris in the 1930s. The lectures were highly influential; members of the audience included not only Sartre and Merleau-Ponty, but Raymond Queneau, Georges Bataille, Louis Althusser, André Breton, and Jacques Lacan. A selection from Heidegger's \"Being and Time\" was published in French in 1938, and his essays began to appear in French philosophy journals.\nHeidegger read Sartre's work and was initially impressed, commenting: \"Here for the first time I encountered an independent thinker who, from the foundations up, has experienced the area out of which I think. Your work shows such an immediate comprehension of my philosophy as I have never before encountered.\" Later, however, in response to a question posed by his French follower Jean Beaufret, Heidegger distanced himself from Sartre's position and existentialism in general in his \"Letter on Humanism\". Heidegger's reputation continued to grow in France during the 1950s and 1960s. In the 1960s, Sartre attempted to reconcile existentialism and Marxism in his work \"Critique of Dialectical Reason\". A major theme throughout his writings was freedom and responsibility.\n\nCamus was a friend of Sartre, until their falling-out, and wrote several works with existential themes including \"The Rebel\", \"Summer in Algiers\", \"The Myth of Sisyphus\", and \"The Stranger\", the latter being \"considered—to what would have been Camus's irritation—the exemplary existentialist novel.\" Camus, like many others, rejected the existentialist label, and considered his works concerned with facing the absurd. In the titular book, Camus uses the analogy of the Greek myth of Sisyphus to demonstrate the futility of existence. In the myth, Sisyphus is condemned for eternity to roll a rock up a hill, but when he reaches the summit, the rock will roll to the bottom again. Camus believes that this existence is pointless but that Sisyphus ultimately finds meaning and purpose in his task, simply by continually applying himself to it. The first half of the book contains an extended rebuttal of what Camus took to be existentialist philosophy in the works of Kierkegaard, Shestov, Heidegger, and Jaspers.\n\nSimone de Beauvoir, an important existentialist who spent much of her life as Sartre's partner, wrote about feminist and existentialist ethics in her works, including \"The Second Sex\" and \"The Ethics of Ambiguity\". Although often overlooked due to her relationship with Sartre, de Beauvoir integrated existentialism with other forms of thinking such as feminism, unheard of at the time, resulting in alienation from fellow writers such as Camus.\n\nPaul Tillich, an important existentialist theologian following Kierkegaard and Karl Barth, applied existentialist concepts to Christian theology, and helped introduce existential theology to the general public. His seminal work \"The Courage to Be\" follows Kierkegaard's analysis of anxiety and life's absurdity, but puts forward the thesis that modern humans must, via God, achieve selfhood in spite of life's absurdity. Rudolf Bultmann used Kierkegaard's and Heidegger's philosophy of existence to demythologize Christianity by interpreting Christian mythical concepts into existentialist concepts.\n\nMaurice Merleau-Ponty, an existential phenomenologist, was for a time a companion of Sartre. Merleau-Ponty's \"Phenomenology of Perception\" (1945) was recognized as a major statement of French existentialism. It has been said that Merleau-Ponty's work \"Humanism and Terror\" greatly influenced Sartre. However, in later years they were to disagree irreparably, dividing many existentialists such as de Beauvoir, who sided with Sartre.\n\nColin Wilson, an English writer, published his study \"The Outsider\" in 1956, initially to critical acclaim. In this book and others (e.g. \"Introduction to the New Existentialism\"), he attempted to reinvigorate what he perceived as a pessimistic philosophy and bring it to a wider audience. He was not, however, academically trained, and his work was attacked by professional philosophers for lack of rigor and critical standards.\n\nStanley Kubrick's 1957 anti-war film \"Paths of Glory\" \"illustrates, and even illuminates...existentialism\" by examining the \"necessary absurdity of the human condition\" and the \"horror of war\". The film tells the story of a fictional World War I French army regiment ordered to attack an impregnable German stronghold; when the attack fails, three soldiers are chosen at random, court-martialed by a \"kangaroo court\", and executed by firing squad. The film examines existentialist ethics, such as the issue of whether objectivity is possible and the \"problem of authenticity\". Orson Welles' 1962 film \" The Trial\", based upon Franz Kafka's book of the same name (Der Process), is characteristic of both existentialist and absurdist themes in its depiction of a man (Joseph K.) arrested for a crime for which the charges are neither revealed to him nor to the reader.\n\n\"Neon Genesis Evangelion\" is a Japanese science fiction animation series created by the anime studio Gainax and was both directed and written by Hideaki Anno. Existential themes of individuality, consciousness, freedom, choice, and responsibility are heavily relied upon throughout the entire series, particularly through the philosophies of Jean-Paul Sartre and Søren Kierkegaard. Episode 16's title, is a reference to Kierkegaard's book, \"The Sickness Unto Death\".\n\nSome contemporary films dealing with existentialist issues include \"Melancholia\", \"Fight Club\", \"I Heart Huckabees\", \"Waking Life\", \"The Matrix\", \"Ordinary People\", and \"Life in a Day\". Likewise, films throughout the 20th century such as \"The Seventh Seal\", \"Ikiru\", \"Taxi Driver\", the \"Toy Story\" films, \"The Great Silence\", \"Ghost in the Shell\", \"Harold and Maude\", \"High Noon\", \"Easy Rider\", \"One Flew Over the Cuckoo's Nest\", \"A Clockwork Orange\", \"Groundhog Day\", \"Apocalypse Now\", \"Badlands\", and \"Blade Runner\" also have existentialist qualities.\nNotable directors known for their existentialist films include Ingmar Bergman, François Truffaut, Jean-Luc Godard, Michelangelo Antonioni, Akira Kurosawa, Terrence Malick, Stanley Kubrick, Andrei Tarkovsky, Hideaki Anno, Wes Anderson, Gaspar Noé, Woody Allen, and Christopher Nolan. Charlie Kaufman's \"Synecdoche, New York\" focuses on the protagonist's desire to find existential meaning. Similarly, in Kurosawa's \"Red Beard\", the protagonist's experiences as an intern in a rural health clinic in Japan lead him to an existential crisis whereby he questions his reason for being. This, in turn, leads him to a better understanding of humanity. The French film, \"Mood Indigo\" (directed by Michel Gondry) embraced various elements of existentialism. The film \"The Shawshank Redemption\", released in 1994, depicts life in a prison in Maine, United States to explore several existentialist concepts.\n\nExistential perspectives are also found in modern literature to varying degrees, especially since the 1920s. Louis-Ferdinand Céline's \"Journey to the End of the Night\" (Voyage au bout de la nuit, 1932) celebrated by both Sartre and Beauvoir, contained many of the themes that would be found in later existential literature, and is in some ways, the proto-existential novel. Jean-Paul Sartre's 1938 novel \"Nausea\" was \"steeped in Existential ideas\", and is considered an accessible way of grasping his philosophical stance. Between 1900 and 1960, other authors such as Albert Camus, Franz Kafka, Rainer Maria Rilke, T.S. Eliot, Herman Hesse, Luigi Pirandello, Ralph Ellison, and Jack Kerouac, composed literature or poetry that contained, to varying degrees, elements of existential or proto-existential thought. The philosophy's influence even reached pulp literature shortly after the turn of the 20th century, as seen in the existential disparity witnessed in Man's lack of control of his fate in the works of H.P. Lovecraft. Since the late 1960s, a great deal of cultural activity in literature contains postmodernist as well as existential elements. Books such as \"Do Androids Dream of Electric Sheep?\" (1968) (now republished as \"Blade Runner\") by Philip K. Dick, \"Slaughterhouse-Five\" by Kurt Vonnegut, \"Fight Club\" by Chuck Palahniuk and Formless Meanderings by Bharath Srinivasan all distort the line between reality and appearance while simultaneously espousing existential themes.\n\nJean-Paul Sartre wrote \"No Exit\" in 1944, an existentialist play originally published in French as \"Huis Clos\" (meaning \"In Camera\" or \"behind closed doors\"), which is the source of the popular quote, \"Hell is other people.\" (In French, \"L'enfer, c'est les autres\"). The play begins with a Valet leading a man into a room that the audience soon realizes is in hell. Eventually he is joined by two women. After their entry, the Valet leaves and the door is shut and locked. All three expect to be tortured, but no torturer arrives. Instead, they realize they are there to torture each other, which they do effectively by probing each other's sins, desires, and unpleasant memories.\n\nExistentialist themes are displayed in the Theatre of the Absurd, notably in Samuel Beckett's \"Waiting for Godot\", in which two men divert themselves while they wait expectantly for someone (or something) named Godot who never arrives. They claim Godot is an acquaintance, but in fact, hardly know him, admitting they would not recognize him if they saw him. Samuel Beckett, once asked who or what Godot is, replied, \"If I knew, I would have said so in the play.\" To occupy themselves, the men eat, sleep, talk, argue, sing, play games, exercise, swap hats, and contemplate suicide—anything \"to hold the terrible silence at bay\". The play \"exploits several archetypal forms and situations, all of which lend themselves to both comedy and pathos.\" The play also illustrates an attitude toward human experience on earth: the poignancy, oppression, camaraderie, hope, corruption, and bewilderment of human experience that can be reconciled only in the mind and art of the absurdist. The play examines questions such as death, the meaning of human existence and the place of God in human existence.\n\nTom Stoppard's \"Rosencrantz & Guildenstern Are Dead\" is an absurdist tragicomedy first staged at the Edinburgh Festival Fringe in 1966. The play expands upon the exploits of two minor characters from Shakespeare's \"Hamlet\". Comparisons have also been drawn to Samuel Beckett's \"Waiting For Godot\", for the presence of two central characters who appear almost as two halves of a single character. Many plot features are similar as well: the characters pass time by playing Questions, impersonating other characters, and interrupting each other or remaining silent for long periods of time. The two characters are portrayed as two clowns or fools in a world beyond their understanding. They stumble through philosophical arguments while not realizing the implications, and muse on the irrationality and randomness of the world.\n\nJean Anouilh's \"Antigone\" also presents arguments founded on existentialist ideas. It is a tragedy inspired by Greek mythology and the play of the same name (Antigone, by Sophocles) from the 5th century BC. In English, it is often distinguished from its antecedent by being pronounced in its original French form, approximately \"Ante-GŌN.\" The play was first performed in Paris on 6 February 1944, during the Nazi occupation of France. Produced under Nazi censorship, the play is purposefully ambiguous with regards to the rejection of authority (represented by Antigone) and the acceptance of it (represented by Creon). The parallels to the French Resistance and the Nazi occupation have been drawn. Antigone rejects life as desperately meaningless but without affirmatively choosing a noble death. The crux of the play is the lengthy dialogue concerning the nature of power, fate, and choice, during which Antigone says that she is, \"... disgusted with [the]...promise of a humdrum happiness.\" She states that she would rather die than live a mediocre existence.\n\nCritic Martin Esslin in his book \"Theatre of the Absurd\" pointed out how many contemporary playwrights such as Samuel Beckett, Eugène Ionesco, Jean Genet, and Arthur Adamov wove into their plays the existentialist belief that we are absurd beings loose in a universe empty of real meaning. Esslin noted that many of these playwrights demonstrated the philosophy better than did the plays by Sartre and Camus. Though most of such playwrights, subsequently labeled \"Absurdist\" (based on Esslin's book), denied affiliations with existentialism and were often staunchly anti-philosophical (for example Ionesco often claimed he identified more with 'Pataphysics or with Surrealism than with existentialism), the playwrights are often linked to existentialism based on Esslin's observation.\n\nA major offshoot of existentialism as a philosophy is existentialist psychology and psychoanalysis, which first crystallized in the work of Otto Rank, Freud's closest associate for 20 years. Without awareness of the writings of Rank, Ludwig Binswanger was influenced by Freud, Edmund Husserl, Heidegger, and Sartre. A later figure was Viktor Frankl, who briefly met Freud as a young man. His logotherapy can be regarded as a form of existentialist therapy. The existentialists would also influence social psychology, antipositivist micro-sociology, symbolic interactionism, and post-structuralism, with the work of thinkers such as Georg Simmel and Michel Foucault. Foucault was a great reader of Kierkegaard even though he almost never refers this author, who nonetheless had for him an importance as secret as it was decisive.\n\nAn early contributor to existentialist psychology in the United States was Rollo May, who was strongly influenced by Kierkegaard and Otto Rank. One of the most prolific writers on techniques and theory of existentialist psychology in the USA is Irvin D. Yalom. Yalom states that\n\nAside from their reaction against Freud's mechanistic, deterministic model of the mind and their assumption of a phenomenological approach in therapy, the existentialist analysts have little in common and have never been regarded as a cohesive ideological school. These thinkers—who include Ludwig Binswanger, Medard Boss, Eugène Minkowski, V. E. Gebsattel, Roland Kuhn, G. Caruso, F. T. Buytendijk, G. Bally and Victor Frankl—were almost entirely unknown to the American psychotherapeutic community until Rollo May's highly influential 1958 book \"Existence\"—and especially his introductory essay—introduced their work into this country.\n\nA more recent contributor to the development of a European version of existentialist psychotherapy is the British-based Emmy van Deurzen.\n\nAnxiety's importance in existentialism makes it a popular topic in psychotherapy. Therapists often offer existentialist philosophy as an explanation for anxiety. The assertion is that anxiety is manifested of an individual's complete freedom to decide, and complete responsibility for the outcome of such decisions. Psychotherapists using an existentialist approach believe that a patient can harness his anxiety and use it constructively. Instead of suppressing anxiety, patients are advised to use it as grounds for change. By embracing anxiety as inevitable, a person can use it to achieve his full potential in life. Humanistic psychology also had major impetus from existentialist psychology and shares many of the fundamental tenets. Terror management theory, based on the writings of Ernest Becker and Otto Rank, is a developing area of study within the academic study of psychology. It looks at what researchers claim are implicit emotional reactions of people confronted with the knowledge that they will eventually die.\n\nAlso, Gerd B. Achenbach has refreshed the Socratic tradition with his own blend of philosophical counseling. So did Michel Weber with his Chromatiques Center in Belgium.\n\nWalter Kaufmann criticized 'the profoundly unsound methods and the dangerous contempt for reason that have been so prominent in existentialism.'\nLogical positivist philosophers, such as Rudolf Carnap and A. J. Ayer, assert that existentialists are often confused about the verb \"to be\" in their analyses of \"being\". Specifically, they argue that the verb \"is\" is transitive and pre-fixed to a predicate (e.g., an apple \"is red\") (without a predicate, the word \"is\" is meaningless), and that existentialists frequently misuse the term in this manner. Colin Wilson has stated in his book \"The Angry Years\" that existentialism has created many of its own difficulties: \"we can see how this question of freedom of the will has been vitiated by post-romantic philosophy, with its inbuilt tendency to laziness and boredom, we can also see how it came about that existentialism found itself in a hole of its own digging, and how the philosophical developments since then have amounted to walking in circles round that hole\".\n\nMany critics argue Jean-Paul Sartre's philosophy is contradictory. Specifically, they argue that Sartre makes metaphysical arguments despite his claiming that his philosophical views ignore metaphysics. Herbert Marcuse criticized Sartre's 1943 \"Being and Nothingness\" for projecting anxiety and meaninglessness onto the nature of existence itself: \"Insofar as Existentialism is a philosophical doctrine, it remains an idealistic doctrine: it hypostatizes specific historical conditions of human existence into ontological and metaphysical characteristics. Existentialism thus becomes part of the very ideology which it attacks, and its radicalism is illusory\".\n\nIn \"Letter on Humanism\", Martin Heidegger criticized Sartre's existentialism:\n\nExistentialism says existence precedes essence. In this statement he is taking \"existentia\" and \"essentia\" according to their metaphysical meaning, which, from Plato's time on, has said that \"essentia\" precedes \"existentia\". Sartre reverses this statement. But the reversal of a metaphysical statement remains a metaphysical statement. With it, he stays with metaphysics, in oblivion of the truth of Being.\n\nBULLET::::- Abandonment (existentialism)\nBULLET::::- Disenchantment\nBULLET::::- Existential phenomenology\nBULLET::::- Existential therapy\nBULLET::::- Existentiell\nBULLET::::- List of existentialists\nBULLET::::- Meaning (existential)\nBULLET::::- Meaning-making\n\nBULLET::::- \"Albert Camus: Lyrical and Critical Essays\". Edited by Philip Thody (interviev with Jeanie Delpech, in \"Les Nouvelles littéraires\", November 15, 1945). p. 345.\nBULLET::::- Fallico, Arthuro B. (1962). \"Art & Existentialism\". Englewood Cliffs, N.J.: Prentice-Hall.\nBULLET::::- Friesian interpretation of Existentialism\nBULLET::::- \"Existentialism is a Humanism\", a lecture given by Jean-Paul Sartre\nBULLET::::- \"The Existential Primer\"\nBULLET::::- Buddhists, Existentialists and Situationists: Waking up in Waking Life\nBULLET::::- What Is an Existential Threat? A threat to existence (see Global catastrophic risk) or to a particular state or group.\n\nBULLET::::- Stirrings Still: The International Journal of Existential Literature\nBULLET::::- Existential Analysis published by The Society for Existential Analysis\n"}
{"id": "9596", "url": "https://en.wikipedia.org/wiki?curid=9596", "title": "Ellipsis", "text": "Ellipsis\n\nAn ellipsis (plural ellipses; from the , , 'omission' or 'falling short') is a series of dots (typically three, such as \"…\") that usually indicates an intentional omission of a word, sentence, or whole section from a text without altering its original meaning.\n\nOpinions differ as to how to render ellipses in printed material. According to the \"Chicago Manual of Style\", each dot should be separated from its neighbor by a non-breaking space. Such spaces should be omitted, however, according to the Associated Press. A third option, illustrated in the opening sentence of this article, is to use the precomposed Unicode character with code point U+2026, in which the gaps are not as wide as standard spaces, though not every font in practice obeys this dictate. It's also not uncommon to see the three dots set extremely tight.\n\nThe ellipsis is also called a suspension point, points of ellipsis, periods of ellipsis, or (colloquially) \"dot-dot-dot\".\n\nDepending on their context and placement in a sentence, ellipses can indicate an unfinished thought, a leading statement, a slight pause, an echoing voice, or a nervous or awkward silence. Aposiopesis is the use of an ellipsis to trail off into silence—for example: \"But I thought he was …\" When placed at the beginning or end of a sentence, the ellipsis can also inspire a feeling of melancholy or longing.\n\nThe most common form of an ellipsis is a row of three periods or full points (...) or a precomposed triple-dot glyph (...). The usage of the em dash (—) can overlap the usage of the ellipsis, especially in dialogue. Style guides often have their own rules governing the use of ellipses. For example, \"The Chicago Manual of Style\" (\"Chicago\" style) recommends that an ellipsis be formed by typing three periods, each with a space on both sides ( . . . ), while the \"Associated Press Stylebook\" (\"AP\" style) puts the dots together, but retains a space before and after the group.\n\nWhether an ellipsis at the end of a sentence needs a fourth dot to finish the sentence is a matter of debate; \"Chicago\" advises it, as does the \"Publication Manual of the American Psychological Association\" (APA style), while some other style guides do not; the \"Merriam-Webster Dictionary\" and related works treat this style as optional, saying that it \"may\" be used. More commonly, a normal full stop (period) terminates the sentence, then a three-dot ellipsis is used to indicate one or more subsequent elided sentences before continuing a longer quotation. \"Business Insider\" magazine suggests this style, and it is also used in many academic journals. Even the \"Associated Press Stylebook\" – notably hostile to punctuation that journalists may consider optional and removable to save newsprint column width – favors this approach. It is consistent in intent if not exact form with the agreement among those in favor of a fused four-dot ellipsis that the first of them is a full stop terminating the sentence and the other three are the ellipsis.\n\nIn her book on the ellipsis, \"Ellipsis in English Literature: Signs of Omission\" (Cambridge University Press, 2015), Anne Toner suggests that the first use of the punctuation in the English language dates to a 1588 translation of Terence's \"Andria\", by Maurice Kyffin. In this case, however, the ellipsis consists not of dots but of short dashes. \"Subpuncting\" of medieval manuscripts also denotes omitted meaning and may be related.\n\nIn the 19th and early 20th centuries, an ellipsis was often used when a writer intentionally omitted a specific proper noun, such as a location: \"Jan was born on . . . Street in Warsaw.\"\n\nAs commonly used, this juxtaposition of characters is referred to as \"dots of ellipsis\" in the English language.\n\nOccasionally, it would be used in pulp fiction and other works of early 20th-century fiction to denote expletives that would otherwise have been censored.\n\nAn ellipsis may also imply an unstated alternative indicated by context. For example, when Sue says \"I never drink wine . . . \", the implication is that she does drink something elsesuch as vodka.\n\nIn reported speech, the ellipsis can be used to represent an intentional silence.\n\nIn poetry, an ellipsis is used as a thought-pause or line break at the caesura or this is used to highlight sarcasm or make the reader think about the last points in the poem.\n\nIn news reporting, often associated with brackets, it is used to indicate that a quotation has been condensed for space, brevity or relevance.\n\nHerb Caen, Pulitzer-prize-winning columnist for the \"San Francisco Chronicle\", became famous for his \"three-dot journalism\".\n\n\"The Chicago Manual of Style\" suggests the use of an ellipsis for any omitted word, phrase, line, or paragraph from within but not at the end of a quoted passage. There are two commonly used methods of using ellipses: one uses three dots for any omission, while the second one makes a distinction between omissions within a sentence (using three dots: . . .) and omissions between sentences (using a period and a space followed by three dots: . ...).\n\nThe Modern Language Association (MLA) used to indicate that an ellipsis must include spaces before and after each dot in all uses. If an ellipsis is meant to represent an omission, square brackets must surround the ellipsis to make it clear that there was no pause in the original quote: [ . . . ]. Currently, the MLA has removed the requirement of brackets in its style handbooks. However, some maintain that the use of brackets is still correct because it clears confusion.\n\nThe MLA now indicates that a three-dot, spaced ellipsis ( . . . ) should be used for removing material from within one sentence within a quote. When crossing sentences (when the omitted text contains a period, so that omitting the end of a sentence counts), a four-dot, spaced (except for before the first dot) ellipsis (. . . . ) should be used. When ellipsis points are used in the original text, ellipsis points that are not in the original text should be distinguished by enclosing them in square brackets (e.g. \"text […] text\").\n\nAccording to the Associated Press, the ellipsis should be used to condense quotations. It is less commonly used to indicate a pause in speech or an unfinished thought or to separate items in material such as show business gossip. The stylebook indicates that if the shortened sentence before the mark can stand as a sentence, it should do so, with an ellipsis placed after the period or other ending punctuation. When material is omitted at the end of a paragraph and also immediately following it, an ellipsis goes both at the end of that paragraph and at the beginning of the next, according to this style.\n\nAccording to Robert Bringhurst's \"Elements of Typographic Style\", the details of typesetting ellipses depend on the character and size of the font being set and the typographer's preference. Bringhurst writes that a full space between each dot is \"another Victorian eccentricity. In most contexts, the Chicago ellipsis is much too wide\"—he recommends using flush dots, or \"thin\"-spaced dots (up to one-fifth of an em), or the prefabricated ellipsis character (. Bringhurst suggests that normally an ellipsis should be spaced fore-and-aft to separate it from the text, but when it combines with other punctuation, the leading space disappears and the other punctuation follows. This is the usual practice in typesetting. He provides the following examples:\n\nIn legal writing in the United States, Rule 5.3 in the \"Bluebook\" citation guide governs the use of ellipses and requires a space before the first dot and between the two subsequent dots. If an ellipsis ends the sentence, then there are three dots, each separated by a space, followed by the final punctuation (e.g. Hah . . . ?). In some legal writing, an ellipsis is written as three asterisks (*** or * * *) to make it obvious that text has been omitted.\n(...) is also used for awkward silence.\n\n\"The Oxford Style Guide\" recommends setting the ellipsis as a single character (...) or as a series of three (narrow) spaced dots (. . .), and surrounding it by spaces. If there is an ellipsis at the end of an incomplete sentence, the final full stop is omitted. However, it is retained if the following ellipsis represents an omission between two complete sentences.\n\nContrary to \"The Oxford Style Guide\", the \"University of Oxford Style Guide\" demands an ellipsis not to be surrounded by spaces, except when it stands for a pause; then, a space has to be set after the ellipsis (but not before). An ellipsis is never preceded or followed by a full stop.\n\nWhen applied in Polish language syntax, the ellipsis is called , which means \"multidot\". The word \"wielokropek\" distinguishes the ellipsis of Polish syntax from that of mathematical notation, in which it is known as an .\n\nWhen an ellipsis replaces a fragment omitted from a quotation, the ellipsis is enclosed in parentheses or square brackets. An unbracketed ellipsis indicates an interruption or pause in speech.\n\nThe syntactical rules for ellipses are standardized by the 1983 Polska Norma document PN-83/P-55366, (\"Rules for setting texts in the Polish Language\").\n\nThe combination \"ellipsis+period\" is replaced by the ellipsis. The combinations \"ellipsis+exclamation mark\" and \"ellipsis+question mark\" are written in this way: !.. ?..\n\nThe most common character corresponding to an ellipsis is called \"3\"-ten rīdā (\"\"3\"-dot leaders\", ). 2-ten rīdā exists as a character, but it is used less commonly. In writing, the ellipsis consists usually of six dots (two \"3\"-ten rīdā characters, ). Three dots (one \"3\"-ten rīdā character) may be used where space is limited, such as in a header. However, variations in the number of dots exist. In horizontally written text the dots are commonly vertically centered within the text height (between the baseline and the ascent line), as in the standard Japanese Windows fonts; in vertically written text the dots are always centered horizontally. As the Japanese word for dot is pronounced \"\", the dots are colloquially called \"\" (, akin to the English \"dot dot dot\").\n\nIn text in Japanese media, such as in manga or video games, ellipses are much more frequent than in English, and are often changed to another punctuation sign in translation. The ellipsis by itself represents speechlessness, or a \"pregnant pause\". Depending on the context, this could be anything from an admission of guilt to an expression of being dumbfounded at another person's words or actions. As a device, the \"ten-ten-ten\" is intended to focus the reader on a character while allowing the character to not speak any dialogue. This conveys to the reader a focus of the narrative \"camera\" on the silent subject, implying an expectation of some motion or action. It is not unheard of to see inanimate objects \"speaking\" the ellipsis.\n\nIn Chinese, the ellipsis is six dots (in two groups of three dots, occupying the same horizontal or vertical space as two characters) (i.e. ...).\n\nIn Spanish, ellipsis is commonly used as a substitute of \"et cetera\" at the end of unfinished lists. So it means \"and so forth\" or \"and other things\".\n\nOther use is the suspension of a part of a text, or a paragraph, or a phrase or a part of a word because it is obvious, or unnecessary, or implied. For instance, sometimes the ellipsis is used to avoid the complete use of expletives.\n\nWhen the ellipsis is placed alone into a parenthesis (...) or—less often—between brackets [...], which is what happens usually within a text transcription, it means the original text had more contents on the same position but are not useful to our target in the transcription. When the suppressed text is at the beginning or at the end of a text, the ellipsis does not need to be placed in a parenthesis.\n\nThe number of dots is three and only three.\n\nIn French, the ellipsis is commonly used at the end of lists to represent \"et cetera\". In French typography, the ellipsis is written close up to the preceding word but has a space after it, for example: \"comme ça… pas comme ceci\". If, exceptionally, it begins a sentence, there is a space before and after, for example: \"Lui ? … vaut rien, je crois… \".\n\nHowever, any omitted word, phrase or line at the end of a quoted passage would be indicated like this: [...] (space before and after the square brackets but not inside), for example: \" … à Paris, Nice, Nantes, Toulouse […] \".\n\nIn German, the ellipsis in general is surrounded by spaces, if it stands for one or more omitted words. On the other side there is no space between a letter or (part of) a word and an ellipsis, if it stands for one or more omitted letters, that should stick to the written letter or letters.\n\nExample for both cases, using German style: \"The first el…is stands for omitted letters, the second … for an omitted word.\"\n\nIf the ellipsis is at the end of a sentence, the final full stop is omitted.\n\nExample: \"I think that …\"\n\nIn computer menu functions or buttons, an ellipsis means that upon selection more options (sometimes in the form of a dialog box) will be displayed, where the user can or must make a choice. If the ellipsis is missing, the function is immediately executed upon selection.\n\nE.g., the menu item \"Save\" indicates that the file will be overwritten without further input, whereas \"Save as…\" indicates that a dialog follows where the user can, for example, select another location, file name, or format.\n\nEllipsis are also used as a separate button (particularly considering the limited screen area of mobile apps) to represent partially or completely hidden options. This usage may alternatively be described as a \"More button\" (see also hamburger button signifying completely hidden options).\n\nAn ellipsis is also often used in mathematics to mean \"and so forth\". In a list, between commas, or following a comma, a normal ellipsis is used, as in:\n\nor to mean an infinite list, as:\n\nTo indicate the omission of values in a repeated operation, an ellipsis raised to the center of the line is used between two operation symbols or following the last operation symbol, as in:\n\nSometimes, e.g. in Russian mathematical texts, normal, non-raised, ellipses are used even in repeated summations.\n\nThe latter formula means the sum of all natural numbers from 1 to 100. However, it is not a formally defined mathematical symbol. Repeated summations or products may similarly be denoted using capital sigma and capital pi notation, respectively:\n\nNormally dots should be used only where the pattern to be followed is clear, the exception being to show the indefinite continuation of an irrational number such as:\n\nSometimes, it is useful to display a formula compactly, for example:\n\nAnother example is the set of positive zeros of the cosine function:\n\nThere are many related uses of the ellipsis in set notation.\n\nThe diagonal and vertical forms of the ellipsis are particularly useful for showing missing terms in matrices, such as the size-\"n\" identity matrix:\n\nA two- or three-dot ellipsis is used as an operator in some programming languages. The precise meaning varies by language, but it generally involves something dealing with multiple items. One of its most common uses is in defining ranges or sequences. This is used in many languages, including Pascal, Modula, Oberon, Ada, Haskell, Perl, Python, Ruby, Bash shell and F#. It is also used to indicate so called variadic functions in the C, C++ and Java languages. \"See Ellipsis (programming operator)\".\n\nThe CSS codice_1 property can be set to codice_2, which cuts off text with an ellipsis when it overflows the content area.\n\nThe ellipsis is a non-verbal cue that is often used in computer-mediated interactions, in particular in synchronous genres, such as chat. The reason behind its popularity is the fact that it allows people to indicate in writing several functions:\nBULLET::::- The sign of ellipsis can function as a floor holding device, and signal that more is to come, for instance when people break up longer turns in chat.\nBULLET::::- Dot-dot-dot can be used systematically to enact linguistic politeness, for instance indicating topic change or hesitation.\nBULLET::::- Suspension dots can be turn construction units to signal silence, for example when indicating disagreement, disapproval or confusion.\n\nAlthough an ellipsis is technically complete with three periods (...), its rise in popularity as a \"trailing-off\" or \"silence\" indicator, particularly in mid-20th-century comic strip and comic book prose writing, has led to expanded uses online. Today, extended ellipsis anywhere from two to dozens of periods have become common constructions in Internet chat rooms and text messages. The extent of repetition in itself might serve as an additional contextualization or paralinguistic cue, to \"extend the lexical meaning of the words, add character to the sentences, and allow fine-tuning and personalisation of the message\".\n\nIn computing, several ellipsis characters have been codified, depending on the system used.\n\nIn the Unicode standard, there are the following characters:\n! Name !! Character !! Unicode !! UTF-8 !! HTML entity name orNumeric character reference !! Use\n\nIn Windows, the horizontal ellipsis can be inserted with , using the numeric keypad.\n\nIn macOS, it can be inserted with (on an English language keyboard).\n\nIn some Linux distributions, it can be inserted with , or alternatively sequence can be used.\n\nIn Chinese and sometimes in Japanese, ellipsis characters are made by entering two consecutive \"horizontal ellipsis\" (U+2026). In vertical texts, the application should rotate the symbol accordingly.\n\nUnicode recognizes a series of three period characters (U+002E) as compatibility equivalent (though not canonical) to the horizontal ellipsis character.\n\nIn HTML, the horizontal ellipsis character may be represented by the entity reference codice_3 (since HTML 4.0), and the vertical ellipsis character by the entity reference codice_7 (since HTML 5.0). Alternatively, in HTML, XML, and SGML, a numeric character reference such as codice_14 or codice_15 can be used.\n\nIn the TeX typesetting system, the following types of ellipsis are available:\n! Name !! Glyph !! TeX markup\n\nIn LaTeX, note that the reverse orientation of codice_18 can be achieved with codice_21 provided by the codice_22 package: codice_23 yields .\n\nWith the codice_24 package from AMS-LaTeX, more specific ellipses are provided for math mode.\n! Markup !! Usage  Example  Output\n\nThe horizontal ellipsis character also appears in the following older character maps:\nBULLET::::- in Windows-1250—Windows-1258 and in IBM/MS-DOS Code page 874, at code 85 (hexadecimal)\nBULLET::::- in Mac-Roman, Mac-CentEuro and several other Macintosh encodings, at code C9 (hexadecimal)\nBULLET::::- in Ventura International encoding at code C1 (hexadecimal)\n\nNote that ISO/IEC 8859 encoding series provides no code point for ellipsis.\n\nAs with all characters, especially those outside the ASCII range, the author, sender and receiver of an encoded ellipsis must be in agreement upon what bytes are being used to represent the character. Naive text processing software may improperly assume that a particular encoding is being used, resulting in mojibake.\n\nThe Chicago Style Q&A recommends to avoid the use of ... (U+2026) character in manuscripts and to place three periods plus two nonbreaking spaces (. . .) instead, so that an editor, publisher, or designer can replace them later.\n\nIn Abstract Syntax Notation One (ASN.1), the ellipsis is used as an extension marker to indicate the possibility of type extensions in future revisions of a protocol specification. In a type constraint expression like codice_34 an ellipsis is used to separate the extension root from extension additions. The definition of type A in version 1 system of the form codice_35 and the definition of type A in version 2 system of the form codice_34 constitute an extension series of the same type A in different versions of the same specification. The ellipsis can also be used in compound type definitions to separate the set of fields belonging to the extension root from the set of fields constituting extension additions. Here is an example: codice_37 \n\nBULLET::::- Caesura\nBULLET::::- Cohesion (linguistics)\nBULLET::::- Elision – Omission or deletion of a sound or syllable\nBULLET::::- Leader (typography) – A row of characters (usually dots or dashes) to connect items across a page (as in a table of contents)\nBULLET::::- Leiden Conventions\nBULLET::::- Line break (poetry)\n\nBULLET::::- Halliday, M.A.K, and Ruqayia, H. (1976), \"Cohesion in English\", London: Longman.\n"}
{"id": "9597", "url": "https://en.wikipedia.org/wiki?curid=9597", "title": "Enola Gay", "text": "Enola Gay\n\nThe Enola Gay () is a Boeing B-29 Superfortress bomber, named after Enola Gay Tibbets, the mother of the pilot, Colonel Paul Tibbets. On 6 August 1945, during the final stages of World War II, piloted by Tibbets and Robert A. Lewis it became the first aircraft to drop an atomic bomb. The bomb, code-named \"Little Boy\", was targeted at the city of Hiroshima, Japan, and caused the near-complete destruction of the city. \"Enola Gay\" participated in the second atomic attack as the weather reconnaissance aircraft for the primary target of Kokura. Clouds and drifting smoke resulted in a secondary target, Nagasaki, being bombed instead.\n\nAfter the war, the \"Enola Gay\" returned to the United States, where it was operated from Roswell Army Air Field, New Mexico. In May 1946, it was flown to Kwajalein for the Operation Crossroads nuclear tests in the Pacific, but was not chosen to make the test drop at Bikini Atoll. Later that year it was transferred to the Smithsonian Institution, and spent many years parked at air bases exposed to the weather and souvenir hunters, before being disassembled and transported to the Smithsonian's storage facility at Suitland, Maryland, in 1961.\n\nIn the 1980s, veterans groups engaged in a call for the Smithsonian to put the aircraft on display, leading to an acrimonious debate about exhibiting the aircraft without a proper historical context. The cockpit and nose section of the aircraft were exhibited at the National Air and Space Museum (NASM) in downtown Washington, D.C., for the bombing's 50th anniversary in 1995, amid controversy. Since 2003, the entire restored B-29 has been on display at NASM's Steven F. Udvar-Hazy Center. The last survivor of its crew, Theodore Van Kirk, died on 28 July 2014 at the age of 93.\n\nThe \"Enola Gay\" (Model number B-29-45-MO, Serial number 44-86292, Victor number 82) was built by the Glenn L. Martin Company (later part of Lockheed Martin) at its Bellevue, Nebraska, plant, located at what is now known as Offutt Air Force Base. The bomber was one of the 15 initial examples of B-29s built to the \"Silverplate\" specification—65 of these eventually being completed during and after World War II—giving them the primary ability to function as nuclear \"weapon delivery\" aircraft. These modifications included an extensively modified bomb bay with pneumatic doors and British bomb attachment and release systems, reversible pitch propellers that gave more braking power on landing, improved engines with fuel injection and better cooling, and the removal of protective armor and gun turrets.\n\n\"Enola Gay\" was personally selected by Colonel Paul W. Tibbets Jr., the commander of the 509th Composite Group, on 9 May 1945, while still on the assembly line. The aircraft was accepted by the United States Army Air Forces (USAAF) on 18 May 1945 and assigned to the 393d Bombardment Squadron, Heavy, 509th Composite Group. Crew B-9, commanded by Captain Robert A. Lewis, took delivery of the bomber and flew it from Omaha to the 509th's base at Wendover Army Air Field, Utah, on 14 June 1945.\n\nThirteen days later, the aircraft left Wendover for Guam, where it received a bomb-bay modification, and flew to North Field, Tinian, on 6 July. It was initially given the Victor (squadron-assigned identification) number 12, but on 1 August, was given the circle R tail markings of the 6th Bombardment Group as a security measure and had its Victor number changed to 82 to avoid misidentification with actual 6th Bombardment Group aircraft. During July, the bomber made eight practice or training flights, and flew two missions, on 24 and 26 July, to drop pumpkin bombs on industrial targets at Kobe and Nagoya. \"Enola Gay\" was used on 31 July on a rehearsal flight for the actual mission.\n\nThe partially assembled Little Boy gun-type fission weapon L-11, weighing , was contained inside a × × wooden crate that was secured to the deck of the . Unlike the six uranium-235 target discs, which were later flown to Tinian on three separate aircraft arriving 28 and 29 July, the assembled projectile with the nine uranium-235 rings installed was shipped in a single lead-lined steel container weighing that was locked to brackets welded to the deck of Captain Charles B. McVay III's quarters. Both the L-11 and projectile were dropped off at Tinian on 26 July 1945.\n\nOn 5 August 1945, during preparation for the first atomic mission, Tibbets assumed command of the aircraft and named it after his mother, Enola Gay Tibbets, who, in turn, had been named for the heroine of a novel. When it came to selecting a name for the plane, Tibbets later recalled that: \n\nThe name was painted on the aircraft on 5 August by Allan L. Karl, an enlisted man in the 509th. Regularly-assigned aircraft commander Robert Lewis was unhappy to be displaced by Tibbets for this important mission, and became furious when he arrived at the aircraft on the morning of 6 August to see it painted with the now-famous nose art.\n\nHiroshima was the primary target of the first nuclear bombing mission on 6 August, with Kokura and Nagasaki as alternative targets. \"Enola Gay\", piloted by Tibbets, took off from North Field, in the Northern Mariana Islands, about six hours' flight time from Japan, accompanied by two other B-29s, \"The Great Artiste\", carrying instrumentation, and a then-nameless aircraft later called \"Necessary Evil\", commanded by Captain George Marquardt, to take photographs. The director of the Manhattan Project, Major General Leslie R. Groves, Jr., wanted the event recorded for posterity, so the takeoff was illuminated by floodlights. When he wanted to taxi, Tibbets leaned out the window to direct the bystanders out of the way. On request, he gave a friendly wave for the cameras.\nAfter leaving Tinian, the aircraft made their way separately to Iwo Jima, where they rendezvoused at and set course for Japan. The aircraft arrived over the target in clear visibility at . Captain William S. \"Deak\" Parsons of Project Alberta, who was in command of the mission, armed the bomb during the flight to minimize the risks during takeoff. His assistant, Second Lieutenant Morris R. Jeppson, removed the safety devices 30 minutes before reaching the target area.\n\nThe release at 08:15 (Hiroshima time) went as planned, and the Little Boy took 43 seconds to fall from the aircraft flying at to the predetermined detonation height about above the city. \"Enola Gay\" traveled before it felt the shock waves from the blast. Although buffeted by the shock, neither \"Enola Gay\" nor \"The Great Artiste\" was damaged.\n\nThe detonation created a blast equivalent to . The U-235 weapon was considered very inefficient, with only 1.7% of its fissile material reacting. The radius of total destruction was about one mile (1.6 km), with resulting fires across . Americans estimated that of the city were destroyed. Japanese officials determined that 69% of Hiroshima's buildings were destroyed and another 6–7% damaged. Some 70,000–80,000 people, 30% of the city's population, were killed by the blast and resultant firestorm, and another 70,000 injured. Out of those killed, 20,000 were soldiers.\n\n\"Enola Gay\" returned safely to its base on Tinian to great fanfare, touching down at 2:58 pm, after 12 hours 13 minutes. \"The Great Artiste\" and \"Necessary Evil\" followed at short intervals. Several hundred people, including journalists and photographers, had gathered to watch the planes return. Tibbets was the first to disembark, and was presented with the Distinguished Service Cross on the spot.\n\nThe Hiroshima mission was followed by another atomic strike. Originally scheduled for 11 August, it was brought forward by two days to 9 August owing to a forecast of bad weather. This time, a Fat Man nuclear weapon was carried by B-29 \"Bockscar\", piloted by Major Charles W. Sweeney. \"Enola Gay\", flown by Captain George Marquardt's Crew B-10, was the weather reconnaissance aircraft for Kokura, the primary target. \"Enola Gay\" reported clear skies over Kokura, but by the time \"Bockscar\" arrived, the city was obscured by smoke from fires from the conventional bombing of Yahata by 224 B-29s the day before. After three unsuccessful passes, \"Bockscar\" diverted to its secondary target, Nagasaki, where it dropped its bomb. In contrast to the Hiroshima mission, the Nagasaki mission has been described as tactically botched, although the mission did meet its objectives. The crew encountered a number of problems in execution, and had very little fuel by the time they landed at the emergency backup landing site Yontan Airfield on Okinawa.\n\n\"Enola Gay\"'s crew on 6 August 1945, consisted of 12 men. The crew was:\n\nBULLET::::- Colonel Paul W. Tibbets Jr. – pilot and aircraft commander\nBULLET::::- Captain Robert A. Lewis – co-pilot; \"Enola Gay\"'s regularly assigned aircraft commander*\nBULLET::::- Major Thomas Ferebee – bombardier\nBULLET::::- Captain Theodore \"Dutch\" Van Kirk – navigator\nBULLET::::- Captain William S. Parsons, USN – weaponeer and mission commander.\nBULLET::::- First Lieutenant Jacob Beser – radar countermeasures (also the only man to fly on both of the nuclear bombing aircraft)\nBULLET::::- Second Lieutenant Morris R. Jeppson – assistant weaponeer\nBULLET::::- Staff Sergeant Robert \"Bob\" Caron  – tail gunner*\nBULLET::::- Staff Sergeant Wyatt E. Duzenbury – flight engineer*\nBULLET::::- Sergeant Joe S. Stiborik – radar operator*\nBULLET::::- Sergeant Robert H. Shumard – assistant flight engineer*\nBULLET::::- Private First Class Richard H. Nelson – VHF radio operator*\n\nOf mission commander Parsons, it was said: \"There is no one more responsible for getting this bomb out of the laboratory and into some form useful for combat operations than Captain Parsons, by his plain genius in the ordnance business.\"\n\nFor the Nagasaki mission, \"Enola Gay\" was flown by Crew B-10, normally assigned to \"Up An' Atom\":\nBULLET::::- Captain George W. Marquardt – aircraft commander\nBULLET::::- Second Lieutenant James M. Anderson – co-pilot\nBULLET::::- Second Lieutenant Russell Gackenbach – navigator\nBULLET::::- Captain James W. Strudwick – bombardier\nBULLET::::- First Lieutenant Jacob Beser – radar countermeasures\nBULLET::::- Technical Sergeant James R. Corliss – flight engineer\nBULLET::::- Sergeant Warren L. Coble – radio operator\nBULLET::::- Sergeant Joseph M. DiJulio – radar operator\nBULLET::::- Sergeant Melvin H. Bierman – tail gunner\nBULLET::::- Sergeant Anthony D. Capua Jr. – assistant engineer/scanner\n\nOn 6 November 1945, Lewis flew the \"Enola Gay\" back to the United States, arriving at the 509th's new base at Roswell Army Air Field, New Mexico, on 8 November. On 29 April 1946, \"Enola Gay\" left Roswell as part of the Operation Crossroads nuclear weapons tests in the Pacific. It flew to Kwajalein Atoll on 1 May. It was not chosen to make the test drop at Bikini Atoll and left Kwajalein on 1 July, the date of the test, reaching Fairfield-Suisun Army Air Field, California, the next day.\n\nThe decision was made to preserve the \"Enola Gay\", and on 24 July 1946, the aircraft was flown to Davis–Monthan Air Force Base, Tucson, Arizona, in preparation for storage. On 30 August 1946, the title to the aircraft was transferred to the Smithsonian Institution and the \"Enola Gay\" was removed from the USAAF inventory. From 1946 to 1961, the \"Enola Gay\" was put into temporary storage at a number of locations. It was at Davis-Monthan from 1 September 1946 until 3 July 1949, when it was flown to Orchard Place Air Field, Park Ridge, Illinois, by Tibbets for acceptance by the Smithsonian. It was moved to Pyote Air Force Base, Texas, on 12 January 1952, and then to Andrews Air Force Base, Maryland, on 2 December 1953, because the Smithsonian had no storage space for the aircraft.\n\nIt was hoped that the Air Force would guard the plane, but, lacking hangar space, it was left outdoors on a remote part of the air base, exposed to the elements. Souvenir hunters broke in and removed parts. Insects and birds then gained access to the aircraft. Paul E. Garber of the Smithsonian Institution, became concerned about the \"Enola Gay\"s condition, and on 10 August 1960, Smithsonian staff began dismantling the aircraft. The components were transported to the Smithsonian storage facility at Suitland, Maryland, on 21 July 1961.\n\n\"Enola Gay\" remained at Suitland for many years. By the early 1980s, two veterans of the 509th, Don Rehl and his former navigator in the 509th, Frank B. Stewart, began lobbying for the aircraft to be restored and put on display. They enlisted Tibbets and Senator Barry Goldwater in their campaign. In 1983, Walter J. Boyne, a former B-52 pilot with the Strategic Air Command, became director of the National Air and Space Museum, and he made the \"Enola Gay\"s restoration a priority. Looking at the aircraft, Tibbets recalled, was a \"sad meeting. [My] fond memories, and I don't mean the dropping of the bomb, were the numerous occasions I flew the airplane ... I pushed it very, very hard and it never failed me ... It was probably the most beautiful piece of machinery that any pilot ever flew.\"\n\nRestoration of the bomber began on 5 December 1984, at the Paul E. Garber Preservation, Restoration, and Storage Facility in Suitland-Silver Hill, Maryland. The propellers that were used on the bombing mission were later shipped to Texas A&M University. One of these propellers was trimmed to for use in the university's Oran W. Nicks Low Speed Wind Tunnel. The lightweight aluminum variable-pitch propeller is powered by a 1,250 kVA electric motor, providing a wind speed up to . Two engines were rebuilt at Garber and two at San Diego Air & Space Museum. Some parts and instruments had been removed and could not be located. Replacements were found or fabricated, and marked so that future curators could distinguish them from the original components.\n\n\"Enola Gay\" became the center of a controversy at the Smithsonian Institution when the museum planned to put its fuselage on public display in 1995 as part of an exhibit commemorating the 50th anniversary of the atomic bombing of Hiroshima. The exhibit, \"The Crossroads: The End of World War II, the Atomic Bomb and the Cold War,\" was drafted by the Smithsonian's National Air and Space Museum staff, and arranged around the restored \"Enola Gay\".\n\nCritics of the planned exhibit, especially those of the American Legion and the Air Force Association, charged that the exhibit focused too much attention on the Japanese casualties inflicted by the nuclear bomb, rather than on the motives for the bombing or the discussion of the bomb's role in ending the conflict with Japan. The exhibit brought to national attention many long-standing academic and political issues related to retrospective views of the bombings. After attempts to revise the exhibit to meet the satisfaction of competing interest groups, the exhibit was canceled on 30 January 1995. Martin O. Harwit, Director of the National Air and Space Museum, was compelled to resign over the controversy. He later reflected that\n\nThe forward fuselage went on display on 28 June 1995. On 2 July 1995, three people were arrested for throwing ash and human blood on the aircraft's fuselage, following an earlier incident in which a protester had thrown red paint over the gallery's carpeting. The exhibition closed on 18 May 1998 and the fuselage was returned to the Garber Facility for final restoration.\n\nRestoration work began in 1984, and would eventually require 300,000 staff hours. While the fuselage was on display, from 1995 to 1998, work continued on the remaining unrestored components. The aircraft was shipped in pieces to the National Air and Space Museum's Steven F. Udvar-Hazy Center in Chantilly, Virginia from March–June 2003, with the fuselage and wings reunited for the first time since 1960 on 10 April 2003 and assembly completed on 8 August 2003. The aircraft has been on display at the Udvar-Hazy Center since the museum annex opened on 15 December 2003. As a result of the earlier controversy, the signage around the aircraft provided only the same succinct technical data as is provided for other aircraft in the museum, without discussion of the controversial issues. It read: \n\nThe display of the \"Enola Gay\" without reference to the historical context of World War II, the Cold War, or the development and deployment of nuclear weapons aroused controversy. A petition from a group calling themselves the Committee for a National Discussion of Nuclear History and Current Policy bemoaned the display of \"Enola Gay\" as a technological achievement, which it described as an \"extraordinary callousness toward the victims, indifference to the deep divisions among American citizens about the propriety of these actions, and disregard for the feelings of most of the world's peoples\". It attracted signatures from notable figures including historian Gar Alperovitz, social critic Noam Chomsky, whistle blower Daniel Ellsberg, physicist Joseph Rotblat, writer Kurt Vonnegut, producer Norman Lear, actor Martin Sheen and filmmaker Oliver Stone.\n\nBULLET::::- The Smithsonian's site on \"Enola Gay\" includes links to crew lists and other details\nBULLET::::- Eyewitnesses to Hiroshima, \"Time\" magazine, 1 August 2005\nBULLET::::- \"Inside the \"Enola Gay\"\", \"Air & Space\", 18 May 2010\n"}
{"id": "9598", "url": "https://en.wikipedia.org/wiki?curid=9598", "title": "Electronvolt", "text": "Electronvolt\n\nIn physics, an electronvolt (symbol eV, also written electron-volt and electron volt) is the amount of kinetic energy gained (or lost) by a single electron accelerating from rest through an electric potential difference of one volt in vacuum. When used as a unit of energy, the numerical value of 1 eV in joules (symbol J) is equivalent to the numerical value of the charge of an electron in coulombs (symbol C). Under the 2019 redefinition of the SI base units, this sets 1 eV equal to J. \n\nHistorically, the electronvolt was devised as a standard unit of measure through its usefulness in electrostatic particle accelerator sciences, because a particle with electric charge \"q\" has an energy after passing through the potential \"V\"; if \"q\" is quoted in integer units of the elementary charge and the potential in volts, one gets an energy in eV.\n\nIt is a common unit of energy within physics, widely used in solid state, atomic, nuclear, and particle physics. It is commonly used with the metric prefixes milli-, kilo-, mega-, giga-, tera-, peta- or exa- (meV, keV, MeV, GeV, TeV, PeV and EeV respectively). In some older documents, and in the name Bevatron, the symbol BeV is used, which stands for billion (10) electronvolts; it is equivalent to the GeV.\n! Measurement !! Unit  SI value of unit\n\nAn electronvolt is the amount of kinetic energy gained or lost by a single electron accelerating from rest through an electric potential difference of one volt in vacuum. Hence, it has a value of one volt, , multiplied by the electron's elementary charge \"e\", Therefore, one electronvolt is equal to \n\nThe electronvolt, as opposed to the volt, is not an SI unit. The electronvolt (eV) is a unit of energy whereas the volt (V) is the derived SI unit of electric potential. The SI unit for energy is the joule (J).\n\nBy mass–energy equivalence, the electronvolt is also a unit of mass. It is common in particle physics, where units of mass and energy are often interchanged, to express mass in units of eV/\"c\", where \"c\" is the speed of light in vacuum (from ). It is common to simply express mass in terms of \"eV\" as a unit of mass, effectively using a system of natural units with \"c\" set to 1. The mass equivalent of is\n\nFor example, an electron and a positron, each with a mass of , can annihilate to yield of energy. The proton has a mass of . In general, the masses of all hadrons are of the order of , which makes the GeV (gigaelectronvolt) a convenient unit of mass for particle physics:\n\nThe unified atomic mass unit (u), almost exactly 1 gram divided by the Avogadro number, is almost the mass of a hydrogen atom, which is mostly the mass of the proton. To convert to electron volts, use the formula:\n\nIn high-energy physics, the electronvolt is often used as a unit of momentum. A potential difference of 1 volt causes an electron to gain an amount of energy (i.e., ). This gives rise to usage of eV (and keV, MeV, GeV or TeV) as units of momentum, for the energy supplied results in acceleration of the particle.\n\nThe dimensions of momentum units are . The dimensions of energy units are . Then, dividing the units of energy (such as eV) by a fundamental constant that has units of velocity (), facilitates the required conversion of using energy units to describe momentum. In the field of high-energy particle physics, the fundamental velocity unit is the speed of light in vacuum \"c\". \n\nBy dividing energy in eV by the speed of light, one can describe the momentum of an electron in units of eV/\"c\".\nThe fundamental velocity constant \"c\" is often \"dropped\" from the units of momentum by way of defining units of length such that the value of \"c\" is unity. For example, if the momentum \"p\" of an electron is said to be , then the conversion to MKS can be achieved by:\n\nIn particle physics, a system of \"natural units\" in which the speed of light in vacuum \"c\" and the reduced Planck constant \"ħ\" are dimensionless and equal to unity is widely used: . In these units, both distances and times are expressed in inverse energy units (while energy and mass are expressed in the same units, see mass–energy equivalence). In particular, particle scattering lengths are often presented in units of inverse particle masses.\n\nOutside this system of units, the conversion factors between electronvolt, second, and nanometer are the following:\n\nThe above relations also allow expressing the mean lifetime \"τ\" of an unstable particle (in seconds) in terms of its decay width \"Γ\" (in eV) via . For example, the B meson has a lifetime of 1.530(9) picoseconds, mean decay length is , or a decay width of .\n\nConversely, the tiny meson mass differences responsible for meson oscillations are often expressed in the more convenient inverse picoseconds.\n\nEnergy in electronvolts is sometimes expressed through the wavelength of light with photons of the same energy: \n\nformula_4 \n\nIn certain fields, such as plasma physics, it is convenient to use the electronvolt to express temperature. The electronvolt is divided by the Boltzmann constant to convert to the Kelvin scale:\n\nWhere \"k\" is the Boltzmann constant, K is Kelvin, J is Joules, eV is electronvolts.\n\nThe \"k\" is assumed when using the electronvolt to express temperature, for example, a typical magnetic confinement fusion plasma is (kilo-electronvolts), which is equal to 170 MK (million degrees Kelvin).\n\nAs an approximation: \"k\"\"T\" is about (≈ ) at a temperature of .\n\nThe energy \"E\", frequency \"v\", and wavelength λ of a photon are related by\n\nwhere \"h\" is the Planck constant, \"c\" is the speed of light. This reduces to\n\nA photon with a wavelength of (green light) would have an energy of approximately . Similarly, would correspond to an infrared photon of wavelength or frequency .\n\nIn a low-energy nuclear scattering experiment, it is conventional to refer to the nuclear recoil energy in units of eVr, keVr, etc. This distinguishes the nuclear recoil energy from the \"electron equivalent\" recoil energy (eVee, keVee, etc.) measured by scintillation light. For example, the yield of a phototube is measured in phe/keVee (photoelectrons per keV electron-equivalent energy). The relationship between eV, eVr, and eVee depends on the medium the scattering takes place in, and must be established empirically for each material.\n\n! Energy  Source\n\nOne mole of particles given 1 eV of energy has approximately 96.5 kJ of energy — this corresponds to the Faraday constant (\"F\" ≈ ), where the energy in joules of \"n\" moles of particles each with energy \"E\" eV is equal to \"E\"·\"F\"·\"n\".\n\nBULLET::::- Orders of magnitude (energy)\n\nBULLET::::- BIPM's definition of the electronvolt\nBULLET::::- physical constants reference; CODATA data\n"}
{"id": "9601", "url": "https://en.wikipedia.org/wiki?curid=9601", "title": "Electrochemistry", "text": "Electrochemistry\n\nElectrochemistry is the branch of chemistry that studies the relationship between electricity, as a measurable and quantitative phenomenon, and identifiable chemical change, with either electricity considered an outcome of a particular chemical change or vice versa. These reactions involve electric charges moving between electrodes and an electrolyte (or ionic species in a solution). Thus electrochemistry deals with the interaction between electrical energy and chemical change.\n\nWhen a chemical reaction is caused by an externallsupplied current, as in electrolysis, or if an electric current is produced by a spontaneous chemical reaction as in a battery, it is called an \"electrochemical\" reaction. Chemical reactions where electrons are transferred directly between molecules and/or atoms are called oxidation-reduction or redox reactions. In general, electrochemistry describes the overall reactions when individual redox reactions are separate but connected by an external electric circuit and an intervening electrolyte.\n\nUnderstanding of electrical matters began in the sixteenth century. During this century, the English scientist William Gilbert spent 17 years experimenting with magnetism and, to a lesser extent, electricity. For his work on magnets, Gilbert became known as the \"\"Father of Magnetism.\"\" He discovered various methods for producing and strengthening magnets.\n\nIn 1663, the German physicist Otto von Guericke created the first electric generator, which produced static electricity by applying friction in the machine. The generator was made of a large sulfur ball cast inside a glass globe, mounted on a shaft. The ball was rotated by means of a crank and an electric spark was produced when a pad was rubbed against the ball as it rotated. The globe could be removed and used as source for experiments with electricity.\n\nBy the mid—18th century the French chemist Charles François de Cisternay du Fay had discovered two types of static electricity, and that like charges repel each other whilst unlike charges attract. Du Fay announced that electricity consisted of two fluids: \"\"vitreous\"\" (from the Latin for \"\"glass\"\"), or positive, electricity; and \"\"resinous,\"\" or negative, electricity. This was the \"two-fluid theory\" of electricity, which was to be opposed by Benjamin Franklin's \"one-fluid theory\" later in the century.\n\nIn 1785, Charles-Augustin de Coulomb developed the law of electrostatic attraction as an outgrowth of his attempt to investigate the law of electrical repulsions as stated by Joseph Priestley in England.\n\nIn the late 18th century the Italian physician and anatomist Luigi Galvani marked the birth of electrochemistry by establishing a bridge between chemical reactions and electricity on his essay \"\"De Viribus Electricitatis in Motu Musculari Commentarius\"\" (Latin for Commentary on the Effect of Electricity on Muscular Motion) in 1791 where he proposed a \"\"nerveo-electrical substance\"\" on biological life forms.\n\nIn his essay Galvani concluded that animal tissue contained a here-to-fore neglected innate, vital force, which he termed \"\"animal electricity,\"\" which activated nerves and muscles spanned by metal probes. He believed that this new force was a form of electricity in addition to the \"\"natural\"\" form produced by lightning or by the electric eel and torpedo ray as well as the \"\"artificial\"\" form produced by friction (i.e., static electricity).\n\nGalvani's scientific colleagues generally accepted his views, but Alessandro Volta rejected the idea of an \"\"animal electric fluid,\"\" replying that the frog's legs responded to differences in metal temper, composition, and bulk. Galvani refuted this by obtaining muscular action with two pieces of the same material.\n\nIn 1800, William Nicholson and Johann Wilhelm Ritter succeeded in decomposing water into hydrogen and oxygen by electrolysis. Soon thereafter Ritter discovered the process of electroplating. He also observed that the amount of metal deposited and the amount of oxygen produced during an electrolytic process depended on the distance between the electrodes. By 1801, Ritter observed thermoelectric currents and anticipated the discovery of thermoelectricity by Thomas Johann Seebeck.\n\nBy the 1810s, William Hyde Wollaston made improvements to the galvanic cell.\nSir Humphry Davy's work with electrolysis led to the conclusion that the production of electricity in simple electrolytic cells resulted from chemical action and that chemical combination occurred between substances of opposite charge. This work led directly to the isolation of sodium and potassium from their compounds and of the alkaline earth metals from theirs in 1808.\n\nHans Christian Ørsted's discovery of the magnetic effect of electric currents in 1820 was immediately recognized as an epoch-making advance, although he left further work on electromagnetism to others. André-Marie Ampère quickly repeated Ørsted's experiment, and formulated them mathematically.\n\nIn 1821, Estonian-German physicist Thomas Johann Seebeck demonstrated the electrical potential in the juncture points of two dissimilar metals when there is a heat difference between the joints.\n\nIn 1827, the German scientist Georg Ohm expressed his law in this famous book \"\"Die galvanische Kette, mathematisch bearbeitet\"\" (The Galvanic Circuit Investigated Mathematically) in which he gave his complete theory of electricity.\n\nIn 1832, Michael Faraday's experiments led him to state his two laws of electrochemistry. In 1836, John Daniell invented a primary cell which solved the problem of polarization by eliminating hydrogen gas generation at the positive electrode. Later results revealed that alloying the amalgamated zinc with mercury would produce a higher voltage.\n\nWilliam Grove produced the first fuel cell in 1839. In 1846, Wilhelm Weber developed the electrodynamometer. In 1868, Georges Leclanché patented a new cell which eventually became the forerunner to the world's first widely used battery, the zinc carbon cell.\n\nSvante Arrhenius published his thesis in 1884 on \"Recherches sur la conductibilité galvanique des électrolytes\" (Investigations on the galvanic conductivity of electrolytes). From his results the author concluded that electrolytes, when dissolved in water, become to varying degrees split or dissociated into electrically opposite positive and negative ions.\n\nIn 1886, Paul Héroult and Charles M. Hall developed an efficient method (the Hall–Héroult process) to obtain aluminium using electrolysis of molten alumina.\n\nIn 1894, Friedrich Ostwald concluded important studies of the conductivity and electrolytic dissociation of organic acids.\n\nWalther Hermann Nernst developed the theory of the electromotive force of the voltaic cell in 1888. In 1889, he showed how the characteristics of the current produced could be used to calculate the free energy change in the chemical reaction producing the current. He constructed an equation, known as Nernst equation, which related the voltage of a cell to its properties.\n\nIn 1898, Fritz Haber showed that definite reduction products can result from electrolytic processes if the potential at the cathode is kept constant. In 1898, he explained the reduction of nitrobenzene in stages at the cathode and this became the model for other similar reduction processes.\n\nIn 1902, The Electrochemical Society (ECS) was founded.\n\nIn 1909, Robert Andrews Millikan began a series of experiments (see oil drop experiment) to determine the electric charge carried by a single electron.\n\nIn 1923, Johannes Nicolaus Brønsted and Martin Lowry published essentially the same theory about how acids and bases behave, using an electrochemical basis.\n\nIn 1937, Arne Tiselius developed the first sophisticated electrophoretic apparatus. Some years later, he was awarded the 1948 Nobel Prize for his work in protein electrophoresis.\n\nA year later, in 1949, the International Society of Electrochemistry (ISE) was founded.\n\nBy the 1960s–1970s quantum electrochemistry was developed by Revaz Dogonadze and his pupils.\n\nThe term \"redox\" stands for reduction-oxidation. It refers to electrochemical processes involving electron transfer to or from a molecule or ion changing its oxidation state. This reaction can occur through the application of an external voltage or through the release of chemical energy. Oxidation and reduction describe the change of oxidation state that takes place in the atoms, ions or molecules involved in an electrochemical reaction. Formally, oxidation state is the hypothetical charge that an atom would have if all bonds to atoms of different elements were 100% ionic. An atom or ion that gives up an electron to another atom or ion has its oxidation state increase, and the recipient of the negatively charged electron has its oxidation state decrease.\n\nFor example, when atomic sodium reacts with atomic chlorine, sodium donates one electron and attains an oxidation state of +1. Chlorine accepts the electron and its oxidation state is reduced to −1. The sign of the oxidation state (positive/negative) actually corresponds to the value of each ion's electronic charge. The attraction of the differently charged sodium and chlorine ions is the reason they then form an ionic bond.\n\nThe loss of electrons from an atom or molecule is called oxidation, and the gain of electrons is reduction. This can be easily remembered through the use of mnemonic devices. Two of the most popular are \"\"OIL RIG\"\" (Oxidation Is Loss, Reduction Is Gain) and \"\"LEO\"\" the lion says \"\"GER\"\" (Lose Electrons: Oxidation, Gain Electrons: Reduction). Oxidation and reduction always occur in a paired fashion such that one species is oxidized when another is reduced. For cases where electrons are shared (covalent bonds) between atoms with large differences in electronegativity, the electron is assigned to the atom with the largest electronegativity in determining the oxidation state.\n\nThe atom or molecule which loses electrons is known as the \"reducing agent\", or \"reductant\", and the substance which accepts the electrons is called the \"oxidizing agent\", or \"oxidant\". Thus, the oxidizing agent is always being reduced in a reaction; the reducing agent is always being oxidized. Oxygen is a common oxidizing agent, but not the only one. Despite the name, an oxidation reaction does not necessarily need to involve oxygen. In fact, a fire can be fed by an oxidant other than oxygen; fluorine fires are often unquenchable, as fluorine is an even stronger oxidant (it has a higher electronegativity and thus accepts electrons even better) than oxygen.\n\nFor reactions involving oxygen, the gain of oxygen implies the oxidation of the atom or molecule to which the oxygen is added (and the oxygen is reduced). In organic compounds, such as butane or ethanol, the loss of hydrogen implies oxidation of the molecule from which it is lost (and the hydrogen is reduced). This follows because the hydrogen donates its electron in covalent bonds with non-metals but it takes the electron along when it is lost. Conversely, loss of oxygen or gain of hydrogen implies reduction.\n\nElectrochemical reactions in water are better understood by balancing redox reactions using the ion-electron method where H, OH ion, HO and electrons (to compensate the oxidation changes) are added to cell's half-reactions for oxidation and reduction.\n\nIn acid medium H ions and water are added to half-reactions to balance the overall reaction.\nFor example, when manganese reacts with sodium bismuthate.\n\nFinally, the reaction is balanced by multiplying the number of electrons from the reduction half reaction to oxidation half reaction and vice versa and adding both half reactions, thus solving the equation.\nReaction balanced:\n\nIn basic medium OH ions and water are added to half reactions to balance the overall reaction. For example, on reaction between potassium permanganate and sodium sulfite.\n\nThe same procedure as followed on acid medium by multiplying electrons to opposite half reactions solve the equation thus balancing the overall reaction.\nEquation balanced:\n\nThe same procedure as used on acid medium is applied, for example on balancing using electron ion method to complete combustion of propane.\n\nAs in acid and basic medium, electrons which were used to compensate oxidation changes are multiplied to opposite half reactions, thus solving the equation.\nEquation balanced:\n\nAn electrochemical cell is a device that produces an electric current from energy released by a spontaneous redox reaction, this can be caused from electricity. This kind of cell includes the Galvanic cell or Voltaic cell, named after Luigi Galvani and Alessandro Volta, both scientists who conducted several experiments on chemical reactions and electric current during the late 18th century.\n\nElectrochemical cells have two conductive electrodes (the anode and the cathode). The anode is defined as the electrode where oxidation occurs and the cathode is the electrode where the reduction takes place. Electrodes can be made from any sufficiently conductive materials, such as metals, semiconductors, graphite, and even conductive polymers. In between these electrodes is the electrolyte, which contains ions that can freely move.\n\nThe galvanic cell uses two different metal electrodes, each in an electrolyte where the positively charged ions are the oxidized form of the electrode metal. One electrode will undergo oxidation (the anode) and the other will undergo reduction (the cathode). The metal of the anode will oxidize, going from an oxidation state of 0 (in the solid form) to a positive oxidation state and become an ion. At the cathode, the metal ion in solution will accept one or more electrons from the cathode and the ion's oxidation state is reduced to 0. This forms a solid metal that electrodeposits on the cathode. The two electrodes must be electrically connected to each other, allowing for a flow of electrons that leave the metal of the anode and flow through this connection to the ions at the surface of the cathode. This flow of electrons is an electric current that can be used to do work, such as turn a motor or power a light.\n\nA galvanic cell whose electrodes are zinc and copper submerged in zinc sulfate and copper sulfate, respectively, is known as a Daniell cell.\n\nHalf reactions for a Daniell cell are these:\n\nIn this example, the anode is the zinc metal which is oxidized (loses electrons) to form zinc ions in solution, and copper ions accept electrons from the copper metal electrode and the ions deposit at the copper cathode as an electrodeposit. This cell forms a simple battery as it will spontaneously generate a flow of electric current from the anode to the cathode through the external connection. This reaction can be driven in reverse by applying a voltage, resulting in the deposition of zinc metal at the anode and formation of copper ions at the cathode.\n\nTo provide a complete electric circuit, there must also be an ionic conduction path between the anode and cathode electrolytes in addition to the electron conduction path. The simplest ionic conduction path is to provide a liquid junction. To avoid mixing between the two electrolytes, the liquid junction can be provided through a porous plug that allows ion flow while reducing electrolyte mixing. To further minimize mixing of the electrolytes, a salt bridge can be used which consists of an electrolyte saturated gel in an inverted U-tube. As the negatively charged electrons flow in one direction around this circuit, the positively charged metal ions flow in the opposite direction in the electrolyte.\n\nA voltmeter is capable of measuring the change of electrical potential between the anode and the cathode.\n\nElectrochemical cell voltage is also referred to as electromotive force or emf.\n\nA cell diagram can be used to trace the path of the electrons in the electrochemical cell. For example, here is a cell diagram of a Daniell cell:\n\nFirst, the reduced form of the metal to be oxidized at the anode (Zn) is written. This is separated from its oxidized form by a vertical line, which represents the limit between the phases (oxidation changes). The double vertical lines represent the saline bridge on the cell. Finally, the oxidized form of the metal to be reduced at the cathode, is written, separated from its reduced form by the vertical line. The electrolyte concentration is given as it is an important variable in determining the cell potential.\n\nTo allow prediction of the cell potential, tabulations of standard electrode potential are available. Such tabulations are referenced to the standard hydrogen electrode (SHE). The standard hydrogen electrode undergoes the reaction\n\nwhich is shown as reduction but, in fact, the SHE can act as either the anode or the cathode, depending on the relative oxidation/reduction potential of the other electrode/electrolyte combination. The term standard in SHE requires a supply of hydrogen gas bubbled through the electrolyte at a pressure of 1 atm and an acidic electrolyte with H activity equal to 1 (usually assumed to be [H] = 1 mol/liter).\n\nThe SHE electrode can be connected to any other electrode by a salt bridge to form a cell. If the second electrode is also at standard conditions, then the measured cell potential is called the standard electrode potential for the electrode. The standard electrode potential for the SHE is zero, by definition. The polarity of the standard electrode potential provides information about the relative reduction potential of the electrode compared to the SHE. If the electrode has a positive potential with respect to the SHE, then that means it is a strongly reducing electrode which forces the SHE to be the anode (an example is Cu in aqueous CuSO with a standard electrode potential of 0.337 V). Conversely, if the measured potential is negative, the electrode is more oxidizing than the SHE (such as Zn in ZnSO where the standard electrode potential is −0.76 V).\n\nStandard electrode potentials are usually tabulated as reduction potentials. However, the reactions are reversible and the role of a particular electrode in a cell depends on the relative oxidation/reduction potential of both electrodes. The oxidation potential for a particular electrode is just the negative of the reduction potential. A standard cell potential can be determined by looking up the standard electrode potentials for both electrodes (sometimes called half cell potentials). The one that is smaller will be the anode and will undergo oxidation. The cell potential is then calculated as the sum of the reduction potential for the cathode and the oxidation potential for the anode.\n\nFor example, the standard electrode potential for a copper electrode is:\n\nAt standard temperature, pressure and concentration conditions, the cell's emf (measured by a multimeter) is 0.34 V. By definition, the electrode potential for the SHE is zero. Thus, the Cu is the cathode and the SHE is the anode giving\nOr,\n\nChanges in the stoichiometric coefficients of a balanced cell equation will not change E° value because the standard electrode potential is an intensive property.\n\nDuring operation of electrochemical cells, chemical energy is transformed into electrical energy and is expressed mathematically as the product of the cell's emf and the electric charge transferred through the external circuit.\n\nwhere E is the cell potential measured in volts (V) and C is the cell current integrated over time and measured in coulombs (C); C can also be determined by multiplying the total number of electrons transferred (measured in moles) times Faraday's constant (F).\n\nThe emf of the cell at zero current is the maximum possible emf. It is used to calculate the maximum possible electrical energy that could be obtained from a chemical reaction. This energy is referred to as electrical work and is expressed by the following equation:\n\nwhere work is defined as positive into the system.\n\nSince the free energy is the maximum amount of work that can be extracted from a system, one can write:\n\nA positive cell potential gives a negative change in Gibbs free energy. This is consistent with the cell production of an electric current from the cathode to the anode through the external circuit. If the current is driven in the opposite direction by imposing an external potential, then work is done on the cell to drive electrolysis.\n\nA spontaneous electrochemical reaction (change in Gibbs free energy less than zero) can be used to generate an electric current in electrochemical cells. This is the basis of all batteries and fuel cells. For example, gaseous oxygen (O) and\nhydrogen (H) can be combined in a fuel cell to form water and energy, typically a combination of heat and electrical energy.\n\nConversely, non-spontaneous electrochemical reactions can be driven forward by the application of a current at sufficient voltage. The electrolysis of water into gaseous oxygen and hydrogen is a typical example.\n\nThe relation between the equilibrium constant, \"K\", and the Gibbs free energy for an electrochemical cell is expressed as follows:\n\nRearranging to express the relation between standard potential and equilibrium constant yields\n\nThe previous equation can use Briggsian logarithm as shown below:\n\nThe standard potential of an electrochemical cell requires standard conditions (ΔG°) for all of the reactants. When reactant concentrations differ from standard conditions, the cell potential will deviate from the standard potential. In the 20th century German chemist Walther Nernst proposed a mathematical model to determine the effect of reactant concentration on electrochemical cell potential.\n\nIn the late 19th century, Josiah Willard Gibbs had formulated a theory to predict whether a chemical reaction is spontaneous based on the free energy\n\nHere \"ΔG\" is change in Gibbs free energy, \"ΔG°\" is the cell potential when \"Q\" is equal to 1, \"T\" is absolute temperature (Kelvin), \"R\" is the gas constant and \"Q\" is reaction quotient which can be found by dividing products by reactants using only those products and reactants that are aqueous or gaseous.\n\nGibbs' key contribution was to formalize the understanding of the effect of reactant concentration on spontaneity.\n\nBased on Gibbs' work, Nernst extended the theory to include the contribution from electric potential on charged species. As shown in the previous section, the change in Gibbs free energy for an electrochemical cell can be related to the cell potential. Thus, Gibbs' theory becomes\n\nHere \"n\" is the number of electrons/mole product, \"F\" is the Faraday constant (coulombs/mole), and \"ΔE\" is cell potential.\n\nFinally, Nernst divided through by the amount of charge transferred to arrive at a new equation which now bears his name:\n\nAssuming standard conditions (T = 25 °C) and R = 8.3145 J/(K·mol), the equation above can be expressed on base—10 logarithm as shown below:\n\nA concentration cell is an electrochemical cell where the two electrodes are the same material, the electrolytes on the two half-cells involve the same ions, but the electrolyte concentration differs between the two half-cells.\n\nAn example is an electrochemical cell, where two copper electrodes are submerged in two copper(II) sulfate solutions, whose concentrations are 0.05 M and 2.0 M, connected through a salt bridge. This type of cell will generate a potential that can be predicted by the Nernst equation. Both can undergo the same chemistry (although the reaction proceeds in reverse at the anode)\n\nLe Chatelier's principle indicates that the reaction is more favorable to reduction as the concentration of Cu ions increases. Reduction will take place in the cell's compartment where concentration is higher and oxidation will occur on the more dilute side.\n\nThe following cell diagram describes the cell mentioned above:\n\nWhere the half cell reactions for oxidation and reduction are:\n\nThe cell's emf is calculated through Nernst equation as follows:\n\nThe value of \"E\"° in this kind of cell is zero, as electrodes and ions are the same in both half-cells.\n\nAfter replacing values from the case mentioned, it is possible to calculate cell's potential:\n\nor by:\n\nHowever, this value is only approximate, as reaction quotient is defined in terms of ion activities which can be approximated with the concentrations as calculated here.\n\nThe Nernst equation plays an important role in understanding electrical effects in cells and organelles. Such effects include nerve synapses and cardiac beat as well as the resting potential of a somatic cell.\n\nMany types of battery have been commercialized and represent an important practical application of electrochemistry. Early wet cells powered the first telegraph and telephone systems, and were the source of current for electroplating. The zinc-manganese dioxide dry cell was the first portable, non-spillable battery type that made flashlights and other portable devices practical. The mercury battery using zinc and mercuric oxide provided higher levels of power and capacity than the original dry cell for early electronic devices, but has been phased out of common use due to the danger of mercury pollution from discarded cells.\n\nThe lead–acid battery was the first practical secondary (rechargeable) battery that could have its capacity replenished from an external source. The electrochemical reaction that produced current was (to a useful degree) reversible, allowing electrical energy and chemical energy to be interchanged as needed. Common lead acid batteries contain a mixture of sulfuric acid and water, as well as lead plates. The most common mixture used today is 30% acid. One problem however is if left uncharged acid will crystallize within the lead plates of the battery rendering it useless. These batteries last an average of 3 years with daily use however it is not unheard of for a lead acid battery to still be functional after 7–10 years. Lead-acid cells continue to be widely used in automobiles.\n\nAll the preceding types have water-based electrolytes, which limits the maximum voltage per cell. The freezing of water limits low temperature performance. The lithium battery, which does not (and cannot) use water in the electrolyte, provides improved performance over other types; a rechargeable lithium-ion battery is an essential part of many mobile devices.\n\nThe flow battery, an experimental type, offers the option of vastly larger energy capacity because its reactants can be replenished from external reservoirs. The fuel cell can turn the chemical energy bound in hydrocarbon gases or hydrogen directly into electrical energy with much higher efficiency than any combustion process; such devices have powered many spacecraft and are being applied to grid energy storage for the public power system.\n\nCorrosion is an electrochemical process, which reveals itself in rust or tarnish on metals like iron or copper and their respective alloys, steel and brass.\n\nFor iron rust to occur the metal has to be in contact with oxygen and water, although chemical reactions for this process are relatively complex and not all of them are completely understood. It is believed the causes are the following:\nElectron transfer (reduction-oxidation)\n\nIron corrosion takes place in an acid medium; H ions come from reaction between carbon dioxide in the atmosphere and water, forming carbonic acid. Fe ions oxidize, following this equation:\nIron(III) oxide hydrate is known as rust. The concentration of water associated with iron oxide varies, thus the chemical formula is represented by <chem>2Fe2O3.\\mathit{x}H2O</chem>.\n\nAn electric circuit is formed as passage of electrons and ions occurs, thus if an electrolyte is present it will facilitate oxidation, explaining why rusting is quicker in salt water.\n\nCoinage metals, such as copper and silver, slowly corrode through use.\nA patina of green-blue copper carbonate forms on the surface of copper with exposure to the water and carbon dioxide in the air. Silver coins or cutlery that are exposed to high sulfur foods such as eggs or the low levels of sulfur species in the air develop a layer of black Silver sulfide.\n\nGold and platinum are extremely difficult to oxidize under normal circumstances, and require exposure to a powerful chemical oxidizing agent such as aqua regia.\n\nSome common metals oxidize extremely rapidly in air. Titanium and aluminium oxidize instantaneously in contact with the oxygen in the air. These metals form an extremely thin layer of oxidized metal on the surface which bonds with the underlying metal. This thin layer of oxide protects the underlying layers of the metal from the air preventing the entire metal from oxidizing. These metals are used in applications where corrosion resistance is important. Iron, in contrast, has an oxide that forms in air and water, called rust, that does not bond with the iron and therefore does not stop the further oxidation of the iron. Thus iron left exposed to air and water will continue to rust until all of the iron is oxidized.\n\nAttempts to save a metal from becoming anodic are of two general types. Anodic regions dissolve and destroy the structural integrity of the metal.\n\nWhile it is almost impossible to prevent anode/cathode formation, if a non-conducting material covers the metal, contact with the electrolyte is not possible and corrosion will not occur.\n\nMetals can be coated with paint or other less conductive metals (\"passivation\"). This prevents the metal surface from being exposed to electrolytes. Scratches exposing the metal substrate will result in corrosion. The region under the coating adjacent to the scratch acts as the anode of the reaction.\n\nSee Anodizing\n\nA method commonly used to protect a structural metal is to attach a metal which is more anodic than the metal to be protected. This forces the structural metal to be cathodic, thus spared corrosion. It is called \"\"sacrificial\"\" because the anode dissolves and has to be replaced periodically.\n\nZinc bars are attached to various locations on steel ship hulls to render the ship hull cathodic. The zinc bars are replaced periodically. Other metals, such as magnesium, would work very well but zinc is the least expensive useful metal.\n\nTo protect pipelines, an ingot of buried or exposed magnesium (or zinc) is buried beside the pipeline and is connected electrically to the pipe above ground. The pipeline is forced to be a cathode and is protected from being oxidized and rusting. The magnesium anode is sacrificed. At intervals new ingots are buried to replace those lost.\n\nThe spontaneous redox reactions of a conventional battery produce electricity through the different chemical potentials of the cathode and anode in the electrolyte. However, electrolysis requires an external source of electrical energy to induce a chemical reaction, and this process takes place in a compartment called an electrolytic cell.\n\nWhen molten, the salt sodium chloride can be electrolyzed to yield metallic sodium and gaseous chlorine. Industrially this process takes place in a special cell named Down's cell. The cell is connected to an electrical power supply, allowing electrons to migrate from the power supply to the electrolytic cell.\n\nReactions that take place at Down's cell are the following:\n\nThis process can yield large amounts of metallic sodium and gaseous chlorine, and is widely used on mineral dressing and metallurgy industries.\n\nThe emf for this process is approximately −4 V indicating a (very) non-spontaneous process. In order for this reaction to occur the power supply should provide at least a potential of 4 V. However, larger voltages must be used for this reaction to occur at a high rate.\n\nWater can be converted to its component elemental gasses, H and O through the application of an external voltage. Water doesn't decompose into hydrogen and oxygen spontaneously as the Gibbs free energy for the process at standard conditions is about 474.4 kJ. The decomposition of water into hydrogen and oxygen can be performed in an electrolytic cell. In it, a pair of inert electrodes usually made of platinum immersed in water act as anode and cathode in the electrolytic process. The electrolysis starts with the application of an external voltage between the electrodes. This process will not occur except at extremely high voltages without an electrolyte such as sodium chloride or sulfuric acid (most used 0.1 M).\n\nBubbles from the gases will be seen near both electrodes. The following half reactions describe the process mentioned above:\n\nAlthough strong acids may be used in the apparatus, the reaction will not net consume the acid. While this reaction will work at any conductive electrode at a sufficiently large potential, platinum catalyzes both hydrogen and oxygen formation, allowing for relatively mild voltages (~2 V depending on the pH).\n\nElectrolysis in an aqueous solution is a similar process as mentioned in electrolysis of water. However, it is considered to be a complex process because the contents in solution have to be analyzed in half reactions, whether reduced or oxidized.\n\nThe presence of water in a solution of sodium chloride must be examined in respect to its reduction and oxidation in both electrodes. Usually, water is electrolysed as mentioned in electrolysis of water yielding \"gaseous oxygen in the anode\" and gaseous hydrogen in the cathode. On the other hand, sodium chloride in water dissociates in Na and Cl ions, cation, which is the positive ion, will be attracted to the cathode (-), thus reducing the sodium ion. The anion will then be attracted to the anode (+) oxidizing chloride ion.\n\nThe following half reactions describes the process mentioned:\n\nReaction 1 is discarded as it has the most negative value on standard reduction potential thus making it less thermodynamically favorable in the process.\n\nWhen comparing the reduction potentials in reactions 2 and 4, the reduction of chloride ion is favored. Thus, if the Cl ion is favored for reduction, then the water reaction is favored for oxidation producing gaseous oxygen, however experiments show gaseous chlorine is produced and not oxygen.\n\nAlthough the initial analysis is correct, there is another effect that can happen, known as the overvoltage effect. Additional voltage is sometimes required, beyond the voltage predicted by the E°. This may be due to kinetic rather than thermodynamic considerations. In fact, it has been proven that the activation energy for the chloride ion is very low, hence favorable in kinetic terms. In other words, although the voltage applied is thermodynamically sufficient to drive electrolysis, the rate is so slow that to make the process proceed in a reasonable time frame, the voltage of the external source has to be increased (hence, overvoltage).\n\nFinally, reaction 3 is favorable because it describes the proliferation of OH ions thus letting a probable reduction of H ions less favorable an option.\n\nThe overall reaction for the process according to the analysis would be the following:\n\nAs the overall reaction indicates, the concentration of chloride ions is reduced in comparison to OH ions (whose concentration increases). The reaction also shows the production of gaseous hydrogen, chlorine and aqueous sodium hydroxide.\n\nQuantitative aspects of electrolysis were originally developed by Michael Faraday in 1834. Faraday is also credited to have coined the terms \"electrolyte\", electrolysis, among many others while he studied quantitative analysis of electrochemical reactions. Also he was an advocate of the law of conservation of energy.\n\nFaraday concluded after several experiments on electric current in non-spontaneous process, the mass of the products yielded on the electrodes was proportional to the value of current supplied to the cell, the length of time the current existed, and the molar mass of the substance analyzed. In other words, the amount of a substance deposited on each electrode of an electrolytic cell is directly proportional to the quantity of electricity passed through the cell.\n\nBelow is a simplified equation of Faraday's first law:\n\nWhere\n\nFaraday devised the laws of chemical electrodeposition of metals from solutions in 1857. He formulated the second law of electrolysis stating \"\"the amounts of bodies which are equivalent to each other in their ordinary chemical action have equal quantities of electricity naturally associated with them.\"\" In other words, the quantities of different elements deposited by a given amount of electricity are in the ratio of their chemical equivalent weights.\n\nAn important aspect of the second law of electrolysis is electroplating which together with the first law of electrolysis, has a significant number of applications in the industry, as when used to protect metals to avoid corrosion.\n\nThere are various extremely important electrochemical processes in both nature and industry, like the coating of objects with metals or metal oxides through electrodeposition, the addition (electroplating) or removal (electropolishing) of thin layers of metal from an object's surface, and the detection of alcohol in drunken drivers through the redox reaction of ethanol. The generation of chemical energy through photosynthesis is inherently an electrochemical process, as is production of metals like aluminum and titanium from their ores. Certain diabetes blood sugar meters measure the amount of glucose in the blood through its redox potential. As well as the established electrochemical technologies (like deep cycle lead acid batteries) there is also a wide range of new emerging technologies such as fuel cells, large format lithium-ion batteries, electrochemical reactors and super-capacitors that are becoming increasingly commercial. Electrochemistry has also important applications in the food industry, like the assessment of food/package interactions, the analysis of milk composition, the characterization and the determination of the freezing end-point of ice-cream mixes, the determination of free acidity in olive oil.\n\nThe action potentials that travel down connected neurons are based on electric current generated by the movement of sodium and potassium ions into and out of cells. Specialized cells in certain animals like the electric eel can generate electric currents powerful enough to disable much larger animals.\n\nBULLET::::- Reactivity series\nBULLET::::- Bioelectromagnetism\nBULLET::::- Bioelectrochemistry\nBULLET::::- Contact tension – a historical forerunner to the theory of electrochemistry.\nBULLET::::- Cyclic Voltammetry\nBULLET::::- Electrochemical impedance spectroscopy\nBULLET::::- Electroanalytical method\nBULLET::::- Electrochemical potential\nBULLET::::- Electrochemiluminescence\nBULLET::::- Electrodeionization\nBULLET::::- Electropolishing\nBULLET::::- Electroplating\nBULLET::::- Electrochemical engineering\nBULLET::::- Electrochemical energy conversion\nBULLET::::- Electrosynthesis\nBULLET::::- Fuel cells\nBULLET::::- Frost diagram\nBULLET::::- List of electrochemists\nBULLET::::- Important publications in electrochemistry\nBULLET::::- Magnetoelectrochemistry\nBULLET::::- Nanoelectrochemistry\nBULLET::::- Protein film voltammetry\nBULLET::::- Photoelectrochemistry\nBULLET::::- Pourbaix diagram\nBULLET::::- Redox titration\nBULLET::::- Standard electrode potential (data page)\nBULLET::::- Voltammetry\nBULLET::::- ITIES\nBULLET::::- Bipolar electrochemistry\nBULLET::::- Ebbing, Darrell D. and Gammon, Steven D. General Chemistry (2007) ,\nBULLET::::- Nobel Lectures in Chemistry, Volume 1, World Scientific (1999)\nBULLET::::- Swaddle, Thomas Wilson Inorganic chemistry: an industrial and environmental perspective, Academic Press (1997)\nBULLET::::- Wiberg, Egon; Wiberg, Nils and Holleman, Arnold Frederick Inorganic chemistry, Academic Press (2001)\n\n"}
{"id": "9602", "url": "https://en.wikipedia.org/wiki?curid=9602", "title": "Edinburgh", "text": "Edinburgh\n\nEdinburgh (; ; ) is the capital of Scotland and one of its 32 council areas. Historically part of the county of Midlothian (interchangeably Edinburghshire before 1921), it is located in Lothian on the Firth of Forth's southern shore.\n\nRecognised as the capital of Scotland since at least the 15th century, Edinburgh is the seat of the Scottish Government, the Scottish Parliament and the supreme courts of Scotland. The city's Palace of Holyroodhouse is the official residence of the monarch in Scotland. The city has long been a centre of education, particularly in the fields of medicine, Scots law, literature, philosophy, the sciences and engineering. It is the second largest financial centre in the United Kingdom (after London) and the city's historical and cultural attractions have made it the United Kingdom's second most popular tourist destination attracting 1.75 million visits from overseas in 2016.\n\nEdinburgh is Scotland's second most populous city and the seventh most populous in the United Kingdom. The official population estimates are 488,050 (2016) for the Locality of Edinburgh (Edinburgh pre 1975 regionalisation plus Currie and Balerno), 518,500 (2018) for the City of Edinburgh, and 1,339,380 (2014) for the city region. Edinburgh lies at the heart of the Edinburgh and South East Scotland city region comprising East Lothian, Edinburgh, Fife, Midlothian, Scottish Borders and West Lothian.\n\nThe city is the annual venue of the General Assembly of the Church of Scotland. It is home to national institutions such as the National Museum of Scotland, the National Library of Scotland and the Scottish National Gallery. The University of Edinburgh, founded in 1582 and now one of four in the city, is placed 20th in the QS World University Rankings for 2020. The city is also famous for the Edinburgh International Festival and the Fringe, the latter being the world's largest annual international arts festival. Historic sites in Edinburgh include Edinburgh Castle, the Palace of Holyroodhouse, the churches of St. Giles, Greyfriars and the Canongate, and the extensive Georgian New Town built in the 18th/19th centuries. Edinburgh's Old Town and New Town together are listed as a UNESCO World Heritage site, which has been managed by Edinburgh World Heritage since 1999.\n\n\"Edin\", the root of the city's name, derives from \"Eidyn\", the name for this region in Cumbric, the Brittonic Celtic language formerly spoken there. The name's meaning is unknown. The district of Eidyn centred on the stronghold Din Eidyn, the dun or hillfort of Eidyn. This stronghold is believed to have been located at Castle Rock, now the site of Edinburgh Castle. Eidyn was conquered by the Angles of Bernicia in the 7th century and later by the Scots in the 10th century. As the language shifted to Old English, and subsequently to modern English and Scots, the Brittonic \"din\" in Din Eidyn was replaced by \"burh\", producing \"Edinburgh\". Similarly, \"din\" became \"dùn\" in Scottish Gaelic, producing \"Dùn Èideann\".\n\nThe city is affectionately nicknamed \"Auld Reekie\", Scots for \"Old Smoky\", for the views from the country of the smoke-covered Old Town.\nA remark on a poem in an 1800 collection of the poems of Allan Ramsay said, \"Auld Reeky. A name the country people give Edinburgh from the cloud of smoke or reek that is always impending over it.\"\n\nThomas Carlyle said, \"Smoke cloud hangs over old Edinburgh,—for, ever since Aeneas Silvius's time and earlier, the people have the art, very strange to Aeneas, of burning a certain sort of black stones, and Edinburgh with its chimneys is called 'Auld Reekie' by the country people.\"\n\nA character in Walter Scott's \"The Abbot\" says \"... yonder stands Auld Reekie—you may see the smoke hover over her at twenty miles' distance.\"\n\nRobert Chambers who said that the sobriquet could not be traced before the reign of Charles II attributed the name to a Fife laird, Durham of Largo, who regulated the bedtime of his children by the smoke rising above Edinburgh from the fires of the tenements. \"It's time now bairns, to tak' the beuks, and gang to our beds, for yonder's Auld Reekie, I see, putting on her nicht -cap!\"\n\nSome have called Edinburgh the \"Athens of the North\" for a variety of reasons. The earliest comparison between the two cities showed that they had a similar topography, with the Castle Rock of Edinburgh performing a similar role to the Athenian Acropolis. Both of them had flatter, fertile agricultural land sloping down to a port several miles away (respectively Leith and Piraeus). Although this arrangement is common in Southern Europe, it is rare in Northern Europe. The 18th-century intellectual life, referred to as the Scottish Enlightenment, was a key influence in gaining the name. Such luminaries as David Hume and Adam Smith shone during this period. Having lost most of its political importance after the Union, some hoped that Edinburgh could gain a similar influence on London as Athens had on Rome. Also a contributing factor was the later neoclassical architecture, particularly that of William Henry Playfair, and the National Monument. Tom Stoppard's character Archie, of \"Jumpers\", said, perhaps playing on Reykjavík meaning \"smoky bay\", that the \"Reykjavík of the South\" would be more appropriate.\n\nThe city has also been known by several Latin names, such as \"Aneda\" or \"Edina\". The adjectival form of the latter, \"Edinensis\", can often be seen inscribed on educational buildings.\n\nThe Scots poets Robert Fergusson and Robert Burns used the city's Latin name, \"Edina\", in their poems. Ben Jonson described it as \"Britaine's other eye\", and Sir Walter Scott referred to it as \"yon Empress of the North\". Robert Louis Stevenson, also a son of the city, wrote that Edinburgh \"is what Paris ought to be.\"\n\nThe colloquial pronunciation \"Embra\" or \"Embro\" has also been used, as in Robert Garioch's \"Embro to the Ploy\".\n\nThe earliest known human habitation in the Edinburgh area was at Cramond, where evidence was found of a Mesolithic camp site dated to c. 8500 BC. Traces of later Bronze Age and Iron Age settlements have been found on Castle Rock, Arthur's Seat, Craiglockhart Hill and the Pentland Hills.\n\nWhen the Romans arrived in Lothian at the end of the 1st century AD, they found a Brittonic Celtic tribe whose name they recorded as the Votadini. The Votadini transitioned into the Gododdin kingdom in the Early Middle Ages, with Eidyn serving as one of the kingdom's districts. During this period, the Castle Rock site, thought to have been the stronghold of Din Eidyn, emerged as the kingdom's major centre. The medieval poem \"Y Gododdin\" describes a war band from across the Brittonic world who gathered in Eidyn before a fateful raid; this may describe a historical event around AD 600.\n\nIn 638, the Gododdin stronghold was besieged by forces loyal to King Oswald of Northumbria, and around this time control of Lothian passed to the Angles. Their influence continued for the next three centuries until around 950, when, during the reign of Indulf, son of Constantine II, the \"burh\" (fortress), named in the 10th-century \"Pictish Chronicle\" as \"oppidum Eden\", was abandoned to the Scots. It thenceforth remained under their jurisdiction.\n\nThe royal burgh was founded by King David I in the early 12th century on land belonging to the Crown, though the date of its charter is unknown. The first documentary evidence of the medieval burgh is a royal charter, , by King David I granting a toft in to the Priory of Dunfermline. By the middle of the 14th century, the French chronicler Jean Froissart was describing it as the capital of Scotland (c. 1365), and James III (1451–88) referred to it in the 15th century as \"the principal burgh of our kingdom\". Despite the destruction caused by an English assault in 1544, the town slowly recovered, and was at the centre of events in the 16th-century Scottish Reformation and 17th-century Wars of the Covenant.\n\nIn 1603, King James VI of Scotland succeeded to the English throne, uniting the crowns of Scotland and England in a personal union known as the Union of the Crowns, though Scotland remained, in all other respects, a separate kingdom. In 1638, King Charles I's attempt to introduce Anglican church forms in Scotland encountered stiff Presbyterian opposition culminating in the conflicts of the Wars of the Three Kingdoms. Subsequent Scottish support for Charles Stuart's restoration to the throne of England resulted in Edinburgh's occupation by Oliver Cromwell's Commonwealth of England forces – the New Model Army – in 1650.\n\nIn the 17th century, Edinburgh's boundaries were still defined by the city's defensive town walls. As a result, the city's growing population was accommodated by increasing the height of the houses. Buildings of 11 storeys or more were common, and have been described as forerunners of the modern-day skyscraper. Most of these old structures were replaced by the predominantly Victorian buildings seen in today's Old Town.\n\nFollowing the Treaty of Union in 1706, the Parliaments of England and Scotland passed Acts of Union in 1706 and 1707 respectively, uniting the two kingdoms in the Kingdom of Great Britain effective from 1 May 1707. As a consequence, the Parliament of Scotland merged with the Parliament of England to form the Parliament of Great Britain, which sat at Westminster in London. The Union was opposed by many Scots, resulting in riots in the city.\n\nBy the first half of the 18th century, Edinburgh was described as one of Europe's most densely populated, overcrowded and unsanitary towns. Visitors were struck by the fact that the various social classes shared the same urban space, even inhabiting the same tenement buildings; although here a form of social segregation did prevail, whereby shopkeepers and tradesmen tended to occupy the cheaper-to-rent cellars and garrets, while the more well-to-do professional classes occupied the more expensive middle storeys.\n\nDuring the Jacobite rising of 1745, Edinburgh was briefly occupied by the Jacobite \"Highland Army\" before its march into England. After its eventual defeat at Culloden, there followed a period of reprisals and pacification, largely directed at the rebellious clans. In Edinburgh, the Town Council, keen to emulate London by initiating city improvements and expansion to the north of the castle, reaffirmed its belief in the Union and loyalty to the Hanoverian monarch George III by its choice of names for the streets of the New Town: for example, Rose Street and Thistle Street; and for the royal family, George Street, Queen Street, Hanover Street, Frederick Street and Princes Street (in honour of George's two sons).\n\nIn the second half of the century, the city was at the heart of the Scottish Enlightenment, when thinkers like David Hume, Adam Smith, James Hutton and Joseph Black were familiar figures in its streets. Edinburgh became a major intellectual centre, earning it the nickname \"Athens of the North\" because of its many neo-classical buildings and reputation for learning, recalling ancient Athens. In the 18th-century novel \"The Expedition of Humphry Clinker\" by Tobias Smollett one character describes Edinburgh as a \"hotbed of genius\". Edinburgh was also a major centre for the Scottish book trade. The highly successful London bookseller Andrew Millar was apprenticed there to James McEuen.\n\nFrom the 1770s onwards, the professional and business classes gradually deserted the Old Town in favour of the more elegant \"one-family\" residences of the New Town, a migration that changed the city's social character. According to the foremost historian of this development, \"Unity of social feeling was one of the most valuable heritages of old Edinburgh, and its disappearance was widely and properly lamented.\"\n\nAlthough Edinburgh's traditional industries of printing, brewing and distilling continued to grow in the 19th century, and were joined by new rubber works and engineering works, there was little industrialisation compared with other cities in Britain. By 1821, Edinburgh had been overtaken by Glasgow as Scotland's largest city. The city centre between Princes Street and George Street became a major commercial and shopping district, a development partly stimulated by the arrival of railways in the 1840s. The Old Town became an increasingly dilapidated, overcrowded slum with high mortality rates. Improvements carried out under Lord Provost William Chambers in the 1860s began the transformation of the area into the predominantly Victorian Old Town seen today. More improvements followed in the early 20th century as a result of the work of Patrick Geddes, but relative economic stagnation during the two world wars and beyond saw the Old Town deteriorate further before major slum clearance in the 1960s and 1970s began to reverse the process. University building developments which transformed the George Square and Potterrow areas proved highly controversial.\n\nSince the 1990s a new \"financial district\", including the Edinburgh International Conference Centre, has grown mainly on demolished railway property to the west of the castle, stretching into Fountainbridge, a run-down 19th-century industrial suburb which has undergone radical change since the 1980s with the demise of industrial and brewery premises. This ongoing development has enabled Edinburgh to maintain its place as the United Kingdom's second largest financial and administrative centre after London. Financial services now account for a third of all commercial office space in the city. The development of Edinburgh Park, a new business and technology park covering , west of the city centre, has also contributed to the District Council's strategy for the city's major economic regeneration.\n\nIn 1998, the Scotland Act, which came into force the following year, established a devolved Scottish Parliament and Scottish Executive (renamed the Scottish Government since September 2007). Both based in Edinburgh, they are responsible for governing Scotland while reserved matters such as defence, taxation and foreign affairs remain the responsibility of the Parliament of the United Kingdom in London.\n\nSituated in Scotland's Central Belt, Edinburgh lies on the Firth of Forth's southern shore. The city centre is southwest of the shoreline of Leith and inland, as the crow flies, from the east coast of Scotland and the North Sea at Dunbar. While the early burgh grew up near the prominent Castle Rock, the modern city is often said to be built on seven hills, namely Calton Hill, Corstorphine Hill, Craiglockhart Hill, Braid Hill, Blackford Hill, Arthur's Seat and the Castle Rock, giving rise to allusions to the seven hills of Rome.\n\nOccupying a narrow gap between the Firth of Forth to the north and the Pentland Hills and their outrunners to the south, the city sprawls over a landscape which is the product of early volcanic activity and later periods of intensive glaciation.\n\nOther prominent landforms such as Calton Hill and Corstorphine Hill are also products of glacial erosion. The Braid Hills and Blackford Hill are a series of small summits to the city's south-west that command expansive views looking northwards over the urban area to the Firth of Forth.\n\nEdinburgh is drained by the river named the Water of Leith, which rises at the Colzium Springs in the Pentland Hills and runs for through the south and west of the city, emptying into the Firth of Forth at Leith. The nearest the river gets to the city centre is at Dean Village on the north-western edge of the New Town, where a deep gorge is spanned by Thomas Telford's Dean Bridge, built in 1832 for the road to Queensferry. The Water of Leith Walkway is a mixed-use trail that follows the course of the river for from Balerno to Leith.\n\nExcepting the shoreline of the Firth of Forth, Edinburgh is encircled by a green belt, designated in 1957, which stretches from Dalmeny in the west to Prestongrange in the east. With an average width of the principal objectives of the green belt were to contain the outward expansion of the city and to prevent the agglomeration of urban areas. Expansion affecting the green belt is strictly controlled but developments such as Edinburgh Airport and the Royal Highland Showground at Ingliston lie within the zone. Similarly, suburbs such as Juniper Green and Balerno are situated on green belt land. One feature of the Edinburgh green belt is the inclusion of parcels of land within the city which are designated green belt, even though they do not connect with the peripheral ring. Examples of these independent wedges of green belt include Holyrood Park and Corstorphine Hill.\n\nEdinburgh includes former towns and villages that retain much of their original character as settlements in existence before they were absorbed into the expanding city of the nineteenth and twentieth centuries. Many areas, such as Dalry contain residences that are multi-occupancy buildings known as tenements, although the more southern and western parts of the city have traditionally been more affluent with a greater number of detached and semi-detached villas.\n\nThe historic centre of Edinburgh is divided in two by the broad green swathe of Princes Street Gardens. To the south, the view is dominated by Edinburgh Castle, built high on Castle Rock, and the long sweep of the Old Town descending towards Holyrood Palace. To the north lie Princes Street and the New Town.\n\nThe West End includes the financial district, with insurance and banking offices as well as the Edinburgh International Conference Centre.\n\nEdinburgh's Old and New Towns were listed as a UNESCO World Heritage Site in 1995 in recognition of the unique character of the Old Town with its medieval street layout and the planned Georgian New Town, including the adjoining Dean Village and Calton Hill areas. There are over 4,500 listed buildings within the city, a higher proportion relative to area than any other city in the United Kingdom.\n\nThe Royal Mile runs downhill and terminates at Holyrood Palace. Minor streets (called closes or wynds) lie on either side of the main spine forming a herringbone pattern. The street has several fine public buildings such as St Giles' Cathedral, the City Chambers and the Law Courts. Other places of historical interest nearby are Greyfriars Kirkyard and the Grassmarket. The street layout is typical of the old quarters of many northern European cities.\n\nThe castle is perched on top of a rocky crag (the remnant of an extinct volcano) and the Royal Mile runs down the crest of a ridge from it. Due to space restrictions imposed by the narrowness of this landform, the Old Town became home to some of the earliest \"high rise\" residential buildings. Multi-storey dwellings known as \"lands\" were the norm from the 16th century onwards with ten and eleven storeys being typical and one even reaching fourteen or fifteen storeys. Numerous vaults below street level were inhabited to accommodate the influx of incomers, particularly Irish immigrants, during the Industrial Revolution.\n\nThe New Town was an 18th-century solution to the problem of an increasingly crowded city which had been confined to the ridge sloping down from the castle. In 1766 a competition to design a \"New Town\" was won by James Craig, a 27-year-old architect. The plan was a rigid, ordered grid, which fitted in well with Enlightenment ideas of rationality. The principal street was to be George Street, running along the natural ridge to the north of what became known as the \"Old Town\". To either side of it are two other main streets: Princes Street and Queen Street. Princes Street has become Edinburgh's main shopping street and now has few of its Georgian buildings in their original state. The three main streets are connected by a series of streets running perpendicular to them. The east and west ends of George Street are terminated by St Andrew Square and Charlotte Square respectively. The latter, designed by Robert Adam, influenced the architectural style of the New Town into the early 19th century. Bute House, the official residence of the First Minister of Scotland, is on the north side of Charlotte Square.\n\nThe hollow between the Old and New Towns was formerly the Nor Loch, which was created for the town's defence but came to be used by the inhabitants for dumping their sewage. It was drained by the 1820s as part of the city's northward expansion. Craig's original plan included an ornamental canal on the site of the loch, but this idea was abandoned. Soil excavated while laying the foundations of buildings in the New Town was dumped on the site of the loch to create the slope connecting the Old and New Towns known as The Mound.\n\nIn the middle of the 19th century the National Gallery of Scotland and Royal Scottish Academy Building were built on The Mound, and tunnels for the railway line between Haymarket and Waverley stations were driven through it.\n\nThe Southside is a popular residential part of the city, which includes the districts of St Leonards, Marchmont, Morningside, Newington, Sciennes, the Grange and Blackford. The Southside is broadly analogous to the area covered formerly by the Burgh Muir, and grew in popularity as a residential area after the opening of the South Bridge in the 1780s. The Southside is particularly popular with families (many state and private schools are here), young professionals and students (the central University of Edinburgh campus is based around George Square just north of Marchmont and the Meadows), and Napier University (with major campuses around Merchiston and Morningside). The area is also well provided with hotel and \"bed and breakfast\" accommodation for visiting festival-goers. These districts often feature in works of fiction. For example, Church Hill in Morningside, was the home of Muriel Spark's Miss Jean Brodie, and Ian Rankin's Inspector Rebus lives in Marchmont and works in St Leonards.\n\nLeith was historically the port of Edinburgh, an arrangement of unknown date that was confirmed by the royal charter Robert the Bruce granted to the city in 1329. The port developed a separate identity from Edinburgh, which to some extent it still retains, and it was a matter of great resentment when the two burghs merged in 1920 into the City of Edinburgh. Even today the parliamentary seat is known as \"Edinburgh North and Leith\". The loss of traditional industries and commerce (the last shipyard closed in 1983) resulted in economic decline. The Edinburgh Waterfront development has transformed old dockland areas from Leith to Granton into residential areas with shopping and leisure facilities and helped rejuvenate the area. With the redevelopment, Edinburgh has gained the business of cruise liner companies which now provide cruises to Norway, Sweden, Denmark, Germany, and the Netherlands.\n\nThe coastal suburb of Portobello is characterised by Georgian villas, Victorian tenements, a popular beach and promenade and cafés, bars, restaurants and independent shops. There are rowing and sailing clubs and a restored Victorian swimming pool, including Turkish baths.\n\nThe urban area of Edinburgh is almost entirely within the City of Edinburgh Council boundary, merging with Musselburgh in East Lothian. Towns within easy reach of the city boundary include Haddington, Tranent, Prestonpans, Dalkeith, Bonnyrigg, Loanhead, Penicuik, Broxburn, Livingston and Dunfermline. Edinburgh lies at the heart of the Edinburgh & South East Scotland City region with a population in 2014 of 1,339,380.\n\nLike most of Scotland, Edinburgh has a temperate, maritime climate which is relatively mild despite its northerly latitude. Winter daytime temperatures rarely fall below freezing and are milder than places such as Moscow and Labrador which lie at similar latitudes. Summer temperatures are normally moderate, rarely exceeding . The highest temperature ever recorded in the city was on 25 July 2019 at Gogarbank, beating the previous record of on 4 August 1975 at Edinburgh Airport. The lowest temperature recorded in recent years was during December 2010 at Gogarbank. In an average year, the temperature will drop to a minimum of .\n\nThe city's proximity to the sea mitigates any large variations in temperature or extremes of climate. Given Edinburgh's position between the coast and hills, it is renowned as \"the windy city\", with the prevailing wind direction coming from the south-west, which is often associated with warm, unstable air from the North Atlantic Current that can give rise to rainfall – although considerably less than cities to the west, such as Glasgow. Rainfall is distributed fairly evenly throughout the year. Winds from an easterly direction are usually drier but considerably colder, and may be accompanied by haar, a persistent coastal fog. Vigorous Atlantic depressions, known as European windstorms, can affect the city between October and May.\n\nThere is also a weather station in Gogarbank on the city's outskirts. This slightly inland station has a slightly wider temperature span between seasons, is cloudier and somewhat wetter, but differences are minor.\n\nTemperature and rainfall records have been kept at the Royal Observatory since 1764. In that time, the warmest month on record was July 1779, with an average temperature of , whereas the coldest was January 1814, with a mean temperature of . The warmest years on record are 1779 and 1846, both with mean temperatures of . The coldest year on record is 1879, with a mean temperature of . The wettest month on record was August 1948, with . The driest was February 1934, with . The wettest year on record was 1916, with . The driest year on record was 1826, with of rainfall.\n\nThe most recent official population estimates are 512,150 (2016) for the Edinburgh settlement (includes Musselburgh) and 518,500 (2018) for the local authority area.\n\nEdinburgh has a high proportion of young adults, with 19.5% of the population in their 20s (exceeded only by Aberdeen) and 15.2% in their 30s which is the highest in Scotland. The proportion of Edinburgh's population born in the UK fell from 92% to 84% between 2001 and 2011, while the proportion of White Scottish-born fell from 78% to 70%. Of those Edinburgh residents born in the UK, 335,000 or 83% were born in Scotland, with 58,000 or 14% being born in England.\n\n!rowspan=\"2\"Ethnic Group\n!colspan=\"2\"2001\n!colspan=\"2\"2011\n!Number\n!Number\n\nstyle=\"text-align:left\"  White: Scottish  354,053  78.9%  334,987  70.2%\nstyle=\"text-align:left\"  White: Other British  51,407  11.4%  56,132  11.7%\nstyle=\"text-align:left\"  White: Irish  6,470  1.4%  8,603  1.8%\nstyle=\"text-align:left\"  White: Other  18,439  4.1%  37,445  7.9%\nstyle=\"text-align:left\"  White: Total  430,369  95.9%  437,167  91.7%\nstyle=\"text-align:left\"  Asian:  11,600  2.5%  26,264  5.5%\nstyle=\"text-align:left\"  African:  1,285  0.2%  4,474  0.9%\nstyle=\"text-align:left\"  Caribbean/Black:  292†  <0.1%  1,031  0.2%\nstyle=\"text-align:left\"  Mixed/Multiple:  2,776††  0.6%  4,087  0.8%\nstyle=\"text-align:left\"  Other Non-White:  2,302  0.5%  3,603  0.8%\nstyle=\"text-align:left\"  Non-White: Total  18,255  4.0%  39,459  8.2%\nstyle=\"text-align:left\"  Total  448,624  100.00%  476,626  \n100.00%\n†† Previously ‘Mixed’\n\nSome 13,000 people or 2.7% of the city's population are of Polish descent. 39,500 people or 8.2% of Edinburgh's population class themselves as Non-White which is an increase from 4% in 2001. Of the Non-White population, the largest group by far are Asian, totalling 26,264 people. Within the Asian population, people of Chinese descent are now the largest sub-group, with 8,076 people, amounting to about 1.7% of the city's total population. The city's population of Indian descent amounts to 6,470 (1.4% of the total population), while there are some 5,858 of Pakistani descent (1.2% of the total population). Although they account for only 1,277 people or 0.3% of the city's population, Edinburgh has the highest number and proportion of people of Bangladeshi descent in Scotland. Over 7,000 people were born in African countries (1.6% of the total population) and nearly 7,000 in the Americas. With the notable exception of Inner London, Edinburgh has a higher number of people born in the United States (over 3,700) than any other city in the UK.\n\nThe proportion of people born outside the UK was 15.9% compared with 8% in 2001.\n\n! scope=\"col\"  Place of birth\n! scope=\"col\"  Estimated resident population (2011)\n\nA census by the Edinburgh presbytery in 1592 recorded a population of 8,003 adults spread equally north and south of the High Street which runs along the spine of the ridge sloping down from the Castle. In the 18th and 19th centuries, the population expanded rapidly, rising from 49,000 in 1751 to 136,000 in 1831, primarily due to migration from rural areas. As the population grew, problems of overcrowding in the Old Town, particularly in the cramped tenements that lined the present day Royal Mile and the Cowgate, were exacerbated. Poor sanitary arrangements resulted in a high incidence of disease, with outbreaks of cholera occurring in 1832, 1848 and 1866.\n\nThe construction of the New Town from 1767 onwards witnessed the migration of the professional and business classes from the difficult living conditions in the Old Town to the lower density, higher quality surroundings taking shape on land to the north.\n\nEarly-20th-century population growth coincided with lower-density suburban development. As the city expanded to the south and west, detached and semi-detached villas with large gardens replaced tenements as the predominant building style. Nonetheless, the 2001 census revealed that over 55% of Edinburgh's population were still living in tenements or blocks of flats, a figure in line with other Scottish cities, but much higher than other British cities, and even central London.\n\nFrom the early to mid 20th century the growth in population, together with slum clearance in the Old Town and other areas, such as Dumbiedykes, Leith, and Fountainbridge, led to the creation of new estates such as Stenhouse and Saughton, Craigmillar and Niddrie, Pilton and Muirhouse, Piershill, and Sighthill.\n\nThe Church of Scotland has 11,484 members (2018) in Edinburgh . In 2010 there were 83 congregations in the Presbytery of Edinburgh. Its most prominent church is St Giles' on the Royal Mile, first dedicated in 1243 but believed to date from before the 12th century. Saint Giles is historically the patron saint of Edinburgh. St Cuthbert's, situated at the west end of Princes Street Gardens in the shadow of Edinburgh Castle and St Giles' can lay claim to being the oldest Christian sites in the city, though the present St Cuthbert's, designed by Hippolyte Blanc, was dedicated in 1894.\n\nOther Church of Scotland churches include Greyfriars Kirk, the Canongate Kirk, St Andrew's and St George's West Church and the Barclay Church. The Church of Scotland Offices are in Edinburgh, as is the Assembly Hall where the annual General Assembly is held.\n\nThe Roman Catholic Archdiocese of St Andrews and Edinburgh has 27 parishes across the city. The Archbishop of St Andrews and Edinburgh has his official residence in Greenhill, and the diocesan offices are in nearby Marchmont. The Diocese of Edinburgh of the Scottish Episcopal Church has over 50 churches, half of them in the city. Its centre is the late-19th-century Gothic style St Mary's Cathedral in the West End's Palmerston Place. Orthodox Christianity is represented by Pan, Romanian and Russian Orthodox churches. There are several independent churches in the city, both Catholic and Protestant, including Charlotte Chapel, Carrubbers Christian Centre, Bellevue Chapel and Sacred Heart. There are also churches belonging to Quakers, Christadelphians, Seventh-day Adventists, Church of Christ, Scientist, The Church of Jesus Christ of Latter-day Saints (LDS Church) and Elim Pentecostal Church.\n\nEdinburgh Central Mosque – Edinburgh's main mosque and Islamic Centre – is in Potterrow, on the city's Southside, near Bristo Square. Construction was largely financed by a gift from King Fahd of Saudi Arabia and was completed in 1998. There are other mosques in Annandale Street Lane, off Leith Walk, and in Queensferry Road, Blackhall as well as other Islamic centres across the city. There is also an active presence of the Ahmadiyya Muslim community.\nThe first recorded presence of a Jewish community in Edinburgh dates back to the late 18th century. Edinburgh's Orthodox synagogue, opened in 1932, is in Salisbury Road and can accommodate a congregation of 2000. A Liberal Jewish congregation also meets in the city. There are a Sikh gurdwara and a Hindu mandir, both in Leith, and a Brahma Kumaris centre in the Polwarth area. The Edinburgh Buddhist Centre, run by the Triratna Buddhist Community, formerly situated in Melville Terrace, now runs sessions at the Healthy Life Centre, Bread Street. Other Buddhist traditions are represented by groups which meet in the capital: the Community of Interbeing (followers of Thich Nhat Hanh), Rigpa, Samye Dzong, Theravadin, Pure Land and Shambala. There is a Sōtō Zen Priory in Portobello and a Theravadin Thai Buddhist Monastery in Slateford Road. Edinburgh is home to an active Bahá'í Community, and a Theosophical Society meets in Great King Street. Edinburgh has an active Inter-Faith Association.\n\nEdinburgh has the strongest economy of any city in the United Kingdom outside London and the highest percentage of professionals in the UK with 43% of the population holding a degree-level or professional qualification. According to the Centre for International Competitiveness, it is the most competitive large city in the United Kingdom. It also has the highest gross value added per employee of any city in the UK outside London, measuring £57,594 in 2010. It was named European \"Best Large City of the Future for Foreign Direct Investment\" and \"Best Large City for Foreign Direct Investment Strategy\" in the\" Financial Times \"fDi magazine awards 2012/13.\n\nIn the 19th century, Edinburgh's economy was known for banking, publishing and brewing. Today, its economy is based mainly on financial services, scientific research, higher education, and tourism. In March 2010, unemployment in Edinburgh was comparatively low at 3.6%, and it remains consistently below the Scottish average of 4.5%. Edinburgh is the 2nd most visited city by foreign visitors in the UK after London.\n\nBanking has been a mainstay of the Edinburgh economy for over 300 years, since the Bank of Scotland (now part of the Lloyds Banking Group) was established by an act of the Scottish Parliament in 1695. Today, the financial services industry, with its particularly strong insurance and investment sectors, and underpinned by Edinburgh-based firms such as Scottish Widows and Standard Life Aberdeen, accounts for the city being the UK's second financial centre after London and Europe's fourth in terms of equity assets. The Royal Bank of Scotland opened new global headquarters at Gogarburn in the west of the city in October 2005, and Edinburgh is home to the headquarters of Bank of Scotland, Sainsbury's Bank, Tesco Bank, and TSB Bank.\n\nTourism is also an important element in the city's economy. As a World Heritage Site, tourists visit historical sites such as Edinburgh Castle, the Palace of Holyroodhouse and the Old and New Towns. Their numbers are augmented in August each year during the Edinburgh Festivals, which attracts 4.4 million visitors, and generates over £100m for the local economy.\n\nAs the centre of Scotland's government and legal system, the public sector plays a central role in Edinburgh's economy. Many departments of the Scottish Government are in the city. Other major employers include NHS Scotland and local government administration.\n\nThe city hosts a series of festivals that run between the end of July and early September each year. The best known of these events are the Edinburgh Festival Fringe, the Edinburgh International Festival, the Edinburgh Military Tattoo and the Edinburgh International Book Festival.\n\nThe longest established of these festivals is the Edinburgh International Festival, which was first held in 1947 and consists mainly of a programme of high-profile theatre productions and classical music performances, featuring international directors, conductors, theatre companies and orchestras.\n\nThis has since been overtaken both in size and popularity by the Edinburgh Fringe which began as a programme of marginal acts alongside the \"official\" Festival and has become the world's largest performing arts festival. In 2017, nearly 3400 different shows were staged in 300 venues across the city. Comedy has become one of the mainstays of the Fringe, with numerous well-known comedians getting their first 'break' there, often by being chosen to receive the Edinburgh Comedy Award. The Edinburgh Military Tattoo, occupies the Castle Esplanade every night for three weeks each August, with massed pipe bands and military bands drawn from around the world. Performances end with a short fireworks display.\n\nAs well as the various summer festivals, many other festivals are held during the rest of the year, including the Edinburgh International Film Festival and Edinburgh International Science Festival.\n\nThe annual Edinburgh Hogmanay celebration was originally an informal street party focused on the Tron Kirk in the Old Town's High Street. Since 1993, it has been officially organised with the focus moved to Princes Street. In 1996, over 300,000 people attended, leading to ticketing of the main street party in later years up to a limit of 100,000 tickets. Hogmanay now covers four days of processions, concerts and fireworks, with the street party beginning on Hogmanay. Alternative tickets are available for entrance into the Princes Street Gardens concert and Cèilidh, where well-known artists perform and ticket holders can participate in traditional Scottish cèilidh dancing. The event attracts thousands of people from all over the world.\n\nOn the night of 30 April the Beltane Fire Festival takes place on Calton Hill, involving a procession followed by scenes inspired by pagan old spring fertility celebrations. At the beginning of October each year the Dussehra Hindu Festival is also held on Calton Hill.\n\nOutside the Festival season, Edinburgh supports several theatres and production companies. The Royal Lyceum Theatre has its own company, while the King's Theatre, Edinburgh Festival Theatre and Edinburgh Playhouse stage large touring shows. The Traverse Theatre presents a more contemporary repertoire. Amateur theatre companies productions are staged at the Bedlam Theatre, Church Hill Theatre and King's Theatre among others.\n\nThe Usher Hall is Edinburgh's premier venue for classical music, as well as occasional popular music concerts. It was the venue for the Eurovision Song Contest 1972. Other halls staging music and theatre include The Hub, the Assembly Rooms and the Queen's Hall. The Scottish Chamber Orchestra is based in Edinburgh.\n\nEdinburgh has two repertory cinemas, the Edinburgh Filmhouse and The Cameo, as well as the independent Dominion Cinema and a range of multiplexes.\n\nEdinburgh has a healthy popular music scene. Occasionally large concerts are staged at Murrayfield and Meadowbank, while mid-sized events take place at smaller venues such as the Corn Exchange, the Liquid Rooms and the Bongo Club. In 2010, PRS for Music listed Edinburgh among the UK's top ten 'most musical' cities. Several city pubs are well known for their live performances of folk music. They include 'Sandy Bell's' in Forrest Road, 'Captain's Bar' in South College Street and 'Whistlebinkies' in South Bridge.\n\nEdinburgh is home to a flourishing group of contemporary composers such as Nigel Osborne, Peter Nelson, Lyell Cresswell, Hafliði Hallgrímsson, Edward Harper, Robert Crawford, Robert Dow and John McLeod. McLeod's music is heard regularly on BBC Radio 3 and throughout the UK.\n\nThe main local newspaper is the \"Edinburgh Evening News\". It is owned and published alongside its sister titles \"The Scotsman\" and \"Scotland on Sunday\" by JPIMedia.\n\nThe city has two commercial radio stations: Forth 1, a station which broadcasts mainstream chart music, and Forth 2 on medium wave which plays classic hits. Capital Radio Scotland and Eklipse Sports Radio also have transmitters covering Edinburgh. Along with the UK national radio stations, Radio Scotland and the Gaelic language service BBC Radio nan Gàidheal are also broadcast. DAB digital radio is broadcast over two local multiplexes. BFBS Radio broadcasts from studios on the base at Dreghorn Barracks across the city on 98.5FM as part of its UK Bases network\n\nTelevision, along with most radio services, is broadcast to the city from the Craigkelly transmitting station situated in Fife on the opposite side of the Firth of Forth and the Black Hill transmitting station in North Lanarkshire to the west.\n\nThere are currently no television stations based in the city. Edinburgh Television existed in the late 90's to early 2003 and STV Edinburgh existed from 2015 to 2018.\n\nEdinburgh has many museums and libraries. These include the National Museum of Scotland, the National Library of Scotland, National War Museum, the Museum of Edinburgh, Surgeons' Hall Museum, the Writers' Museum, the Museum of Childhood and Our Dynamic Earth. The Museum on The Mound has exhibits on money and banking.\n\nEdinburgh Zoo, covering on Corstorphine Hill, is the second most popular paid tourist attraction in Scotland, and currently home to two giant pandas, Tian Tian and Yang Guang, on loan from the People's Republic of China.\n\nEdinburgh is also home to The Royal Yacht Britannia, decommissioned in 1997 and now a five-star visitor attraction and evening events venue permanently berthed at Ocean Terminal.\n\nEdinburgh contains Scotland's five National Galleries of Art as well as numerous smaller art galleries. The national collection is housed in the Scottish National Gallery, located on The Mound, now linked to the Royal Scottish Academy which holds regular major exhibitions of paintings. Contemporary collections are shown in the Scottish National Gallery of Modern Art which occupies a split site at Belford. The Scottish National Portrait Gallery on Queen Street focuses on portraits and photography.\n\nThe council-owned City Art Centre in Market Street mounts regular art exhibitions. Across the road, The Fruitmarket Gallery offers world-class exhibitions of contemporary art, featuring work by British and international artists with both emerging and established international reputations.\n\nThere are also many small private shops/galleries that provide space to showcase works from local artists.\n\nThe city hosts several of Scotland's galleries and organisations dedicated to contemporary visual art. Significant strands of this infrastructure include: The Scottish Arts Council, Edinburgh College of Art, Talbot Rice Gallery (University of Edinburgh) and the Edinburgh Annuale.\n\nThe locale around Princes Street is the main shopping area in the city centre, with souvenir shops, chain stores such as Boots the Chemist, Edinburgh Woollen Mill, H&M and Jenners. George Street, north of Princes Street, is the preferred location for some upmarket shops and independent stores. The St. James Centre at the east end of Princes Street is currently being redeveloped. Multrees Walk, adjacent to the St. James Centre, is a recent addition to the central shopping district, dominated by the presence of Harvey Nichols. Shops here include Louis Vuitton, Mulberry and Calvin Klein.\n\nEdinburgh also has substantial retail parks outside the city centre. These include The Gyle Shopping Centre and Hermiston Gait in the west of the city, Cameron Toll Shopping Centre, Straiton Retail Park (actually just outside the city, in Midlothian) and Fort Kinnaird in the south and east, and Ocean Terminal in the north on the Leith waterfront.\n\nFollowing local government reorganisation in 1996, The City of Edinburgh Council constitutes one of the 32 council areas of Scotland. Like all other local authorities of Scotland, the council has powers over most matters of local administration such as housing, planning, local transport, parks, economic development and regeneration. The council comprises 58 elected councillors, returned from 17 multi-member electoral wards in the city. Following the 2007 City of Edinburgh Council election the incumbent Labour Party lost majority control of the council after 23 years to a Liberal Democrat/SNP coalition. The 2012 City of Edinburgh Council election saw a Scottish Labour/SNP coalition. The 2017 City of Edinburgh Council election, saw a continuation of this administration, but with the SNP as the largest party.\nThe city's coat of arms was registered by the Lord Lyon King of Arms in 1732.\n\nEdinburgh, like all of Scotland, is represented in the Scottish Parliament. For electoral purposes, the city is divided into six constituencies which, along with 3 seats outside of the city, form part of the Lothian region. Each constituency elects one Member of the Scottish Parliament (MSP) by the first past the post system of election, and the region elects seven additional MSPs to produce a result based on a form of proportional representation.\n\nAs of the 2016 election, the Scottish National Party have three MSPs: Ash Denham for Edinburgh Eastern, Ben Macpherson for Edinburgh Northern and Leith and Gordon MacDonald for Edinburgh Pentlands constituencies. Alex Cole-Hamilton of the Scottish Liberal Democrats represents Edinburgh Western, Daniel Johnson of the Scottish Labour Party represents Edinburgh Southern constituency, and Scottish Conservative leader Ruth Davidson currently represents the Edinburgh Central constituency.\n\nEdinburgh is also represented in the House of Commons of the United Kingdom by five Members of Parliament. The city is divided into Edinburgh North and Leith, Edinburgh East, Edinburgh South, Edinburgh South West, and Edinburgh West, each constituency electing one member by the first past the post system. Edinburgh is currently represented by three MPs affiliated with the Scottish National Party, one Liberal Democrat MP in Edinburgh West and one Labour MP in Edinburgh South.\n\nEdinburgh Airport is Scotland's busiest and biggest airport and the principal international gateway to the capital, handling over 12 million passengers in 2016. In anticipation of rising passenger numbers, the former operator of the airport BAA outlined a draft masterplan in 2011 to provide for the expansion of the airfield and the terminal building. In June 2012, Global Infrastructure Partners purchased the airport for £807 million. The possibility of building a second runway to cope with an increased number of aircraft movements has also been mooted.\n\nTravel in Edinburgh is undertaken predominantly by bus. Lothian Buses, the successor company to Edinburgh Corporation Transport Department, operate the majority of city bus services within the city and to surrounding suburbs, with the most routes running via Princes Street. Services further afield operate from the Edinburgh Bus Station off St Andrew Square and Waterloo Place and are operated mainly by Stagecoach East Scotland, Scottish Citylink, National Express Coaches and Borders Buses.\n\nLothian Buses also operates all of the city's branded public tour buses, night bus service and airport bus link.\n\nEdinburgh Waverley is the second-busiest railway station in Scotland, with only Glasgow Central handling more passengers. On the evidence of passenger entries and exits between April 2015 and March 2016, Edinburgh Waverley is the fifth-busiest station outside London; it is also the UK's second biggest station in terms of the number of platforms and area size. Waverley is the terminus for most trains arriving from London King's Cross and the departure point for many rail services within Scotland operated by Abellio ScotRail.\n\nTo the west of the city centre lies Haymarket Station which is an important commuter stop. Opened in 2003, Edinburgh Park station serves the Gyle business park in the west of the city and the nearby Gogarburn headquarters of the Royal Bank of Scotland. The Edinburgh Crossrail route connects Edinburgh Park with Haymarket, Edinburgh Waverley and the suburban stations of Brunstane and Newcraighall in the east of the city. There are also commuter lines to South Gyle and Dalmeny, the latter serving South Queensferry by the Forth Bridges, and to Wester Hailes and Curriehill in the south-west of the city.\n\nTo tackle traffic congestion, Edinburgh is now served by six park and ride sites on the periphery of the city at Sheriffhall (in Midlothian), Ingliston, Riccarton, Inverkeithing (in Fife), Newcraighall and Straiton (in Midlothian). A referendum of Edinburgh residents in February 2005 rejected a proposal to introduce congestion charging in the city.\n\nEdinburgh Trams became operational on 31 May 2014. The city had been without a tram system since Edinburgh Corporation Tramways ceased on 16 November 1956. Following parliamentary approval in 2007, construction began in early 2008. The first stage of the project was expected to be completed by July 2011 but, following delays caused by extra utility work and a long-running contractual dispute between the Council and the main contractor, Bilfinger SE, the project was rescheduled. The cost of the project rose from the original projection of £545 million to £750 million in mid-2011 and some suggest it could eventually exceed £1 billion. The completed line is in length, running from Edinburgh Airport, west of the city, to its current terminus at York Place in the city centre's East End. It was originally planned to continue down Leith Walk to Ocean Terminal and terminate at Newhaven.\n\nShould the original plan be taken to completion, trams will also run from Haymarket through Ravelston and Craigleith to Granton Square on the Waterfront Edinburgh. Long-term proposals envisage a line running west from the airport to Ratho and Newbridge and another connecting Granton Square to Newhaven via Lower Granton Road, thus completing the Line 1 (North Edinburgh) loop. A further line serving the south of the city has also been suggested.\n\nLothian Buses and Edinburgh Trams are both owned and operated by Transport for Edinburgh.\n\nThere are three universities in Edinburgh, the University of Edinburgh, Heriot-Watt University and Edinburgh Napier University.\n\nEstablished by royal charter in 1583, the University of Edinburgh is one of Scotland's ancient universities and is the fourth oldest in the country after St Andrews, Glasgow and Aberdeen. Originally centred on Old College the university expanded to premises on The Mound, the Royal Mile and George Square. Today, the King's Buildings in the south of the city contain most of the schools within the College of Science and Engineering. In 2002, the medical school moved to purpose built accommodation adjacent to the new Royal Infirmary of Edinburgh at Little France. The University is placed 20th in the QS World University Rankings for 2020.\n\nHeriot-Watt University is based at the Riccarton campus in the west of Edinburgh. Originally established in 1821 as the world's first mechanics' institute it was granted university status by royal charter in 1966. It has other campuses in the Scottish Borders, Orkney, United Arab Emirates and Putrajaya in Malaysia. It takes the name Heriot-Watt from Scottish inventor James Watt and Scottish philanthropist and goldsmith George Heriot. Heriot-Watt University has been named International University of the Year by The Times and Sunday Times Good University Guide 2018. In the latest Research Excellence Framework, it was ranked overall in the Top 25% of UK universities and 1st in Scotland for research impact.\n\nEdinburgh Napier University is another public university in Edinburgh, Scotland. The former Napier College was renamed Napier Polytechnic in 1986 and gained university status in 1992. Edinburgh Napier University has campuses in the south and west of the city, including the former Merchiston Tower and Craiglockhart Hydropathic. It is home to the Screen Academy Scotland.\n\nQueen Margaret University was located in Edinburgh before it moved to a new campus on the edge of Musselburgh in 2008.\nUntil 2012 further education colleges in the city included Jewel and Esk College (incorporating Leith Nautical College founded in 1903), Telford College, opened in 1968, and Stevenson College, opened in 1970. These have now been amalgamated to form Edinburgh College. Scotland's Rural College also has a campus in south Edinburgh. Other institutions include the Royal College of Surgeons of Edinburgh and the Royal College of Physicians of Edinburgh which were established by royal charter in 1506 and 1681 respectively. The Trustees Drawing Academy of Edinburgh, founded in 1760, became the Edinburgh College of Art in 1907.\n\nThere are 18 nursery, 94 primary and 23 secondary schools administered by the City of Edinburgh Council.\nEdinburgh is home to The Royal High School, one of the oldest schools in the country and the world. The city also has several independent, fee-paying schools including Edinburgh Academy, Fettes College, George Heriot's School, George Watson's College, Merchiston Castle School, Stewart's Melville College and The Mary Erskine School. In 2009, the proportion of pupils attending independent schools was 24.2%, far above the Scottish national average of just over 7% and higher than in any other region of Scotland. In August 2013, the City of Edinburgh Council opened the city's first stand-alone Gaelic primary school, Bun-sgoil Taobh na Pàirce.\n\nThe main NHS Lothian hospitals serving the Edinburgh area are the Royal Infirmary of Edinburgh, which includes the University of Edinburgh Medical School, and the Western General Hospital, which has a large cancer treatment centre and nurse-led Minor Injuries Clinic. The Royal Edinburgh Hospital in Morningside specialises in mental health. The Royal Hospital for Sick Children, popularly referred to as 'the Sick Kids', is a specialist paediatrics hospital.\n\nThere are two private hospitals: Murrayfield Hospital in the west of the city and Shawfair Hospital in the south. Both are owned by Spire Healthcare.\n\nEdinburgh has three football clubs that play in the Scottish Professional Football League (SPFL): Heart of Midlothian, founded in 1874, Hibernian, founded in 1875 and Edinburgh City, founded in 1966.\n\nHeart of Midlothian and Hibernian are known locally as \"Hearts\" and \"Hibs\" respectively, both play in the Scottish Premiership. They are the oldest city rivals in Scotland and the Edinburgh derby is one of the oldest derby matches in world football. Both clubs have won the Scottish league championship four times. Hearts have won the Scottish Cup eight times and the Scottish League Cup four times. Hibs have won the Scottish Cup and the Scottish League Cup three times each. Edinburgh City were promoted to Scottish League Two in the 2015–16 season, becoming the first club to win promotion to the SPFL via the pyramid system playoffs.\n\nEdinburgh was also home to four other former Scottish Football League clubs: the original Edinburgh City, Leith Athletic, Meadowbank Thistle and St Bernard's. Meadowbank Thistle played at Meadowbank Stadium until 1995, when the club moved to Livingston and became Livingston F.C. The Scottish national team has very occasionally played at Easter Road and Tynecastle, although its normal home stadium is Hampden Park in Glasgow. St Bernard's' New Logie Green was used to host the 1896 Scottish Cup Final, the only time the match has been played outside Glasgow.\n\nThe city also plays host to Lowland Football League clubs Civil Service Strollers, Edinburgh University and Spartans, as well as East of Scotland League clubs Craigroyston, Edinburgh United, Heriot-Watt University, Leith Athletic, Lothian Thistle Hutchison Vale, and Tynecastle.\n\nIn women's football, Hibs and Spartans play in the SWPL 1. Hutchison Vale and Hearts play in the SWPL 2.\n\nThe Scotland national rugby union team and the professional Edinburgh Rugby team play at Murrayfield Stadium, which is owned by the Scottish Rugby Union and also used for other events, including music concerts. It is the largest capacity stadium in Scotland, seating 67,144 spectators. Edinburgh is also home to Scottish Premiership teams Boroughmuir RFC, Currie RFC, the Edinburgh Academicals, Heriot's Rugby Club and Watsonians RFC.\n\nRugby league is represented by the Edinburgh Eagles who play in the Rugby League Conference Scotland Division. Murrayfield Stadium has hosted the Magic Weekend where all Super League matches are played in the stadium over one weekend.\n\nThe Scottish cricket team, which represents Scotland internationally, play their home matches at the Grange cricket club.\n\nThe Murrayfield Racers are the latest of a succession of ice hockey clubs in the Scottish capital. Previously Edinburgh was represented by the Edinburgh Capitals \"(who folded in 2018)\", the original Murrayfield Racers \"(who folded in 1996)\" and the Edinburgh Racers. The club play their home games at the Murrayfield Ice Rink and have competed in the eleven-team professional Scottish National League (SNL) since the 2018–19 season.\n\nNext door to Murrayfield Ice Rink is a 7-sheeter dedicated curling facility where curling is played from October to March each season.\n\nCaledonia Pride are the only women's professional basketball team in Scotland. Established in 2016, the team compete in the UK wide Women's British Basketball League and play their home matches at the Oriam National Performance Centre. Edinburgh also has several men's basketball teams within the Scottish National League. Boroughmuir Blaze, City of Edinburgh Kings, Edinburgh Lions and Edinburgh University all compete in Division 1 of the National League, and Pleasance B.C. compete in Division 2. Boroughmuir won the league in 2016, and won the playoffs in the same year, beating the University in the final.\n\nThe Edinburgh Diamond Devils is a baseball club which won its first Scottish Championship in 1991 as the \"Reivers.\" 1992 saw the team repeat the achievement, becoming the first team to do so in league history. The same year saw the start of their first youth team, the Blue Jays. The club adopted its present name in 1999.\n\nEdinburgh has also hosted national and international sports events including the World Student Games, the 1970 British Commonwealth Games, the 1986 Commonwealth Games and the inaugural 2000 Commonwealth Youth Games. For the 1970 Games the city built Olympic standard venues and facilities including Meadowbank Stadium and the Royal Commonwealth Pool. The Pool underwent refurbishment in 2012 and is due to host the Diving competition in the 2014 Commonwealth Games which will be held in Glasgow.\n\nIn American football, the Scottish Claymores played WLAF/NFL Europe games at Murrayfield, including their World Bowl 96 victory. From 1995 to 1997 they played all their games there, from 1998 to 2000 they split their home matches between Murrayfield and Glasgow's Hampden Park, then moved to Glasgow full-time, with one final Murrayfield appearance in 2002. The city's most successful non-professional team are the Edinburgh Wolves who play at Meadowbank Stadium.\n\nThe Edinburgh Marathon has been held annually in the city since 2003 with more than 16,000 runners taking part on each occasion. Its organisers have called it \"the fastest marathon in the UK\" due to the elevation drop of . The city also organises a half-marathon, as well as 10 km () and 5 km () races, including a race on 1 January each year.\n\nEdinburgh has a speedway team, the Edinburgh Monarchs, which, since the loss of its stadium in the city, has raced at the Lothian Arena in Armadale, West Lothian. The Monarchs have won the Premier League championship five times in their history, in 2003 and again in 2008, 2010, 2014 and 2015.\n\nEdinburgh has a long literary tradition, which became especially evident during the Scottish Enlightenment. This heritage and the city's lively literary life in the present led to it being declared the first UNESCO City of Literature in 2004. Famous authors who have lived in Edinburgh include the economist Adam Smith, born in Kirkcaldy and author of \"The Wealth of Nations\",\n\nScotland has a rich history of science and engineering, with Edinburgh producing a number of famous names. John Napier, inventor of logarithms, was born in Merchiston Tower and lived and died in the city. His house now forms part of the original campus of Napier University which was named in his honour. He lies buried under St. Cuthbert's Church. James Clerk Maxwell, founder of the modern theory of electromagnetism, was born at 14 India Street (now the home of the James Clerk Maxwell Foundation) and educated at the Edinburgh Academy and the University of Edinburgh, as was the engineer and telephone pioneer Alexander Graham Bell. James Braidwood, who organised Britain's first municipal fire brigade, was also born in the city and began his career there.\n\nOther names connected with the city include Max Born, physicist and Nobel laureate; Charles Darwin, the biologist who propounded the theory of natural selection; David Hume, philosopher, economist and historian; James Hutton, regarded as the \"Father of Geology\"; Joseph Black, the chemist and one of the founders of thermodynamics; pioneering medical researchers Joseph Lister and James Young Simpson; chemist and discoverer of the element nitrogen Daniel Rutherford; Colin Maclaurin, mathematician and developer of the Maclaurin series, and Ian Wilmut, the geneticist involved in the cloning of Dolly the sheep just outside Edinburgh. The stuffed carcass of Dolly the sheep is now on display in the National Museum of Scotland. The latest in a long line of science celebrities associated with the city is theoretical physicist and Nobel Prizewinner Professor Emeritus Peter Higgs, born in Newcastle but resident in Edinburgh for most of his academic career, after whom the Higgs boson particle has been named.\nEdinburgh has been the birthplace of actors like Alastair Sim and Sir Sean Connery, famed as the first cinematic James Bond, the comedian and actor Ronnie Corbett, best known as one of The Two Ronnies, and the impressionist Rory Bremner. Famous artists from the city include the portrait painters Sir Henry Raeburn, Sir David Wilkie and Allan Ramsay.\n\nThe city has produced or been home to some very successful musicians in recent decades, particularly Ian Anderson, front man of the band Jethro Tull, The Incredible String Band, the folk duo The Corries, Wattie Buchan, lead singer and founding member of punk band The Exploited, Shirley Manson, lead singer of the band Garbage, the Bay City Rollers, The Proclaimers, Boards of Canada and Idlewild.\n\nEdinburgh is the birthplace of former British Prime Minister Tony Blair who attended the city's Fettes College.\n\nNotorious criminals from Edinburgh's past include Deacon Brodie, head of a trades guild and Edinburgh city councillor by day but a burglar by night, who is said to have been the inspiration for Robert Louis Stevenson's story, the \"Strange Case of Dr Jekyll and Mr Hyde\", and murderers Burke and Hare who delivered fresh corpses for dissection to the famous anatomist Robert Knox.\n\nAnother well-known Edinburgh resident was Greyfriars Bobby. The small Skye Terrier reputedly kept vigil over his dead master's grave in Greyfriars Kirkyard for 14 years in the 1860s and 1870s, giving rise to a story of canine devotion which plays a part in attracting visitors to the city.\n\nThe City of Edinburgh has entered into 14 international twinning arrangements since 1954. Most of the arrangements are styled as 'Twin Cities' but the agreement with Kraków is designated as a 'Partner City', and the agreement with Kyoto Prefecture is officially styled as a 'Friendship Link', reflecting its status as the only region to be twinned with Edinburgh.\n\n! City\n! Since\n\nFor a list of consulates in Edinburgh see List of diplomatic missions in Scotland.\n\nBULLET::::- Outline of Edinburgh\nBULLET::::- National Archives of Scotland\nBULLET::::- OPENCities\nBULLET::::- Tourism in Scotland\n\nBULLET::::- H Coghill, \"Edinburgh, The Old Town\", John Donald, Edinburgh 1990,\nBULLET::::- A Herman, \"\", Three Rivers Press, New York, 2001, ; also published as \"The Scottish Enlightenment: The Scots' Invention of the Modern World\", HarperCollins, London, 2001,\nBULLET::::- A Massie, \"Edinburgh\", Sinclair-Stevenson, London 1994,\nBULLET::::- S Mullay, \"The Edinburgh Encyclopedia\", Mainstream Publishing, Edinburgh and London 1996,\nBULLET::::- S Mullay, \"The Illustrated History of Edinburgh's Suburbs\", Breedon Books, Derby 2008,\n\nBULLET::::- The City of Edinburgh Council official website\nBULLET::::- Marketing Edinburgh official tourist agency\n"}
{"id": "9603", "url": "https://en.wikipedia.org/wiki?curid=9603", "title": "Ernest Rutherford", "text": "Ernest Rutherford\n\nErnest Rutherford, 1st Baron Rutherford of Nelson, , HFRSE (30 August 1871 – 19 October 1937), was a New Zealand-born British physicist who came to be known as the father of nuclear physics. \"Encyclopædia Britannica\" considers him to be the greatest experimentalist since Michael Faraday (1791–1867).\n\nIn early work, Rutherford discovered the concept of radioactive half-life, the radioactive element radon, and differentiated and named alpha and beta radiation. This work was performed at McGill University in Montreal, Quebec, Canada. It is the basis for the Nobel Prize in Chemistry he was awarded in 1908 \"for his investigations into the disintegration of the elements, and the chemistry of radioactive substances\", for which he was the first Canadian and Oceanian Nobel laureate.\n\nRutherford moved in 1907 to the Victoria University of Manchester (today University of Manchester) in the UK, where he and Thomas Royds proved that alpha radiation is helium nuclei. Rutherford performed his most famous work after he became a Nobel laureate. In 1911, although he could not prove that it was positive or negative, he theorized that atoms have their charge concentrated in a very small nucleus, and thereby pioneered the Rutherford model of the atom, through his discovery and interpretation of Rutherford scattering by the gold foil experiment of Hans Geiger and Ernest Marsden. He performed the first artificially induced nuclear reaction in 1917 in experiments where nitrogen nuclei were bombarded with alpha particles. As a result, he discovered the emission of a subatomic particle which, in 1919, he called the \"hydrogen atom\" but, in 1920, he more accurately named the proton.\n\nRutherford became Director of the Cavendish Laboratory at the University of Cambridge in 1919. Under his leadership the neutron was discovered by James Chadwick in 1932 and in the same year the first experiment to split the nucleus in a fully controlled manner was performed by students working under his direction, John Cockcroft and Ernest Walton. After his death in 1937, he was buried in Westminster Abbey near Sir Isaac Newton's tomb. The chemical element rutherfordium (element 104) was named after him in 1997.\n\nErnest Rutherford was the son of James Rutherford, a farmer, and his wife Martha Thompson, originally from Hornchurch, Essex, England. James had emigrated to New Zealand from Perth, Scotland, \"to raise a little flax and a lot of children\". Ernest was born at Brightwater, near Nelson, New Zealand. His first name was mistakenly spelled 'Earnest' when his birth was registered. Rutherford's mother Martha Thompson was a schoolteacher.\n\nHe studied at Havelock School and then Nelson College and won a scholarship to study at Canterbury College, University of New Zealand, where he participated in the debating society and played rugby. After gaining his BA, MA and BSc, and doing two years of research during which he invented a new form of radio receiver, in 1895 Rutherford was awarded an 1851 Research Fellowship from the Royal Commission for the Exhibition of 1851, to travel to England for postgraduate study at the Cavendish Laboratory, University of Cambridge. He was among the first of the 'aliens' (those without a Cambridge degree) allowed to do research at the university, under the leadership of J. J. Thomson, which aroused jealousies from the more conservative members of the Cavendish fraternity. With Thomson's encouragement, he managed to detect radio waves at half a mile and briefly held the world record for the distance over which electromagnetic waves could be detected, though when he presented his results at the British Association meeting in 1896, he discovered he had been outdone by another lecturer, by the name of Guglielmo Marconi.\n\nIn 1898, Thomson recommended Rutherford for a position at McGill University in Montreal, Canada. He was to replace Hugh Longbourne Callendar who held the chair of Macdonald Professor of physics and was coming to Cambridge. Rutherford was accepted, which meant that in 1900 he could marry Mary Georgina Newton (1876–1954) to whom he had become engaged before leaving New Zealand; they married at St Paul's Anglican Church, Papanui in Christchurch, they had one daughter, Eileen Mary (1901–1930), who married Ralph Fowler. In 1901, he gained a DSc from the University of New Zealand. In 1907, Rutherford returned to Britain to take the chair of physics at the Victoria University of Manchester.\n\nRutherford was knighted in 1914. During World War I, he worked on a top secret project to solve the practical problems of submarine detection by sonar. In 1916, he was awarded the Hector Memorial Medal. In 1919, he returned to the Cavendish succeeding J. J. Thomson as the Cavendish professor and Director. Under him, Nobel Prizes were awarded to James Chadwick for discovering the neutron (in 1932), John Cockcroft and Ernest Walton for an experiment which was to be known as \"splitting the atom\" using a particle accelerator, and Edward Appleton for demonstrating the existence of the ionosphere. In 1925, Rutherford pushed calls to the Government of New Zealand to support education and research, which led to the formation of the Department of Scientific and Industrial Research (DSIR) in the following year. Between 1925 and 1930, he served as President of the Royal Society, and later as president of the Academic Assistance Council which helped almost 1,000 university refugees from Germany. He was appointed to the Order of Merit in the 1925 New Year Honours and raised to the peerage as Baron Rutherford of Nelson, of Cambridge in the County of Cambridge in 1931, a title that became extinct upon his unexpected death in 1937. In 1933, Rutherford was one of the two inaugural recipients of the T. K. Sidey Medal, set up by the Royal Society of New Zealand as an award for outstanding scientific research.\nFor some time before his death, Rutherford had a small hernia, which he had neglected to have fixed, and it became strangulated, causing him to be violently ill. Despite an emergency operation in London, he died four days afterwards of what physicians termed \"intestinal paralysis\", at Cambridge. After cremation at Golders Green Crematorium, he was given the high honour of burial in Westminster Abbey, near Isaac Newton and other illustrious British scientists.\n\nAt Cambridge, Rutherford started to work with J. J. Thomson on the conductive effects of X-rays on gases, work which led to the discovery of the electron which Thomson presented to the world in 1897. Hearing of Becquerel's experience with uranium, Rutherford started to explore its radioactivity, discovering two types that differed from X-rays in their penetrating power. Continuing his research in Canada, he coined the terms alpha ray and beta ray in 1899 to describe the two distinct types of radiation. He then discovered that thorium gave off a gas which produced an emanation which was itself radioactive and would coat other substances. He found that a sample of this radioactive material of any size invariably took the same amount of time for half the sample to decay – its \"half-life\" (11½ minutes in this case).\n\nFrom 1900 to 1903, he was joined at McGill by the young chemist Frederick Soddy (Nobel Prize in Chemistry, 1921) for whom he set the problem of identifying the thorium emanations. Once he had eliminated all the normal chemical reactions, Soddy suggested that it must be one of the inert gases, which they named thoron (later found to be an isotope of radon). They also found another type of thorium they called Thorium X, and kept on finding traces of helium. They also worked with samples of \"Uranium X\" from William Crookes and radium from Marie Curie.\n\nIn 1903, they published their \"Law of Radioactive Change,\" to account for all their experiments. Until then, atoms were assumed to be the indestructible basis of all matter and although Curie had suggested that radioactivity was an atomic phenomenon, the idea of the atoms of radioactive substances breaking up was a radically new idea. Rutherford and Soddy demonstrated that radioactivity involved the spontaneous disintegration of atoms into other, as yet, unidentified matter. The Nobel Prize in Chemistry 1908 was awarded to Ernest Rutherford \"for his investigations into the disintegration of the elements, and the chemistry of radioactive substances\".\n\nIn 1903, Rutherford considered a type of radiation discovered (but not named) by French chemist Paul Villard in 1900, as an emission from radium, and realised that this observation must represent something different from his own alpha and beta rays, due to its very much greater penetrating power. Rutherford therefore gave this third type of radiation the name of gamma ray. All three of Rutherford's terms are in standard use today – other types of radioactive decay have since been discovered, but Rutherford's three types are among the most common.\n\nIn Manchester, he continued to work with alpha radiation. In conjunction with Hans Geiger, he developed zinc sulfide scintillation screens and ionisation chambers to count alphas. By dividing the total charge they produced by the number counted, Rutherford decided that the charge on the alpha was two. In late 1907, Ernest Rutherford and Thomas Royds allowed alphas to penetrate a very thin window into an evacuated tube. As they sparked the tube into discharge, the spectrum obtained from it changed, as the alphas accumulated in the tube. Eventually, the clear spectrum of helium gas appeared, proving that alphas were at least ionised helium atoms, and probably helium nuclei.\n\nA long-standing myth existed, at least as early as 1948, running at least to 2017, that Rutherford was the first scientist to observe and report an artificial transmutation of a stable element into another element: nitrogen into oxygen. It was thought by many people to be one of Rutherford's greatest accomplishments. The New Zealand government even commemorated a stamp in honor of its belief that that the nitrogen-to-oxygen discovery belonged to Rutherford. Beginning in 2017, many scientific institutions corrected their versions of this history to indicate that the discovery credit for the reaction belongs to Patrick Blackett. Rutherford did detect the ejected proton in 1919 and interpreted it as evidence for disintegration of the nitrogen nucleus (to lighter nuclei). However, in 1925 Blackett showed that the actual product is oxygen and identified the true reaction as N + α → O + p. Rutherford therefore recognized \"that the nucleus may increase rather than diminish in mass as the result of collisions in which the proton is expelled.\"\n\nRutherford performed his most famous work after receiving the Nobel prize in 1908. Along with Hans Geiger and Ernest Marsden in 1909, he carried out the Geiger–Marsden experiment, which demonstrated the nuclear nature of atoms by deflecting alpha particles passing through a thin gold foil. Rutherford was inspired to ask Geiger and Marsden in this experiment to look for alpha particles with very high deflection angles, of a type not expected from any theory of matter at that time. Such deflections, though rare, were found, and proved to be a smooth but high-order function of the deflection angle. It was Rutherford's interpretation of this data that led him to formulate the Rutherford model of the atom in 1911that a very small charged nucleus, containing much of the atom's mass, was orbited by low-mass electrons.\n\nIn 1919–1920, Rutherford found that nitrogen and other light elements ejected a proton, which he called a \"hydrogen atom\", when hit with α (alpha) particles. This result showed Rutherford that hydrogen nuclei were a part of nitrogen nuclei (and by inference, probably other nuclei as well). Such a construction had been suspected for many years on the basis of atomic weights which were whole numbers of that of hydrogen; see Prout's hypothesis. Hydrogen was known to be the lightest element, and its nuclei presumably the lightest nuclei. Now, because of all these considerations, Rutherford decided that a hydrogen nucleus was possibly a fundamental building block of all nuclei, and also possibly a new fundamental particle as well, since nothing was known from the nucleus that was lighter. Thus, confirming and extending the work of Wilhelm Wien who in 1898 discovered the proton in streams of ionized gas, Rutherford postulated the hydrogen nucleus to be a new particle in 1920, which he dubbed the \"proton\".\n\nIn 1921, while working with Niels Bohr (who postulated that electrons moved in specific orbits), Rutherford theorized about the existence of neutrons, (which he had christened in his 1920 Bakerian Lecture), which could somehow compensate for the repelling effect of the positive charges of protons by causing an attractive nuclear force and thus keep the nuclei from flying apart from the repulsion between protons. The only alternative to neutrons was the existence of \"nuclear electrons\" which would counteract some of the proton charges in the nucleus, since by then it was known that nuclei had about twice the mass that could be accounted for if they were simply assembled from hydrogen nuclei (protons). But how these nuclear electrons could be trapped in the nucleus, was a mystery.\n\nRutherford's theory of neutrons was proved in 1932 by his associate James Chadwick, who recognized neutrons immediately when they were produced by other scientists and later himself, in bombarding beryllium with alpha particles. In 1935, Chadwick was awarded the Nobel Prize in Physics for this discovery.\n\nRutherford is considered to have been among the greatest scientists in history. At the opening session of the 1938 Indian Science Congress, which Rutherford had been expected to preside over before his death, astrophysicist James Jeans spoke in his place and deemed him \"one of the greatest scientists of all time,\" saying:\n\nRutherford's research, and work done under him as laboratory director, established the nuclear structure of the atom and the essential nature of radioactive decay as a nuclear process. Patrick Blackett, a research fellow working under Rutherford, using natural alpha particles, demonstrated \"induced\" nuclear transmutation. Rutherford's team later, using protons from an accelerator, demonstrated \"artificially-induced\" nuclear reactions and transmutation. He is known as the father of nuclear physics. Rutherford died too early to see Leó Szilárd's idea of controlled nuclear chain reactions come into being. However, a speech of Rutherford's about his artificially-induced transmutation in lithium, printed in 12 September 1933 London paper \"The Times\", was reported by Szilárd to have been his inspiration for thinking of the possibility of a controlled energy-producing nuclear chain reaction. Szilard had this idea while walking in London, on the same day.\n\nRutherford's speech touched on the 1932 work of his students John Cockcroft and Ernest Walton in \"splitting\" lithium into alpha particles by bombardment with protons from a particle accelerator they had constructed. Rutherford realized that the energy released from the split lithium atoms was enormous, but he also realized that the energy needed for the accelerator, and its essential inefficiency in splitting atoms in this fashion, made the project an impossibility as a practical source of energy (accelerator-induced fission of light elements remains too inefficient to be used in this way, even today). Rutherford's speech in part, read:\n\nBULLET::::- Scientific discoveries\nBULLET::::- The element rutherfordium, Rf, Z=104. (1997)\nBULLET::::- The rutherford (Rd), an obsolete unit of radioactivity equivalent to one megabecquerel.\nBULLET::::- Institutions\nBULLET::::- Rutherford Appleton Laboratory, a scientific research laboratory near Didcot, Oxfordshire.\nBULLET::::- Rutherford College, Auckland, a school in Auckland, New Zealand\nBULLET::::- Rutherford College, Kent, a college at the University of Kent in Canterbury, England\nBULLET::::- Rutherford Institute for Innovation at the University of Cambridge\nBULLET::::- Rutherford Intermediate School, Wanganui, New Zealand\nBULLET::::- Rutherford Hall, a hall of residence at Loughborough University\nBULLET::::- Awards\nBULLET::::- Rutherford Medal, the highest science medal awarded by the Royal Society of New Zealand\nBULLET::::- Rutherford Award at Thomas Carr College for excellence in Victorian Certificate of Education chemistry, Australia.\nBULLET::::- Rutherford Memorial Medal is an award for research in the fields of physics and chemistry by the Royal Society of Canada.\nBULLET::::- Rutherford Medal and Prize is awarded once every two years by the Institute of Physics for \"distinguished research in nuclear physics or nuclear technology\".\nBULLET::::- Rutherford Memorial Lecture is an international lecture tour under the auspices of the Royal Society created under the Rutherford Memorial Scheme in 1952.\n\nBULLET::::- Buildings\nBULLET::::- Rutherford House, a boarding house at Nelson College\nBULLET::::- Rutherford Hotel, Nelson's largest hotel, which incorporates the Rutherford Cafe and Bar\nBULLET::::- The physics and chemistry building at the University of Canterbury, New Zealand\nBULLET::::- Rochester and Rutherford Hall at the University of Canterbury, New Zealand\nBULLET::::- Rutherford House, the primary building of Victoria University of Wellington's Pipitea Campus, originally the headquarters of the New Zealand Electricity Department, in Wellington, New Zealand.\nBULLET::::- Rutherford building at Bedford Modern School.\nBULLET::::- A building of the modern Cavendish Laboratory at the University of Cambridge\nBULLET::::- The Ernest Rutherford Physics Building at McGill University, Montreal\nBULLET::::- The Coupland Building at the University of Manchester, where Rutherford worked, was renamed \"The Rutherford Building\" in 2006.\nBULLET::::- The Rutherford lecture theatre in the Schuster Laboratory at the University of Manchester\nBULLET::::- Major streets\nBULLET::::- Lord Rutherford Road (the location of his birthplace in Brightwater, New Zealand)\nBULLET::::- Rutherford Street, a major thoroughfare in central Nelson, New Zealand\nBULLET::::- Rutherford Close, a residential street in Abingdon, Oxfordshire\nBULLET::::- Rutherford Road in the biotechnology district of Carlsbad, California\nBULLET::::- Rutherford Road, commercial/residential street in Vaughan, Ontario, Canada\nBULLET::::- Other\nBULLET::::- Rutherford Park, a sports ground in Nelson, New Zealand\nBULLET::::- The Rutherford Memorial at the site of his birth in Brightwater, New Zealand\nBULLET::::- His image is on the obverse of the New Zealand one hundred-dollar note (since 1992).\nBULLET::::- The Rutherford Foundation, a charitable trust set up by the Royal Society of New Zealand to support research in science and technology.\nBULLET::::- Rutherford House, at Macleans College, Auckland, New Zealand\nBULLET::::- Rutherford House, at Hillcrest High School, Hamilton, New Zealand\nBULLET::::- Rutherford House, at Rotorua Intermediate School, Rotorua, New Zealand\nBULLET::::- Rutherford House, at Rangiora High School\nBULLET::::- The crater Rutherford on the Moon, and the crater Rutherford on the planet Mars\nBULLET::::- Ernest Rutherford was the subject of a play by Stuart Hoar.\nBULLET::::- On the side of the Mond Laboratory on the site of the original Cavendish Laboratory in Cambridge, there is an engraving in Rutherford's memory in the form of a crocodile, this being the nickname given to him by its commissioner, his colleague Peter Kapitza.\nBULLET::::- Rutherford rocket engine, an engine developed in New Zealand by Rocket Lab and the first to use the electric pump feed cycle.\nBULLET::::- His image is depicted in the stained glass window of the Presbyterian chapel at Lindisfarne College in Hastings, New Zealand. The window, unveiled in 2007, is dedicated to the college's concept of men with supreme content of character, and depicts Rutherford along with Charles Upham, Edmund Hillary, and John Rangihau as iconic examples.\n\nThe Coupland Building at Manchester University, at which Rutherford conducted many of his experiments, has been the subject of a cancer cluster investigation. There has been a statistically high incidence of pancreatic cancer, brain cancer, and motor neuron disease occurring in and around Rutherford's former laboratories and, since 1984, a total of six workers have been stricken with these ailments. In 2009, an independent commission concluded that the very slightly elevated levels of various radiation related to Rutherford's experiments decades earlier are not the likely cause of such cancers and ruled the illnesses a coincidence.\n\nBULLET::::- \"Radio-activity\" (1904), 2nd ed. (1905),\nBULLET::::- \"Radioactive Transformations\" (1906),\nBULLET::::- \"Radioactive Substances and their Radiations\" (1913)\nBULLET::::- \"The Electrical Structure of Matter\" (1926)\nBULLET::::- \"The Artificial Transmutation of the Elements\" (1933)\nBULLET::::- \"The Newer Alchemy\" (1937)\n\nBULLET::::- \"Disintegration of the Radioactive Elements\" \"Harper's Monthly Magazine,\" January 1904, pages 279 to 284.\n\nBULLET::::- \"The Rutherford Journal\"\n\nBULLET::::- Campbell, John. (1999) \"Rutherford: Scientist Supreme\", AAS Publications, Christchurch,\nBULLET::::- Reeves, Richard (2008). \"A Force of Nature: The Frontier Genius of Ernest Rutherford\". New York: W. W. Norton.\nBULLET::::- Rhodes, Richard (1986). \"The Making of the Atomic Bomb\". New York: Simon & Schuster.\nBULLET::::- Wilson, David (1983). \"Rutherford. Simple Genius\", Hodder & Stoughton,\n\nBULLET::::- Biography and web exhibit from the American Institute of Physics\nBULLET::::- Biography from Nobel prize official website\nBULLET::::- Nobel Lecture \"The Chemical Nature of the Alpha Particles from Radioactive Substances\"\nBULLET::::- The Rutherford Museum\nBULLET::::- Rutherford Scientist Supreme\n"}
{"id": "9604", "url": "https://en.wikipedia.org/wiki?curid=9604", "title": "Many-worlds interpretation", "text": "Many-worlds interpretation\n\nThe many-worlds interpretation (MWI) is an interpretation of quantum mechanics that asserts that the universal wavefunction is objectively real, and that there is no wavefunction collapse. This implies that all possible outcomes of quantum measurements are physically realized in some \"world\" or universe. In contrast to some other interpretations, such as the Copenhagen interpretation, the evolution of reality as a whole in MWI is rigidly deterministic. Many-worlds is also referred to as the relative state formulation or the Everett interpretation, after the physicist Hugh Everett who first proposed it in 1957. The formulation was popularized and named \"many-worlds\" by Bryce DeWitt in the 1960s and 1970s.\n\nIn many-worlds, the subjective appearance of wavefunction collapse is explained by the mechanism of quantum decoherence. Decoherence approaches to interpreting quantum theory have been widely explored and developed since the 1970s, and have become quite popular. MWI is currently considered a mainstream interpretation along with the other decoherence interpretations, collapse theories (including the Copenhagen interpretation), and hidden variable theories such as Bohmian mechanics.\n\nThe many-worlds interpretation implies that there is a very large—perhaps infinite—number of universes. It is one of many multiverse hypotheses in physics and philosophy. MWI views time as a many-branched tree, wherein every possible quantum outcome is realised. This is intended to resolve the correlation paradoxes of quantum theory, such as the EPR paradox and Schrödinger's cat, since every possible outcome of a quantum event exists in its own universe.\n\nIn 1952 Erwin Schrödinger gave a lecture in Dublin in which at one point he jocularly warned his audience that what he was about to say might \"seem lunatic\". He went on to assert that what the equation that won him a Nobel prize seems to be describing is several different histories, they are \"not alternatives but all really happen simultaneously\". This is the earliest known reference to the many-worlds.\n\nAlthough several versions of many-worlds have been proposed since Hugh Everett's original work, they all contain one key idea: the equations of physics that model the time evolution of systems \"without\" embedded observers are sufficient for modelling systems which \"do\" contain observers; in particular there is no observation-triggered wave function collapse which the Copenhagen interpretation proposes. Provided the theory is linear with respect to the wavefunction, the exact form of the quantum dynamics modelled, be it the non-relativistic Schrödinger equation, relativistic quantum field theory or some form of quantum gravity or string theory, does not alter the validity of MWI since MWI is a metatheory applicable to all linear quantum theories, and there is no experimental evidence for any non-linearity of the wavefunction in physics. MWI's main conclusion is that the universe (or multiverse in this context) is composed of a quantum superposition of very many, possibly even non-denumerably infinitely many, increasingly divergent, non-communicating parallel universes or quantum worlds.\n\nThe idea of MWI originated in Everett's Princeton Ph.D. thesis \"The Theory of the Universal Wavefunction\", developed under his thesis advisor John Archibald Wheeler, a shorter summary of which was published in 1957 entitled \"Relative State Formulation of Quantum Mechanics\" (Wheeler contributed the title \"relative state\"; Everett originally called his approach the \"Correlation Interpretation\", where \"correlation\" refers to quantum entanglement). The phrase \"many-worlds\" is due to Bryce DeWitt, who was responsible for the wider popularisation of Everett's theory, which had been largely ignored for the first decade after publication. DeWitt's phrase \"many-worlds\" has become so much more popular than Everett's \"Universal Wavefunction\" or Everett–Wheeler's \"Relative State Formulation\" that many forget that this is only a difference of terminology; the content of both of Everett's papers and DeWitt's popular article is the same.\n\nThe many-worlds interpretation shares many similarities with later, other \"post-Everett\" interpretations of quantum mechanics which also use decoherence to explain the process of measurement or wavefunction collapse. MWI treats the other histories or worlds as real since it regards the universal wavefunction as the \"basic physical entity\" or \"the fundamental entity, obeying at all times a deterministic wave equation\". The other decoherent interpretations, such as consistent histories, the Existential Interpretation etc., either regard the extra quantum worlds as metaphorical in some sense, or are agnostic about their reality; it is sometimes hard to distinguish between the different varieties. MWI is distinguished by two qualities: it assumes realism, which it assigns to the wavefunction, and it has the minimal formal structure possible, rejecting any hidden variables, quantum potential, any form of a collapse postulate (i.e., Copenhagenism) or mental postulates (such as the many-minds interpretation makes).\n\nDecoherent interpretations of many-worlds using einselection to explain how a small number of classical pointer states can emerge from the enormous Hilbert space of superpositions have been proposed by Wojciech H. Zurek. \"Under scrutiny of the environment, only pointer states remain unchanged. Other states decohere into mixtures of stable pointer states that can persist, and, in this sense, exist: They are einselected.\" These ideas complement MWI and bring the interpretation in line with our perception of reality.\n\nMany-worlds is often referred to as a theory, rather than just an interpretation, by those who propose that many-worlds can make testable predictions (such as David Deutsch) or is falsifiable (such as Everett) or by those who propose that all the other, non-MW interpretations, are inconsistent, illogical or unscientific in their handling of measurements; Hugh Everett argued that his formulation was a metatheory, since it made statements about other interpretations of quantum theory; that it was the \"only completely coherent approach to explaining both the contents of quantum mechanics and the appearance of the world.\" Deutsch is dismissive that many-worlds is an \"interpretation\", saying that calling it an interpretation \"is like talking about dinosaurs as an 'interpretation' of fossil records.\"\n\nAs with the other interpretations of quantum mechanics, the many-worlds interpretation is motivated by behavior that can be illustrated by the double-slit experiment. When particles of light (or anything else) are passed through the double slit, a calculation assuming wave-like behavior of light can be used to identify where the particles are likely to be observed. Yet when the particles are observed in this experiment, they appear as particles (i.e., at definite places) and not as non-localized waves.\n\nSome versions of the Copenhagen interpretation of quantum mechanics proposed a process of \"collapse\" in which an indeterminate quantum system would probabilistically collapse down onto, or select, just one determinate outcome to \"explain\" this phenomenon of observation. Wavefunction collapse was widely regarded as artificial and \"ad hoc\", so an alternative interpretation in which the behavior of measurement could be understood from more fundamental physical principles was considered desirable.\n\nEverett's Ph.D. work provided such an alternative interpretation. Everett stated that for a composite system – for example a subject (the \"observer\" or measuring apparatus) observing an object (the \"observed\" system, such as a particle) – the statement that either the observer or the observed has a well-defined state is meaningless; in modern parlance, the observer and the observed have become entangled; we can only specify the state of one \"relative\" to the other, i.e., the state of the observer and the observed are correlated \"after\" the observation is made. This led Everett to derive from the unitary, deterministic dynamics alone (i.e., without assuming wavefunction collapse) the notion of a \"relativity of states\".\n\nEverett noticed that the unitary, deterministic dynamics alone decreed that after an observation is made each element of the quantum superposition of the combined subject–object wavefunction contains two \"relative states\": a \"collapsed\" object state and an associated observer who has observed the same collapsed outcome; what the observer sees and the state of the object have become correlated by the act of measurement or observation. The subsequent evolution of each pair of relative subject–object states proceeds with complete indifference as to the presence or absence of the other elements, \"as if\" wavefunction collapse has occurred, which has the consequence that later observations are always consistent with the earlier observations. Thus the \"appearance\" of the object's wavefunction's collapse has emerged from the unitary, deterministic theory itself. (This answered Einstein's early criticism of quantum theory, that the theory should define what is observed, not for the observables to define the theory.) Since the wavefunction merely appears to have collapsed then, Everett reasoned, there was no need to actually assume that it had collapsed. And so, invoking Occam's razor, he removed the postulate of wavefunction collapse from the theory.\n\nAccording to Martin Gardner, the \"other\" worlds of MWI have two different interpretations: real or unreal; he claimed that Stephen Hawking and Steven Weinberg both favour the unreal interpretation. Gardner also claims that the nonreal interpretation is favoured by the majority of physicists, whereas the \"realist\" view is only supported by MWI experts such as Deutsch and Bryce DeWitt. Hawking has said that \"according to Feynman's idea\", all the other histories are as \"equally real\" as our own, and Martin Gardner reports Hawking saying that MWI is \"trivially true\". In a 1983 interview, Hawking also said he regarded the MWI as \"self-evidently correct\" but was dismissive towards questions about the interpretation of quantum mechanics, saying, \"When I hear of Schrödinger's cat, I reach for my gun.\" In the same interview, he also said, \"But, look: All that one does, really, is to calculate conditional probabilities—in other words, the probability of A happening, given B. I think that that's all the many worlds interpretation is. Some people overlay it with a lot of mysticism about the wave function splitting into different parts. But all that you're calculating is conditional probabilities.\" Elsewhere Hawking contrasted his attitude towards the \"reality\" of physical theories with that of his colleague Roger Penrose, saying, \"He's a Platonist and I'm a positivist. He's worried that Schrödinger's cat is in a quantum state, where it is half alive and half dead. He feels that can't correspond to reality. But that doesn't bother me. I don't demand that a theory correspond to reality because I don't know what it is. Reality is not a quality you can test with litmus paper. All I'm concerned with is that the theory should predict the results of measurements. Quantum theory does this very successfully.\" For his own part, Penrose agrees with Hawking that QM applied to the universe implies MW, although he considers the current lack of a successful theory of quantum gravity negates the claimed universality of conventional QM.\n\nKim Joris Boström has proposed a non-relativistic quantum mechanical theory that combines elements of the de Broglie–Bohm mechanics and that of Everett’s many-‘worlds’. In particular, the unreal MW interpretation of Hawking and Weinberg is similar to the Bohmian concept of unreal empty branch ‘worlds’:\n\nAttempts have been made, by many-world advocates and others, over the years to \"derive\" the Born rule, rather than just conventionally \"assume\" it, so as to reproduce all the required statistical behaviour associated with quantum mechanics. There is no consensus on whether this has been successful.\n\nEverett (1957) briefly derived the Born rule by showing that the Born rule was the only possible rule, and that its derivation was as justified as the procedure for defining probability in classical mechanics. Everett stopped doing research in theoretical physics shortly after obtaining his Ph.D., but his work on probability has been extended by a number of people. Andrew Gleason (1957) and James Hartle (1965) independently reproduced Everett's work which was later extended. These results are closely related to Gleason's theorem, a mathematical result according to which the Born probability measure is the only one on Hilbert space that can be constructed purely from the quantum state vector.\n\nBryce DeWitt and his doctoral student R. Neill Graham later provided alternative (and longer) derivations to Everett's derivation of the Born rule. They demonstrated that the norm of the worlds where the usual statistical rules of quantum theory broke down vanished, in the limit where the number of measurements went to infinity.\n\nA decision-theoretic derivation of the Born rule from Everettarian assumptions, was produced by David Deutsch (1999) and refined by Wallace (2002–2009) and Saunders (2004). Some reviews have been positive, although the status of these arguments remains highly controversial; some theoretical physicists have taken them as supporting the case for parallel universes. In the \"New Scientist\" article, reviewing their presentation at a September 2007 conference, Andy Albrecht, a physicist at the University of California at Davis, is quoted as saying \"This work will go down as one of the most important developments in the history of science.\"\n\nThe Born rule and the collapse of the wave function have been obtained in the framework of the relative-state formulation of quantum mechanics by Armando V. D. B. Assis. He has proved that the Born rule and the collapse of the wave function follow from a game-theoretical strategy, namely the Nash equilibrium within a von Neumann zero-sum game between nature and observer.\n\nWojciech H. Zurek (2005) has produced a derivation of the Born rule, where decoherence has replaced Deutsch's informatic assumptions. Lutz Polley (2000) has produced Born rule derivations where the informatic assumptions are replaced by symmetry arguments.\n\nCharles Sebens and Sean M. Carroll, building on work by Lev Vaidman, proposed a similar approach based on self-locating uncertainty. In this approach, decoherence creates multiple identical copies of observers, who can assign credences to being on different branches using the Born rule.\n\nIn Everett's formulation, a measuring apparatus M and an object system S form a composite system, each of which prior to measurement exists in well-defined (but time-dependent) states. Measurement is regarded as causing M and S to interact. After S interacts with M, it is no longer possible to describe either system by an independent state. According to Everett, the only meaningful descriptions of each system are relative states: for example the relative state of S given the state of M or the relative state of M given the state of S. In DeWitt's formulation, the state of S after a sequence of measurements is given by a quantum superposition of states, each one corresponding to an alternative measurement history of S.\nFor example, consider the smallest possible truly quantum system S, as shown in the illustration. This describes for instance, the spin-state of an electron. Considering a specific axis (say the \"z\"-axis) the north pole represents spin \"up\" and the south pole, spin \"down\". The superposition states of the system are described by (the surface of) a sphere called the Bloch sphere. To perform a measurement on S, it is made to interact with another similar system M. After the interaction, the combined system is described by a state that ranges over a six-dimensional space (the reason for the number six is explained in the article on the Bloch sphere). This six-dimensional object can also be regarded as a quantum superposition of two \"alternative histories\" of the original system S, one in which \"up\" was observed and the other in which \"down\" was observed. Each subsequent binary measurement (that is interaction with a system M) causes a similar split in the history tree. Thus after three measurements, the system can be regarded as a quantum superposition of 8 = 2 × 2 × 2 copies of the original system S.\n\nThe accepted terminology is somewhat misleading because it is incorrect to regard the universe as splitting at certain times; at any given instant there is one state in one universe.\n\nIn his 1957 doctoral dissertation, Everett proposed that rather than modeling an isolated quantum system subject to external observation, one could mathematically model an object as well as its observers as purely physical systems within the mathematical framework developed by Paul Dirac, von Neumann and others, discarding altogether the \"ad hoc\" mechanism of wave function collapse.\n\nSince Everett's original work, there have appeared a number of similar formalisms in the literature. One such is the relative state formulation. It makes two assumptions: first, the wavefunction is not simply a description of the object's state, but that it actually is entirely equivalent to the object, a claim it has in common with some other interpretations. Secondly, observation or measurement has no special laws or mechanics, unlike in the Copenhagen interpretation which considers the wavefunction collapse as a special kind of event which occurs as a result of observation. Instead, measurement in the relative state formulation is the consequence of a configuration change in the memory of an observer described by the same basic wave physics as the object being modeled.\n\nThe many-worlds interpretation is DeWitt's popularisation of Everett's work, who had referred to the combined observer–object system as being split by an observation, each split corresponding to the different or multiple possible outcomes of an observation. These splits generate a possible tree as shown in the graphic below. Subsequently, DeWitt introduced the term \"world\" to describe a complete measurement history of an observer, which corresponds roughly to a single branch of that tree. Note that \"splitting\" in this sense is hardly new or even quantum mechanical. The idea of a space of complete alternative histories had already been used in the theory of probability since the mid-1930s for instance to model Brownian motion. \n\nUnder the many-worlds interpretation, the Schrödinger equation, or relativistic analog, holds all the time everywhere. An observation or measurement is modeled by applying the wave equation to the entire system comprising the observer \"and\" the object. One consequence is that every observation can be thought of as causing the combined observer–object's wavefunction to change into a quantum superposition of two or more non-interacting branches, or split into many \"worlds\". Since many observation-like events have happened and are constantly happening, there are an enormous and growing number of simultaneously existing states.\n\nIf a system is composed of two or more subsystems, the system's state will be a superposition of products of the subsystems' states. Each product of subsystem states in the overall superposition evolves over time independently of other products. Once the subsystems interact, their states have become correlated or entangled and it is no longer possible to consider them independent of one another. In Everett's terminology each subsystem state was now \"correlated\" with its \"relative state\", since each subsystem must now be considered relative to the other subsystems with which it has interacted.\n\nMWI removes the observer-dependent role in the quantum measurement process by replacing wavefunction collapse with quantum decoherence. Since the role of the observer lies at the heart of most if not all \"quantum paradoxes,\" this automatically resolves a number of problems; see for example Schrödinger's cat thought experiment, the EPR paradox, von Neumann's \"boundary problem\" and even wave-particle duality. Quantum cosmology also becomes intelligible, since there is no need anymore for an observer outside of the universe.\n\nMWI is a realist, deterministic, arguably local theory, akin to classical physics (including the theory of relativity), at the expense of losing counterfactual definiteness. MWI achieves this by removing wavefunction collapse, which is indeterministic and non-local, from the deterministic and local equations of quantum theory.\n\nMWI (or other, broader multiverse considerations) provides a context for the anthropic principle which may provide an explanation for the fine-tuned universe.\n\nMWI, being a decoherent formulation, is axiomatically more streamlined than the Copenhagen and other collapse interpretations; and thus favoured under certain interpretations of Occam's razor. Of course there are other decoherent interpretations that also possess this advantage with respect to the collapse interpretations.\n\nOne of the salient properties of the many-worlds interpretation is that it does not require an exceptional method of wave function collapse to explain it. \"It seems that there is no experiment distinguishing the MWI from other no-collapse theories such as Bohmian mechanics or other variants of MWI... In most no-collapse interpretations, the evolution of the quantum state of the Universe is the same. Still, one might imagine that there is an experiment distinguishing the MWI from another no-collapse interpretation based on the difference in the correspondence between the formalism and the experience (the results of experiments).\"\n\nHowever, in 1985, David Deutsch published three related thought experiments which could test the theory vs the Copenhagen interpretation. The experiments require macroscopic quantum state preparation and quantum erasure by a hypothetical quantum computer which is currently outside experimental possibility. Since then Lockwood (1989), Vaidman and others have made similar proposals. These proposals also require an advanced technology which is able to place a macroscopic object in a coherent superposition, another task which it may not ever be possible to perform. Many other controversial ideas have been put forward though, such as a recent claim that cosmological observations could test the theory, and another claim by Rainer Plaga (1997), published in \"Foundations of Physics\", that communication might be possible between worlds.\n\nThe \"many-minds\" interpretation is a multi-world interpretation that defines the splitting of reality on the level of the observers' minds. In this, it differs from Everett's many-worlds interpretation, in which there is no special role for the observer's mind.\n\nMany-worlds assumes the full and literal existence of a non-relativistic wave function which precisely dictates the properties all characteristics of the universe; and yet this function is unable to account for the color of gold without relativistic adjustments. No relativistic wave function has been rigorously put forth to address this.\n\nThe many-worlds interpretation is very vague about the ways to determine when splitting happens, and nowadays usually the criterion is that the two branches have decohered. However, present day understanding of decoherence does not allow a completely precise, self-contained way to say when the two branches have decohered/\"do not interact\", and hence many-worlds interpretation remains arbitrary. This objection is saying that it is not clear what is precisely meant by branching, and point to the lack of self-contained criteria specifying branching.\n\nMWI states that there is no special role, or need for precise definition of measurement in MWI, yet Everett uses the word \"measurement\" repeatedly throughout its exposition.\n\nThe splitting of worlds forward in time, but not backwards in time (i.e., merging worlds), is time asymmetric and incompatible with the time symmetric nature of Schrödinger's equation, or CPT invariance in general.\n\nThere is circularity in Everett's measurement theory. Under the assumptions made by Everett, there are no 'good observations' as defined by him, and since his analysis of the observational process depends on the latter, it is void of any meaning. The concept of a 'good observation' is the projection postulate in disguise and Everett's analysis simply derives this postulate by having assumed it, without any discussion.\n\nTalk of probability in Everett presumes the existence of a preferred basis to identify measurement outcomes for the probabilities to range over. But the existence of a preferred basis can only be established by the process of decoherence, which is itself probabilistic or arbitrary.\n\nWe cannot be sure that the universe is a quantum multiverse until we have a theory of everything and, in particular, a successful theory of quantum gravity. If the final theory of everything is non-linear with respect to wavefunctions then many-worlds would be invalid.\n\nConservation of energy is grossly violated if at every instant near-infinite amounts of new matter are generated to create the new universes.\n\nOccam's razor rules against a plethora of unobservable universes – Occam would prefer just one universe; i.e., any non-MWI.\n\nUnphysical universes: If a state is a superposition of two states formula_3 and formula_4, i.e., formula_5, i.e., weighted by coefficients \"a\" and \"b\", then if formula_6, what principle allows a universe with vanishingly small probability \"b\" to be instantiated on an equal footing with the much more probable one with probability \"a\"? This seems to throw away the information in the probability amplitudes.\n\nViolation of the principle of locality, which contradicts special relativity: MWI splitting is instant and total: this may conflict with relativity, since an alien in the Andromeda galaxy can't know I collapse an electron over here before she collapses hers there: the relativity of simultaneity says we can't say which electron collapsed first – so which one splits off another universe first? This leads to a hopeless muddle with everyone splitting differently. Note: EPR is not a get-out here, as the alien's and my electrons need never have been part of the same quantum, i.e., entangled.\n\nThere is a wide range of claims that are considered \"many-worlds\" interpretations. It was often claimed by those who do not believe in MWI that Everett himself was not entirely clear as to what he believed; however, MWI adherents (such as DeWitt, Tegmark, Deutsch and others) believe they fully understand Everett's meaning as implying the literal existence of the other worlds. Additionally, recent biographical sources make it clear that Everett believed in the literal reality of the other quantum worlds. Everett's son reported that Hugh Everett \"never wavered in his belief over his many-worlds theory\". Also Everett was reported to believe \"his many-worlds theory guaranteed him immortality\".\n\nOne of MWI's strongest advocates is David Deutsch. According to Deutsch, the single photon interference pattern observed in the double slit experiment can be explained by interference of photons in multiple universes. Viewed in this way, the single photon interference experiment is indistinguishable from the multiple photon interference experiment. In a more practical vein, in one of the earliest papers on quantum computing, he suggested that parallelism that results from the validity of MWI could lead to \"\"a method by which certain probabilistic tasks can be performed faster by a universal quantum computer than by any classical restriction of it\"\". Deutsch has also proposed that when reversible computers become conscious then MWI will be testable (at least against \"naive\" Copenhagenism) via the reversible observation of spin.\n\nAsher Peres was an outspoken critic of MWI. For example, a section in his 1993 textbook had the title \"Everett's interpretation and other bizarre theories\". Peres not only questioned whether MWI is really an \"interpretation\", but rather, if \"any\" interpretations of quantum mechanics are needed at all. An interpretation can be regarded as a purely formal transformation, which adds nothing to the rules of the quantum mechanics. Peres seems to suggest that positing the existence of an infinite number of non-communicating parallel universes is highly suspect per those who interpret it as a violation of Occam's razor, i.e., that it does not minimize the number of hypothesized entities. However, it is understood that the number of elementary particles are not a gross violation of Occam's razor, one counts the types, not the tokens. Max Tegmark remarks that the alternative to many-worlds is \"many words\", an allusion to the complexity of von Neumann's collapse postulate. On the other hand, the same derogatory qualification \"many words\" is often applied to MWI by its critics who see it as a word game which obfuscates rather than clarifies by confounding the von Neumann branching of possible worlds with the Schrödinger parallelism of many worlds in superposition.\n\nMWI is considered by some to be unfalsifiable and hence unscientific because the multiple parallel universes are non-communicating, in the sense that no information can be passed between them. Others claim MWI is directly testable.\n\nAdvocates of MWI often cite a poll of 72 \"leading cosmologists and other quantum field theorists\" conducted by the American political scientist David Raub in 1995 showing 58% agreement with \"Yes, I think MWI is true\".\n\nHowever, the poll is controversial. For example, Victor J. Stenger remarks that Murray Gell-Mann's published work explicitly rejects the existence of simultaneous parallel universes. Collaborating with James Hartle, Gell-Mann had been, before his death, working toward the development a more \"palatable\" \"post-Everett quantum mechanics\". Stenger thinks it's fair to say that most physicists dismiss the many-world interpretation as too extreme, while noting it \"has merit in finding a place for the observer inside the system being analyzed and doing away with the troublesome notion of wave function collapse\".\n\nMax Tegmark also reports the result of a \"highly unscientific\" poll taken at a 1997 quantum mechanics workshop. According to Tegmark, \"The many worlds interpretation (MWI) scored second, comfortably ahead of the consistent histories and Bohm interpretations.\" Such polls have been taken at other conferences, for example, in response to Sean Carroll's observation, \"As crazy as it sounds, most working physicists buy into the many-worlds theory\" Michael Nielsen counters: \"at a quantum computing conference at Cambridge in 1998, a many-worlder surveyed the audience of approximately 200 people... Many-worlds did just fine, garnering support on a level comparable to, but somewhat below, Copenhagen and decoherence.\" However, Nielsen notes that it seemed most attendees found it to be a waste of time: Asher Peres \"got a huge and sustained round of applause… when he got up at the end of the polling and asked 'And who here believes the laws of physics are decided by a democratic vote?'\"\n\nA 2005 poll of fewer than 40 students and researchers taken after a course on the Interpretation of Quantum Mechanics at the Institute for Quantum Computing University of Waterloo found \"Many Worlds (and decoherence)\" to be the least favored.\n\nA 2011 poll of 33 participants at an Austrian conference found 6 endorsed MWI, 8 \"Information-based/information-theoretical\", and 14 Copenhagen; the authors remark that MWI received a similar percentage of votes as in Tegmark's 1997 poll.\n\nSpeculative physics deals with questions which are also discussed in science fiction.\n\nQuantum suicide, as a thought experiment, was published independently by Hans Moravec in 1987 and Bruno Marchal in 1988 and was independently developed further by Max Tegmark in 1998. It attempts to distinguish between the Copenhagen interpretation of quantum mechanics and the Everett many-worlds interpretation by means of a variation of the Schrödinger's cat thought experiment, from the cat's point of view. Quantum immortality refers to the subjective experience of surviving quantum suicide regardless of the odds.\n\nAnother speculation is that the separate worlds remain weakly coupled (e.g., by gravity) permitting \"communication between parallel universes\". A possible test of this using quantum-optical equipment is described in a 1997 \"Foundations of Physics\" article by Rainer Plaga. It involves an isolated ion in an ion trap, a quantum measurement that would yield two parallel worlds (their difference just being in the detection of a single photon), and the excitation of the ion from only one of these worlds. If the excited ion can be detected from the other parallel universe, then this would constitute direct evidence in support of the many-worlds interpretation and would automatically exclude the orthodox, \"logical\", and \"many-histories\" interpretations. The reason the ion is isolated is to make it not participate immediately in the decoherence which insulates the parallel world branches, therefore allowing it to act as a gateway between the two worlds, and if the measure apparatus could perform the measurements quickly enough before the gateway ion is decoupled then the test would succeed (with electronic computers the necessary time window between the two worlds would be in a time scale of milliseconds or nanoseconds, and if the measurements are taken by humans then a few seconds would still be enough). R. Plaga shows that macroscopic decoherence timescales are a possibility. The proposed test is based on technical equipment described in a 1993 \"Physical Review\" article by Itano et al. and R. Plaga says that this level of technology is enough to realize the proposed inter-world communication experiment. The necessary technology for precision measurements of single ions already exists since the 1970s, and the ion recommended for excitation is Hg. The excitation methodology is described by Itano et al. and the time needed for it is given by the Rabi flopping formula.\n\nSuch a test as described by R. Plaga would mean that energy transfer is possible between parallel worlds. This does not violate the fundamental principles of physics because these require energy conservation only for the whole universe and not for the single parallel branches. Neither the excitation of the single ion (which is a degree of freedom of the proposed system) leads to decoherence, something which is proven by Welcher Weg detectors which can excite atoms without momentum transfer (which causes the loss of coherence).\n\nThe proposed test would allow for low-bandwidth inter-world communication, the limiting factors of bandwidth and time being dependent on the technology of the equipment. Because of the time needed to determine the state of the partially decohered isolated excited ion based on Itano et al.'s methodology, the ion would decohere by the time its state is determined during the experiment, so Plaga's proposal would pass just enough information between the two worlds to confirm their parallel existence and nothing more. The author contemplates that with increased bandwidth, one could even transfer television imagery across the parallel worlds. For example, Itano et al.'s methodology could be improved (by lowering the time needed for state determination of the excited ion) if a more efficient process were found for the detection of fluorescence radiation using 194 nm photons.\n\nA 1991 article by J. Polchinski also supports the view that inter-world communication is a theoretical possibility. Other authors in a 1994 preprint article also contemplated similar ideas.\n\nThe reason inter-world communication seems like a possibility is because decoherence which separates the parallel worlds is never fully complete, therefore weak influences from one parallel world to another can still pass between them, and these should be measurable with advanced technology. Deutsch proposed such an experiment in a 1985 \"International Journal of Theoretical Physics\" article, but the technology it requires involves human-level artificial intelligence.\n\nMany MWI proponents assert that every physically possible event has to be represented in the multiversal stack, and by definition this would include highly unlikely scenarios and timelines.\n\nBryce Seligman DeWitt has stated that \"[Everett, Wheeler and Graham] do not in the end exclude any element of the superposition. All the worlds are there, even those in which everything goes wrong and all the statistical laws break down.\"\n\nBorrowing a phase from T.H. White's \"The Once and Future King\", Murray Gell-Mann describes the implications of his Totalitarian principle, as \"Everything not forbidden is compulsory.\"\n\nMax Tegmark has affirmed in numerous statements that absurd or highly unlikely events are inevitable under the MWI interpretation. To quote Tegmark, \"Things inconsistent with the laws of physics will never happen - everything else will ... it's important to keep track of the statistics, since even if everything conceivable happens somewhere, really freak events happen only exponentially rarely.\"\n\nFrank J. Tipler, although a strong advocate for the many-worlds interpretation, has expressed some skepticism regarding this aspect of the theory. In a 2015 interview he stated \"We simply don't know ... it might be that the modulus over the wavefunction of that possibility [i.e. an extremely absurd yet physically possible event] is zero in which case there is no such world ... There are universes out there which you could imagine ... would not be actualized.\"\n\nDavid Deutsch has proposed that the many-worlds interpretation could be one possible way to resolve the paradoxes that one would expect to arise \"if\" time travel turns out to be permitted by physics. Entering the past would itself be a quantum event causing branching, and therefore the timeline accessed by the time traveller simply would be another timeline of many. In that sense, it would make the Novikov self-consistency principle unnecessary.\n\nBULLET::::- Jeffrey A. Barrett, \"The Quantum Mechanics of Minds and Worlds\", Oxford University Press, Oxford, 1999.\nBULLET::::- Peter Byrne, \"The Many Worlds of Hugh Everett III: Multiple Universes, Mutual Assured Destruction, and the Meltdown of a Nuclear Family\", Oxford University Press, 2010.\nBULLET::::- Jeffrey A. Barrett and Peter Byrne, eds., \"The Everett Interpretation of Quantum Mechanics: Collected Works 1955–1980 with Commentary\", Princeton University Press, 2012.\nBULLET::::- Julian Brown, \"Minds, Machines, and the Multiverse\", Simon & Schuster, 2000,\nBULLET::::- Sean M. Carroll, Charles T. Sebens, \"Many Worlds, the Born Rule, and Self-Locating Uncertainty\",\nBULLET::::- Sean M. Carroll, \"Something deeply hidden\", Penguin Random House, (2019)\nBULLET::::- Paul C.W. Davies, \"Other Worlds\", (1980)\nBULLET::::- James P. Hogan, \"The Proteus Operation\" (science fiction involving the many-worlds interpretation, time travel and World War 2 history), Baen, Reissue edition (August 1, 1996)\nBULLET::::- A study of the painful three-way relationship between Hugh Everett, John A Wheeler and Niels Bohr and how this affected the early development of the many-worlds theory.\nBULLET::::- Asher Peres, \"Quantum Theory: Concepts and Methods\", Kluwer, Dordrecht, 1993.\nBULLET::::- Mark A. Rubin, Locality in the Everett Interpretation of Heisenberg-Picture Quantum Mechanics, \"Foundations of Physics Letters\", 14, (2001), pp. 301–322,\nBULLET::::- David Wallace, Harvey R. Brown, Solving the measurement problem: de Broglie–Bohm loses out to Everett, \"Foundations of Physics\",\nBULLET::::- David Wallace, Worlds in the Everett Interpretation, \"Studies in History and Philosophy of Modern Physics\", 33, (2002), pp. 637–661,\nBULLET::::- John A. Wheeler and Wojciech Hubert Zurek (eds), \"Quantum Theory and Measurement\", Princeton University Press, (1983),\n\nBULLET::::- Everett's Relative-State Formulation of Quantum Mechanics – Jeffrey A. Barrett's article on Everett's formulation of quantum mechanics in the Stanford Encyclopedia of Philosophy.\nBULLET::::- Many-Worlds Interpretation of Quantum Mechanics – Lev Vaidman's article on the many-worlds interpretation of quantum mechanics in the Stanford Encyclopedia of Philosophy.\nBULLET::::- Hugh Everett III Manuscript Archive (UC Irvine) – Jeffrey A. Barrett, Peter Byrne, and James O. Weatherall (eds.).\nBULLET::::- Michael C Price's Everett FAQ – a clear FAQ-style presentation of the theory.\nBULLET::::- The Many-Worlds Interpretation of Quantum Mechanics – a description for the lay reader with links.\nBULLET::::- Many-Worlds is a \"lost cause\" according to R. F. Streater\nBULLET::::- The many worlds of quantum mechanics John Sankey\nBULLET::::- Max Tegmark's web page\nBULLET::::- Henry Stapp's critique of MWI, focusing on the basis problem Canadian J. Phys. 80,1043–1052 (2002).\nBULLET::::- Everett hit count on arxiv.org\nBULLET::::- Many Worlds 50th anniversary conference at Oxford\nBULLET::::- \"Many Worlds at 50\" conference at Perimeter Institute\nBULLET::::- Scientific American report on the Many Worlds 50th anniversary conference at Oxford\nBULLET::::- HowStuffWorks article\nBULLET::::- Physicists Calculate Number of Parallel Universes Physorg.com October 16, 2009.\nBULLET::::- TED-Education video – How many universes are there?.\n"}
{"id": "9611", "url": "https://en.wikipedia.org/wiki?curid=9611", "title": "E-commerce", "text": "E-commerce\n\nE-commerce (electronic commerce) is the activity of electronically buying or selling of products on online services or over the Internet. Electronic commerce draws on technologies such as mobile commerce, electronic funds transfer, supply chain management, Internet marketing, online transaction processing, electronic data interchange (EDI), inventory management systems, and automated data collection systems. E-commerce is in turn driven by the technological advances of the semiconductor industry, and is the largest sector of the electronics industry.\n\nModern electronic commerce typically uses the World Wide Web for at least one part of the transaction's life cycle although it may also use other technologies such as e-mail. Typical e-commerce transactions include the purchase of online books (such as Amazon) and music purchases (music download in the form of digital distribution such as iTunes Store), and to a less extent, customized/personalized online liquor store inventory services. There are three areas of e-commerce: online retailing, electronic markets, and online auctions. E-commerce is supported by electronic business.\n\nE-commerce businesses may also employ some or all of the followings:\nBULLET::::- Online shopping for retail sales direct to consumers via Web sites and mobile apps, and conversational commerce via live chat, chatbots, and voice assistants\nBULLET::::- Providing or participating in online marketplaces, which process third-party business-to-consumer (B2C) or consumer-to-consumer (C2C) sales\nBULLET::::- Business-to-business (B2B) buying and selling;\nBULLET::::- Gathering and using demographic data through web contacts and social media\nBULLET::::- Business-to-business (B2B) electronic data interchange\nBULLET::::- Marketing to prospective and established customers by e-mail or fax (for example, with newsletters)\nBULLET::::- Engaging in pretail for launching new products and services\nBULLET::::- Online financial exchanges for currency exchanges or trading purposes.\n\nA timeline for the development of e-commerce:\nBULLET::::- 1971 or 1972: The ARPANET is used to arrange a cannabis sale between students at the Stanford Artificial Intelligence Laboratory and the Massachusetts Institute of Technology, later described as \"the seminal act of e-commerce\" in John Markoff's book \"What the Dormouse Said\".\nBULLET::::- 1972: Mohamed M. Atalla files a patent for a secure transaction system over telecommunications networks, utilizing encryption techniques to assure telephone link security, a precursor to Internet-based e-commerce.\nBULLET::::- 1976: Atalla Technovation (founded by Mohamed Atalla) and Bunker Ramo Corporation (founded by George Bunker and Simon Ramo) introduce products designed for secure online transaction processing, intended for financial institutions.\nBULLET::::- 1979: Michael Aldrich demonstrates the first online shopping system.\nBULLET::::- 1981: Thomson Holidays UK is the first business-to-business (B2B) online shopping system to be installed.\nBULLET::::- 1982: Minitel was introduced nationwide in France by France Télécom and used for online ordering.\nBULLET::::- 1983: California State Assembly holds first hearing on \"electronic commerce\" in Volcano, California. Testifying are CPUC, MCI Mail, Prodigy, CompuServe, Volcano Telephone, and Pacific Telesis. (Not permitted to testify is Quantum Technology, later to become AOL.)\nBULLET::::- 1984: Gateshead SIS/Tesco is first B2C online shopping system and Mrs Snowball, 72, is the first online home shopper\nBULLET::::- 1984: In April 1984, CompuServe launches the Electronic Mall in the US and Canada. It is the first comprehensive electronic commerce service.\nBULLET::::- 1989: In May 1989, Sequoia Data Corp. Introduced Compumarket, the first internet based system for e-commerce. Sellers and buyers could post items for sale and buyers could search the database and make purchases with a credit card.\nBULLET::::- 1990: Tim Berners-Lee writes the first web browser, WorldWideWeb, using a NeXT computer.\nBULLET::::- 1992: Book Stacks Unlimited in Cleveland opens a commercial sales website (www.books.com) selling books online with credit card processing.\nBULLET::::- 1993: Paget Press releases edition No. 3 of the first app store, The Electronic AppWrapper\nBULLET::::- 1994: Netscape releases the Navigator browser in October under the code name Mozilla. Netscape 1.0 is introduced in late 1994 with SSL encryption that made transactions secure.\nBULLET::::- 1994: Ipswitch IMail Server becomes the first software available online for sale and immediate download via a partnership between Ipswitch, Inc. and OpenMarket.\nBULLET::::- 1994: \"Ten Summoner's Tales\" by Sting becomes the first secure online purchase through NetMarket.\nBULLET::::- 1995: The US National Science Foundation lifts its former strict prohibition of commercial enterprise on the Internet.\nBULLET::::- 1995: Thursday 27 April 1995, the purchase of a book by Paul Stanfield, Product Manager for CompuServe UK, from W H Smith's shop within CompuServe's UK Shopping Centre is the UK's first national online shopping service secure transaction. The shopping service at launch featured W H Smith, Tesco, Virgin Megastores/Our Price, Great Universal Stores (GUS), Interflora, Dixons Retail, Past Times, PC World (retailer) and Innovations.\nBULLET::::- 1995: Amazon.com is launched by Jeff Bezos.\nBULLET::::- 1995: eBay is founded by computer programmer Pierre Omidyar as AuctionWeb. It is the first online auction site supporting person-to-person transactions.\nBULLET::::- 1995: The first commercial-free 24-hour, internet-only radio stations, Radio HK and NetRadio start broadcasting.\nBULLET::::- 1996: The use of Excalibur BBS with replicated \"Storefronts\" was an early implementation of electronic commerce started by a group of SysOps in Australia and replicated to global partner sites.\nBULLET::::- 1998: Electronic postal stamps can be purchased and downloaded for printing from the Web.\nBULLET::::- 1999: Alibaba Group is established in China. Business.com sold for US$7.5 million to eCompanies, which was purchased in 1997 for US$149,000. The peer-to-peer filesharing software Napster launches. ATG Stores launches to sell decorative items for the home online.\nBULLET::::- 1999: Global e-commerce reaches $150 billion\nBULLET::::- 2000: The dot-com bust.\nBULLET::::- 2001: eBay has the largest userbase of any e-commerce site.\nBULLET::::- 2001: Alibaba.com achieved profitability in December 2001.\nBULLET::::- 2002: eBay acquires PayPal for $1.5 billion. Niche retail companies Wayfair and NetShops are founded with the concept of selling products through several targeted domains, rather than a central portal.\nBULLET::::- 2003: Amazon.com posts first yearly profit.\nBULLET::::- 2004: DHgate.com, China's first online B2B transaction platform, is established, forcing other B2B sites to move away from the \"yellow pages\" model.\nBULLET::::- 2007: Business.com acquired by R.H. Donnelley for $345 million.\nBULLET::::- 2014: US e-commerce and Online Retail sales projected to reach $294 billion, an increase of 12 percent over 2013 and 9% of all retail sales. Alibaba Group has the largest Initial public offering ever, worth $25 billion.\nBULLET::::- 2015: Amazon.com accounts for more than half of all e-commerce growth, selling almost 500 Million SKU's in the US.\nBULLET::::- 2017: Retail e-commerce sales across the world reaches $2.304 trillion, which was a 24.8 percent increase than previous year.\nBULLET::::- 2017: Global e-commerce transactions generate , including for business-to-business (B2B) transactions and for business-to-consumer (B2C) sales.\n\nSome common applications related to electronic commerce are:\nIn the United States, certain electronic commerce activities are regulated by the Federal Trade Commission (FTC). These activities include the use of commercial e-mails, online advertising and consumer privacy. The CAN-SPAM Act of 2003 establishes national standards for direct marketing over e-mail. The Federal Trade Commission Act regulates all forms of advertising, including online advertising, and states that advertising must be truthful and non-deceptive. Using its authority under Section 5 of the FTC Act, which prohibits unfair or deceptive practices, the FTC has brought a number of cases to enforce the promises in corporate privacy statements, including promises about the security of consumers' personal information. As a result, any corporate privacy policy related to e-commerce activity may be subject to enforcement by the FTC.\n\nThe Ryan Haight Online Pharmacy Consumer Protection Act of 2008, which came into law in 2008, amends the Controlled Substances Act to address online pharmacies.\n\nConflict of laws in cyberspace is a major hurdle for harmonization of legal framework for e-commerce around the world. In order to give a uniformity to e-commerce law around the world, many countries adopted the UNCITRAL Model Law on Electronic Commerce (1996).<ref name=\"http://www.uncitral.org/uncitral/en/uncitral_texts/electronic_commerce/1996Model.html\"></ref>\n\nInternationally there is the International Consumer Protection and Enforcement Network (ICPEN), which was formed in 1991 from an informal network of government customer fair trade organisations. The purpose was stated as being to find ways of co-operating on tackling consumer problems connected with cross-border transactions in both goods and services, and to help ensure exchanges of information among the participants for mutual benefit and understanding. From this came Econsumer.gov, an ICPEN initiative since April 2001. It is a portal to report complaints about online and related transactions with foreign companies.\n\nThere is also Asia Pacific Economic Cooperation (APEC) was established in 1989 with the vision of achieving stability, security and prosperity for the region through free and open trade and investment. APEC has an Electronic Commerce Steering Group as well as working on common privacy regulations throughout the APEC region.\n\nIn Australia, Trade is covered under Australian Treasury Guidelines for electronic commerce and the Australian Competition and Consumer Commission regulates and offers advice on how to deal with businesses online, and offers specific advice on what happens if things go wrong.\n\nIn the United Kingdom, The Financial Services Authority (FSA) was formerly the regulating authority for most aspects of the EU's Payment Services Directive (PSD), until its replacement in 2013 by the Prudential Regulation Authority and the Financial Conduct Authority. The UK implemented the PSD through the Payment Services Regulations 2009 (PSRs), which came into effect on 1 November 2009. The PSR affects firms providing payment services and their customers. These firms include banks, non-bank credit card issuers and non-bank merchant acquirers, e-money issuers, etc. The PSRs created a new class of regulated firms known as payment institutions (PIs), who are subject to prudential requirements. Article 87 of the PSD requires the European Commission to report on the implementation and impact of the PSD by 1 November 2012.\n\nIn India, the Information Technology Act 2000 governs the basic applicability of e-commerce.\n\nIn China, the Telecommunications Regulations of the People's Republic of China (promulgated on 25 September 2000), stipulated the Ministry of Industry and Information Technology (MIIT) as the government department regulating all telecommunications related activities, including electronic commerce. On the same day, The Administrative Measures on Internet Information Services released, is the first administrative regulation to address profit-generating activities conducted through the Internet, and lay the foundation for future regulations governing e-commerce in China. On 28 August 2004, the eleventh session of the tenth NPC Standing Committee adopted The Electronic Signature Law, which regulates data message, electronic signature authentication and legal liability issues. It is considered the first law in China's e-commerce legislation. It was a milestone in the course of improving China's electronic commerce legislation, and also marks the entering of China's rapid development stage for electronic commerce legislation.\n\nContemporary electronic commerce can be classified into two categories. The first category is business based on types of goods sold (involves everything from ordering \"digital\" content for immediate online consumption, to ordering conventional goods and services, to \"meta\" services to facilitate other types of electronic commerce). The second category is based on the nature of the participant (B2B, B2C, C2B and C2C);\n\nOn the institutional level, big corporations and financial institutions use the internet to exchange financial data to facilitate domestic and international business. Data integrity and security are pressing issues for electronic commerce.\n\nAside from traditional e-commerce, the terms m-Commerce (mobile commerce) as well (around 2013) t-Commerce have also been used.\n\nIn 2010, the United Kingdom had the highest per capita e-commerce spending in the world. As of 2013, the Czech Republic was the European country where e-commerce delivers the biggest contribution to the enterprises´ total revenue. Almost a quarter (24%) of the country's total turnover is generated via the online channel.\n\nAmong emerging economies, China's e-commerce presence continues to expand every year. With 668 million Internet users, China's online shopping sales reached $253 billion in the first half of 2015, accounting for 10% of total Chinese consumer retail sales in that period. The Chinese retailers have been able to help consumers feel more comfortable shopping online. e-commerce transactions between China and other countries increased 32% to 2.3 trillion yuan ($375.8 billion) in 2012 and accounted for 9.6% of China's total international trade. In 2013, Alibaba had an e-commerce market share of 80% in China. In 2014, there were 600 million Internet users in China (twice as many as in the US), making it the world's biggest online market. China is also the largest e-commerce market in the world by value of sales, with an estimated in 2016.\n\nRecent research clearly indicates that electronic commerce, commonly referred to as e-commerce, presently shapes the manner in which people shop for products. The GCC countries have a rapidly growing market and are characterized by a population that becomes wealthier (Yuldashev). As such, retailers have launched Arabic-language websites as a means to target this population. Secondly, there are predictions of increased mobile purchases and an expanding internet audience (Yuldashev). The growth and development of the two aspects make the GCC countries to become larger players in the electronic commerce market with time progress. Specifically, research shows that e-commerce market is expected to grow to over $20 billion by the year 2020 among these GCC countries (Yuldashev). The e-commerce market has also gained much popularity among the western countries, and in particular Europe and the U.S. These countries have been highly characterized with consumer-packaged-goods (CPG) (Geisler, 34). However, trends show that there are future signs of a reverse. Similar to the GCC countries, there has been increased purchase of goods and services in online channels rather than offline channels. Activist investors are trying hard to consolidate and slash their overall cost and the governments in western countries continue to impose more regulation on CPG manufacturers (Geisler, 36). In these senses, CPG investors are being forced to adapt e-commerce as it is effective as a well as a means for them to thrive.\n\nIn 2013, Brazil's e-commerce was growing quickly with retail e-commerce sales expected to grow at a double-digit pace through 2014. By 2016, eMarketer expected retail e-commerce sales in Brazil to reach $17.3 billion. India has an Internet user base of about 460 million as of December 2017. Despite being third largest user base in world, the penetration of Internet is low compared to markets like the United States, United Kingdom or France but is growing at a much faster rate, adding around 6 million new entrants every month. In India, cash on delivery is the most preferred payment method, accumulating 75% of the e-retail activities. The India retail market is expected to rise from 2.5% in 2016 to 5% in 2020.\n\nThe future trends in the GCC countries will be similar with that of the western countries. Despite the forces that push business to adapt e-commerce as a means to sell goods and products, the manner in which customers make purchases is similar in countries from these two regions. For instance, there has been an increased usage of smartphones which comes in conjunction with an increase in the overall internet audience from the regions. Yuldashev writes that consumers are scaling up to more modern technology that allows for mobile marketing.\nHowever, the percentage of smartphone and internet users who make online purchases is expected to vary in the first few years. It will be independent on the willingness of the people to adopt this new trend (The Statistics Portal). For example, UAE has the greatest smartphone penetration of 73.8 percent and has 91.9 percent of its population has access to the internet. On the other hand, smartphone penetration in Europe has been reported to be at 64.7 percent (The Statistics Portal). Regardless, the disparity in percentage between these regions is expected to level out in future because e-commerce technology is expected to grow allowing for more users.\nThe e-commerce business within these two regions will result in a competition. Government bodies at country level will enhance their measures and strategies to ensure sustainability and consumer protection (Krings, et al.). These increased measures will raise the environmental and social standards in the countries, factors that will determine the success of e-commerce market in these countries. For example, an adoption of tough sanctions will make it difficult for companies to enter the e-commerce market while lenient sanctions will allow ease of companies. As such, the future trends between GCC countries and the Western countries will be independent of these sanctions (Krings, et al.). These countries need to make rational conclusions in coming up with effective sanctions.\n\nThe rate of growth of the number of internet users in the Arab countries has been rapid – 13.1% in 2015. A significant portion of the e-commerce market in the Middle East comprises people in the 30–34 year age group. Egypt has the largest number of internet users in the region, followed by Saudi Arabia and Morocco; these constitute 3/4th of the region's share. Yet, internet penetration is low: 35% in Egypt and 65% in Saudi Arabia.\n\nE-commerce has become an important tool for small and large businesses worldwide, not only to sell to customers, but also to engage them.\n\nIn 2012, e-commerce sales topped $1 trillion for the first time in history.\n\nMobile devices are playing an increasing role in the mix of e-commerce, this is also commonly called mobile commerce, or m-commerce. In 2014, one estimate saw purchases made on mobile devices making up 25% of the market by 2017.\n\nFor traditional businesses, one research stated that information technology and cross-border e-commerce is a good opportunity for the rapid development and growth of enterprises. Many companies have invested enormous volume of investment in mobile applications. The DeLone and McLean Model stated that three perspectives contribute to a successful e-business: information system quality, service quality and users' satisfaction. There is no limit of time and space, there are more opportunities to reach out to customers around the world, and to cut down unnecessary intermediate links, thereby reducing the cost price, and can benefit from one on one large customer data analysis, to achieve a high degree of personal customization strategic plan, in order to fully enhance the core competitiveness of the products in company.\n\nModern 3D graphics technologies, such as Facebook 3D Posts, are considered by some social media marketers and advertisers as a preferable way to promote consumer goods than static photos, and some brands like Sony are already paving the way for augmented reality commerce. Wayfair now lets you inspect a 3D version of its furniture in a home setting before buying.\n\nLogistics in e-commerce mainly concerns fulfillment. Online markets and retailers have to find the best possible way to fill orders and deliver products. Small companies usually control their own logistic operation because they do not have the ability to hire an outside company. Most large companies hire a fulfillment service that takes care of a company's logistic needs.\n\nContrary to common misconception, there are significant barriers to entry in e-commerce.\n\nE-commerce markets are growing at noticeable rates. The online market is expected to grow by 56% in 2015–2020. In 2017, retail e-commerce sales worldwide amounted to 2.3 trillion US dollars and e-retail revenues are projected to grow to 4.88 trillion US dollars in 2021. Traditional markets are only expected 2% growth during the same time. Brick and mortar retailers are struggling because of online retailer's ability to offer lower prices and higher efficiency. Many larger retailers are able to maintain a presence offline and online by linking physical and online offerings.\n\nE-commerce allows customers to overcome geographical barriers and allows them to purchase products anytime and from anywhere. Online and traditional markets have different strategies for conducting business. Traditional retailers offer fewer assortment of products because of shelf space where, online retailers often hold no inventory but send customer orders directly to the manufacture. The pricing strategies are also different for traditional and online retailers. Traditional retailers base their prices on store traffic and the cost to keep inventory. Online retailers base prices on the speed of delivery.\n\nThere are two ways for marketers to conduct business through e-commerce: fully online or online along with a brick and mortar store. Online marketers can offer lower prices, greater product selection, and high efficiency rates. Many customers prefer online markets if the products can be delivered quickly at relatively low price. However, online retailers cannot offer the physical experience that traditional retailers can. It can be difficult to judge the quality of a product without the physical experience, which may cause customers to experience product or seller uncertainty. Another issue regarding the online market is concerns about the security of online transactions. Many customers remain loyal to well-known retailers because of this issue.\n\nSecurity is a primary problem for e-commerce in developed and developing countries. E-commerce security is protecting business' websites and costumers from unauthorized access, use, alteration, or destruction. The type of threats include: malicious codes, unwanted programs (ad ware, spyware), phishing, hacking, and cyber vandalism. E-commerce websites use different tools to avert security threats. These tools include firewalls, encryption software, digital certificates, and passwords.\n\nFor a long time, companies had been troubled by the gap between the benefits which supply chain technology has and the solutions to deliver those benefits. However, the emergence of e-commerce has provided a more practical and effective way of delivering the benefits of the new supply chain technologies.\n\nE-commerce has the capability to integrate all inter-company and intra-company functions, meaning that the three flows (physical flow, financial flow and information flow) of the supply chain could be also affected by e-commerce. The affections on physical flows improved the way of product and inventory movement level for companies. For the information flows, e-commerce optimised the capacity of information processing than companies used to have, and for the financial flows, e-commerce allows companies to have more efficient payment and settlement solutions.\n\nIn addition, e-commerce has a more sophisticated level of impact on supply chains: Firstly, the performance gap will be eliminated since companies can identify gaps between different levels of supply chains by electronic means of solutions; Secondly, as a result of e-commerce emergence, new capabilities such implementing ERP systems, like SAP ERP, Xero, or Megaventory, have helped companies to manage operations with customers and suppliers. Yet these new capabilities are still not fully exploited. Thirdly, technology companies would keep investing on new e-commerce software solutions as they are expecting investment return. Fourthly, e-commerce would help to solve many aspects of issues that companies may feel difficult to cope with, such as political barriers or cross-country changes. Finally, e-commerce provides companies a more efficient and effective way to collaborate with each other within the supply chain.\n\nE-commerce helps create new job opportunities due to information related services, software app and digital products. It also causes job losses. The areas with the greatest predicted job-loss are retail, postal, and travel agencies. The development of e-commerce will create jobs that require highly skilled workers to manage large amounts of information, customer demands, and production processes. In contrast, people with poor technical skills cannot enjoy the wages welfare. On the other hand, because e-commerce requires sufficient stocks that could be delivered to customers in time, the warehouse becomes an important element. Warehouse needs more staff to manage, supervise and organize, thus the condition of warehouse environment will be concerned by employees.\n\nE-commerce brings convenience for customers as they do not have to leave home and only need to browse website online, especially for buying the products which are not sold in nearby shops. It could help customers buy wider range of products and save customers’ time. Consumers also gain power through online shopping. They are able to research products and compare prices among retailers. Also, online shopping often provides sales promotion or discounts code, thus it is more price effective for customers. Moreover, e-commerce provides products’ detailed information; even the in-store staff cannot offer such detailed explanation. Customers can also review and track the order history online.\n\nE-commerce technologies cut transaction costs by allowing both manufactures and consumers to skip through the intermediaries. This is achieved through by extending the search area best price deals and by group purchase. The success of e-commerce in urban and regional levels depend on how the local firms and consumers have adopted to e-commerce.\n\nHowever, e-commerce lacks human interaction for customers, especially who prefer face-to-face connection. Customers are also concerned with the security of online transactions and tend to remain loyal to well-known retailers. In recent years, clothing retailers such as Tommy Hilfiger have started adding Virtual Fit platforms to their e-commerce sites to reduce the risk of customers buying the wrong sized clothes, although these vary greatly in their fit for purpose. When the customer regret the purchase of a product, it involves returning goods and refunding process. This process is inconvenient as customers need to pack and post the goods. If the products are expensive, large or fragile, it refers to safety issues.\n\nIn 2018, E-commerce generated 1.3 million tons of container cardboard in North America, an increase from 1.1 million in 2017. Only 35 percent of North American cardboard manufacturing capacity is from recycled content. The recycling rate in Europe is 80 percent and Asia is 93 percent. Amazon, the largest user of boxes, has a strategy to cut back on packing material and has reduced packaging material used by 19 percent by weight since 2016. Amazon is requiring retailers to manufacture their product packaging in a way that doesn't require additional shipping packaging. Amazon also has an 85-person team researching ways to reduce and improve their packaging and shipping materials.\n\nE-commerce has been cited as a major force for the failure of major U.S. retailers in a trend frequently referred to as a \"retail apocalypse.\" The rise of e-commerce outlets like Amazon has made it harder for traditional retailers to attract customers to their stores and forced companies to change their sales strategies. Many companies have turned to sales promotions and increased digital efforts to lure shoppers while shutting down brick-and-mortar locations. The trend has forced some traditional retailers to shutter its brick and mortar operations.\n\nE-commerce has grown in importance as companies have adopted pure-click and brick-and-click channel systems. We can distinguish pure-click and brick-and-click channel system adopted by companies.\nBULLET::::- Pure-click or pure-play companies are those that have launched a website without any previous existence as a firm.\nBULLET::::- Bricks-and-clicks companies are those existing companies that have added an online site for e-commerce.\nBULLET::::- Click-to-brick online retailers that later open physical locations to supplement their online efforts.\n\nE-commerce may take place on retailers' Web sites or mobile apps, or those of e-commerce marketplaces such as on Amazon, or Tmall from AliBaba. Those channels may also be supported by conversational commerce, e.g. live chat or chatbots on Web sites. Conversational commerce may also be standalone such as live chat or chatbots on messaging apps and via voice assistants.\n\nThe contemporary e-commerce trend recommends companies to shift the traditional business model where focus on \"standardized products, homogeneous market and long product life cycle\" to the new business model where focus on \"varied and customized products\". E-commerce requires the company to have the ability to satisfy multiple needs of different customers and provide them with wider range of products.\n\nWith more choices of products, the information of products for customers to select and meet their needs become crucial. In order to address the mass customization principle to the company, the use of recommender system is suggested. This system helps recommend the proper products to the customers and helps customers make the decision during the purchasing process. The recommender system could be operated through the top sellers on the website, the demographics of customers or the consumers' buying behavior. However, there are 3 main ways of recommendations: recommending products to customers directly, providing detailed products' information and showing other buyers' opinions or critiques. It is benefit for consumer experience without physical shopping. In general, recommender system is used to contact customers online and assist finding the right products they want effectively and directly.\n\nBULLET::::- Alternative payments\nBULLET::::- Comparison of free software e-commerce web application frameworks\nBULLET::::- Comparison of shopping cart software\nBULLET::::- Comparison of payment systems\nBULLET::::- Customer intelligence\nBULLET::::- Digital economy\nBULLET::::- E-commerce credit card payment system\nBULLET::::- Electronic bill payment\nBULLET::::- Electronic money\nBULLET::::- Non-store retailing\nBULLET::::- Paid content\nBULLET::::- Payments as a service\nBULLET::::- Types of e-commerce\nBULLET::::- Timeline of e-commerce\nBULLET::::- South Dakota v. Wayfair, Inc.\n\nBULLET::::- .\nBULLET::::- Lowry, Paul Benjamin; Wells, Taylor; Moody, Gregory D.; Humpherys, Sean; and Kettles, Degan (2006). \"Online payment gateways used to facilitate e-commerce transactions and improve risk management,\" Communications of the Association for Information Systems, vol. 17(6), pp. 1–48 (http://aisel.aisnet.org/cais/vol17/iss1/6).\nBULLET::::- 741 pp.\nBULLET::::- 246 pp.\n\n"}
{"id": "9613", "url": "https://en.wikipedia.org/wiki?curid=9613", "title": "Euler's formula", "text": "Euler's formula\n\nEuler's formula, named after Leonhard Euler, is a mathematical formula in complex analysis that establishes the fundamental relationship between the trigonometric functions and the complex exponential function. Euler's formula states that for any real number :\n\nwhere is the base of the natural logarithm, is the imaginary unit, and and are the trigonometric functions cosine and sine respectively, with the argument given in radians. This complex exponential function is sometimes denoted (\"cosine plus i sine\"). The formula is still valid if is a complex number, and so some authors refer to the more general complex version as Euler's formula.\n\nEuler's formula is ubiquitous in mathematics, physics, and engineering. The physicist Richard Feynman called the equation \"our jewel\" and \"the most remarkable formula in mathematics\".\n\nWhen formula_2, Euler's formula evaluates to formula_3, which is known as Euler's identity.\n\nJohann Bernoulli noted that\n\nAnd since\n\nthe above equation tells us something about complex logarithms by relating natural logarithms to imaginary (complex) numbers. Bernoulli, however, did not evaluate the integral.\n\nBernoulli's correspondence with Euler (who also knew the above equation) shows that Bernoulli did not fully understand complex logarithms. Euler also suggested that the complex logarithms can have infinitely many values.\n\nMeanwhile, Roger Cotes in 1714 discovered that\n\nCotes missed the fact that a complex logarithm can have infinitely many values, differing by multiples of , due to the periodicity of the trigonometric functions.\n\nAround 1740 Euler turned his attention to the exponential function instead of logarithms and obtained the formula used today that is named after him. It was published in 1748, obtained by comparing the series expansions of the exponential and trigonometric expressions.\n\nThe view of complex numbers as points in the complex plane was described about 50 years later by Caspar Wessel.\n\nBULLET::::- Interpretation of the formula\n\nThis formula can be interpreted as saying that the function is a unit complex number, i.e., it traces out the unit circle in the complex plane as ranges through the real numbers. Here is the angle that a line connecting the origin with a point on the unit circle makes with the positive real axis, measured counterclockwise and in radians.\n\nThe original proof is based on the Taylor series expansions of the exponential function (where is a complex number) and of and for real numbers (see below). In fact, the same proof shows that Euler's formula is even valid for all \"complex\" numbers .\n\nA point in the complex plane can be represented by a complex number written in cartesian coordinates. Euler's formula provides a means of conversion between cartesian coordinates and polar coordinates. The polar form simplifies the mathematics when used in multiplication or powers of complex numbers. Any complex number , and its complex conjugate, , can be written as\n\nwhere\n\nBULLET::::- Use of the formula to define the logarithm of complex numbers\n\nNow, taking this derived formula, we can use Euler's formula to define the logarithm of a complex number. To do this, we also use the definition of the logarithm (as the inverse operator of exponentiation):\n\nand that\n\nboth valid for any complex numbers and .\n\nTherefore, one can write:\n\nfor any . Taking the logarithm of both sides shows that\n\nand in fact this can be used as the definition for the complex logarithm. The logarithm of a complex number is thus a multi-valued function, because is multi-valued.\n\nFinally, the other exponential law\n\nwhich can be seen to hold for all integers , together with Euler's formula, implies several trigonometric identities, as well as de Moivre's formula.\n\nEuler's formula provides a powerful connection between analysis and trigonometry, and provides an interpretation of the sine and cosine functions as weighted sums of the exponential function:\n\nThe two equations above can be derived by adding or subtracting Euler's formulas:\n\nand solving for either cosine or sine.\n\nThese formulas can even serve as the definition of the trigonometric functions for complex arguments . For example, letting , we have:\n\nComplex exponentials can simplify trigonometry, because they are easier to manipulate than their sinusoidal components. One technique is simply to convert sinusoids into equivalent expressions in terms of exponentials. After the manipulations, the simplified result is still real-valued. For example:\n\nAnother technique is to represent the sinusoids in terms of the real part of a complex expression and perform the manipulations on the complex expression. For example:\n\nThis formula is used for recursive generation of for integer values of and arbitrary (in radians).\n\nSee also Phasor arithmetic.\n\nIn the language of topology, Euler's formula states that the imaginary exponential function is a (surjective) morphism of topological groups from the real line to the unit circle . In fact, this exhibits as a covering space of formula_18. Similarly, Euler's identity says that the kernel of this map is , where . These observations may be combined and summarized in the commutative diagram below:\n\nIn differential equations, the function is often used to simplify solutions, even if the final answer is a real function involving sine and cosine. The reason for this is that the exponential function is the eigenfunction of the operation of differentiation.\n\nIn electrical engineering, signal processing, and similar fields, signals that vary periodically over time are often described as a combination of sinusoidal functions (see Fourier analysis), and these are more conveniently expressed as the sum of exponential functions with imaginary exponents, using Euler's formula. Also, phasor analysis of circuits can include Euler's formula to represent the impedance of a capacitor or an inductor.\n\nIn the four-dimensional space of quaternions, there is a sphere of imaginary units. For any point \"r\" on this sphere, and \"x\" a real number, Euler's formula applies:\nand the element is called a versor in quaternions. The set of all versors forms a 3-sphere in the 4-space.\n\nThe exponential function for real values of may be defined in a few different equivalent ways (see Characterizations of the exponential function). Several of these methods may be directly extended to give definitions of for complex values of simply by substituting in place of and using the complex algebraic operations. In particular we may use either of the three following definitions, which are equivalent. From a more advanced perspective, each of these definitions may be interpreted as giving the unique analytic continuation of to the complex plane.\n\nThe exponential function formula_20 is the unique differentiable function of a complex variable such that \nand \n\nFor complex \n\nUsing the ratio test, it is possible to show that this power series has an infinite radius of convergence and so defines for all complex .\n\nFor complex \n\nHere, n is restricted to positive integers, so there is no question about what the power with exponent n means.\n\nVarious proofs of the formula are possible.\n\nHere is a proof of Euler's formula using power-series expansions, as well as basic facts about the powers of :\n\nUsing now the power-series definition from above, we see that for real values of \n\nIn the last step we have simply recognized the Maclaurin series for and . The rearrangement of terms is justified because each series is absolutely convergent.\n\nAnother proof is based on the fact that all complex numbers can be expressed in polar coordinates. Therefore, for \"some\" and depending on ,\nNo assumptions are being made about and ; they will be determined in the course of the proof. From any of the definitions of the exponential function it can be shown that the derivative of is . Therefore, differentiating both sides gives\nSubstituting for and equating real and imaginary parts in this formula gives and . Thus, is a constant, and is for some constant . The initial values and come from , giving and . This proves the formula\n\nAnother proof is based on differential equations satisfied by exponential and trigonometric functions. See .\n\nBULLET::::- Complex number\nBULLET::::- Euler's identity\nBULLET::::- Integration using Euler's formula\nBULLET::::- List of things named after Leonhard Euler\n\nBULLET::::- Elements of Algebra\n"}
{"id": "9615", "url": "https://en.wikipedia.org/wiki?curid=9615", "title": "Édouard Manet", "text": "Édouard Manet\n\nÉdouard Manet (, , ; 23 January 1832 – 30 April 1883) was a French modernist painter. He was one of the first 19th-century artists to paint modern life, and a pivotal figure in the transition from Realism to Impressionism.\n\nBorn into an upper-class household with strong political connections, Manet rejected the future originally envisioned for him, and became engrossed in the world of painting. His early masterworks, \"The Luncheon on the Grass (Le déjeuner sur l'herbe)\" and \"Olympia\", both 1863, caused great controversy and served as rallying points for the young painters who would create Impressionism. Today, these are considered watershed paintings that mark the start of modern art. The last 20 years of Manet's life saw him form bonds with other great artists of the time, and develop his own style that would be heralded as innovative and serve as a major influence for future painters.\n\nÉdouard Manet was born in Paris on 23 January 1832, in the ancestral hôtel particulier (mansion) on the rue des Petits Augustins (now rue Bonaparte) to an affluent and well-connected family. His mother, Eugénie-Desirée Fournier, was the daughter of a diplomat and goddaughter of the Swedish crown prince Charles Bernadotte, from whom the Swedish monarchs are descended. His father, Auguste Manet, was a French judge who expected Édouard to pursue a career in law. His uncle, Edmond Fournier, encouraged him to pursue painting and took young Manet to the Louvre. In 1841 he enrolled at secondary school, the Collège Rollin. In 1845, at the advice of his uncle, Manet enrolled in a special course of drawing where he met Antonin Proust, future Minister of Fine Arts and subsequent lifelong friend.\n\nAt his father's suggestion, in 1848 he sailed on a training vessel to Rio de Janeiro. After he twice failed the examination to join the Navy, his father relented to his wishes to pursue an art education. From 1850 to 1856, Manet studied under the academic painter Thomas Couture. In his spare time, Manet copied the Old Masters in the Louvre.\n\nFrom 1853 to 1856, Manet visited Germany, Italy, and the Netherlands, during which time he was influenced by the Dutch painter Frans Hals, and the Spanish artists Diego Velázquez and Francisco José de Goya.\n\nIn 1856, Manet opened a studio. His style in this period was characterized by loose brush strokes, simplification of details and the suppression of transitional tones. Adopting the current style of realism initiated by Gustave Courbet, he painted \"The Absinthe Drinker\" (1858–59) and other contemporary subjects such as beggars, singers, Gypsies, people in cafés, and bullfights. After his early career, he rarely painted religious, mythological, or historical subjects; examples include his \"\", now in the Art Institute of Chicago, and \"Christ with Angels\", in the Metropolitan Museum of Art, New York. Manet had two canvases accepted at the Salon in 1861. A portrait of his mother and father, who at the time was paralysed and robbed of speech by a stroke, was ill-received by critics. The other, \"The Spanish Singer\", was admired by Theophile Gautier, and placed in a more conspicuous location as a result of its popularity with Salon-goers. Manet's work, which appeared \"slightly slapdash\" when compared with the meticulous style of so many other Salon paintings, intrigued some young artists. \"The Spanish Singer\", painted in a \"strange new fashion [-] caused many painters' eyes to open and their jaws to drop.\"\n\n\"Music in the Tuileries\" is an early example of Manet's painterly style. Inspired by Hals and Velázquez, it is a harbinger of his lifelong interest in the subject of leisure.\n\nWhile the picture was regarded as unfinished by some, the suggested atmosphere imparts a sense of what the Tuileries gardens were like at the time; one may imagine the music and conversation.\n\nHere, Manet has depicted his friends, artists, authors, and musicians who take part, and he has included a self-portrait among the subjects.\n\nA major early work is \"The Luncheon on the Grass (Le Déjeuner sur l'herbe)\", originally \"Le Bain\". The Paris Salon rejected it for exhibition in 1863, but Manet agreed to exhibit it at the Salon des Refusés (Salon of the Rejected) which was a parallel exhibition to the official Salon, as an alternative exhibition in the Palais des Champs-Elysée. The \"Salon des Refusés\" was initiated by Emperor Napoleon III as a solution to a problematic situation which came about as the Selection Committee of the Salon that year rejected 2,783 paintings of the ca. 5000. Each painter could decide whether to take the opportunity to exhibit at the \"Salon des Refusés\", less than 500 of the rejected painters chose to do so.\n\nManet employed model Victorine Meurent, his wife Suzanne, future brother-in-law Ferdinand Leenhoff, and one of his brothers to pose. Meurent also posed for several more of Manet's important paintings including \"Olympia\"; and by the mid-1870s she became an accomplished painter in her own right.\n\nThe painting's juxtaposition of fully dressed men and a nude woman was controversial, as was its abbreviated, sketch-like handling, an innovation that distinguished Manet from Courbet. At the same time, Manet's composition reveals his study of the old masters, as the disposition of the main figures is derived from Marcantonio Raimondi's engraving of the \"Judgement of Paris\" (c. 1515) based on a drawing by Raphael.\n\nTwo additional works cited by scholars as important precedents for \"Le déjeuner sur l'herbe\" are \"Pastoral Concert\" (c. 1510, The Louvre) and \"The Tempest\" (Gallerie dell'Accademia, Venice), both of which are attributed variously to Italian Renaissance masters Giorgione or Titian. \"The Tempest\" is an enigmatic painting featuring a fully dressed man and a nude woman in a rural setting. The man is standing to the left and gazing to the side, apparently at the woman, who is seated and breastfeeding a baby; the relationship between the two figures is unclear. In \"Pastoral Concert\", two clothed men and a nude woman are seated on the grass, engaged in music making, while a second nude woman stands beside them.\n\nAs he had in \"Luncheon on the Grass\", Manet again paraphrased a respected work by a Renaissance artist in the painting \"Olympia\" (1863), a nude portrayed in a style reminiscent of early studio photographs, but whose pose was based on Titian's \"Venus of Urbino\" (1538). The painting is also reminiscent of Francisco Goya's painting \"The Nude Maja\" (1800).\n\nManet embarked on the canvas after being challenged to give the Salon a nude painting to display. His uniquely frank depiction of a self-assured prostitute was accepted by the Paris Salon in 1865, where it created a scandal. According to Antonin Proust, \"only the precautions taken by the administration prevented the painting being punctured and torn\" by offended viewers. The painting was controversial partly because the nude is wearing some small items of clothing such as an orchid in her hair, a bracelet, a ribbon around her neck, and mule slippers, all of which accentuated her nakedness, sexuality, and comfortable courtesan lifestyle. The orchid, upswept hair, black cat, and bouquet of flowers were all recognized symbols of sexuality at the time. This modern Venus' body is thin, counter to prevailing standards; the painting's lack of idealism rankled viewers. The painting's flatness, inspired by Japanese wood block art, serves to make the nude more human and less voluptuous. A fully dressed black servant is featured, exploiting the then-current theory that black people were hyper-sexed. That she is wearing the clothing of a servant to a courtesan here furthers the sexual tension of the piece.\n\nOlympia's body as well as her gaze is unabashedly confrontational. She defiantly looks out as her servant offers flowers from one of her male suitors. Although her hand rests on her leg, hiding her pubic area, the reference to traditional female virtue is ironic; a notion of modesty is notoriously absent in this work. A contemporary critic denounced Olympia's \"shamelessly flexed\" left hand, which seemed to him a mockery of the relaxed, shielding hand of Titian's Venus. Likewise, the alert black cat at the foot of the bed strikes a sexually rebellious note in contrast to that of the sleeping dog in Titian's portrayal of the goddess in his \"Venus of Urbino\".\n\n\"Olympia\" was the subject of caricatures in the popular press, but was championed by the French avant-garde community, and the painting's significance was appreciated by artists such as Gustave Courbet, Paul Cézanne, Claude Monet, and later Paul Gauguin.\n\nAs with \"Luncheon on the Grass\", the painting raised the issue of prostitution within contemporary France and the roles of women within society.\n\nAfter the death of his father in 1862, Manet married Suzanne Leenhoff in 1863. Leenhoff was a Dutch-born piano teacher two years Manet's senior with whom he had been romantically involved for approximately ten years. Leenhoff initially had been employed by Manet's father, Auguste, to teach Manet and his younger brother piano. She also may have been Auguste's mistress. In 1852, Leenhoff gave birth, out of wedlock, to a son, Leon Koella Leenhoff. Manet painted his wife in \"The Reading\", among other paintings.\n\nEleven-year-old Leon Leenhoff, whose father may have been either of the Manets, posed often for Manet. Most famously, he is the subject of the \"Boy Carrying a Sword\" of 1861 (Metropolitan Museum of Art, New York). He also appears as the boy carrying a tray in the background of \"The Balcony\".\n\nHe became friends with the Impressionists Edgar Degas, Claude Monet, Pierre-Auguste Renoir, Alfred Sisley, Paul Cézanne and Camille Pissarro through another painter, Berthe Morisot, who was a member of the group and drew him into their activities. The supposed grand-niece of the painter Jean-Honoré Fragonard, Morisot had her first painting accepted in the Salon de Paris in 1864, and she continued to show in the salon for the next ten years.\n\nManet became the friend and colleague of Berthe Morisot in 1868. She is credited with convincing Manet to attempt plein air painting, which she had been practicing since she was introduced to it by another friend of hers, Camille Corot. They had a reciprocating relationship and Manet incorporated some of her techniques into his paintings. In 1874, she became his sister-in-law when she married his brother, Eugène.\n\nOne of Manet's frequent models, at the beginning of the 1880s, was the \"semimondaine\" Méry Laurent, who frequently sat for various other Impressionists.\n\nUnlike the core Impressionist group, Manet maintained that modern artists should seek to exhibit at the Paris Salon rather than abandon it in favor of independent exhibitions. Nevertheless, when Manet was excluded from the International Exhibition of 1867, he set up his own exhibition. His mother worried that he would waste all his inheritance on this project, which was enormously expensive. While the exhibition earned poor reviews from the major critics, it also provided his first contacts with several future Impressionist painters, including Degas.\n\nAlthough his own work influenced and anticipated the Impressionist style, he resisted involvement in Impressionist exhibitions, partly because he did not wish to be seen as the representative of a group identity, and partly because he preferred to exhibit at the Salon. Eva Gonzalès, a daughter of the novelist Emmanuel Gonzalès, was his only formal student.\n\nHe was influenced by the Impressionists, especially Monet and Morisot. Their influence is seen in Manet's use of lighter colors: after the early 1870s he made less use of dark backgrounds but retained his distinctive use of black, uncharacteristic of Impressionist painting. He painted many outdoor (plein air) pieces, but always returned to what he considered the serious work of the studio.\n\nManet enjoyed a close friendship with composer Emmanuel Chabrier, painting two portraits of him; the musician owned 14 of Manet's paintings and dedicated his \"Impromptu\" to Manet's wife.\n\nThroughout his life, although resisted by art critics, Manet could number as his champions Émile Zola, who supported him publicly in the press, Stéphane Mallarmé, and Charles Baudelaire, who challenged him to depict life as it was. Manet, in turn, drew or painted each of them.\n\nManet's paintings of café scenes are observations of social life in 19th-century Paris. People are depicted drinking beer, listening to music, flirting, reading, or waiting. Many of these paintings were based on sketches executed on the spot. He often visited the Brasserie Reichshoffen on boulevard de Rochechourt, upon which he based \"At the Cafe\" in 1878. Several people are at the bar, and one woman confronts the viewer while others wait to be served. Such depictions represent the painted journal of a flâneur. These are painted in a style which is loose, referencing Hals and Velázquez, yet they capture the mood and feeling of Parisian night life. They are painted snapshots of bohemianism, urban working people, as well as some of the bourgeoisie.\n\nIn \"Corner of a Cafe Concert\", a man smokes while behind him a waitress serves drinks. In \"The Beer Drinkers\" a woman enjoys her beer in the company of a friend. In \"The Cafe Concert\", shown at right, a sophisticated gentleman sits at a bar while a waitress stands resolutely in the background, sipping her drink. In \"The Waitress\", a serving woman pauses for a moment behind a seated customer smoking a pipe, while a ballet dancer, with arms extended as she is about to turn, is on stage in the background.\n\nManet also sat at the restaurant on the Avenue de Clichy called Pere Lathuille's, which had a garden in addition to the dining area. One of the paintings he produced here was \"Chez le père Lathuille\" (At Pere Lathuille's), in which a man displays an unrequited interest in a woman dining near him.\n\nIn \"Le Bon Bock\" (1873), a large, cheerful, bearded man sits with a pipe in one hand and a glass of beer in the other, looking straight at the viewer.\n\nManet painted the upper class enjoying more formal social activities. In \"Masked Ball at the Opera\", Manet shows a lively crowd of people enjoying a party. Men stand with top hats and long black suits while talking to women with masks and costumes. He included portraits of his friends in this picture.\n\nHis 1868 painting \"The Luncheon\" was posed in the dining room of the Manet house.\n\nManet depicted other popular activities in his work. In \"The Races at Longchamp\", an unusual perspective is employed to underscore the furious energy of racehorses as they rush toward the viewer. In \"Skating\", Manet shows a well dressed woman in the foreground, while others skate behind her. Always there is the sense of active urban life continuing behind the subject, extending outside the frame of the canvas.\n\nIn \"View of the International Exhibition\", soldiers relax, seated and standing, prosperous couples are talking. There is a gardener, a boy with a dog, a woman on horseback—in short, a sample of the classes and ages of the people of Paris.\n\nManet's response to modern life included works devoted to war, in subjects that may be seen as updated interpretations of the genre of \"history painting\". The first such work was the \"Battle of the Kearsarge and Alabama\" (1864), a sea skirmish known as the \"Battle of Cherbourg\" from the American Civil War which took place off the French coast, and may have been witnessed by the artist.\n\nOf interest next was the French intervention in Mexico; from 1867 to 1869 Manet painted three versions of the \"Execution of Emperor Maximilian\", an event which raised concerns regarding French foreign and domestic policy. The several versions of the \"Execution\" are among Manet's largest paintings, which suggests that the theme was one which the painter regarded as most important. Its subject is the execution by Mexican firing squad of a Habsburg emperor who had been installed by Napoleon III. Neither the paintings nor a lithograph of the subject were permitted to be shown in France. As an indictment of formalized slaughter the paintings look back to Goya, and anticipate Picasso's \"Guernica\".\n\nIn January 1871, Manet traveled to Oloron-Sainte-Marie in the Pyrenees. In his absence his friends added his name to the \"Fédération des artistes\" (see: Courbet) of the Paris Commune. Manet stayed away from Paris, perhaps, until after the \"semaine sanglante\": in a letter to Berthe Morisot at Cherbourg (10 June 1871) he writes, \"\"We came back to Paris a few days ago...\"\" (the semaine sanglante ended on 28 May).\n\nThe prints and drawings collection of the Museum of Fine Arts (Budapest) has a watercolour/gouache by Manet, \"The Barricade\", depicting a summary execution of Communards by Versailles troops based on a lithograph of the execution of Maximilian. A similar piece, \"The Barricade\" (oil on plywood), is held by a private collector.\n\nOn 18 March 1871, he wrote to his (confederate) friend Félix Bracquemond in Paris about his visit to Bordeaux, the provisory seat of the French National Assembly of the Third French Republic where Émile Zola introduced him to the sites: \"I never imagined that France could be represented by such doddering old fools, not excepting that little twit Thiers...\" If this could be interpreted as support of the Commune, a following letter to Bracquemond (21 March 1871) expressed his idea more clearly: \"Only party hacks and the ambitious, the Henrys of this world following on the heels of the Milliéres, the grotesque imitators of the Commune of 1793...\" He knew the communard Lucien Henry to have been a former painter's model and Millière, an insurance agent. \"What an encouragement all these bloodthirsty caperings are for the arts! But there is at least one consolation in our misfortunes: that we're not politicians and have no desire to be elected as deputies\".\n\nThe public figure Manet admired most was the republican Léon Gambetta. In the heat of the \"seize mai\" coup in 1877, Manet opened up his atelier to a republican electoral meeting chaired by Gambetta's friend Eugène Spuller.\n\nManet depicted many scenes of the streets of Paris in his works. \"The Rue Mosnier Decked with Flags\" depicts red, white, and blue pennants covering buildings on either side of the street; another painting of the same title features a one-legged man walking with crutches. Again depicting the same street, but this time in a different context, is \"Rue Mosnier with Pavers\", in which men repair the roadway while people and horses move past.\n\"The Railway\", widely known as \"The Gare Saint-Lazare\", was painted in 1873. The setting is the urban landscape of Paris in the late 19th century. Using his favorite model in his last painting of her, a fellow painter, Victorine Meurent, also the model for \"Olympia\" and the \"Luncheon on the Grass\", sits before an iron fence holding a sleeping puppy and an open book in her lap. Next to her is a little girl with her back to the painter, watching a train pass beneath them.\n\nInstead of choosing the traditional natural view as background for an outdoor scene, Manet opts for the iron grating which \"boldly stretches across the canvas\" The only evidence of the train is its white cloud of steam. In the distance, modern apartment buildings are seen. This arrangement compresses the foreground into a narrow focus. The traditional convention of deep space is ignored.\n\nHistorian Isabelle Dervaux has described the reception this painting received when it was first exhibited at the official Paris Salon of 1874: \"Visitors and critics found its subject baffling, its composition incoherent, and its execution sketchy. Caricaturists ridiculed Manet's picture, in which only a few recognized the symbol of modernity that it has become today\". The painting is currently in the National Gallery of Art in Washington, D.C.\n\nManet painted several boating subjects in 1874. \"Boating\", now in the Metropolitan Museum of Art, exemplifies in its conciseness the lessons Manet learned from Japanese prints, and the abrupt cropping by the frame of the boat and sail adds to the immediacy of the image.\n\nIn 1875, a book-length French edition of Edgar Allan Poe's \"The Raven\" included lithographs by Manet and translation by Mallarmé.\n\nIn 1881, with pressure from his friend Antonin Proust, the French government awarded Manet the Légion d'honneur.\nIn his mid-forties Manet's health deteriorated, and he developed severe pain and partial paralysis in his legs. In 1879 he began receiving hydrotherapy treatments at a spa near Meudon intended to improve what he believed was a circulatory problem, but in reality he was suffering from locomotor ataxia, a known side-effect of syphilis. In 1880, he painted a portrait there of the opera singer Émilie Ambre as Carmen. Ambre and her lover Gaston de Beauplan had an estate in Meudon and had organized the first exhibition of Manet's \"The Execution of Emperor Maximilian\" in New York in December 1879.\n\nIn his last years Manet painted many small-scale still lifes of fruits and vegetables, such as \"Bunch of Asparagus\" and \"The Lemon\" (both 1880). He completed his last major work, \"A Bar at the Folies-Bergère (Un Bar aux Folies-Bergère)\", in 1882 and it hung in the Salon that year. Afterwards he limited himself to small formats. His last paintings were of flowers in glass vases.\n\nIn April 1883, his left foot was amputated because of gangrene, due to complications from syphilis and rheumatism. He died eleven days later on 30 April in Paris. He is buried in the Passy Cemetery in the city.\n\nManet's public career lasted from 1861, the year of his first participation in the Salon, until his death in 1883. His known extant works, as catalogued in 1975 by Denis Rouart and Daniel Wildenstein, comprise 430 oil paintings, 89 pastels, and more than 400 works on paper.\n\nAlthough harshly condemned by critics who decried its lack of conventional finish, Manet's work had admirers from the beginning. One was Émile Zola, who wrote in 1867: \"We are not accustomed to seeing such simple and direct translations of reality. Then, as I said, there is such a surprisingly elegant awkwardness ... it is a truly charming experience to contemplate this luminous and serious painting which interprets nature with a gentle brutality.\"\n\nThe roughly painted style and photographic lighting in Manet's paintings was seen as specifically modern, and as a challenge to the Renaissance works he copied or used as source material. He rejected the technique he had learned in the studio of Thomas Couture – in which a painting was constructed using successive layers of paint on a dark-toned ground – in favor of a direct, \"alla prima\" method using opaque paint on a light ground. Novel at the time, this method made possible the completion of a painting in a single sitting. It was adopted by the Impressionists, and became the prevalent method of painting in oils for generations that followed. Manet's work is considered \"early modern\", partially because of the opaque flatness of his surfaces, the frequent sketchlike passages, and the black outlining of figures, all of which draw attention to the surface of the picture plane and the material quality of paint.\n\nThe art historian Beatrice Farwell says Manet \"has been universally regarded as the Father of Modernism. With Courbet he was among the first to take serious risks with the public whose favour he sought, the first to make \"alla prima\" painting the standard technique for oil painting and one of the first to take liberties with Renaissance perspective and to offer ‘pure painting’ as a source of aesthetic pleasure. He was a pioneer, again with Courbet, in the rejection of humanistic and historical subject-matter, and shared with Degas the establishment of modern urban life as acceptable material for high art.\"\n\nThe late Manet painting, \"Le Printemps\" (1881), sold to the J. Paul Getty Museum for $65.1 million, setting a new auction record for Manet, exceeding its pre-sale estimate of $25–35 million at Christie's on 5 November 2014. The previous auction record was held by \"Self-Portrait With Palette\" which sold for $33.2 million at Sotheby's on 22 June 2010.\n\nBULLET::::- List of paintings by Édouard Manet\nBULLET::::- Realism\nBULLET::::- Hispagnolisme\nBULLET::::- Portraiture\nBULLET::::- History of painting\nBULLET::::- Western painting\n\nBULLET::::- \"Manet\" by Gilles Neret (2003; Taschen),\nBULLET::::- \"Manet\" by John Richardson (1992; Phaidon Colour Library),\nBULLET::::- Ross King. \"The Judgment of Paris: The Revolutionary Decade that Gave the World Impressionism\". New York: Waller & Company, 2006 .\nBULLET::::- Henry R. Lew \"Imaging the World\", Hybrid Publishers, 2018, Chapter 10 Edouard Manet.\n\nBULLET::::- \"Édouard Manet: Rebel in a Frock Coat\" by Beth Archer Brombert (1996), and (1997 paperback)\nBULLET::::- \"Manet\" by Françoise Cachin (1990 in French; English translation 1991),\nBULLET::::- \"The Drawings of Édouard Manet\" by Alain de Leiris (1969),\nBULLET::::- \"The Painting of Modern Life: Paris in the Art of Manet and His Followers\" by T.J. Clark (1985), (2000 paperback edition)\nBULLET::::- \"Manet: Painter of Modern Life\" by Françoise Cachin (1995), 'New Horizons' series,\n\nBULLET::::- Union List of Artist Names, Getty Vocabularies. ULAN Full Record Display for Édouard Manet, Getty Research Institute\nBULLET::::- \"Impressionism: a centenary exhibition\", an exhibition catalog from The Metropolitan Museum of Art (p. 110–130)\nBULLET::::- Manet, a video documentary about his work\nBULLET::::- Documenting the Gilded Age: New York City Exhibitions at the Turn of the 20th Century\nBULLET::::- \"The Private Collection of Edgar Degas\", material on Manet's relationship with Degas, Metropolitan Museum of Art\n"}
{"id": "9616", "url": "https://en.wikipedia.org/wiki?curid=9616", "title": "Evolutionarily stable strategy", "text": "Evolutionarily stable strategy\n\nAn evolutionarily stable strategy (ESS) is a strategy (or set of strategies) which, if adopted by a population in a given environment, is impenetrable, meaning that it cannot be invaded by any alternative strategy (or strategies) that are initially rare. It is relevant in game theory, behavioural ecology, and evolutionary psychology. An ESS is an equilibrium refinement of the Nash equilibrium. It is a Nash equilibrium that is \"evolutionarily\" stable: once it is fixed in a population, natural selection alone is sufficient to prevent alternative (mutant) strategies from invading successfully. The theory is not intended to deal with the possibility of gross external changes to the environment that bring new selective forces to bear.\n\nFirst published as a specific term in the 1972 book by John Maynard Smith, the ESS is widely used in behavioural ecology and economics, and has been used in anthropology, evolutionary psychology, philosophy, and political science.\n\nEvolutionarily stable strategies were defined and introduced by John Maynard Smith and George R. Price in a 1973 \"Nature\" paper. Such was the time taken in peer-reviewing the paper for \"Nature\" that this was preceded by a 1972 essay by Maynard Smith in a book of essays titled \"On Evolution\". The 1972 essay is sometimes cited instead of the 1973 paper, but university libraries are much more likely to have copies of \"Nature\". Papers in \"Nature\" are usually short; in 1974, Maynard Smith published a longer paper in the \"Journal of Theoretical Biology\". Maynard Smith explains further in his 1982 book \"Evolution and the Theory of Games\". Sometimes these are cited instead. In fact, the ESS has become so central to game theory that often no citation is given, as the reader is assumed to be familiar with it.\n\nMaynard Smith mathematically formalised a verbal argument made by Price, which he read while peer-reviewing Price's paper. When Maynard Smith realized that the somewhat disorganised Price was not ready to revise his article for publication, he offered to add Price as co-author.\n\nThe concept was derived from R. H. MacArthur and W. D. Hamilton's work on sex ratios, derived from Fisher's principle, especially Hamilton's (1967) concept of an unbeatable strategy. Maynard Smith was jointly awarded the 1999 Crafoord Prize for his development of the concept of evolutionarily stable strategies and the application of game theory to the evolution of behaviour.\n\nUses of ESS:\nBULLET::::- The ESS was a major element used to analyze evolution in Richard Dawkins' bestselling 1976 book \"The Selfish Gene\".\nBULLET::::- The ESS was first used in the social sciences by Robert Axelrod in his 1984 book \"The Evolution of Cooperation\". Since then, it has been widely used in the social sciences, including anthropology, economics, philosophy, and political science.\nBULLET::::- In the social sciences, the primary interest is not in an ESS as the end of biological evolution, but as an end point in cultural evolution or individual learning.\nBULLET::::- In evolutionary psychology, ESS is used primarily as a model for human biological evolution.\n\nThe Nash equilibrium is the traditional solution concept in game theory. It depends on the cognitive abilities of the players. It is assumed that players are aware of the structure of the game and consciously try to predict the moves of their opponents and to maximize their own payoffs. In addition, it is presumed that all the players know this (see common knowledge). These assumptions are then used to explain why players choose Nash equilibrium strategies.\n\nEvolutionarily stable strategies are motivated entirely differently. Here, it is presumed that the players' strategies are biologically encoded and heritable. Individuals have no control over their strategy and need not be aware of the game. They reproduce and are subject to the forces of natural selection, with the payoffs of the game representing reproductive success (biological fitness). It is imagined that alternative strategies of the game occasionally occur, via a process like mutation. To be an ESS, a strategy must be resistant to these alternatives.\n\nGiven the radically different motivating assumptions, it may come as a surprise that ESSes and Nash equilibria often coincide. In fact, every ESS corresponds to a Nash equilibrium, but some Nash equilibria are not ESSes.\n\nAn ESS is a refined or modified form of a Nash equilibrium. (See the next section for examples which contrast the two.) In a Nash equilibrium, if all players adopt their respective parts, no player can \"benefit\" by switching to any alternative strategy. In a two player game, it is a strategy pair. Let E(\"S\",\"T\") represent the payoff for playing strategy \"S\" against strategy \"T\". The strategy pair (\"S\", \"S\") is a Nash equilibrium in a two player game if and only if this is true for both players and for all \"T\"≠\"S\":\n\nIn this definition, strategy \"T\" can be a neutral alternative to \"S\" (scoring equally well, but not better). \n\nA Nash equilibrium is presumed to be stable even if \"T\" scores equally, on the assumption that there is no long-term incentive for players to adopt \"T\" instead of \"S\". This fact represents the point of departure of the ESS.\n\nMaynard Smith and Price specify two conditions for a strategy \"S\" to be an ESS. For all \"T\"≠\"S\", either\nBULLET::::1. E(\"S\",\"S\") > E(\"T\",\"S\"), or\nBULLET::::2. E(\"S\",\"S\") = E(\"T\",\"S\") and E(\"S\",\"T\") > E(\"T\",\"T\")\n\nThe first condition is sometimes called a \"strict\" Nash equilibrium. The second is sometimes called \"Maynard Smith's second condition\". The second condition means that although strategy \"T\" is neutral with respect to the payoff against strategy \"S\", the population of players who continue to play strategy \"S\" has an advantage when playing against \"T\".\n\nThere is also an alternative, stronger definition of ESS, due to Thomas. This places a different emphasis on the role of the Nash equilibrium concept in the ESS concept. Following the terminology given in the first definition above, this definition requires that for all \"T\"≠\"S\"\n\nBULLET::::1. E(\"S\",\"S\") ≥ E(\"T\",\"S\"), and\nBULLET::::2. E(\"S\",\"T\") > E(\"T\",\"T\")\n\nIn this formulation, the first condition specifies that the strategy is a Nash equilibrium, and the second specifies that Maynard Smith's second condition is met. Note that the two definitions are not precisely equivalent: for example, each pure strategy in the coordination game below is an ESS by the first definition but not the second.\n\nIn words, this definition looks like this: The payoff of the first player when both players play strategy S is higher than (or equal to) the payoff of the first player when he changes to another strategy T and the second player keeps his strategy S \"and\" the payoff of the first player when only his opponent changes his strategy to T is higher than his payoff in case that both of players change their strategies to T.\n\nThis formulation more clearly highlights the role of the Nash equilibrium condition in the ESS. It also allows for a natural definition of related concepts such as a weak ESS or an evolutionarily stable set.\n\nIn most simple games, the ESSes and Nash equilibria coincide perfectly. For instance, in the prisoner's dilemma there is only one Nash equilibrium, and its strategy (\"Defect\") is also an ESS.\n\nSome games may have Nash equilibria that are not ESSes. For example, in harm thy neighbor (whose payoff matrix is shown here) both (\"A\", \"A\") and (\"B\", \"B\") are Nash equilibria, since players cannot do better by switching away from either. However, only \"B\" is an ESS (and a strong Nash). \"A\" is not an ESS, so \"B\" can neutrally invade a population of \"A\" strategists and predominate, because \"B\" scores higher against \"B\" than \"A\" does against \"B\". This dynamic is captured by Maynard Smith's second condition, since E(\"A\", \"A\") = E(\"B\", \"A\"), but it is not the case that E(\"A\",\"B\") > E(\"B\",\"B\").\n\nNash equilibria with equally scoring alternatives can be ESSes. For example, in the game \"Harm everyone\", \"C\" is an ESS because it satisfies Maynard Smith's second condition. \"D\" strategists may temporarily invade a population of \"C\" strategists by scoring equally well against \"C\", but they pay a price when they begin to play against each other; \"C\" scores better against \"D\" than does \"D\". So here although E(\"C\", \"C\") = E(\"D\", \"C\"), it is also the case that E(\"C\",\"D\") > E(\"D\",\"D\"). As a result, \"C\" is an ESS.\n\nEven if a game has pure strategy Nash equilibria, it might be that none of those pure strategies are ESS. Consider the Game of chicken. There are two pure strategy Nash equilibria in this game (\"Swerve\", \"Stay\") and (\"Stay\", \"Swerve\"). However, in the absence of an uncorrelated asymmetry, neither \"Swerve\" nor \"Stay\" are ESSes. There is a third Nash equilibrium, a mixed strategy which is an ESS for this game (see Hawk-dove game and Best response for explanation).\n\nThis last example points to an important difference between Nash equilibria and ESS. Nash equilibria are defined on \"strategy sets\" (a specification of a strategy for each player), while ESS are defined in terms of strategies themselves. The equilibria defined by ESS must always be symmetric, and thus have fewer equilibrium points.\n\nIn population biology, the two concepts of an \"evolutionarily stable strategy\" (ESS) and an \"evolutionarily stable state\" are closely linked but describe different situations.\n\nIn an evolutionarily stable \"strategy,\" if all the members of a population adopt it, no mutant strategy can invade. Once virtually all members of the population use this strategy, there is no 'rational' alternative. ESS is part of classical game theory.\n\nIn an evolutionarily stable \"state,\" a population's genetic composition is restored by selection after a disturbance, if the disturbance is not too large. An evolutionarily stable state is a dynamic property of a population that returns to using a strategy, or mix of strategies, if it is perturbed from that initial state. It is part of population genetics, dynamical system, or evolutionary game theory. This is now called convergent stability.\n\nB. Thomas (1984) applies the term ESS to an individual strategy which may be mixed, and evolutionarily stable population state to a population mixture of pure strategies which may be formally equivalent to the mixed ESS.\n\nWhether a population is evolutionarily stable does not relate to its genetic diversity: it can be genetically monomorphic or polymorphic.\n\nIn the classic definition of an ESS, no mutant strategy can invade. In finite populations, any mutant could in principle invade, albeit at low probability, implying that no ESS can exist. In an infinite population, an ESS can instead be defined as a strategy which, should it become invaded by a new mutant strategy with probability p, would be able to counterinvade from a single starting individual with probability >p, as illustrated by the evolution of bet-hedging.\n\nA common model of altruism and social cooperation is the Prisoner's dilemma. Here a group of players would collectively be better off if they could play \"Cooperate\", but since \"Defect\" fares better each individual player has an incentive to play \"Defect\". One solution to this problem is to introduce the possibility of retaliation by having individuals play the game repeatedly against the same player. In the so-called \"iterated\" Prisoner's dilemma, the same two individuals play the prisoner's dilemma over and over. While the Prisoner's dilemma has only two strategies (\"Cooperate\" and \"Defect\"), the iterated Prisoner's dilemma has a huge number of possible strategies. Since an individual can have different contingency plan for each history and the game may be repeated an indefinite number of times, there may in fact be an infinite number of such contingency plans.\n\nThree simple contingency plans which have received substantial attention are \"Always Defect\", \"Always Cooperate\", and \"Tit for Tat\". The first two strategies do the same thing regardless of the other player's actions, while the latter responds on the next round by doing what was done to it on the previous round—it responds to \"Cooperate\" with \"Cooperate\" and \"Defect\" with \"Defect\".\n\nIf the entire population plays \"Tit-for-Tat\" and a mutant arises who plays \"Always Defect\", \"Tit-for-Tat\" will outperform \"Always Defect\". If the population of the mutant becomes too large — the percentage of the mutant will be kept small. \"Tit for Tat\" is therefore an ESS, \"with respect to only these two strategies\". On the other hand, an island of \"Always Defect\" players will be stable against the invasion of a few \"Tit-for-Tat\" players, but not against a large number of them. If we introduce \"Always Cooperate\", a population of \"Tit-for-Tat\" is no longer an ESS. Since a population of \"Tit-for-Tat\" players always cooperates, the strategy \"Always Cooperate\" behaves identically in this population. As a result, a mutant who plays \"Always Cooperate\" will not be eliminated. However, even though a population of \"Always Cooperate\" and \"Tit-for-Tat\" can coexist, if there is a small percentage of the population that is \"Always Defect\", the selective pressure is against \"Always Cooperate\", and in favour of \"Tit-for-Tat\". This is due to the lower payoffs of cooperating than those of defecting in case the opponent defects.\n\nThis demonstrates the difficulties in applying the formal definition of an ESS to games with large strategy spaces, and has motivated some to consider alternatives.\n\nThe fields of sociobiology and evolutionary psychology attempt to explain animal and human behavior and social structures, largely in terms of evolutionarily stable strategies. Sociopathy (chronic antisocial or criminal behavior) may be a result of a combination of two such strategies.\n\nEvolutionarily stable strategies were originally considered for biological evolution, but they can apply to other contexts. In fact, there are stable states for a large class of adaptive dynamics. As a result, they can be used to explain human behaviours that lack any genetic influences.\n\nBULLET::::- Antipredator adaptation\nBULLET::::- Behavioral ecology\nBULLET::::- Evolutionary psychology\nBULLET::::- Fitness landscape\nBULLET::::- Hawk-Dove game\nBULLET::::- Koinophilia\nBULLET::::- Sociobiology\nBULLET::::- War of attrition (game)\n\nBULLET::::- Classic reference textbook.\nBULLET::::- . An 88-page mathematical introduction; see Section 3.8. Free online at many universities.\nBULLET::::- Parker, G. A. (1984) Evolutionary stable strategies. In \"Behavioural Ecology: an Evolutionary Approach\" (2nd ed) Krebs, J. R. & Davies N.B., eds. pp 30–61. Blackwell, Oxford.\nBULLET::::- . A comprehensive reference from a computational perspective; see Section 7.7. Downloadable free online.\nBULLET::::- Maynard Smith, John. (1982) \"Evolution and the Theory of Games\". . Classic reference.\n\nBULLET::::- Evolutionarily Stable Strategies at Animal Behavior: An Online Textbook by Michael D. Breed.\nBULLET::::- Game Theory and Evolutionarily Stable Strategies, Kenneth N. Prestwich's site at College of the Holy Cross.\nBULLET::::- Evolutionarily stable strategies knol\n"}
{"id": "9617", "url": "https://en.wikipedia.org/wiki?curid=9617", "title": "Element", "text": "Element\n\nElement may refer to:\nBULLET::::- Chemical element, a pure substance of one type of atom\nBULLET::::- DNA element, a functional region of DNA, including genes and cis-regulatory elements\nBULLET::::- \"Elements\" (journal), a scientific publication for mineralogy, geochemistry, and petrology\nBULLET::::- Orbital elements, parameters required to uniquely identify a specific orbit of one body around another\nBULLET::::- Weather, sometimes referred to as \"the elements\"\n\nBULLET::::- Element (UML), part of the Unified Modeling Language superstructure\nBULLET::::- Adobe Photoshop Elements, a bitmap graphics program\nBULLET::::- Adobe Premiere Elements, a video editing computer program\nBULLET::::- Data element, a unit of data\nBULLET::::- Markup element, a part of a document defined by a markup language\nBULLET::::- HTML element, a standard part of an HTML document\n\nBULLET::::- Element (category theory)\nBULLET::::- Element (mathematics), one of the constituents of a set\nBULLET::::- Differential element, an infinitesimally small change of a quantity in an integral\nBULLET::::- Euclid's \"Elements\", a mathematical treatise on geometry and number theory\n\nBULLET::::- Electrical element, an abstract part of a circuit\nBULLET::::- Heating element, a device that generates heat by electrical resistance\nBULLET::::- Structural element, in construction and engineering\n\nBULLET::::- Classical elements, ancient beliefs about the fundamental types of matter, expressed in their Aristotelian forms as fire, earth, air, and water\nBULLET::::- Five elements (Japanese philosophy), the basis of the universe according to Japanese philosophy\nBULLET::::- Mahābhūta, the four \"great elements\" in Buddhism, five in Hinduism\nBULLET::::- Tattva, an elemental basis of the universe according to Hindu Samkhya philosophy\nBULLET::::- Wuxing (Chinese philosophy), sometimes translated as \"five elements\", the basis of the universe according to Chinese Taoin\n\nBULLET::::- Element Electronics, an American electronics company\nBULLET::::- Elements, Hong Kong, a shopping mall in Hong Kong\nBULLET::::- Element (Tampa), a skyscraper in Tampa, Florida, US\nBULLET::::- Elements (restaurant), a New American restaurant located in Princeton, New Jersey\nBULLET::::- Honda Element, a car\nBULLET::::- Elements (\"League of Legends\"), a team competing in the European \"League of Legends\" Championship Series\nBULLET::::- Element by Westin, a brand of Starwood Hotels and Resorts Worldwide\nBULLET::::- Element Skateboards, a skateboard manufacturer\n\nBULLET::::- \"Elements\" (Atheist album), 1993\nBULLET::::- \"Elements\" (B.o.B album), 2016\nBULLET::::- \"Elements\" (Ludovico Einaudi album), 2015\nBULLET::::- \"Elements\" (Roger Glover album), 1978\nBULLET::::- \"Elements\" (Steve Howe album), 2003\nBULLET::::- \"Elements, Pt. 1\", a 2003 album by Stratovarius\nBULLET::::- \"Elements, Pt. 2\", a 2003 album by Stratovarius\nBULLET::::- \"The Elements\" (Joe Henderson album), 1973\nBULLET::::- \"The Elements\" (Second Person album), 2007\nBULLET::::- \"The Elements\" (TobyMac album), 2018\nBULLET::::- \"Elements – The Best of Mike Oldfield\", single CD edition\nBULLET::::- \"Elements – The Best of Mike Oldfield\" (video), video/DVD edition\nBULLET::::- \"Elements Box\" by Mike Oldfield, four CD edition\n\nBULLET::::- \"The Elements\" (song), by Tom Lehrer\nBULLET::::- \"Element\" (song), a 2017 song by Kendrick Lamar\nBULLET::::- \"Element\", a song by Deerhunter from their 2019 album \"Why Hasn't Everything Already Disappeared?\"\n\nBULLET::::- Element (production team), a Norwegian production and songwriting team\nBULLET::::- Elements (band), 1980s–90s American jazz ensemble\nBULLET::::- \"Element Magazine\", a men's lifestyle and fashion magazine published online from Singapore since 2013\nBULLET::::- \"Elements\" trilogy, three films written and directed by Deepa Mehta addressing social reform in India\nBULLET::::- \"Elements\" (miniseries), an Cartoon Network miniseries, aired as part of the ninth season of \"Adventure Time\"\nBULLET::::- Element (criminal law), a basic set of common law principles regarding criminal liability\nBULLET::::- Element (sports), a distinct component of a performance\n\nBULLET::::- All pages beginning with \"\" and \"\"\nBULLET::::- All pages with titles containing \"\" and \"\"\nBULLET::::- Elemental (disambiguation)\nBULLET::::- Elementary (disambiguation)\nBULLET::::- Five elements (disambiguation)\nBULLET::::- Fifth Element (disambiguation)\n"}
{"id": "9619", "url": "https://en.wikipedia.org/wiki?curid=9619", "title": "Extremophile", "text": "Extremophile\n\nAn extremophile (from Latin ' meaning \"extreme\" and Greek ' () meaning \"love\") is an organism with optimal growth in environmental conditions considered extreme in comparison to the environmental conditions that are comfortable to humans. In contrast, organisms that live in more moderate environmental conditions, according to an anthropocentric view, may be termed mesophiles or neutrophiles.\n\nIn the 1980s and 1990s, biologists found that microbial life has great flexibility for surviving in extreme environments—niches that are acidic or extraordinarily hot, for example—that would be completely inhospitable to complex organisms. Some scientists even concluded that life may have begun on Earth in hydrothermal vents far under the ocean's surface.\n\nAccording to astrophysicist Steinn Sigurdsson, \"There are viable bacterial spores that have been found that are 40 million years old on Earth—and we know they're very hardened to radiation.\" Some bacteria were found living in the cold and dark in a lake buried a half-mile deep under the ice in Antarctica, and in the Marianas Trench, the deepest place in Earth's oceans. Some microorganisms have been found thriving inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States. According to one of the researchers, \"You can find microbes everywhere—they're extremely adaptable to conditions, and survive wherever they are.\" A key to extremophile adaptation is their amino acid composition, affecting their protein folding ability under particular conditions.\n\nTom Gheysens from Ghent University in Belgium and some of his colleagues have presented research findings that show spores from a species of Bacillus bacteria survived and were still viable after being heated to temperatures of .\n\n! colspan=\"4\" The limits of known life on Earth. \n! Factor !! Environment / source !! Limits !! Examples\n\nThere are many classes of extremophiles that range all around the globe; each corresponding to the way its environmental niche differs from mesophilic conditions. These classifications are not exclusive. Many extremophiles fall under multiple categories and are classified as polyextremophiles. For example, organisms living inside hot rocks deep under Earth's surface are thermophilic and barophilic such as \"Thermococcus barophilus\". A polyextremophile living at the summit of a mountain in the Atacama Desert might be a radioresistant xerophile, a psychrophile, and an oligotroph. Polyextremophiles are well known for their ability to tolerate both high and low pH levels.\n\nBULLET::::- Acidophile:An organism with optimal growth at pH levels of 3.0 or below\n\nBULLET::::- Alkaliphile:An organism with optimal growth at pH levels of 9.0 or above\n\nBULLET::::- Anaerobe:An organism with optimal growth in the absence of molecular oxygen. Two sub-types exist: facultative anaerobe and obligate anaerobe. A \"facultative\" anaerobe can tolerate anoxic and oxic conditions; however, an \"obligate\" anaerobe dies in the presence of even trace levels of molecular oxygen.\n\nBULLET::::- Cryptoendolith:An organism that lives in microscopic spaces within rocks, such as pores between aggregate grains. These may also be called endolith, a term that also includes organisms populating fissures, aquifers, and faults filled with groundwater in the deep subsurface.\n\nBULLET::::- Halophile:An organism with optimal growth at a concentration of dissolved salts of 50 g/L (= 5% m/v) or above.\n\nBULLET::::- Hyperpiezophile:An organism with optimal growth at hydrostatic pressures above 50 MPa (= 493 atm = 7,252 psi).\n\nBULLET::::- Hyperthermophile:An organism with optimal growth at temperatures above .\n\nBULLET::::- Hypolith:An organism that lives underneath rocks in cold deserts.\n\nBULLET::::- Metallotolerant:Capable of tolerating high levels of dissolved heavy metals in solution, such as copper, cadmium, arsenic, and zinc. Examples include \"Ferroplasma sp.,\" \"Cupriavidus metallidurans\" and GFAJ-1.\n\nBULLET::::- Oligotroph:An organism with optimal growth in nutritionally limited environments.\n\nBULLET::::- Osmophile:An organism with optimal growth in environments with a high sugar concentration.\n\nBULLET::::- Piezophile:An organism with optimal growth in hydrostatic pressures above 10 MPa (= 99 atm = 1,450 psi). Also referred to as barophile.\n\nBULLET::::- Polyextremophile:A polyextremophile (faux Ancient Latin/Greek for 'affection for many extremes') is an organism that qualifies as an extremophile under more than one category.\n\nBULLET::::- Psychrophile/Cryophile:An organism with optimal growth at temperatures of or lower.\n\nBULLET::::- Radioresistant:Organisms resistant to high levels of ionizing radiation, most commonly ultraviolet radiation. This category also includes organisms capable of resisting nuclear radiation.\n\nBULLET::::- Thermophile:An organism with optimal growth at temperatures above .\n\nBULLET::::- Xerophile:An organism with optimal growth at water activity below 0.8.\n\nAstrobiology is the study of the origin, evolution, distribution, and future of life in the universe: extraterrestrial life and life on Earth. Astrobiology makes use of physics, chemistry, astronomy, solar physics, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. Astrobiologists are particularly interested in studying extremophiles, as their habitats may be analogous to conditions on other planets. For example, analogous deserts of Antarctica are exposed to harmful UV radiation, low temperature, high salt concentration and low mineral concentration. These conditions are similar to those on Mars. Therefore, finding viable microbes in the subsurface of Antarctica suggests that there may be microbes surviving in endolithic communities and living under the Martian surface. Research indicates it is unlikely that Martian microbes exist on the surface or at shallow depths, but may be found at subsurface depths of around 100 meters.\n\nRecent research carried out on extremophiles in Japan involved a variety of bacteria including \"Escherichia coli\" and \"Paracoccus denitrificans\" being subject to conditions of extreme gravity. The bacteria were cultivated while being rotated in an ultracentrifuge at high speeds corresponding to 403,627 g (i.e. 403,627 times the gravity experienced on Earth). \"Paracoccus denitrificans\" was one of the bacteria which displayed not only survival but also robust cellular growth under these conditions of hyperacceleration which are usually found only in cosmic environments, such as on very massive stars or in the shock waves of supernovas. Analysis showed that the small size of prokaryotic cells is essential for successful growth under hypergravity. The research has implications on the feasibility of panspermia.\n\nOn 26 April 2012, scientists reported that lichen survived and showed remarkable results on the adaptation capacity of photosynthetic activity within the simulation time of 34 days under Martian conditions in the Mars Simulation Laboratory (MSL) maintained by the German Aerospace Center (DLR).\n\nOn 29 April 2013, scientists at Rensselaer Polytechnic Institute, funded by NASA, reported that, during spaceflight on the International Space Station, microbes seem to adapt to the space environment in ways \"not observed on Earth\" and in ways that \"can lead to increases in growth and virulence\".\n\nOn 19 May 2014, scientists announced that numerous microbes, like \"Tersicoccus phoenicis\", may be resistant to methods usually used in spacecraft assembly clean rooms. It's not currently known if such resistant microbes could have withstood space travel and are present on the \"Curiosity\" rover now on the planet Mars.\n\nOn 20 August 2014, scientists confirmed the existence of microorganisms living half a mile below the ice of Antarctica.\n\nOn September 2015, scientists from CNR-National Research Council of Italy reported that \"S.soflataricus\" was able to survive under Martian radiation at a wavelength that was considered extremely lethal to most bacteria. This discovery is significant because it indicates that not only bacterial spores, but also growing cells can be remarkably resistant to strong UV radiation.\n\nOn June 2016, scientists from Brigham Young University conclusively reported that endospores of \"Bacillus subtilis\" were able to survive high speed impacts up to 299±28 m/s, extreme shock, and extreme deceleration. They pointed out that this feature might allow endospores to survive and to be transferred between planets by traveling within meteorites or by experiencing atmosphere disruption. Moreover, they suggested that the landing of spacecraft may also result in interplanetary spore transfer, given that spores can survive high-velocity impact while ejected from the spacecraft onto the planet surface. This is the first study which reported that bacteria can survive in such high-velocity impact. However, the lethal impact speed is unknown, and further experiments should be done by introducing higher-velocity impact to bacterial endospores.\n\nNew sub-types of -philes are identified frequently and the sub-category list for extremophiles is always growing. For example, microbial life lives in the liquid asphalt lake, Pitch Lake. Research indicates that extremophiles inhabit the asphalt lake in populations ranging between 10 to 10 cells/gram. Likewise, until recently boron tolerance was unknown but a strong borophile was discovered in bacteria. With the recent isolation of \"Bacillus boroniphilus\", borophiles came into discussion. Studying these borophiles may help illuminate the mechanisms of both boron toxicity and boron deficiency.\n\nIn July 2019, a scientific study of Kidd Mine in Canada discovered sulfur-breathing organisms which live 7900 feet below the surface, and which breathe sulfur in order to survive. These organisms are also remarkable due to eating rocks such as pyrite as their regular food source.\n\nThe thermoalkaliphilic catalase, which initiates the breakdown of hydrogen peroxide into oxygen and water, was isolated from an organism, \"Thermus brockianus\", found in Yellowstone National Park by Idaho National Laboratory researchers. The catalase operates over a temperature range from 30 °C to over 94 °C and a pH range from 6–10. This catalase is extremely stable compared to other catalases at high temperatures and pH. In a comparative study, the \"T. brockianus\" catalase exhibited a half life of 15 days at 80 °C and pH 10 while a catalase derived from \"Aspergillus niger\" had a half life of 15 seconds under the same conditions. The catalase will have applications for removal of hydrogen peroxide in industrial processes such as pulp and paper bleaching, textile bleaching, food pasteurization, and surface decontamination of food packaging.\n\nDNA modifying enzymes such as \"Taq\" DNA polymerase and some \"Bacillus\" enzymes used in clinical diagnostics and starch liquefaction are produced commercially by several biotechnology companies.\n\nOver 65 prokaryotic species are known to be naturally competent for genetic transformation, the ability to transfer DNA from one cell to another cell followed by integration of the donor DNA into the recipient cell's chromosome. Several extremophiles are able to carry out species-specific DNA transfer, as described below. However, it is not yet clear how common such a capability is among extremophiles.\n\nThe bacterium \"Deinococcus radiodurans\" is one of the most radioresistant organisms known. This bacterium can also survive cold, dehydration, vacuum and acid and is thus known as a polyextremophile. \"D. radiodurans\" is competent to perform genetic transformation. Recipient cells are able to repair DNA damage in donor transforming DNA that had been UV irradiated as efficiently as they repair cellular DNA when the cells themselves are irradiated. The extreme thermophilic bacterium \"Thermus thermophilus\" and other related \"Thermus\" species are also capable of genetic transformation.\n\n\"Halobacterium volcanii\", an extreme halophilic (saline tolerant) archaeon, is capable of natural genetic transformation. Cytoplasmic bridges are formed between cells that appear to be used for DNA transfer from one cell to another in either direction.\n\n\"Sulfolobus solfataricus\" and \"Sulfolobus acidocaldarius\" are hyperthermophilic archaea. Exposure of these organisms to the DNA damaging agents UV irradiation, bleomycin or mitomycin C induces species-specific cellular aggregation. UV-induced cellular aggregation of \"S. acidocaldarius\" mediates chromosomal marker exchange with high frequency. Recombination rates exceed those of uninduced cultures by up to three orders of magnitude. Frols et al. and Ajon et al. hypothesized that cellular aggregation enhances species-specific DNA transfer between \"Sulfolobus\" cells in order to repair damaged DNA by means of homologous recombination. Van Wolferen et al. noted that this DNA exchange process may be crucial under DNA damaging conditions such as high temperatures. It has also been suggested that DNA transfer in \"Sulfolobus\" may be an early form of sexual interaction similar to the more well-studied bacterial transformation systems that involve species-specific DNA transfer leading to homologous recombinational repair of DNA damage (and see Transformation (genetics)).\n\nExtracellular membrane vesicles (MVs) might be involved in DNA transfer between different hyperthermophilic archaeal species. It has been shown that both plasmids and viral genomes can be transferred via MVs. Notably, a horizontal plasmid transfer has been documented between hyperthermophilic \"Thermococcus\" and \"Methanocaldococcus\" species, respectively belonging to the orders \"Thermococcales\" and \"Methanococcales\".\n\nBULLET::::- Extremotroph\nBULLET::::- List of microorganisms tested in outer space\nBULLET::::- Tardigrade\nBULLET::::- RISE project\n\nBULLET::::- Dissimilatory metal-reducing microorganisms\n\nBULLET::::- Extreme Environments - Science Education Resource Center\nBULLET::::- Extremophile Research\nBULLET::::- Eukaryotes in extreme environments\nBULLET::::- The Research Center of Extremophiles\nBULLET::::- DaveDarling's Encyclopedia of Astrobiology, Astronomy, and Spaceflight\nBULLET::::- The International Society for Extremophiles\nBULLET::::- Idaho National Laboratory\nBULLET::::- Polyextremophile on David Darling's \"Encyclopedia of Astrobiology, Astronomy, and Spaceflight\"\nBULLET::::- T-Limit Expedition\n"}
{"id": "9620", "url": "https://en.wikipedia.org/wiki?curid=9620", "title": "Education reform", "text": "Education reform\n\nEducation reform is the name given to the goal of changing public education. Historically, reforms have taken different forms because the motivations of reformers have differed. However, since the 1980s, education reform has been focused on changing the existing system from one focused on inputs to one focused on outputs (i.e., student achievement). In the United States, education reform acknowledges and encourages public education as the primary source of K-12 education for American youth. \nThe one constant for all forms of education reform includes the idea that small changes in education will have large social returns in citizen health, wealth and well-being. For example, a stated motivation has been to reduce cost to students and society. From ancient times until the 1800s, one goal was to reduce the expense of a classical education. Ideally, classical education is undertaken with a highly educated full-time (extremely expensive) personal tutor. Historically, this was available only to the most wealthy. Encyclopedias, public libraries and grammar schools are examples of innovations intended to lower the cost of a classical education.\n\nRelated reforms attempted to develop similar classical results by concentrating on \"why\", and \"which\" questions neglected by classical education. Abstract, introspective answers to these questions can theoretically compress large numbers of facts into relatively few principles. This path was taken by some Transcendentalist educators, such as Amos Bronson Alcott.\nIn the early modern age, Victorian schools were reformed to teach commercially useful topics, such as modern languages and mathematics, rather than classical subjects, such as Latin and Greek.\n\nMany reformers focused on reforming society by reforming education on more scientific, humanistic, pragmatic or democratic principles. John Dewey and Anton Makarenko are prominent examples of such reformers. Some reformers incorporated several motivations, e.g. Maria Montessori, who both \"educated for peace\" (a social goal), and to \"meet the needs of the child\" (A humanistic goal). In historic Prussia, an important motivation for the invention of Kindergarten was to foster national unity by teaching a national language while children were young enough that learning a language was easy. Proponents of evidence-based education call for the use of evidence in guiding education reform.\n\nReform has taken many forms and directions. Throughout history and the present day, the meaning and methods of education have changed through debates over what content or experiences result in an educated individual or an educated society. Changes may be implemented by individual educators and/or by broad-based school organization and/or by curriculum changes with performance evaluations.\n\nPlato believed that children would never learn unless they wanted to learn. In \"The Republic\", he said, \" ... compulsory learning never sticks in the mind.\"\nAn educational debate in the time of the Roman Empire arose after Christianity had achieved broad acceptance. The question concerned the educational value of pre-Christian classical thought: \"Given that the body of knowledge of the pre-Christian Romans was heathen in origin, was it safe to teach it to Christian children?\" \n\nThough educational reform occurred on a local level at various points throughout history, the modern notion of education reform is tied with the spread of compulsory education. Education reforms did not become widespread until after organized schooling was sufficiently systematized to be 'reformed.'\n\nIn the modern world, economic growth and the spread of democracy have raised the value of education and increased the importance of ensuring that all children and adults have access to high-quality, effective education. Modern education reforms are increasingly driven by a growing understanding of what works in education and how to go about successfully improving teaching and learning in schools. However, in some cases, the reformers' goals of \"high-quality education\" has meant \"high-intensity education\", with a narrow emphasis on teaching individual, test-friendly subskills quickly, regardless of long-term outcomes, developmental appropriateness, or broader educational goals.\n\nWestern classical education as taught from the 18th to the 19th century has missing features that inspired reformers. Classical education is most concerned with answering the who, what, where, and when? questions that concern a majority of students. Unless carefully taught, group instruction naturally neglects the theoretical \"why\" and \"which\" questions that strongly concern fewer students.\n\nClassical education in this period also did not teach local (vernacular) languages and cultures. Instead it taught high-status ancient languages (Greek and Latin) and their cultures. This produced odd social effects in which an intellectual class might be more loyal to ancient cultures and institutions than to their native vernacular languages and their actual governing authorities.\n\nBefore there were government-funded public schools, education of the lower classes was by the charity school, pioneered in the 19th century by Protestant organizations and adapted by the Roman Catholic Church and governments. Because these schools operated on very small budgets and attempted to serve as many needy children as possible, they were designed to be inexpensive.\n\nThe basic program was to develop \"grammar\" schools. These taught only grammar and bookkeeping. This program permitted people to start businesses to make money, and gave them the skills to continue their education inexpensively from books. \"Grammar\" was the first third of the then-prevalent system of classical education.\nThe ultimate development of the grammar school was by Joseph Lancaster and Andrew Bell who developed the monitorial system. Lancaster started as a poor Quaker in early 19th century London. Bell started the Madras School of India. The monitorial system uses slightly more-advanced students to teach less-advanced students, achieving student-teacher ratios as small as 2, while educating more than a thousand students per adult. Lancaster promoted his system in a piece called Improvements in Education that spread widely throughout the English-speaking world.\n\nDiscipline and labor in a Lancaster school were provided by an economic system. Scrip, a form of money meaningless outside the school, was created at a fixed exchange rate from a student's tuition. Every job of the school was bid-for by students in scrip, with the largest bid winning. However, \"any\" student tutor could auction positions in his or her classes. Besides tutoring, students could use scrip to buy food, school supplies, books, and childish luxuries in a school store. The adult supervisors were paid from the bids on jobs.\n\nWith fully developed internal economies, Lancaster schools provided a grammar-school education for a cost per student near $40 per year in 1999 U.S. dollars. The students were very clever at reducing their costs, and once invented, improvements were widely adopted in a school. For example, Lancaster students, motivated to save scrip, ultimately rented individual pages of textbooks from the school library, and read them in groups around music stands to reduce textbook costs. Students commonly exchanged tutoring, and paid for items and services with receipts from \"down tutoring.\"\n\nLancaster schools usually lacked sufficient adult supervision. As a result, the older children acting as disciplinary monitors tended to become brutal task masters. Also, the schools did not teach submission to orthodox Christian beliefs or government authorities. As a result, most English-speaking countries developed mandatory publicly paid education explicitly to keep public education in \"responsible\" hands. These elites said that Lancaster schools might become dishonest, provide poor education and were not accountable to established authorities.\n\nLancaster's supporters responded that any schoolchild could avoid cheats, given the opportunity, and that the government was not paying for the education, and thus deserved no say in their composition.\n\nLancaster, though motivated by charity, claimed in his pamphlets to be surprised to find that he lived well on the income of his school, even while the low costs made it available to the poorest street-children.\nIronically, Lancaster lived on the charity of friends in his later life.\n\nThe term \"progressive\" in education has been used somewhat indiscriminately; there are a number of kinds of educational progressivism, most of the historically significant kinds peaking in the period between the late 19th and the middle of the 20th centuries.\n\nJean-Jacques Rousseau has been called the father of the child-study movement. It has been said that Rousseau \"discovered\" the child (as an object of study).\n\nRousseau's principal work on education is \"\", in which he lays out an educational program for a hypothetical newborn's education to adulthood. Rousseau provided a dual critique of both the vision of education set forth in Plato's Republic and also of the society of his contemporary Europe and the educational methods he regarded as contributing to it; he held that a person can either be a man or a citizen, and that while Plato's plan could have brought the latter at the expense of the former, contemporary education failed at both tasks. He advocated a radical withdrawal of the child from society and an educational process that utilized the natural potential of the child and its curiosity, teaching it by confronting it with simulated real-life obstacles and conditioning it by experience rather than teaching it intellectually. His ideas were rarely implemented directly, but were influential on later thinkers, particularly Johann Heinrich Pestalozzi and Friedrich Wilhelm August Fröbel, the inventor of the kindergarten.\n\nIn the United States, Horace Mann (1796 – 1859) of Massachusetts used his political base and role as Secretary of the Massachusetts State Board of Education to promote public education in his home state and nationwide. His crusading style attracted wide middle class support. Historian Ellwood P. Cubberley asserts:\n\nEducation is often seen in Europe and Asia as an important system to maintain national, cultural and linguistic unity. Prussia instituted primary school reforms expressly to teach a unified version of the national language, \"Hochdeutsch\". One significant reform was kindergarten, whose purpose was to have the children spend time in supervised activities in the national language, when the children were young enough that they could easily learn new language skills.\n\nSince most modern schools copy the Prussian models, children start school at an age when their language skills remain plastic, and they find it easy to learn the national language. This was an intentional design on the part of the Prussians.\n\nIn the U.S. over the last twenty years, more than 70% of non-English-speaking school-age immigrants have arrived in the U.S. before they were 6 years old. At this age, they could have been taught English in school, and achieved a proficiency indistinguishable from a native speaker. In other countries, such as the Soviet Union, France, Spain, and Germany this approach has dramatically improved reading and math test scores for linguistic minorities.\n\nJohn Dewey, a philosopher and educator based in Chicago and New York, helped conceptualize the role of American and international education during the first four decades of the 20th century. An important member of the American Pragmatist movement, he carried the subordination of knowledge to action into the educational world by arguing for experiential education that would enable children to learn theory and practice simultaneously; a well-known example is the practice of teaching elementary physics and biology to students while preparing a meal. He was a harsh critic of \"dead\" knowledge disconnected from practical human life.\n\nDewey criticized the rigidity and volume of humanistic education, and the emotional idealizations of education based on the child-study movement that had been inspired by Rousseau and those who followed him. He presented his educational theories as a synthesis of the two views. His slogan was that schools should encourage children to \"Learn by doing.\" He wanted people to realize that children are naturally active and curious. Dewey's understanding of logic is best presented in his \"Logic, the Theory of Inquiry\" (1938). His educational theories were presented in \"My Pedagogic Creed\", \"The School and Society\", \"The Child and Curriculum\", and \"Democracy and Education\" (1916). Bertrand Russell criticized Dewey's conception of logic, saying \"What he calls \"logic\" does not seem to me to be part of logic at all; I should call it part of psychology.\"\n\nThe question of the history of Deweyan educational practice is a difficult one. He was a widely known and influential thinker, but his views and suggestions were often misunderstood by those who sought to apply them, leading some historians to suggest that there was never an actual implementation on any considerable scale of Deweyan progressive education. The schools with which Dewey himself was most closely associated (though the most famous, the \"Laboratory School\", was really run by his wife) had considerable ups and downs, and Dewey left the University of Chicago in 1904 over issues relating to the Dewey School.\n\nDewey's influence began to decline in the time after the Second World War and particularly in the Cold War era, as more conservative educational policies came to the fore.\n\nThe form of educational progressivism which was most successful in having its policies implemented has been dubbed \"administrative progressivism\" by historians. This began to be implemented in the early 20th century. While influenced particularly in its rhetoric by Dewey and even more by his popularizers, administrative progressivism was in its practice much more influenced by the Industrial Revolution and the concept economies of scale.\n\nThe administrative progressives are responsible for many features of modern American education, especially American high schools: counseling programs, the move from many small local high schools to large centralized high schools, curricular differentiation in the form of electives and tracking, curricular, professional, and other forms of standardization, and an increase in state and federal regulation and bureaucracy, with a corresponding reduction of local control at the school board level. (Cf. \"State, federal, and local control of education in the United States\", below) (Tyack and Cuban, pp. 17–26)\n\nThese reforms have since become heavily entrenched, and many today who identify themselves as progressives are opposed to many of them, while conservative education reform during the Cold War embraced them as a framework for strengthening traditional curriculum and standards.\n\nIn more recent times, groups such as the think tank Reform's education division, and S.E.R. have attempted to pressure the government of the U.K. into more modernist educational reform, though this has met with limited success.\n\nFrom the 1950s to the 1970s, many of the proposed and implemented reforms in U.S. education stemmed from the civil rights movement and related trends; examples include ending racial segregation, and busing for the purpose of desegregation, affirmative action, and banning of school prayer.\n\nIn the 1980s, some of the momentum of education reform moved from the left to the right, with the release of \"A Nation at Risk\", Ronald Reagan's efforts to reduce or eliminate the United States Department of Education. \"[T]he federal government and virtually all state governments, teacher training institutions, teachers' unions, major foundations, and the mass media have all pushed strenuously for higher standards, greater accountability, more \"time on task,\" and more impressive academic results\".\n\nThis shift to the right caused many families to seek alternatives, including \"charter schools, progressive schools, Montessori schools, Waldorf schools, Afrocentric schools, religious schools - or teaching them at home and in their communities.\"\n\nIn the latter half of the decade, E. D. Hirsch put forth an influential attack on one or more versions of progressive education, advocating an emphasis on \"cultural literacy\"—the facts, phrases, and texts that Hirsch asserted every American had once known and that now only some knew, but was still essential for decoding basic texts and maintaining communication. Hirsch's ideas remain significant through the 1990s and into the 21st century, and are incorporated into classroom practice through textbooks and curricula published under his own imprint.\n\nMost states and districts in the 1990s adopted Outcome-Based Education (OBE) in some form or another. A state would create a committee to adopt standards, and choose a quantitative instrument to assess whether the students knew the required content or could perform the required tasks. The standards-based National Education Goals (Goals 2000) were set by the U.S. Congress in the 1990s. Many of these goals were based on the principles of outcomes-based education, and not all of the goals were attained by the year 2000 as was intended. The standards-based reform movement culminated in the No Child Left Behind Act of 2001, which is still an active nationwide mandate in the United States.\n\nOBE reforms usually had other disputed methods, such as constructivist mathematics and whole language, added onto them. Some proponents advocated replacing the traditional high school diploma with a Certificate of Initial Mastery. Other reform movements were school-to-work, which would require all students except those in a university track to spend substantial class time on a job site. See also Uncommon Schools.\n\nPresident Donald Trump relegated concerns in education to state governments. This began with the Every Student Succeeds Act (ESSA) which limits the role of the federal government in school liability. Giving states more authority can help prevent considerable discrepancies in educational performance across different states. ESSA was approved by former President Obama in 2015 which amended and empowered the Elementary and Secondary Education Act of 1965. The Department of Education has the choice to carry out measures in drawing attention to said differences by pinpointing lowest-performing state governments and supplying information on the condition and progress of each state on different educational parameters. It can also provide reasonable funding along with technical aid to help states with similar demographics collaborate in improving their public education programs.\n\nDuring his campaign, Trump criticized the 2010 Common Core States Standard and other cases of “federal government overreach.” His advocacy was to give state and local governments more responsibilities over education policies. Trump appointed Betsy DeVos as education secretary. She also supported the idea of leaving education to state governments under the new K-12 legislation. DeVos cited the interventionist approach of the federal government to education policy following the signing of the ESSA. The primary approach to that rule has not changed significantly. Her opinion was that the education movement's populist politics or populism. encouraged reformers to commit promises which were not very realistic and therefore difficult to deliver.\n\nMany opinion makers say the situation in all American social institutions is the same. These institutions which include government, higher education, healthcare, and mass media are still attuned with the traditional or original economic system. There is a need to upgrade to a digital information economy. More providers of higher education which include colleges and universities, non-traditional entities like school districts, libraries, and museums, and for-profit organizations will surface. All of these stakeholders will reach out to bigger audiences and use similar tools and technologies to achieve their goals. An article released by CBNC.com said a principal Senate Committee will take into account legislation that reauthorizes and modernizes the Carl D. Perkins Act. President George Bush approved this statute in 2006 on August 12, 2006. This new bill will emphasize the importance of federal funding for various Career and Technical (CTE) programs that will better provide learners with in-demand skills. Congress can provide more students with access to pertinent skills in education according to 21st century career opportunities.\n\nAt present, there are many initiatives aimed at dealing with these concerns like innovative cooperation between federal and state governments, educators, and the business sector. One of these efforts is the Pathways to Technology Early College High School (P-TECH). This six-year program was launched in cooperation with IBM, educators from three cities in New York, Chicago, and Connecticut, and over 400 businesses. The program offers students high school and associate programs focusing on the STEM curriculum. The High School Involvement Partnership, private and public venture, was established through the help of Northrop Grumman, a global security firm. It has given assistance to some 7,000 high school students (juniors and seniors) since 1971 by means of one-on-one coaching as well as exposure to STEM areas and careers. In 2016, Time.com published an article mentioning that one way of reenergizing the United States economy is to provide quality education and training opportunities for American youngsters. There is a need to update funding streams for schools at the federal, state, and local levels such as Pell Grants addressing the requirements of college students. The Grant or specific amount of money is given by the government every school year for disadvantaged students who need to pay tuition fees in college.\n\nHigher education in the United States of America has always been regarded as exceptional worldwide although there are apprehensions regarding expensive and quality education, unimpressive completion rates, and increasing student debt. These issues raised doubts as to the effectiveness of the conventional approach to higher education. There have been numerous proposals for federal reforms to enhance the status of higher education in the US. Some of the recommendations included making institutions liable for students/ non-attendance or dropping out of school, changing the obsolete accreditation process in overseeing access to federal subsidies, and allowing access to free education.\n\nThis uses a methodology that values purposeful engagement in activities that turn students into self-reliant and efficient learners. Holding on to the view that everyone possesses natural gifts that are unique to one's personality (e.g. computational aptitude, musical talent, visual arts abilities), it likewise upholds the idea that children, despite their inexperience and tender age, are capable of coping with anguish, able to survive hardships, and can rise above difficult times.\n\nPresident Donald Trump signed the Strengthening Career and Technical Education for the 21st Century Act (HR 2353) on July 31, 2018. This is the first law the American president signed that made meaningful amendments to the federal education system. It reauthorizes the Carl D. Perkins Career and Technical Education Act, a $1.2 billion program modified by the United States Congress in 2006.\n\nLegislators have repeatedly rebuffed the efforts of Trump and education secretary Betsy DeVos to implement school choice programs funded by the federal government. The move to change the Higher Education Act was also deferred. Business and education groups such as the Council of Chief State School Officers as well as the National Governors Association commended the US Congress for its prompt work during the past month. However, some advocacy organizations like Advanced CTE and Association for Career and Technical Education are apprehensive that said law can urge states to set passive laws for Career and Technical Education.\n\nThe new legislation takes effect on July 1, 2019 and takes the place of the Carl D. Perkins Career and Technical Education (Perkins IV) Act of 2006. Stipulations in Perkins V enables school districts to make use of federal subsidies for all students' career search and development activities in the middle grades as well as comprehensive guidance and academic mentoring in the upper grades. At the same time, this law updates and magnifies the meaning of \"special populations\" to include homeless persons, foster youth, those who left the foster care system, and children with parents on active duty in the United States armed forces.\n\nIn the first decade of the 21st century, several issues are salient in debates over further education reform:\n\nBULLET::::- Longer school day or school year\nBULLET::::- After-school tutoring\nBULLET::::- Charter schools, school choice, or school vouchers\nBULLET::::- Smaller class sizes\nBULLET::::- Improved teacher quality\nBULLET::::- Improved training\nBULLET::::- Higher credential standards\nBULLET::::- Generally higher pay to attract more qualified applicants\nBULLET::::- Performance bonuses (\"merit pay\")\nBULLET::::- Firing low-performing teachers\nBULLET::::- Internet and computer access in schools\nBULLET::::- Track and reduce drop-out rate\nBULLET::::- Track and reduce absenteeism\nBULLET::::- English-only vs. bilingual education\nBULLET::::- Mainstreaming or fully including students with special educational needs, rather than placing them in separate special schools\nBULLET::::- Content of curriculum standards and textbooks\nBULLET::::- What to teach, at what age, and to which students. Discussion points include the age at which children should learn to read, and the primary mathematical subject that is taught to adolescents – algebra, or statistics or personal finances.\nBULLET::::- Funding, neglected infrastructure, and adequacy of educational supplies\nBULLET::::- Student rights\n\nAccording to a 2005 report from the OECD, the United States is tied for first place with Switzerland when it comes to annual spending per student on its public schools, with each of those two countries spending more than $11,000 (in U.S. currency).\nDespite this high level of funding, U.S. public schools lag behind the schools of other rich countries in the areas of reading, math, and science. A further analysis of developed countries shows no correlation between per student spending and student performance, suggesting that there are other factors influencing education. Top performers include Singapore, Finland and Korea, all with relatively low spending on education, while high spenders including Norway and Luxembourg have relatively low performance. One possible factor is the distribution of the funding. In the US, schools in wealthy areas tend to be over-funded while schools in poorer areas tend to be underfunded. These differences in spending between schools or districts may accentuate inequalities, if they result in the best teachers moving to teach in the most wealthy areas. The inequality between districts and schools led to 23 states instituting school finance reform based on adequacy standards that aim to increase funding to low-income districts. A 2018 study found that between 1990 and 2012, these finance reforms led to an increase in funding and test scores in the low income districts; which suggests finance reform is effective at bridging inter-district performance inequalities. It has also been shown that the socioeconomic situation of the students family has the most influence in determining success; suggesting that even if increased funds in a low income area increase performance, they may still perform worse than their peers from wealthier districts.\n\nStarting in the early 1980s, a series of analyses by Eric Hanushek indicated that the amount spent on schools bore little relationship to student learning. This controversial argument, which focused attention on how money was spent instead of how much was spent, led to lengthy scholarly exchanges. In part the arguments fed into the class size debates and other discussions of \"input policies.\" It also moved reform efforts towards issues of school accountability (including No Child Left Behind) and the use of merit pay and other incentives.\n\nThere have been studies that show smaller class sizes and newer buildings (both of which require higher funding to implement) lead to academic improvements. It should also be noted that many of the reform ideas that stray from the traditional format require greater funding.\n\nIt has been shown that some school districts do not use their funds in the most productive way. For example, according to a 2007 article in the \"Washington Post\", the Washington, D.C. public school district spends $12,979 per student per year. This is the third highest level of funding per student out of the 100 biggest school districts in the United States. Despite this high level of funding, the school district provides outcomes that are lower than the national average. In reading and math, the district's students score the lowest among 11 major school districts—even when poor children are compared only with other poor children. 33% of poor fourth graders in the United States lack basic skills in math, but in Washington, D.C., it's 62%. According to a 2006 study by the Goldwater Institute, Arizona's public schools spend 50% more per student than Arizona's private schools. The study also says that while teachers constitute 72% of the employees at private schools, they make up less than half of the staff at public schools. According to the study, if Arizona's public schools wanted to be like private schools, they would have to hire approximately 25,000 more teachers, and eliminate 21,210 administration employees. The study also said that public school teachers are paid about 50% more than private school teachers.\n\nIn 1985 in Kansas City, Missouri, a judge ordered the school district to raise taxes and spend more money on public education. Spending was increased so much, that the school district was spending more money per student than any of the country's other 280 largest school districts.\n\nAccording to a 1999 article, William J. Bennett, former U.S. Secretary of Education, argued that increased levels of spending on public education have not made the schools better, citing the following statistics:\n\nIn the United States, private schools (independent schools) have long been an alternative to public education for those with the ability to pay tuition. These include religious schools, preparatory and boarding schools, and schools based on alternative paradigms such as Montessori education. Over 4 million students, about one in twelve children attend religious schools in the United States, most of them Christian.\nMontessori pre- and primary school programs employ rigorously tested scientific theories of guided exploration which seek to embrace children's natural curiosity rather than, for instance, scolding them for falling out of rank.\n\nHome education is favored by a growing number of parents who take direct responsibility for their children's education rather than enrolling them in local public schools seen as not meeting expectations.\n\nEconomists such as Nobel laureate Milton Friedman advocate school choice to promote excellence in education through competition and choice. A competitive \"market\" for schools eliminates the need to otherwise attempt a workable method of accountability for results. Public education vouchers permit guardians to select and pay any school, public or private, with public funds currently allocated to local public schools. The theory is that children's guardians will naturally shop for the best schools, much as is already done at college level.\n\nThough appealing in theory, many reforms based on school choice have led to slight to moderate improvements—which some teachers' union members see as insufficient to offset the decreased teacher pay and job security. For instance, New Zealand's landmark reform in 1989, during which schools were granted substantial autonomy, funding was devolved to schools, and parents were given a free choice of which school their children would attend, led to moderate improvements in most schools. It was argued that the associated increases in inequity and greater racial stratification in schools nullified the educational gains. Others, however, argued that the original system created more inequity (due to lower income students being required to attend poorer performing inner city schools and not being allowed school choice or better educations that are available to higher income inhabitants of suburbs). Instead, it was argued that the school choice promoted social mobility and increased test scores especially in the cases of low income students. Similar results have been found in other jurisdictions. Though discouraging, the merely slight improvements of some school choice policies often seems to reflect weaknesses in the way that choice is implemented rather than a failure of the basic principle itself.\n\nCritics of teacher tenure claim that the laws protect ineffective teachers from being fired, which can be detrimental to student success. Tenure laws vary from state to state, but generally they set a probationary period during which the teacher proves themselves worthy of the lifelong position. Probationary periods range from one to three years. Advocates for tenure reform often consider these periods too short to make such an important decision; especially when that decision is exceptionally hard to revoke. Due process restriction protect tenured teachers from being wrongfully fired; however these restrictions can also prevent administrators from removing ineffective or inappropriate teachers. A 2008 survey conducted by the US Department of Education found that, on average, only 2.1% of teachers are dismissed each year for poor performance.\n\nIn October 2010 Apple Inc. CEO Steve Jobs had a consequential meeting with U.S. President Barack Obama to discuss U.S. competitiveness and the nation's education system. During the meeting Jobs recommended pursuing policies that would make it easier for school principals to hire and fire teachers based on merit.\n\nIn 2012 tenure for school teachers was challenged in a California lawsuit called \"Vergara v. California\". The primary issue in the case was the impact of tenure on student outcomes and on equity in education. On June 10, 2014, the trial judge ruled that California's teacher tenure statute produced disparities that \" shock the conscience\" and violate the equal protection clause of the California Constitution. On July 7, 2014, U.S. Secretary of Education Arne Duncan commented on the \"Vergara\" decision during a meeting with President Barack Obama and representatives of teacher's unions. Duncan said that tenure for school teachers \"should be earned through demonstrated effectiveness\" and should not be granted too quickly. Specifically, he criticized the 18-month tenure period at the heart of the \"Vergara\" case as being too short to be a \"meaningful bar.\"\n\nA study by the Fordham Institute found that some labor agreements with teachers' unions may restrict the ability of school systems to implement merit pay and other reforms. Contracts were more restrictive in districts with high concentrations of poor and minority students. The methodology and conclusions of the study have been criticized by teachers' unions.\n\nAnother barrier to reform is assuming that schools are like businesses—when in fact they are very different.\n\nLegal barriers to reform are low in the United States compared to other countries: State and local governance of education creates \"wiggle room for educational innovators\" who can change local laws or move somewhere more favourable. Cultural barriers to reform are also relatively low, because the question of who should control education is still open.\n\nThere are factors that can impede innovations in K-12 education. One could be “Site-Based Decision Making Councils” composed of teachers and some parents who vote on school rules and regulations, adoption of curriculum, hiring of new mentors, and other related matters. There are times attendance in meetings is not adequate or stakeholders are not represented properly. The belief is small meetings attended by a few individuals may not be ideal for innovation. Turnover of teachers is another possible hindrance to such innovations. The learning process is adversely affected because of frequent teacher resignations and replacements. Constant changing of mentors leads to waste of resources and dormant thinking influenced by policies, systems, and traditions.\n\nEducation 2030 Agenda refers to the global commitment of the Education for All movement to ensure access to basic education for all. It is an essential part of the 2030 Agenda for Sustainable Development. The roadmap to achieve the Agenda is the Education 2030 Incheon Declaration and Framework for Action, which outlines how countries, working with UNESCO and global partners, can translate commitments into action.\n\nThe United Nations, over 70 ministers, representatives of member-countries, bilateral and multilateral agencies, regional organizations, academic institutions, teachers, civil society, and the youth supported the Framework for Action of the Education 2030 platform. The Framework was described as the outcome of continuing consultation to provide guidance for countries in implementing this Agenda. At the same time, it mobilizes various stakeholders in the new education objectives, coordination, implementation process, funding, and review of Education 2030.\n\nIn other parts of the world, educational reform has had a number of different meanings. In Taiwan in the 1990s and first decade of the 21st century a movement tried to prioritize reasoning over mere facts, reduce the emphasis on central control and standardized testing. There was consensus on the problems. Efforts were limited because there was little consensus on the goals of educational reforms, and therefore on how to fix the problems. By 2003, the push for education reform had declined.\n\nIn 1995, the minister of education, Sukavich Rangsitpol, launched a series of education reforms in 1995 with the intention of the education reform is to realize the potential of Thai people to develop themselves for a better quality of life and to develop the nation for a peaceful co-existence in the global community.\n\nAccording to UNESCO, Thailand education reform has led to the following results: \n\nBULLET::::- The educational budget increased from 133 billion baht in 1996 to 163 billion baht in 1997 (22.5% increase)\nBULLET::::- Since 1996, first grade students have been taught English as a second or foreign language and computer literacy.\nBULLET::::- Professional advancement from teacher level 6 to teacher level 7 without having to submit academic work for consideration was approved by the Thai government.\nBULLET::::- Free 12 years education for all children provided by the government. This program was added to the 1997 Constitution of Thailand and gave access to all citizens.\n\nWorld Bank report that after the 1997 Asian financial crisis Income in the northeast, the poorest part of Thailand , has risen by 46 percent from 1998 to 2006. Nationwide poverty fell from 21.3 to 11.3 percent.\n\nEducation reform has been pursued for a variety of specific reasons, but generally most reforms aim at redressing some societal ills, such as poverty-, gender-, or class-based inequities, or perceived ineffectiveness. Current education trends in the United States represent multiple achievement gaps across ethnicities, income levels, and geographies. As McKinsey and Company reported in a 2009 analysis, “These educational gaps impose on the United States the economic equivalent of a permanent national recession.” Reforms are usually proposed by thinkers who aim to redress societal ills or institute societal changes, most often through a change in the education of the members of a class of people—the preparation of a ruling class to rule or a working class to work, the social hygiene of a lower or immigrant class, the preparation of citizens in a democracy or republic, etc. The idea that all children should be provided with a high level of education is a relatively recent idea, and has arisen largely in the context of Western democracy in the 20th century.\n\nThe \"beliefs\" of school districts are optimistic that quite literally \"all students will succeed\", which in the context of high school graduation examination in the United States, all students in all groups, regardless of heritage or income will pass tests that in the introduction typically fall beyond the ability of all but the top 20 to 30 percent of students. The claims clearly renounce historical research that shows that all ethnic and income groups score differently on all standardized tests and standards based assessments and that students will achieve on a bell curve. Instead, education officials across the world believe that by setting clear, achievable, higher standards, aligning the curriculum, and assessing outcomes, learning can be increased for all students, and more students can succeed than the 50 percent who are defined to be above or below grade level by norm referenced standards.\n\nStates have tried to use state schools to increase state power, especially to make better soldiers and workers. This strategy was first adopted to unify related linguistic groups in Europe, including France, Germany and Italy. Exact mechanisms are unclear, but it often fails in areas where populations are culturally segregated, as when the U.S. Indian school service failed to suppress Lakota and Navaho, or when a culture has widely respected autonomous cultural institutions, as when the Spanish failed to suppress Catalan.\n\nMany students of democracy have desired to improve education in order to improve the quality of governance in democratic societies; the necessity of good public education follows logically if one believes that the quality of democratic governance depends on the ability of citizens to make informed, intelligent choices, and that education can improve these abilities.\n\nPolitically motivated educational reforms of the democratic type are recorded as far back as Plato in \"The Republic\". In the United States, this lineage of democratic education reform was continued by Thomas Jefferson, who advocated ambitious reforms partly along Platonic lines for public schooling in Virginia.\n\nAnother motivation for reform is the desire to address socio-economic problems, which many people see as having significant roots in lack of education. Starting in the 20th century, people have attempted to argue that small improvements in education can have large returns in such areas as health, wealth and well-being. For example, in Kerala, India in the 1950s, increases in women's health were correlated with increases in female literacy rates. In Iran, increased primary education was correlated with increased farming efficiencies and income. In both cases some researchers have concluded these correlations as representing an underlying causal relationship: education causes socio-economic benefits. In the case of Iran, researchers concluded that the improvements were due to farmers gaining reliable access to national crop prices and scientific farming information.\n\nReforms can be based on bringing education into alignment with a society's core values. Reforms that attempt to change a society's core values can connect alternative education initiatives with a network of other alternative institutions.\n\nProponents of the evidence-based education movement call for the use of evidence in guiding education reform. Evidence-based education is the use of well designed scientific studies to determine which education methods work best. Evidence-based learning techniques such as spaced repetition have been shown to increase the rate at which students learn. The evidence-based education movement has its roots in the larger movement towards evidence-based-practices.\n\nThe movement to use computers more in education naturally includes many unrelated ideas, methods, and pedagogies since there are many uses for digital computers. For example, the fact that computers are naturally good at math leads to the question of the use of calculators in math education. The Internet's communication capabilities make it potentially useful for collaboration, and foreign language learning. The computer's ability to simulate physical systems makes it potentially useful in teaching science. More often, however, debate of digital education reform centers around more general applications of computers to education, such as electronic test-taking and online classes.\n\nThe idea of creating artificial intelligence led some computer scientists to believe that teachers could be replaced by computers, through something like an expert system; however, attempts to accomplish this have predictably proved inflexible. The computer is now more understood to be a tool or assistant for the teacher and students.\n\nHarnessing the richness of the Internet is another goal. In some cases classrooms have been moved entirely online, while in other instances the goal is more to learn how the Internet can be more than a classroom.\n\nWeb-based international educational software is under development by students at New York University, based on the belief that current educational institutions are too rigid: effective teaching is not routine, students are not passive, and questions of practice are not predictable or standardized. The software allows for courses tailored to an individual's abilities through frequent and automatic multiple intelligences assessments. Ultimate goals include assisting students to be intrinsically motivated to educate themselves, and aiding the student in self-actualization. Courses typically taught only in college are being reformatted so that they can be taught to any level of student, whereby elementary school students may learn the foundations of any topic they desire. Such a program has the potential to remove the bureaucratic inefficiencies of education in modern countries, and with the decreasing digital divide, help developing nations rapidly achieve a similar quality of education. With an open format similar to Wikipedia, any teacher may upload their courses online and a feedback system will help students choose relevant courses of the highest quality. Teachers can provide links in their digital courses to webcast videos of their lectures. Students will have personal academic profiles and a forum will allow students to pose complex questions, while simpler questions will be automatically answered by the software, which will bring you to a solution by searching through the knowledge database, which includes all available courses and topics.\n\nThe 21st century ushered in the acceptance and encouragement of internet research conducted on college and university campuses, in homes, and even in gathering areas of shopping centers. Addition of cyber cafes on campuses and coffee shops, loaning of communication devices from libraries, and availability of more portable technology devices, opened up a world of educational resources. Availability of knowledge to the elite had always been obvious, yet provision of networking devices, even wireless gadget sign-outs from libraries, made availability of information an expectation of most persons. Cassandra B. Whyte researched the future of computer use on higher education campuses focusing on student affairs. Though at first seen as a data collection and outcome reporting tool, the use of computer technology in the classrooms, meeting areas, and homes continued to unfold. The sole dependence on paper resources for subject information diminished and e-books and articles, as well as on-line courses, were anticipated to become increasingly staple and affordable choices provided by higher education institutions according to Whyte in a 2002 presentation.\n\nDigitally \"flipping\" classrooms is a trend in digital education that has gained significant momentum. Will Richardson, author and visionary for the digital education realm, points to the not-so-distant future and the seemingly infinite possibilities for digital communication linked to improved education. Education on the whole, as a stand-alone entity, has been slow to embrace these changes. The use of web tools such as wikis, blogs, and social networking sites is tied to increasing overall effectiveness of digital education in schools. Examples exist of teacher and student success stories where learning has transcended the classroom and has reached far out into society.\n\nCreativity is of the utmost importance when improving education. The \"creative teachers\" must have the confidence through training and availability of support and resources. These creative teachers are strongly encouraged to embrace a person-centered approach that develops the psychology of the educator ahead or in conjunction with the deployment of machines. Creative teachers have been also been inspired through Crowd-Accelerated Innovation. Crowd-Accelerated Innovation has pushed people to transition between media types and their understanding thereof at record-breaking paces. This process serves as a catalyst for creative direction and new methods of innovation. Innovation without desire and drive inevitably flat lines.\n\nMainstream media continues to be both very influential and the medium where Crowd-Accelerated Innovation gains its leverage. Media is in direct competition with formal educational institutions in shaping the minds of today and those of tomorrow. [Buchanan, Rachel footnote] The media has been instrumental in pushing formal educational institutions to become savvier in their methods. Additionally, advertising has been (and continues to be) a vital force in shaping students and parents thought patterns.\n\nTechnology is a dynamic entity that is constantly in flux. As time presses on, new technologies will continue to break paradigms that will reshape human thinking regarding technological innovation. This concept stresses a certain disconnect between teachers and learners and the growing chasm that started some time ago. Richardson asserts that traditional classroom's will essentially enter entropy unless teachers increase their comfort and proficiency with technology.\n\nAdministrators are not exempt from the technological disconnect. They must recognize the existence of a younger generation of teachers who were born during the Digital Age and are very comfortable with technology. However, when old meets new, especially in a mentoring situation, conflict seems inevitable. Ironically, the answer to the outdated mentor may be digital collaboration with worldwide mentor webs; composed of individuals with creative ideas for the classroom.\n\nAnother viable addition to digital education has been blended learning. In 2009, over 3 million K-12 students took an online course, compared to 2000 when 45,000 took an online course. Blended learning examples include pure online, blended, and traditional education. Research results show that the most effective learning takes place in a blended format. This allows children to view the lecture ahead of time and then spend class time practicing, refining, and applying what they have previously learned.\n\nBULLET::::- Anti-schooling activism\nBULLET::::- Blab school\nBULLET::::- Block scheduling\nBULLET::::- Certificate of Initial Mastery\nBULLET::::- Criterion-referenced test\nBULLET::::- Educational philosophies\nBULLET::::- High school graduation examination\nBULLET::::- Higher-order thinking\nBULLET::::- Inquiry-based Science\nBULLET::::- Learning environment\nBULLET::::- Learning space\nBULLET::::- Merit pay\nBULLET::::- Multiculturalism\nBULLET::::- Political correctness\nBULLET::::- Project-based learning\nBULLET::::- Special Assistance Program\nBULLET::::- Student-centered learning\nBULLET::::- Sudbury model democratic schools\nBULLET::::- Sudbury Valley School\nBULLET::::- Teaching for social justice\nBULLET::::- University reform\nBULLET::::- Web literacy\n\nBULLET::::- Comer, J.P. (1997). \"Waiting for a Miracle: Why Schools Can’t Solve Our Problems- and How We Can\". New York: Penguin Books.\nBULLET::::- Cuban, L. (2003). \"Why Is It So Hard to Get Good Schools?\" New York: Teachers College, Columbia University.\nBULLET::::- Darling-Hammond, Linda. (1997) \"The Right to Learn: A Blueprint for Creating Schools that Work\". Jossey-Bass.\nBULLET::::- Dewey, J. and Dewey, E. (1915). \"Schools of To-morrow\". New York: E.P. Dutton and Company.\nBULLET::::- Gatto, John Taylor (1992). \"Dumbing Us Down: The Hidden Curriculum of Compulsory Schooling\". Canada: New Society Publishers.\nBULLET::::- Glazek, S.D. and Sarason, S.B. (2007). \"Productive Learning: Science, Art, and Einstein’s Relativity in Education Reform\". New York: Sage Publications, Inc.\nBULLET::::- Goodland, J.I. and Anderson, R.H. (1959 and 1987). \"The Nongraded Elementary School\". New York: Harcourt, Brace and Company.\nBULLET::::- James, Laurie. (1994) \"Outrageous Questions: Legacy of Bronson Alcott and America's One-Room Schools\" New York.\nBULLET::::- Katz, M.B. (1971). \"Class, Bureaucracy, and Schools: The Illusion of Educational Change in America\". New York: Praeger Publishers.\nBULLET::::- Kliebard, Herbert. (1987) \"The Struggle for the American Curriculum\". New York : Routledge & Kegan Paul.\nBULLET::::- Kohn, A. (1999). \"The Schools Our Children Deserve: Moving Beyond Traditional Classrooms and 'Tougher Standards\". Boston: Houghton Mifflin Co.\nBULLET::::- Murphy, J.H. and Beck, L.G. (1995). \"School-Based Management as School Reform: Taking Stock\". Thousand Oaks, CA: Corwin Press, Inc.\nBULLET::::- Ogbu, J.U. (1978). \"Minority Education and Caste: The American System in Cross-Cultural Perspective\". New York: Academic Press.\nBULLET::::- Ravitch, D. (1988). \"The Great School Wars: A History of the New York City Public Schools\". New York: Basic Books, Inc.\nBULLET::::- Sarason, S.B. (1996). \"Revisiting 'The Culture of the School and the Problem of Change\". New York: Teachers College Press.\nBULLET::::- Sarason, S.B. (1990). \"The Predictable Failure of Educational Reform: Can We Change Course Before Its Too Late?\" San Francisco: Josey-Bass, Inc.\nBULLET::::- Sizer, T.R. (1984). \"Horace’s Compromise: The Dilemma of the American High School\". Boston: Houghton Mifflin Company.\nBULLET::::- Tough, Paul. (2008). \"Whatever It Takes: Geoffrey Canada’s Quest to Change Harlem and America\". New York: Houghton Mifflin Company.\nBULLET::::- Tough, Paul. (2012). \"How Children Succeed\". New York: Houghton Mifflin Company.\nBULLET::::- Tyack, David and Cuban, Larry. (1995) \"\". Cambridge, MA: Harvard University Press.\nBULLET::::- Zwaagstra, Michael; Clifton, Rodney; and Long, John. (2010) \"What's Wrong with Our Schools: and How We Can Fix Them\". Rowman & Littlefield.\n\n"}
{"id": "9621", "url": "https://en.wikipedia.org/wiki?curid=9621", "title": "Ellensburg, Washington", "text": "Ellensburg, Washington\n\nEllensburg is a city in and county seat of Kittitas County, Washington, United States. The population was 20,977 in a July 2018 census estimate. Located just east of the Cascade Range on Interstate 90, Ellensburg is the most centrally located city in the state, and is the home of Central Washington University (CWU).\n\nThe surrounding Kittitas Valley is internationally known for the timothy hay that it produces. There are several local hay brokering and processing operations that ship to Pacific Rim countries.\nDowntown Ellensburg has many historic buildings, many of which were constructed in the late 19th century. This is a legacy of its bid to be the state capital, which it lost to Olympia. CWU being placed there is another product of that legacy. The state legislature selected Ellensburg as the location for the then Normal School as a consolation prize.\n\nEllensburg was officially incorporated on November 26, 1883. John Alden Shoudy came to the Kittitas Valley in 1871, and purchased a small trading post from Andrew Jackson \"A.J.\" Splawn, called \"Robber's Roost.\" Robber's Roost was the first business in the valley, other than the early trading that occurred among Native Americans, cattle drivers, trappers, and miners. Robber's Roost was located on the present-day 3rd Avenue, just west of Main Street near the alley. There is a placard on the wall commemorating the location, as well as a small stone monument against the wall on the sidewalk. Shoudy named the town after his wife, Mary Ellen Shoudy, thus officially began the city of Ellensburgh around 1872. Shoudy was not the first settler in the Kittitas Valley, nor was he the first businessperson, but he was responsible for platting the city of Ellensburgh in the 1870s, and he was the person who named the streets in the downtown district.\n\nThe city was originally named Ellensburgh, until the final -\"h\" was dropped under standardization pressure from the United States Postal Service and Board of Geography Names in 1894.\n\nThere were several early newspapers in Ellensburg. The Daily Record, however, began in 1909 and is the name of the local newspaper today.\n\nConcerns over the state of Ellensburg's historic downtown led to the formation of the Ellensburg Downtown Association to work on revitalizing the area.\n\nThe City of Ellensburg is home to a number of local art museums and galleries: \nBULLET::::- Kittitas County Historical Museum\nBULLET::::- The Goodey Gallery\nBULLET::::- Clymer Museum and Gallery\nBULLET::::- Gallery-One Visual Arts Center\nBULLET::::- 420 Loft Art Gallery\nBULLET::::- Sarah Spurgeon Gallery, Central Washington University (CWU) Department of Art\nBULLET::::- Museum of Culture & Environment, Central Washington University\n\nEvery first Friday of each month, Ellensburg hosts First Friday Art Walk from 5:00 to 7:00 pm. This downtown event showcases art of all forms. The local businesses, galleries and museums come alive with art, music, wine and people as they celebrate art in the community.\n\nBULLET::::- The Ellensburg Farmers Market is held every Saturday from May to October in the heart of downtown Ellensburg.\nBULLET::::- Ellensburg hosts the annual Winterhop Brewfest in January. Over 21 micro breweries from around the Pacific Northwest serve their product at various venues in the historic downtown buildings.\nBULLET::::- Every June, Ellensburg hosts Dachshunds on Parade, an event that draws Dachshund dog owners from all over the Northwest. Events include a parade, Dachshund races, pet tricks, and a dog costume contest.\nBULLET::::- Ellensburg hosts the annual Jazz in the Valley music festival on the last weekend in July.\nBULLET::::- Ellensburg is a stop on the PRCA professional rodeo circuit, occurring each year on Labor Day weekend. The Ellensburg Rodeo has been a town tradition since 1923, and is the largest rodeo in Washington state. The rodeo arena is encompassed by the popular Kittitas County Fair, also held during Labor Day weekend. The Kittitas County Fair officially began in 1885, and has been held at its current location since 1923.\nBULLET::::- Downtown Ellensburg hosts Buskers in the Burg the last Saturday in September. Featuring a variety of street performers (buskers), giant puppet art parade, tasting halls, children's activities, and outdoor evening concert.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water.\n\nOwing to the strong Cascade rain shadow, Ellensburg experiences a typical Intermountain cool semi-arid climate (Köppen \"BSk\").\nAs of the census of 2010, there were 18,174 people, 7,301 households, and 2,889 families residing in the city. The population density was . There were 7,867 housing units at an average density of . The racial makeup of the city was 85.7% White, 1.5% African American, 1.0% Native American, 3.2% Asian, 0.2% Pacific Islander, 4.6% from other races, and 3.7% from two or more races. Hispanic or Latino of any race were 9.7% of the population.\n\nThere were 7,301 households, of which 19.3% had children under the age of 18 living with them, 28.2% were married couples living together, 8.2% had a female householder with no husband present, 3.1% had a male householder with no wife present, and 60.4% were non-families. 35.1% of all households were made up of individuals and 9.6% had someone living alone who was 65 years of age or older. The average household size was 2.16 and the average family size was 2.86.\n\nThe median age in the city was 23.5 years. 14.2% of residents were under the age of 18; 41.2% were between the ages of 18 and 24; 21.8% were from 25 to 44; 13.9% were from 45 to 64; and 8.9% were 65 years of age or older. The gender makeup of the city was 50.1% male and 49.9% female.\n\nAs of the census of 2000, there were 15,414 people, 6,249 households, and 2,649 families residing in the city. The population density was 2,338.9 people per square mile (903.1/km²). There were 6,732 housing units at an average density of 1,021.5 per square mile (394.4/km²). The racial makeup of the city was 88.07% White, 1.17% Black or African American, 0.95% Native American, 4.09% Asian, 0.16% Pacific Islander, 2.86% from other races, and 2.69% from two or more races. 6.33% of the population were Hispanic or Latino of any race.\n\nThere were 6,249 households, of which 20.8% had children under the age of 18 living with them, 31.4% were married couples living together, 8.1% had a female householder with no husband present, and 57.6% were non-families. 35.5% of all households were made up of individuals and 9.1% had someone living alone who was 65 years of age or older. The average household size was 2.12 and the average family size was 2.84.\n\nIn the city, the population was spread out with 15.8% under the age of 18, 39.3% from 18 to 24, 22.7% from 25 to 44, 12.8% from 45 to 64, and 9.4% who were 65 years of age or older. The median age was 24 years. For every 100 females, there were 95.0 males. For every 100 females age 18 and over, there were 93.1 males.\n\nThe median income for a household in the city was $20,034, and the median income for a family was $37,625. Males had a median income of $31,022 versus $22,829 for females. The per capita income for the city was $13,662. About 18.8% of families and 34.3% of the population were below the poverty line, including 29.0% of those under age 18 and 11.2% of those age 65 or over.\n\nThe City of Ellensburg uses the Manager/Council form of government with a City Manager hired by the City Council. The seven-member City Council is elected at large and serve 4-year terms. The City Council elects a Mayor and Deputy Mayor from the Council to serve 2-year terms. The Council meets the first and third Monday of each month, at 7:00 pm, in the City Council Chambers at City Hall.\n\nOn the state legislative level, Ellensburg is in the 13th district. As of May, 2018, its state senator is Republican Judy Warnick, and its two state representatives are Republicans Matt Manweller and Tom Dent. On the congressional level, Ellensburg is located in Washington's 8th congressional district and is represented by Democrat Kim Schrier.\n\nKittitas County is served by the \"Daily Record\", a newspaper published in Ellensburg five days a week.\n\nThe city maintains its own public library, which opened on January 20, 1910, using funds donated by Andrew Carnegie.\n\nBULLET::::- Central Washington University (est. 1891 as Washington State Normal School) offers both bachelor's and master's degrees, with over 10,000 undergraduates.\n\nPublic schools are operated by Ellensburg School District 401. The district includes one high school (Ellensburg High School), one middle school, and three elementary schools.\n\nBULLET::::- Brenden Adams, formerly the tallest teenager in the world at 7'8\"\nBULLET::::- Byron Beck, American Basketball Association player\nBULLET::::- Drew Bledsoe, National Football League player\nBULLET::::- Daryl Chapin, physicist best known for co-inventing solar cells\nBULLET::::- John Clymer, Western artist\nBULLET::::- Brian Habib, National Football League player\nBULLET::::- Brian Haley, actor, comedian\nBULLET::::- Dave Heaverlo, Major League pitcher\nBULLET::::- Jon Kitna, National Football League player\nBULLET::::- Mark Lanegan, singer-songwriter\nBULLET::::- Ron Magers, television news anchor\nBULLET::::- Brian Thompson, actor\nBULLET::::- Mark Pickerel, singer-songwriter acoustic guitar percussionist\nBULLET::::- Stevin John (Blippi), youtube childrens entertainer and educator\n\nBULLET::::- Kirk, Ruth, and Carmela Alexander, (1990, revised edition 1995), \"Exploring Washington's Past\", University of Washington Press, Seattle.\nBULLET::::- Caveness, Andrew. \"Images of America: Ellensburg,\" Arcadia Publishing, Mount Pleasant, S.C., 2009.\n\nBULLET::::- Ellensburg official website\nBULLET::::- Kittitas County Chamber of Commerce\nBULLET::::- Ellensburg Downtown Association\nBULLET::::- Ellensburg Public Library's Historic Local Photograph Collection hosted by the CWU Brooks Library\n"}
{"id": "9623", "url": "https://en.wikipedia.org/wiki?curid=9623", "title": "Eugene, Oregon", "text": "Eugene, Oregon\n\nEugene ( ) is a city in the U.S. state of Oregon, in the Pacific Northwest. It is at the southern end of the verdant Willamette Valley, near the confluence of the McKenzie and Willamette Rivers, about east of the Oregon Coast.\n\nAs of the 2010 census, Eugene had a population of 156,185; it is the state's third most populous city (after Portland and Salem) and the county seat of Lane County. The Eugene-Springfield, Oregon metropolitan statistical area (MSA) is the 146th largest metropolitan statistical area in the US and the third-largest in the state, behind the Portland Metropolitan Area and the Salem Metropolitan Area. The city's population for 2018 was estimated to be 171,245 by the US Census.\n\nEugene is home to the University of Oregon, Northwest Christian University, and Lane Community College. The city is also noted for its natural environment, recreational opportunities (especially bicycling, running/jogging, rafting, and kayaking), and focus on the arts. Eugene's official slogan is \"A Great City for the Arts and Outdoors\". It is also referred to as the \"Emerald City\" and as \"Track Town, USA\". The Nike corporation had its beginnings in Eugene. In 2021, the city will host the 18th Track and Field World Championships.\n\nThe first people to settle in the Eugene area were known as the Kalapuyans, also written Calapooia or Calapooya. They made \"seasonal rounds,\" moving around the countryside to collect and preserve local foods, including acorns, the bulbs of the wapato and camas plants, and berries. They stored these foods in their permanent winter village. When crop activities waned, they returned to their winter villages and took up hunting, fishing, and trading. They were known as the Chifin Kalapuyans and called the Eugene area where they lived \"Chifin\", sometimes recorded as \"Chafin\" or \"Chiffin\".\n\nOther Kalapuyan tribes occupied villages that are also now within Eugene city limits. Pee-you or Mohawk Calapooians, Winefelly or Pleasant Hill Calapooians, and the Lungtum or Long Tom. They were close-neighbors to the Chifin, intermarried, and were political allies. Some authorities suggest the Brownsville Kalapuyans (Calapooia Kalapuyans) were related to the Pee-you. It is likely that since the Santiam had an alliance with the Brownsville Kalapuyans that the Santiam influence also went as far at Eugene.\n\nAccording to archeological evidence, the ancestors of the Kalapuyans may have been in Eugene for as long as 10,000 years. In the 1800s their traditional way of life faced significant changes due to devastating epidemics and settlement, first by French fur traders and later by an overwhelming number of American settlers\n\nFrench fur traders had settled seasonally in the Willamette Valley by the beginning of the 19th century. Their settlements were concentrated in the \"French Prairie\" community in Northern Marion County but may have extended south to the Eugene area. Having already developed relationships with Native communities through intermarriage and trade, they negotiated for land from the Kalapuyans. By 1828 to 1830 they and their Native wives began year-round occupation of the land, raising crops and tending animals. In this process, the mixed race families began to impact Native access to land, food supply, and traditional materials for trade and religious practices.\n\nIn July 1830, \"intermittent fever\" struck the lower Columbia region and a year later, the Willamette Valley. Natives traced the arrival of the disease, then new to the Northwest, to the U.S. ship, Owyhee, captained by John Dominis. \"Intermittent fever\" is thought by researchers now to be malaria. According to Robert T. Boyd, an anthropologist at Portland State University, the first three years of the epidemic, \"probably constitute the single most important epidemiological event in the recorded history of what would eventually become the state of Oregon\". In his book \"The Coming of the Spirit Pestilence\" Boyd reports there was a 92% population loss for the Kalapuyans between 1830 and 1841. This catastrophic event shattered the social fabric of Kalapuyan society and altered the demographic balance in the Valley. This balance was further altered over the next few years by the arrival of Anglo-American settlers, beginning in 1840 with 13 people and growing steadily each year until within 20 years more than 11,000 American settlers, including Eugene Skinner, had arrived.\n\nAs the demographic pressure from the settlers grew, the remaining Kalapuyans were forcibly removed to Indian reservations. Though some Natives escaped being swept into the reservation, most were moved to the Grand Ronde reservation in 1856. Strict racial segregation was enforced and mixed race people, known as Métis in French, had to make a choice between the reservation and Anglo society. Native Americans could not leave the reservation without traveling papers and white people could not enter the reservation.\n\nEugene Franklin Skinner, after whom Eugene is named, arrived in the Willamette Valley in 1846 with 1,200 other settlers that year. Advised by the Kalapuyans to build on high ground to avoid flooding, he erected the first Anglo cabin on south or west slope of what the Kalapuyans called Ya-po-ah. The \"isolated hill\" is now known as Skinner's Butte. The cabin was used as a trading post and was registered as an official post office on January 8, 1850.\n\nAt this time the settlement was known by Anglos as Skinner's Mudhole. It was relocated in 1853 and named Eugene City in 1853. Formally incorporated as a city in 1862, it was named simply Eugene in 1889. Skinner ran a ferry service across the Willamette River where the Ferry Street Bridge now stands.\n\nThe first major educational institution in the area was Columbia College, founded a few years earlier than the University of Oregon. It fell victim to two major fires in four years, and after the second fire, the college decided not to rebuild again. The part of south Eugene known as College Hill was the former location of Columbia College. There is no college there today.\n\nThe town raised the initial funding to start a public university, which later became the University of Oregon, with the hope of turning the small town into a center of learning. In 1872, the Legislative Assembly passed a bill creating the University of Oregon as a state institution. Eugene bested the nearby town of Albany in the competition for the state university. In 1873, community member J.H.D. Henderson donated the hilltop land for the campus, overlooking the city.\n\nThe university first opened in 1876 with the regents electing the first faculty and naming John Wesley Johnson as president. The first students registered on October 16, 1876. The first building was completed in 1877; it was named Deady Hall in honor of the first Board of Regents President and community leader Judge Matthew P. Deady.\n\nEugene grew rapidly throughout most of the twentieth century, with the exception being the early 1980s when a downturn in the timber industry caused high unemployment. By 1985, the industry had recovered and Eugene began to attract more high-tech industries, earning it the moniker the \"Emerald Shire\".\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water. Eugene is at an elevation of .\n\nTo the north of downtown is Skinner Butte. Northeast of the city is the Coburg Hills. Spencer Butte is a prominent landmark south of the city. Mount Pisgah is southeast of Eugene and includes Mount Pisgah Arboretum and Howard Buford Recreation Area, a Lane County Park. Eugene is surrounded by foothills and forests to the south, east, and west, while to the north the land levels out into the Willamette Valley and consists of mostly farmland.\n\nThe Willamette and McKenzie Rivers run through Eugene and its neighboring city, Springfield. Another important stream is Amazon Creek, whose headwaters are near Spencer Butte. The creek discharges west of the city into Fern Ridge Reservoir, maintained for winter flood control by the Army Corps of Engineers. Eugene Yacht Club hosts a sailing school and sailing regattas at Fern Ridge during summer months.\n\nEugene has 23 neighborhood associations:\n\nBULLET::::- Amazon\nBULLET::::- Bethel\nBULLET::::- Cal Young\nBULLET::::- Churchill\nBULLET::::- Crest Drive\nBULLET::::- Downtown\nBULLET::::- Fairmount\nBULLET::::- Far West\nBULLET::::- Friendly\nBULLET::::- Goodpasture Island\nBULLET::::- Harlow\nBULLET::::- Industrial Corridor\nBULLET::::- Jefferson Westside\nBULLET::::- Laurel Hill Valley\nBULLET::::- Northeast\nBULLET::::- River Road\nBULLET::::- Santa Clara (including Irving)\nBULLET::::- South University\nBULLET::::- Southeast\nBULLET::::- Spencer Butte\nBULLET::::- Trainsong\nBULLET::::- West Eugene\nBULLET::::- West University\nBULLET::::- Whiteaker\n\nLike the rest of the Willamette Valley, Eugene lies in the Marine West Coast climate zone, with Mediterranean characteristics. Under the Köppen climate classification scheme, Eugene has a cool-summer Mediterranean climate (Köppen \"Csb\"). Temperatures can vary from cool to warm, with warm, dry summers and cool, wet winters. Spring and fall are also moist seasons, with light rain falling for long periods. The average rainfall is , with the wettest \"rain year\" being from July 1973 to June 1974 with and the driest from July 2000 to June 2001 with . Winter snowfall does occur, but it is sporadic and rarely accumulates in large amounts: the normal seasonal amount is , but the median is zero. The record snowfall was of accumulation due to a pineapple express on January 25–29, 1969. Ice storms, like snowfall, are rare, but occur sporadically.\n\nThe hottest months are July and August, with a normal monthly mean temperature of , with an average of 16 days per year reaching . The coolest month is December, with a mean temperature of , and there are 53 mornings per year with a low at or below freezing, and 2.7 afternoons with highs not exceeding the freezing mark.\n\nEugene's average annual temperature is , and annual precipitation at . Eugene is more wet and slightly cooler on average than Portland. Despite being about south and having only a slightly higher elevation, Eugene has a more continental climate, less subject to the maritime air that blows inland from the Pacific Ocean via the Columbia River. Eugene's normal annual mean minimum is , compared to in Portland; in August, the gap in the normal mean minimum widens to and for Eugene and Portland, respectively. Average winter temperatures (and summer high temperatures) are similar for the two cities. This disparity may be additionally caused by Portland's urban heat island, where the combination of black pavement and urban energy use raises nighttime temperatures.\n\nExtreme temperatures range from , recorded on December 8, 2013, to on August 9, 1981; the record cold daily maximum is , recorded on December 13, 1919, while, conversely, the record warm daily minimum is on July 22, 2006.\n\nEugene is downwind of Willamette Valley grass seed farms. The combination of summer grass pollen and the confining shape of the hills around Eugene make it \"the area of the highest grass pollen counts in the USA (>1,500 pollen grains/m of air).\" These high pollen counts have led to difficulties for some track athletes who compete in Eugene. In the Olympic trials in 1972, \"Jim Ryun won the 1,500 after being flown in by helicopter because he was allergic to Eugene's grass seed pollen.\" Further, six-time Olympian Maria Mutola abandoned Eugene as a training area \"in part to avoid allergies\".\n\nAccording to the 2010 census, Eugene's population was 156,185. The population density was 3,572.2 people per square mile. There were 69,951 housing units at an average density of 1,600 per square mile. Those age 18 and over accounted for 81.8% of the total population.\n\nThe racial makeup of the city was 85.8% White, 4.0% Asian, 1.4% Black or African American, 1.0% Native American, 0.2% Pacific Islander, and 4.7% from other races.\n\nHispanics and Latinos of any race accounted for 7.8% of the total population. Of the non-Hispanics, 82% were White, 1.3% Black or African American, 0.8% Native American, 4% Asian, 0.2% Pacific Islander, 0.2% some other race alone, and 3.4% were of two or more races.\n\nFemales represented 51.1% of the total population, and males represented 48.9%. The median age in the city was 33.8 years.\n\nThe census of 2000 showed there were 137,893 people, 58,110 households, and 31,321 families residing in the city of Eugene. The population density was 3,404.8 people per square mile (1,314.5/km²). There were 61,444 housing units at an average density of 1,516.4 per square mile (585.5/km²). The racial makeup of the city was 88.15% White, down from 99.5% in 1950, 3.57% Asian, 1.25% Black or African American, 0.93% Native American, 0.21% Pacific Islander, 2.18% from other races, and 3.72% from two or more races. 4.96% of the population were Hispanic or Latino of any race.\n\nThere were 58,110 households, of which 25.8% had children under the age of 18 living with them, 40.6% were married couples living together, 9.7% had a female householder with no husband present, and 46.1% were non-families. 31.7% of all households were made up of individuals and 9.4% had someone living alone who was 65 years of age or older. The average household size was 2.27 and the average family size was 2.87. In the city, the population was 20.3% under the age of 18, 17.3% from 18 to 24, 28.5% from 25 to 44, 21.8% from 45 to 64, and 12.1% who were 65 years of age or older. The median age was 33 years. For every 100 females, there were 96.0 males. For every 100 females age 18 and over, there were 94.0 males. The median income for a household in the city was $35,850, and the median income for a family was $48,527. Males had a median income of $35,549 versus $26,721 for females. The per capita income for the city was $21,315. About 8.7% of families and 17.1% of the population were below the poverty line, including 14.8% of those under age 18 and 7.1% of those age 65 or over.\n\nReligious institutions of higher learning in Eugene include Northwest Christian University and New Hope Christian College. Northwest Christian University (formerly Northwest Christian College), founded in 1895, has ties with the Christian Church (Disciples of Christ). New Hope Christian College (formerly Eugene Bible College) originated with the Bible Standard Conference in 1915, which joined with Open Bible Evangelistic Association to create Open Bible Standard Churches in 1932. Eugene Bible College was started from this movement by Fred Hornshuh in 1925.\n\nThere are two Eastern Orthodox Church parishes in Eugene: St John the Wonderworker Orthodox Christian Church in the Historic Whiteaker Neighborhood and Saint George Greek Orthodox Church.\n\nThere are six Roman Catholic parishes in Eugene as well: St. Mary Catholic Church, St. Jude Catholic Church, St. Mark Catholic Church, St. Peter Catholic Church, St. Paul Catholic Church, and St. Thomas More Catholic Church.\n\nEugene also has a Ukrainian Catholic Church named Nativity of the Mother of God.\n\nThere is a mainline Protestant contingency in the city as well—such as the largest of the Lutheran Churches, Central Lutheran near the U of O Campus and the Episcopal Church of the Resurrection.\n\nThe Eugene area has a sizeable LDS Church presence, with three stakes, consisting of 23 congregations (wards and branches). The Portland Oregon Temple is the nearest temple.\n\nThe greater Eugene-Springfield area also has a Jehovah's Witnesses presence with five Kingdom Halls, several having multiple congregations in one Kingdom Hall.\n\nThe Reconstructionist Temple Beth Israel is Eugene's largest Jewish congregation. It was also, for many decades, Eugene's only synagogue, until Orthodox members broke away in 1992 and formed \"Congregation Ahavas Torah\".\n\nEugene has a community of some 140 Sikhs, who have established a Sikh temple.\n\nThe 340-member congregation of the Unitarian Universalist Church in Eugene (UUCE) purchased the former Eugene Scottish Rite Temple in May 2010, renovated it, and began services there in September 2012.\n\nSaraha Nyingma Buddhist Temple in Eugene opened in 2012 in the former site of the Unitarian Universalist Church.\n\nAbout 82% of Eugene residents are eligible voters. Of those registered to vote, about 43% are registered Democrat, 25% Republican, 25% non-affiliated, with about 7% registered to third parties.\n\nEnvironmental activism\n\nIn January 2006, the FBI conducted Operation Backfire, leading to federal indictment of eleven people, all members of a Eugene-based cell of the Earth Liberation Front (ELF). Operation Backfire was the largest investigation into radical underground environmental groups in United States history. Ongoing trials of accused eco-terrorists kept Eugene in the spotlight for a few years.\n\nEugene's largest employers are PeaceHealth Medical Group, the University of Oregon, and the Eugene School District. Eugene's largest industries are wood products manufacturing and recreational vehicle manufacturing.\n\nLuckey's Club Cigar Store is one of the oldest bars in Oregon. Tad Luckey, Sr., purchased it in 1911, making it one of the oldest businesses in Eugene. The \"Club Cigar\", as it was called in the late 19th century, was for many years a men-only salon. It survived both the Great Depression and Prohibition, partly because Eugene was a dry town before the end of Prohibition.\n\nCorporate headquarters for the employee-owned Bi-Mart corporation and family-owned supermarket Market of Choice remain in Eugene. \n\nEugene has quickly made a name for itself as a culinary hub in Oregon. The city has over 25 breweries, offers a variety of fine dining options with a local focus; the city is surrounded by award-winning wineries. The most notable fungi here is the truffle; Eugene hosts the annual Oregon Truffle Festival in January.\n\nOrganically Grown Company, the largest distributor of organic fruits and vegetables in the northwest, started in Eugene in 1978 as a non-profit co-op for organic farmers. Notable local food processors, many of whom manufacture certified organic products, include Golden Temple (Yogi Tea), Merry Hempsters and Springfield Creamery (Nancy's Yogurt & owned by the Kesey Family), and Mountain Rose Herbs.\n\nUntil July 2008, Hynix Semiconductor America had operated a large semiconductor plant in west Eugene. In late September 2009, Uni-Chem of South Korea announced its intention to purchase the Hynix site for solar cell manufacturing. However, this deal fell through and as of late 2012, is no longer planned. In 2015, semiconductor manufacturer Broadcom purchased the plant with plans to upgrade and reopen it. The company abandoned these plans and put it up for sale in November 2016.\n\nThe footwear repair product Shoe Goo is manufactured by Eclectic Products, based in Eugene.\n\nRun Gum, an energy gum created for runners, also began its life in Eugene. Run Gum was created by track athlete Nick Symmonds and track and field coach Sam Lapray in 2014.\n\nBurley Design LLC produces bicycle trailers and was founded in Eugene by Alan Scholz out of a Saturday Market business in 1978. Eugene is also the birthplace and home of Bike Friday bicycle manufacturer Green Gear Cycling.\n\nMany multinational businesses were launched in Eugene. Some of the most famous include Nike, Taco Time, and Brøderbund Software.\n\nIn 2012, the Eugene metro region was dubbed the Silicon Shire for its growing tech industry.\n\nAccording to Eugene's 2017 Comprehensive Annual Financial Report, the city's top employers are:\n\n! #\n! Employer\n! Number of employees\n1\nPeaceHealth Medical Group\n5,808\n2\nUniversity of Oregon\n5,549\n3\nEugene School District 4J\n2,553\n4\nU.S. Government\n1,750\n5\nLane Community College\n1,650\n6\nSpringfield School District\n1,610\n7\nState of Oregon\n1,594\n8\nLane County\n1,567\n9\nCity of Eugene\n1,417\n10\nMcKenzie-Willamette Medical Center\n898\n\nEugene has a significant population of people in pursuit of alternative ideas and a large original hippie population. Beginning in the 1960s, the countercultural ideas and viewpoints espoused by Ken Kesey became established as the seminal elements of the vibrant social tapestry that continue to define Eugene. The Merry Prankster, as Kesey was known, has arguably left the most indelible imprint of any cultural icon in his hometown. He is best known as the author of \"One Flew Over the Cuckoo's Nest\" and as the male protagonist in Tom Wolfe's \"The Electric Kool-Aid Acid Test\".\n\nIn 2005, the city council unanimously approved a new slogan for the city: \"World's Greatest City for the Arts & Outdoors\". While Eugene has a vibrant arts community for a city its size, and is well situated near many outdoor opportunities, this slogan was frequently criticized by locals as embarrassing and ludicrous. In early 2010, the slogan was changed to \"A Great City for the Arts & Outdoors.\"\n\nEugene's Saturday Market, open every Saturday from April through November, was founded in 1970 as the first \"Saturday Market\" in the United States. It is adjacent to the Lane County Farmer's Market in downtown Eugene. All vendors must create or grow all their own products. The market reappears as the \"Holiday Market\" between Thanksgiving and New Year's in the Lane County Events Center at the fairgrounds.\n\nEugene is noted for its \"community inventiveness.\" Many U.S. trends in community development originated in Eugene. The University of Oregon's participatory planning process, known as The Oregon Experiment, was the result of student protests in the early 1970s. The book of the same name is a major document in modern enlightenment thinking in planning and architectural circles. The process, still used by the university in modified form, was created by Christopher Alexander, whose works also directly inspired the creation of the Wiki. Some research for the book \"A Pattern Language\", which inspired the Design Patterns movement and Extreme Programming, was done by Alexander in Eugene. Not coincidentally, those engineering movements also had origins here. Decades after its publication, \"A Pattern Language\" is still one of the best-selling books on urban design.\n\nIn the 1970s, Eugene was packed with cooperative and community projects. It still has small natural food stores in many neighborhoods, some of the oldest student cooperatives in the country, and alternative schools have been part of the school district since 1971. The old Grower's Market, downtown near the Amtrak depot, is the only food cooperative in the U.S. with no employees. It is possible to see Eugene's trend-setting non-profit tendencies in much newer projects, such as the Tango Center and the Center for Appropriate Transport. In 2006, an initiative began to create a tenant-run development process for downtown Eugene.\n\nIn the fall of 2003, neighbors noticed \"an unassuming two-acre remnant orchard tucked into the Friendly Area Neighborhood\" had been put up for sale by its owner, a resident of New York City. Learning a prospective buyer had plans to build several houses on the property, they formed a nonprofit organization called Madison Meadow in June 2004 in order to buy the property and \"preserve it as undeveloped space in perpetuity.\" In 2007 their effort was named Third Best Community Effort by the \"Eugene Weekly\", and by the end of 2008 they had raised enough money to purchase the property.\n\nThe City of Eugene has an active Neighborhood Program. Several neighborhoods are known for their green activism. Friendly Neighborhood has a highly popular neighborhood garden established on the right of way of a street never built. There are a number of community gardens on public property. Amazon Neighborhood has a former church turned into a community center. Whiteaker hosts a housing co-op that dates from the early 1970s that has re-purposed both their parking lots into food production and play space. An unusual eco-village with natural building techniques and large shared garden can be found in Jefferson Westside neighborhood. A several block area in the River Road Neighborhood is known as a permaculture hotspot with an increasing number of suburban homes trading grass for garden, installing rain water catchment systems, food producing landscapes and solar retrofits. Several sites have planted gardens by removing driveways. Citizen volunteers are working with the City of Eugene to restore a 65-tree filbert grove on public property. There are deepening social and economic networks in the neighborhood.\n\nBULLET::::- Asian Celebration, presented by the Asian Council of Eugene and Springfield, takes place in February at the Lane County Fairgrounds.\nBULLET::::- The KLCC Microbrew Festival is held in February at the Lane County Fairgrounds. It provides participants with an introduction to a large range of microbrewery and craft beers, which play an important role in Pacific Northwest culture and the economy.\nBULLET::::- Mount Pisgah Arboretum, which resides at the base of Mount Pisgah, holds a Wildflower Festival in May and a Mushroom Festival and Plant Sale in October.\nBULLET::::- Oregon Festival of American Music, or OFAM is held annually in the early summer.\nBULLET::::- Art and the Vineyard festival, held around the Fourth of July at Alton Baker Park, is the principal fundraiser for the Maude Kerns Art Center.\nBULLET::::- The Oregon Bach Festival is a major international festival in July, hosted by the University of Oregon.\nBULLET::::- The nonprofit Oregon Country Fair takes place in July in nearby Veneta.\nBULLET::::- The Lane County Fair occurs in July at the Lane County Fairgrounds.\nBULLET::::- The Eugene/Springfield Pride Festival is held annually on the second Saturday in August from noon to 7:00 p.m. at Alton Baker Park. A part of Eugene LGBT culture since 1993, it provides a lighthearted and supportive social venue for the LGBT community, families, and friends.\nBULLET::::- Eugene Celebration is a three-day block party that usually takes place in the downtown area in August or September. The SLUG Queen coronation in August, a pageant with a campy spin, crowns a new SLUG Queen who \"rains\" over the Eugene Celebration Parade and is an unofficial ambassador of Eugene.\n\nEugene museums include the University of Oregon's Jordan Schnitzer Museum of Art and Museum of Natural and Cultural History, the Oregon Air and Space Museum, Lane County History Museum, Maude Kerns Art Center, Shelton McMurphey Johnson House, and the Eugene Science Center.\n\nEugene is home to numerous cultural organizations, including the Eugene Symphony, the Eugene Ballet, the Eugene Opera, the Eugene Concert Choir, the Northwest Christian University Community Choir, the Oregon Mozart Players, the Oregon Bach Festival, the Oregon Children's Choir, the Eugene-Springfield Youth Orchestras, Ballet Fantastique and Oregon Festival of American Music. Principal performing arts venues include the Hult Center for the Performing Arts, The John G. Shedd Institute for the Arts (\"The Shedd\"), Matthew Knight Arena, Beall Concert Hall and the Erb Memorial Union ballroom on the University of Oregon campus, the McDonald Theatre, and W.O.W. Hall.\n\nA number of live theater groups are based in Eugene, including Free Shakespeare in the Park, Oregon Contemporary Theatre, The Very Little Theatre, Actors Cabaret, LCC Theatre, Rose Children's Theatre, and University Theatre. Each has its own performance venue.\n\nBecause of its status as a college town, Eugene has been home to many music genres, musicians and bands, ranging from electronic dance music such as dubstep and drum and bass to garage rock, hip hop, folk and heavy metal. Eugene also has a growing reggae and street-performing bluegrass and jug band scene. Multi-genre act the Cherry Poppin' Daddies became a prominent figure in Eugene's music scene and became the house band at Eugene's W.O.W. Hall. In the late 1990s, their contributions to the swing revival movement propelled them to national stardom. Rock band Floater originated in Eugene as did the Robert Cray blues band. Doom metal band YOB is among the leaders of the Eugene heavy music scene.\n\nEugene is home to \"Classical Gas\" Composer and two-time Grammy award winner Mason Williams who spent his years as a youth living between his parents in Oakridge, Oregon and Oklahoma. Mason Williams puts on a yearly Christmas show at the Hult center for performing arts with a full orchestra produced by author, audio engineer and University of Oregon professor Don Latarski.\n\nDick Hyman, noted jazz pianist and musical director for many of Woody Allen's films, designs and hosts the annual Now Hear This! jazz festival at the Oregon Festival of American Music (OFAM). OFAM and the Hult Center routinely draw major jazz talent for concerts.\n\nEugene is also home to a large Zimbabwean music community. Kutsinhira Cultural Arts Center, which is \"dedicated to the music and people of Zimbabwe,\" is based in Eugene.\n\nEugene's visual arts community is supported by over 20 private art galleries and several organizations, including Maude Kerns Art Center, Lane Arts Council, DIVA (the Downtown Initiative for the Visual Arts) and the Eugene Glass School.\n\nIn 2015 installations from a group of Eugene-based artists known as Light At Play were showcased in several events around the world as part of the International Year of Light, including displays at the Smithsonian and the National Academy of Sciences.\n\nThe Eugene area has been used as a filming location for several Hollywood films, most famously for 1978's \"National Lampoon's Animal House\", which was also filmed in nearby Cottage Grove. John Belushi had the idea for the film \"The Blues Brothers\" during filming of \"Animal House\" when he happened to meet Curtis Salgado at what was then the Eugene Hotel.\n\n\"Getting Straight\", starring Elliott Gould and Candice Bergen, was filmed at Lane Community College in 1969. As the campus was still under construction at the time, the \"occupation scenes\" were easier to shoot.\n\nThe \"Chicken Salad on Toast\" scene in the 1970 Jack Nicholson movie \"Five Easy Pieces\" was filmed at the Denny's restaurant at the southern I-5 freeway interchange near Glenwood. Nicholson directed the 1971 film \"Drive, He Said\" in Eugene.\n\n\"How to Beat the High Co$t of Living\", starring Jane Curtin, Jessica Lange and Susan St. James, was filmed in Eugene in the fall of 1979. Locations visible in the film include Valley River Center (which is a driving force in the plot), Skinner Butte and Ya-Po-Ah Terrace, the Willamette River and River Road Hardware.\n\nSeveral track and field movies have used Eugene as a setting and/or a filming location. \"Personal Best\", starring Mariel Hemingway, was filmed in Eugene in 1982. The film centered on a group of women who are trying to qualify for the Olympic track and field team. Two track and field movies about the life of Steve Prefontaine, \"Prefontaine\" and \"Without Limits\", were released within a year of each other in 1997–1998. Kenny Moore, Eugene-trained Olympic runner and co-star in \"Prefontaine\", co-wrote the screenplay for \"Without Limits\". \"Prefontaine\" was filmed in Washington because the \"Without Limits\" production bought out Hayward Field for the summer to prevent its competition from shooting there. Kenny Moore also wrote a biography of Bill Bowerman, played in \"Without Limits\" by Donald Sutherland back in Eugene 20 years after he had appeared in \"Animal House\". Moore had also had a role in \"Personal Best\".\n\n\"Stealing Time\", a 2003 independent film, was partially filmed in Eugene. When the film premiered in June 2001 at the Seattle International Film Festival, it was titled \"Rennie's Landing\" after a popular bar near the University of Oregon campus. The title was changed for its DVD release. \"Zerophilia\" was filmed in Eugene in 2006.\n\nEugene's Oregon Ducks are part of the Pac-12 Conference (Pac-12). American football is especially popular, with intense rivalries between the Ducks and both the Oregon State University Beavers and the University of Washington Huskies. Autzen Stadium is home to Duck football, with a seating capacity of 54,000 but has had over 60,000 with standing room only.\n\nThe basketball arena, McArthur Court, was built in 1926. The arena was replaced by the Matthew Knight Arena in late 2010.\n\nFor nearly 40 years, Eugene has been the \"Track and Field Capital of the World.\" Oregon's most famous track icon is the late world-class distance runner Steve Prefontaine, who was killed in a car crash in 1975.\n\nEugene's jogging trails include Pre's Trail in Alton Baker Park, Rexius Trail, the Adidas Oregon Trail, and the Ridgeline Trail. Jogging was introduced to the U.S. through Eugene, brought from New Zealand by Bill Bowerman, who wrote the best-selling book \"Jogging\", and coached the champion University of Oregon track and cross country teams. During Bowerman's tenure, his \"Men of Oregon\" won 24 individual NCAA titles, including titles in 15 out of the 19 events contested. During Bowerman's 24 years at Oregon, his track teams finished in the top ten at the NCAA championships 16 times, including four team titles (1962, '64, '65, '70), and two second-place trophies. His teams also posted a dual meet record of 114–20.\n\nBowerman also invented the waffle sole for running shoes in Eugene, and with Oregon alumnus Phil Knight founded shoe giant Nike. Eugene's miles of running trails, through its unusually large park system, are the most extensive in the U.S. The city has dozens of running clubs. The climate is cool and temperate, good both for jogging and record-setting. Eugene is home to the University of Oregon's Hayward Field track, which hosts numerous collegiate and amateur track and field meets throughout the year, most notably the Prefontaine Classic. Hayward Field was host to the 2004 AAU Junior Olympic Games, the 1989 World Masters Athletics Championships, the track and field events of the 1998 World Masters Games, the 2006 Pacific-10 track and field championships, the 1971, 1975, 1986, 1993, 1999, 2001, 2009, and 2011 USA Track & Field Outdoor Championships and the 1972, 1976, 1980, 2008, 2012, and 2016 U.S. Olympic trials.\n\nOn April 16, 2015, it was announced by the IAAF that Eugene had been awarded the right to host the 2021 World Athletics Championships. The city bid for the 2019 event but lost narrowly to Doha, Qatar.\n\nEugene is also home to the Eugene Emeralds, a short-season Class A minor-league baseball team. The \"Ems\" play their home games in PK Park, also the home of the University of Oregon baseball team.\n\nThe Nationwide Tour's golfing event Oregon Classic takes place at Shadow Hills Country Club, just north of Eugene. The event has been played every year since 1998, except in 2001 when it was slated to begin the day after the 9/11 terrorist attacks. The top 20 players from the Nationwide Tour are promoted to the PGA Tour for the following year.\n\nThe Eugene Jr. Generals, a Tier III Junior \"A\" ice hockey team belonging to the Northern Pacific Hockey League (NPHL) consisting of 8 teams throughout Oregon and Washington, plays at the Lane County Ice Center.\n\nThe following table lists some sports clubs in Eugene and their usual home venue:\n\n!style=\"text-align:left; width:16%;\"Club\n!style=\"text-align:left; width:32%;\"Sport\n!style=\"text-align:left;\"Founded\n!style=\"text-align:left;\"League\n!style=\"text-align:left;\"Venue\nstyle=\"\"University of Oregon Ducks\nstyle=\"text-align:left;\"Football, Basketball, Track and Field, Softball, Volleyball, Golf, Tennis, Baseball, Lacrosse, Ice hockey, Soccer, Ultimate\nstyle=\"text-align:left;\"1876\nstyle=\"text-align:left;\"National Collegiate Athletic Association: Pac-12 Conference\nstyle=\"text-align:left;\"Autzen Stadium, Matthew Knight Arena, PK Park, Hayward Field\nstyle=\"\"Northwest Christian University Beacons\nstyle=\"text-align:left;\"Basketball, Cross Country, Distance Track, Golf, Soccer, Volleyball\nstyle=\"text-align:left;\"1895\nstyle=\"text-align:left;\"National Association of Intercollegiate Athletics, Cascade Collegiate Conference\nstyle=\"text-align:left;\"Morse Event Center\nstyle=\"\"New Hope Christian College Deacons\nstyle=\"text-align:left;\"Basketball, Soccer, Volleyball\nstyle=\"text-align:left;\"1925\nstyle=\"text-align:left;\"\nstyle=\"text-align:left;\"Rexius Event Center\nstyle=\"\"Eugene Emeralds\nstyle=\"text-align:left;\"Baseball\nstyle=\"text-align:left;\"1955\nstyle=\"text-align:left;\"Northwest League\nstyle=\"text-align:left;\"PK Park\nstyle=\"\"Lane Community College Titans\nstyle=\"text-align:left;\"Basketball, Cross Country, Track and Field, Soccer, Baseball\nstyle=\"text-align:left;\"1965\nstyle=\"text-align:left;\"Northwest Athletic Association of Community Colleges\nstyle=\"text-align:left;\"Lane Community College\nstyle=\"\"Eugene Gentlemen\nstyle=\"text-align:left;\"Rugby\nstyle=\"text-align:left;\"1973\nstyle=\"text-align:left;\"Pacific Northwest Rugby Football Union\nstyle=\"text-align:left;\"\nstyle=\"\"Eugene Chargers\nstyle=\"text-align:left;\"Basketball\nstyle=\"text-align:left;\"2006\nstyle=\"text-align:left;\"International Basketball League\nstyle=\"text-align:left;\"Morse Event Center\nstyle=\"\"Eugene Generals\nstyle=\"text-align:left;\"Ice hockey\nstyle=\"text-align:left;\"2005\nstyle=\"text-align:left;\"Junior A Tier III-League Hockey: Northern Pacific Hockey League\nstyle=\"text-align:left;\"Lane County Ice Center\nstyle=\"\"Lane United FC\nstyle=\"text-align:left;\"Soccer\nstyle=\"text-align:left;\"2013\nstyle=\"text-align:left;\"USL Premier Development League\nstyle=\"text-align:left;\" Willamalane Center\n\nSpencer Butte Park at the southern edge of town provides access to Spencer Butte, a dominant feature of Eugene's skyline. Hendricks Park, situated on a knoll to the east of downtown, is known for its rhododendron garden and nearby memorial to Steve Prefontaine, known as Pre's Rock, where the legendary University of Oregon runner was killed in an auto accident. Alton Baker Park, next to the Willamette River, contains Pre's Trail. Also next to the Willamette are Skinner Butte Park and the Owen Memorial Rose Garden, which is home to more than 4,500 roses of over 400 varieties, as well as the 150-year-old Black Tartarian Cherry tree, an Oregon Heritage Tree.\n\nThe city of Eugene maintains an urban forest. The University of Oregon campus is an arboretum, with over 500 species of trees. The city operates and maintains scenic hiking trails that pass through and across the ridges of a cluster of hills in the southern portion of the city, on the fringe of residential neighborhoods. Some trails allow biking, and others are for hikers and runners only.\n\nThe nearest ski resort, Willamette Pass, is one hour from Eugene by car. On the way, along Oregon Route 58, are several reservoirs and lakes, the Oakridge mountain bike trails, hot springs, and waterfalls within Willamette National Forest. Eugene residents also frequent the Hoodoo and Mount Bachelor ski resorts. The Three Sisters Wilderness, the Oregon Dunes National Recreation Area, and Smith Rock are just a short drive away.\n\nIn 1944, Eugene adopted a council-manager form of government, replacing the day-to-day management of city affairs by the part-time mayor and volunteer city council with a full-time professional city manager. The subsequent history of Eugene city government has largely been one of the dynamics—often contentious—between the city manager, the mayor and city council.\n\nThe mayor of Eugene is Lucy Vinis, who has been in office since winning the popular vote in 2017. Recent mayors include Edwin Cone (1958–69), Les Anderson (1969–77) Gus Keller (1977–84), Brian Obie (1985–88), Jeff Miller (1989–92), Ruth Bascom (1993–96), Jim Torrey (1997–2004) and Kitty Piercy (2005-2017).\n\nJon Ruiz has been the city manager since April 2008. Ten other people have held the city manager position. They were: Deane Seeger (1945–49), Oren King (1949–53), Robert Finlayson (1953–59), Hugh McKinley (1959–75), Charles Henry (1975–80), Mike Gleason (1981–96), Vicki Elmer (1996–98), Jim Johnson (1998–2002), Dennis Taylor (2002–2007), Angel Jones (2007–2008).\n\nMayor: Lucy Vinis\nBULLET::::- Ward 1 – Emily Semple\nBULLET::::- Ward 2 – Betty Taylor\nBULLET::::- Ward 3 – Alan Zelenka\nBULLET::::- Ward 4 – Jennifer Yeh\nBULLET::::- Ward 5 – Mike Clark\nBULLET::::- Ward 6 – Greg Evans\nBULLET::::- Ward 7 – Claire Syrett\nBULLET::::- Ward 8 – Chris Pryor\n\nThe Eugene Police Department (EPD) is the city's law enforcement and public safety agency. The Lane County Sheriff's Office also has its headquarters in Eugene.\nThe University of Oregon is served by the University of Oregon Police Department (UOPD), and EPD has a police station in the West University District near campus. Lane Community College is served by the Lane Community College Public Safety Department. The Oregon State Police have a presence in the rural areas and highways around the Eugene metro area. The LTD downtown station, and the EmX lines are patrolled by LTD Transit Officers.\n\nEugene City Hall was abandoned in 2012 for reasons of structural integrity, energy efficiency, and obsolete size. Various offices of city government became tenants in eight other buildings.\n\nEugene is home to the University of Oregon. Other institutions of higher learning include Northwest Christian University, Lane Community College, New Hope Christian College, Gutenberg College, and Pacific University's Eugene campus.\n\nThe Eugene School District includes four full-service high schools (Churchill, North Eugene, Sheldon, and South Eugene) and many alternative education programs, such as international schools and charter schools. Foreign language immersion programs in the district are available in Spanish, French, Chinese, and Japanese.\n\nThe Bethel School District serves children in the Bethel neighborhood on the northwest edge of Eugene. The district is home to the traditional Willamette High School and the alternative Kalapuya High School. There are 11 schools in this district.\n\nEugene also has several private schools, including the Eugene Waldorf School, the Outdoor High School, Eugene Montessori, Far Horizon Montessori, Eugene Sudbury School, Wellsprings Friends School, Oak Hill School, and The Little French School.\n\nParochial schools in Eugene include Marist Catholic High School, O'Hara Catholic Elementary School, Eugene Christian School, and St. Paul Parish School.\n\nThe largest library in Oregon is the University of Oregon's Knight Library, with collections totaling more than 3 million volumes and over 100,000 audio and video items. The Eugene Public Library moved into a new, larger building downtown in 2002. The four-story library is an increase from . There are also two branches of the Eugene Public Library, the Sheldon Branch Library in the neighborhood of Cal Young/Sheldon, and the Bethel Branch Library, in the neighborhood of Bethel. Eugene also has the Lane County Law Library.\n\nThe largest newspaper serving the area is \"The Register-Guard\", a daily newspaper with a circulation of about 70,000, published independently by the Baker family of Eugene until 2018, before being acquired by GateHouse Media. Other newspapers serving the area include the \"Eugene Weekly\", the \"Emerald\", the student-run independent newspaper at the University of Oregon, now published on Mondays and Thursdays;\"The Torch\", the student-run newspaper at Lane Community College, the \"Ignite\", the newspaper at New Hope Christian College and \"The Beacon Bolt,\" the student-run newspaper at Northwest Christian University. \"Eugene Magazine\", \"Lifestyle Quarterly\", \"Eugene Living\", and \"Sustainable Home and Garden\" magazines also serve the area. \"Adelante Latino\" is a Spanish language newspaper in Eugene that serves all of Lane County.\n\nLocal television stations include KMTR (NBC), KVAL (CBS), KLSR-TV (Fox), KEVU-CD, KEZI (ABC), KEPB (PBS), and KTVC (independent).\nBULLET::::- KEZI (Channel 9) (ABC)\nBULLET::::- KVAL (Channel 13) (CBS)\nBULLET::::- KMTR (Channel 16) (NBC)\nBULLET::::- KEVU-CD (Channel 23)\nBULLET::::- KEPB (Channel 28) (PBS)\nBULLET::::- KLSR (Channel 34) (Fox)\nBULLET::::- KTVC (Channel 36) (Independent)\nBULLET::::- KHWB-LD (Channel 38) (TBN)\n\nThe local NPR affiliates are KOPB, and KLCC. Radio station KRVM-AM is an affiliate of Jefferson Public Radio, based at Southern Oregon University. The Pacifica Radio affiliate is the University of Oregon student-run radio station, KWVA. Additionally, the community supports two other radio stations: KWAX (classical) and KRVM-FM (alternative).\n\nAM Stations\nBULLET::::- KOAC 550 Corvallis – NPR News/Talk (Oregon Public Broadcasting)\nBULLET::::- KUGN 590 Eugene – NEWS/TALK (Cumulus)\nBULLET::::- KXOR 660 Junction City – Spanish Religious (Zion Media)\nBULLET::::- KKNX 840 Eugene – Oldies (Willamette Media Group)\nBULLET::::- KORE 1050 Springfield – FOX Sports Radio\nBULLET::::- KPNW 1120 Eugene – NEWS/TALK (Bicostal Media)\nBULLET::::- KRVM 1280 Eugene – NPR News/Talk (Eugene School District) (JPR affiliate)\nBULLET::::- KSCR 1320 Eugene – Business Radio (Cumulus)\nBULLET::::- KNND 1400 Cottage Grove – Oldies (Swartzberg Communications Inc)\nBULLET::::- KEED 1450 Eugene – Comedy (Eugene Comedy Radio)\nBULLET::::- KOPB 1600 Eugene – NPR News/Talk (Oregon Public Broadcasting)\n\nFM Stations\nBULLET::::- KWVA 88.1 Eugene – Freeform (University of Oregon)\nBULLET::::- KPIJ 88.5 Junction City – Christian (Calvary Satellite Network) (Calvary Chapel)\nBULLET::::- KQFE 88.9 Springfield – Christian (Family Radio)\nBULLET::::- KLCC 89.7 Eugene – NPR News/Talk/Jazz (Lane Community College)\nBULLET::::- KWAX 91.1 Eugene – Classical (University of Oregon)\nBULLET::::- KRVM 91.9 Eugene – Adult Album Alternative (AAA) (Eugene School District)\nBULLET::::- KKNU 93.3 Springfield – Country (McKenzie River Broadcasting)\nBULLET::::- KMGE 94.5 Eugene – Adult Contemporary (McKenzie River Broadcasting)\nBULLET::::- KUJZ 95.3 Creswell – Sports (Cumulus)\nBULLET::::- KZEL 96.1 Eugene – Classic Rock (Cumulus)\nBULLET::::- KEPW 97.3 Eugene - PeaceWorks Community Radio (Eugene PeaceWorks)\nBULLET::::- KEQB 97.7 Colburg - Regional Mexican (McKenzie River Broadcasting)\nBULLET::::- KODZ 99.1 Eugene – Classic Hits (Bicoastal Media)\nBULLET::::- KRKT 99.9 Albany – Country (Bicoastal Media)\nBULLET::::- KMME 100.5 Cottage Grove – Catholic Program (Catholic Radio Northwest)\nBULLET::::- KFLY 101.5 Corvallis - Country (Bicoastal Media)\nBULLET::::- KEHK 102.3 Brownsville – Hot Adult Contemporary (Cumulus)\nBULLET::::- KNRQ 103.7 Eugene – Alternative Rock (Cumulus)\nBULLET::::- KDUK 104.7 Florence – Top 40 (CHR) (Bicoastal Media)\nBULLET::::- KEUG 105.5 Veneta – Adult Hits (McKenzie River Broadcasting)\nBULLET::::- KLOO 106.3 Corvallis – Classic Rock (Bicoastal Media)\nBULLET::::- KLVU 107.1 Sweet Home – Contemporary Christian Music (K-LOVE) Educational Media Foundation\nBULLET::::- KHPE 107.9 Albany – Contemporary Christian Music (Extra Mile Media)\n\nLane Transit District (LTD), a public transportation agency formed in 1970, covers of Lane County, including Creswell, Cottage Grove, Junction City, Veneta, and Blue River. Operating more than 90 buses during peak hours, LTD carries riders on 3.7 million trips every year. LTD also operates a bus rapid transit line that runs between Eugene and Springfield—Emerald Express (EmX)—much of which runs in its own lane, with stations providing for off-board fare payment. LTD's main terminus in Eugene is at the Eugene Station. LTD also offers paratransit.\n\nCycling is popular in Eugene and many people commute via bicycle. Summertime events and festivals frequently have bike parking \"corrals\" that are often filled to capacity by three hundred or more bikes. Many people commute to work by bicycle every month of the year. Bike trails take commuting and recreational bikers along the Willamette River past a scenic rose garden, along Amazon Creek, through the downtown, and through the University of Oregon campus.\n\nIn 2009, the League of American Bicyclists cited Eugene as 1 of 10 \"Gold-level\" cities in the U.S. because of its \"remarkable commitments to bicycling.\" In 2010, \"Bicycling\" magazine named Eugene the 5th most bike-friendly city in America. The U.S. Census Bureau's annual American Community Survey reported that Eugene had a bicycle commuting mode share of 7.3% in 2011, the fifth highest percentage nationwide among U.S. cities with 65,000 people or more, and 13 times higher than the national average of 0.56%.\n\nThe 1908 Amtrak depot downtown was restored in 2004; it is the southern terminus for two daily runs of the Amtrak \"Cascades\", and a stop along the route in each direction for the daily \"Coast Starlight\".\n\nAir travel is served by the Eugene Airport, also known as Mahlon Sweet Field, which is the fifth largest airport in the Northwest and second largest airport in Oregon. The Eugene Metro area also has numerous private airports. The Eugene Metro area also has several heliports, such as the Sacred Heart Medical Center Heliport and Mahlon Sweet Field Heliport, and many single helipads.\n\nHighways traveling within and through Eugene include:\nBULLET::::- Interstate 5: Interstate 5 forms much of the eastern city limit, acting as an effective, though unofficial boundary between Eugene and Springfield. To the north, I-5 leads to the Willamette Valley and Portland. To the south, I-5 leads to Roseburg, Medford, and the southwestern portion of the state. In full, Interstate 5 continues north to the Canada–US border at Blaine, Washington and Vancouver, British Columbia and extends south to the Mexico–US border at Tijuana and San Diego.\nBULLET::::- Officer Chris Kilcullen Memorial Highway: Oregon Route 126 is routed along the Eugene-Springfield Highway, a limited-access freeway. The Eugene portion of this highway begins at an interchange with Interstate 5 and ends two miles (3 km) west at a freeway terminus. This portion of Oregon Route 126 is also signed Interstate 105, a spur route of Interstate 5. Oregon Route 126 continues west, a portion shared with Oregon Route 99, and continues west to Florence. Eastward, Oregon Route 126 crosses the Cascades and leads to central and eastern Oregon.\nBULLET::::- Randy Papé Beltline: Beltline is a limited-access freeway which runs along the northern and western edges of incorporated Eugene.\nBULLET::::- Delta Highway: The Delta Highway forms a connector of less than between Interstate 105 and Beltline Highway.\nBULLET::::- Oregon Route 99: Oregon Route 99 forks off Interstate 5 south of Eugene, and forms a major surface artery in Eugene. It continues north into the Willamette valley, parallel to I-5. It is sometimes called the \"scenic route\" since it has a great view of the Coast Range and also stretches through many scenic farmlands of the Willamette Valley.\n\nEugene is the home of Oregon's largest publicly owned water and power utility, the Eugene Water & Electric Board (EWEB). EWEB got its start in the first decade of the 20th century, after an epidemic of typhoid found in the groundwater supply. The City of Eugene condemned Eugene's private water utility and began treating river water (first the Willamette; later the McKenzie) for domestic use. EWEB got into the electric business when power was needed for the water pumps. Excess electricity generated by the EWEB's hydropower plants was used for street lighting.\n\nNatural gas service is provided by NW Natural.\n\nWastewater treatment services are provided by the Metropolitan Wastewater Management Commission, a partnership between the Cities of Eugene and Springfield and Lane County.\n\nThree hospitals serve the Eugene-Springfield area. Sacred Heart Medical Center University District is the only one within Eugene city limits. McKenzie-Willamette Medical Center and Sacred Heart Medical Center at RiverBend are in Springfield. Oregon Medical Group, a primary care based multi-specialty group, operates several clinics in Eugene, as does PeaceHealth Medical Group. White Bird Clinic provides a broad range of health and human services, including low-cost clinics. The Volunteers in Medicine & Occupy Medical clinics provide free medical and mental care to low-income adults without health insurance.\n\nEugene is one of the few municipalities in the US that does not fluoridate its water supply.\n\nEugene has four sister cities:\n\nBULLET::::- Kathmandu, Nepal\nBULLET::::- Irkutsk, Russia\nBULLET::::- Kakegawa, Shizuoka Prefecture, Japan\nBULLET::::- Jinju, South Gyeongsang, South Korea\n\nBULLET::::- Stan Bettis, \"Market Days; An Informal History of the Eugene Producers' Public Market.\" Eugene, OR: Lane Pomona Grange Fraternal Society, 1969.\n\nBULLET::::- Official website\nBULLET::::- Entry for Eugene in the \"Oregon Blue Book\"\nBULLET::::- \"Eugene Register-Guard,\" Google news archive.\n"}
{"id": "9627", "url": "https://en.wikipedia.org/wiki?curid=9627", "title": "Elizabeth Barrett Browning", "text": "Elizabeth Barrett Browning\n\nElizabeth Barrett Browning (née Moulton-Barrett, ; 6 March 1806 – 29 June 1861) was an English poet of the Victorian era, popular in Britain and the United States during her lifetime.\n\nBorn in County Durham, the eldest of 12 children, Elizabeth Barrett wrote poetry from the age of eleven. Her mother's collection of her poems forms one of the largest extant collections of juvenilia by any English writer. At 15 she became ill, suffering intense head and spinal pain for the rest of her life. Later in life she also developed lung problems, possibly tuberculosis. She took laudanum for the pain from an early age, which is likely to have contributed to her frail health. \n\nIn the 1840s Elizabeth was introduced to literary society through her cousin, John Kenyon. Her first adult collection of poems was published in 1838 and she wrote prolifically between 1841 and 1844, producing poetry, translation and prose. She campaigned for the abolition of slavery and her work helped influence reform in the child labour legislation. Her prolific output made her a rival to Tennyson as a candidate for poet laureate on the death of Wordsworth.\n\nElizabeth's volume \"Poems\" (1844) brought her great success, attracting the admiration of the writer Robert Browning. Their correspondence, courtship and marriage were carried out in secret, for fear of her father's disapproval. Following the wedding she was indeed disinherited by her father. The couple moved to Italy in 1846, where she would live for the rest of her life. They had one son, Robert Wiedeman Barrett Browning, whom they called Pen. She died in Florence in 1861. A collection of her last poems was published by her husband shortly after her death.\n\nElizabeth's work had a major influence on prominent writers of the day, including the American poets Edgar Allan Poe and Emily Dickinson. She is remembered for such poems as \"How Do I Love Thee?\" (Sonnet 43, 1845) and \"Aurora Leigh \"(1856).\n\nSome of Elizabeth Barrett's family had lived in Jamaica since 1655. Their wealth derived mainly from Edward Barrett (1734–1798), owner of in the estates of Cinnamon Hill, Cornwall, Cambridge and Oxford in northern Jamaica. Elizabeth's maternal grandfather owned sugar plantations, mills, glassworks and ships that traded between Jamaica and Newcastle. Biographer Julia Markus states the poet \"believed that she had African blood through her grandfather Charles Moulton\", but there is no evidence of this – although other branches of her family had African blood through relationships between plantation owners and slaves. What the family believed to be their genealogy in relation to Jamaica is unclear.\n\nThe family wished to hand down their name, stipulating that Barrett should always be held as a surname. In some cases inheritance was given on condition that the name was used by the beneficiary; the English gentry and \"squirearchy\" had long encouraged this sort of name changing. Given this strong tradition, Elizabeth used \"Elizabeth Barrett Moulton Barrett\" on legal documents and before she was married often signed herself \"Elizabeth Barrett Barrett\" or \"EBB\" (initials which she was able to keep after her wedding).\n\nElizabeth's father chose to raise his family in England while his business enterprises remained in Jamaica. The fortune of Elizabeth's mother's line, the Graham Clarke family, also derived in part from slave labour, and was considerable.\n\nElizabeth Barrett Moulton-Barrett was born on 6 March 1806, in Coxhoe Hall, between the villages of Coxhoe and Kelloe in County Durham, England. Her parents were Edward Barrett Moulton Barrett and Mary Graham Clarke; Elizabeth was the eldest of 12 children (eight boys and four girls). All lived to adulthood except for one girl, who died at the age of three, when Elizabeth was eight.\n\nThe children all had nicknames: Elizabeth was \"Ba\". She rode her pony, went for family walks and picnics, socialised with other county families, and participated in home theatrical productions. But unlike her siblings, she immersed herself in books as often as she could get away from the social rituals of her family.\n\nShe was baptized in 1809 at Kelloe parish church, although she had already been baptised by a family friend in her first week of life.\n\nIn 1809, the family moved to Hope End, a estate near the Malvern Hills in Ledbury, Herefordshire. Her father converted the Georgian house into stables and built a new mansion of opulent Turkish design, which his wife described as something from the \"Arabian Nights Entertainments\".\n\nThe interior's brass balustrades, mahogany doors inlaid with mother-of-pearl, and finely carved fireplaces were eventually complemented by lavish landscaping: ponds, grottos, kiosks, an ice house, a hothouse, and a subterranean passage from house to gardens. Her time at Hope End would inspire her in later life to write her most ambitious work, \"Aurora Leigh\" (1856), which went through more than 20 editions by 1900, but none between 1905 and 1978.\n\nShe was educated at home and tutored by Daniel McSwiney with her oldest brother. She began writing verses at the age of four. During the Hope End period, she was an intensely studious, precocious child. She claimed that at the age of six she was reading novels, at eight entranced by Pope's translations of Homer, studying Greek at ten, and at eleven writing her own Homeric epic, \"\".\n\nIn 1820 Mr Barrett privately published \"The Battle of Marathon\", an epic-style poem, though all copies remained within the family. Her mother compiled the child's poetry into collections of \"Poems by Elizabeth B. Barrett\". Her father called her the \"Poet Laureate of Hope End\" and encouraged her work. The result is one of the largest collections of juvenilia of any English writer. Mary Russell Mitford described the young Elizabeth at this time, as having \"a slight, delicate figure, with a shower of dark curls falling on each side of a most expressive face; large, tender eyes, richly fringed by dark eyelashes, and a smile like a sunbeam.\"\n\nAt about this time, Elizabeth began to battle with illness, which the medical science of the time was unable to diagnose. All three sisters came down with the syndrome although it lasted only with Elizabeth. She had intense head and spinal pain with loss of mobility. Various biographies link this to a riding accident at the time (she fell while trying to dismount a horse), but there is no evidence to support the link. Sent to recover at the Gloucester spa, she was treated – in the absence of symptoms supporting another diagnosis – for a spinal problem. Though this illness continued for the rest of her life, it is believed to be unrelated to the lung disease which she developed in 1837.\n\nShe began to take opiates for the pain, laudanum (an opium concoction) followed by morphine, then commonly prescribed. She would become dependent on them for much of her adulthood; the use from an early age may well have contributed to her frail health. Biographers such as Alethea Hayter have suggested this may also have contributed to the wild vividness of her imagination and the poetry that it produced.\n\nBy 1821 she had read Mary Wollstonecraft's \"A Vindication of the Rights of Woman\" (1792), and become a passionate supporter of Wollstonecraft's ideas. The child's intellectual fascination with the classics and metaphysics was reflected in a religious intensity which she later described as \"not the deep persuasion of the mild Christian but the wild visions of an enthusiast.\" The Barretts attended services at the nearest Dissenting chapel, and Edward was active in Bible and Missionary societies.\n\nElizabeth's mother died in 1828, and is buried at St Michael's Church, Ledbury, next to her daughter Mary. Sarah Graham-Clarke, Elizabeth's aunt, helped to care for the children, and she had clashes with Elizabeth's strong will. In 1831 Elizabeth's grandmother, Elizabeth Moulton, died. Following lawsuits and the abolition of slavery Mr Barrett incurred great financial and investment losses that forced him to sell Hope End. Although the family was never poor, the place was seized and put up for sale to satisfy creditors. Always secret in his financial dealings, he would not discuss his situation and the family was haunted by the idea that they might have to move to Jamaica.\n\nBetween 1833 and 1835, she was living, with her family, at Belle Vue in Sidmouth. The site has now been renamed Cedar Shade and redeveloped. A blue plaque at the entrance to the site attests to this. In 1838, some years after the sale of Hope End, the family settled at 50 Wimpole Street.\n\nDuring 1837–38 the poet was struck with illness again, with symptoms today suggesting tuberculous ulceration of the lungs. That same year, at her physician's insistence, she moved from London to Torquay, on the Devonshire coast. Two tragedies then struck. In February 1840 her brother Samuel died of a fever in Jamaica. Then her favourite brother Edward (\"Bro\") was drowned in a sailing accident in Torquay in July. This had a serious effect on her already fragile health. She felt guilty as her father had disapproved of Edward's trip to Torquay. She wrote to Mitford, \"That was a very near escape from madness, absolute hopeless madness\". The family returned to Wimpole Street in 1841.\n\nAt Wimpole Street Barrett Browning spent most of her time in her upstairs room. Her health began to improve, though she saw few people other than her immediate family. One of those was Kenyon, a wealthy friend of the family and patron of the arts. She received comfort from a spaniel named Flush, a gift from Mary Mitford. (Virginia Woolf later fictionalised the life of the dog, making him the protagonist of her 1933 novel \"\").\n\nBetween 1841 and 1844 Barrett Browning was prolific in poetry, translation and prose. The poem \"The Cry of the Children\", published in 1842 in \"Blackwoods\", condemned child labour and helped bring about child-labour reforms by raising support for Lord Shaftesbury's Ten Hours Bill (1844). At about the same time, she contributed critical prose pieces to Richard Henry Horne's \"A New Spirit of the Age\".\n\nIn 1844 she published two volumes of \"Poems\", which included \"A Drama of Exile\", \"A Vision of Poets\", and \"Lady Geraldine's Courtship\" and two substantial critical essays for 1842 issues of \"The Athenaeum\". \"Since she was not burdened with any domestic duties expected of her sisters, Barrett Browning could now devote herself entirely to the life of the mind, cultivating an enormous correspondence, reading widely\". Her prolific output made her a rival to Tennyson as a candidate for poet laureate in 1850 on the death of Wordsworth.\n\nA Royal Society of Arts blue plaque now commemorates Elizabeth at 50 Wimpole Street.\n\nHer 1844 volume \"Poems\" made her one of the most popular writers in the country, and inspired Robert Browning to write to her. He wrote, \"I love your verses with all my heart, dear Miss Barrett,\" praising their \"fresh strange music, the affluent language, the exquisite pathos and true new brave thought.\"\n\nKenyon arranged for Browning to meet Elizabeth on 20 May 1845, in her rooms, and so began one of the most famous courtships in literature. Elizabeth had already produced a large amount of work, but Browning had a great influence on her subsequent writing, as did she on his: two of Barrett's most famous pieces were written after she met Browning, \"Sonnets from the Portuguese\" and \"Aurora Leigh.\" Robert's \"Men and Women\" is also a product of that time.\n\nSome critics state that her activity was, in some ways, in decay before she met Browning: \"Until her relationship with Robert Browning began in 1845, Barrett's willingness to engage in public discourse about social issues and about aesthetic issues in poetry, which had been so strong in her youth, gradually diminished, as did her physical health. As an intellectual presence and a physical being, she was becoming a shadow of herself.\"\n\nThe courtship and marriage between Robert Browning and Elizabeth were carried out secretly, as she knew her father would disapprove. After a private marriage at St Marylebone Parish Church, they honeymooned in Paris before moving to Italy, in September 1846, which became their home almost continuously until her death. Elizabeth's loyal nurse, Wilson, who witnessed the marriage, accompanied the couple to Italy.\n\nMr Barrett disinherited Elizabeth, as he did each of his children who married. Elizabeth had foreseen her father's anger but had not anticipated her brothers' rejection. As Elizabeth had some money of her own, the couple were reasonably comfortable in Italy. The Brownings were well respected, and even famous. Elizabeth grew stronger and in 1849, at the age of 43, between four miscarriages, she gave birth to a son, Robert Wiedeman Barrett Browning, whom they called Pen. Their son later married, but had no legitimate children.\n\nAt her husband's insistence, Elizabeth's second edition of \"Poems\" included her love sonnets; as a result, her popularity increased (as well as critical regard), and her artistic position was confirmed.\n\nThe couple came to know a wide circle of artists and writers including William Makepeace Thackeray, sculptor Harriet Hosmer (who, she wrote, seemed to be the \"perfectly emancipated female\") and Harriet Beecher Stowe. In 1849 she met Margaret Fuller, and the female French novelist George Sand in 1852, whom she had long admired. Among her intimate friends in Florence was the writer Isa Blagden, whom she encouraged to write novels. They met Alfred Tennyson in Paris, and John Forster, Samuel Rogers and the Carlyles in London, later befriending Charles Kingsley and John Ruskin.\n\nAfter the death of an old friend, G. B. Hunter, and then of her father, Barrett Browning's health started to deteriorate. The Brownings moved from Florence to Siena, residing at the \"Villa Alberti\". Engrossed in Italian politics, she issued a small volume of political poems titled \"Poems before Congress\" (1860) \"most of which were written to express her sympathy with the Italian cause after the outbreak of fighting in 1859\". They caused a furore in England, and the conservative magazines \"Blackwood's\" and the \"Saturday Review\" labelled her a fanatic. She dedicated this book to her husband. Her last work was \"A Musical Instrument\", published posthumously.\n\nBarrett Browning's sister Henrietta died in November 1860. The couple spent the winter of 1860–61 in Rome where Barrett Browning's health further deteriorated and they returned to Florence in early June 1861. She became gradually weaker, using morphine to ease her pain. She died on 29 June 1861 in her husband<nowiki>'s arms. Browning said that she died \"smilingly, happily, and with a face like a girl's... Her last word was... \"</nowiki>Beautiful\". She was buried in the Protestant English Cemetery of Florence. \"On Monday July 1 the shops in the area around Casa Guidi were closed, while Elizabeth was mourned with unusual demonstrations.\" The nature of her illness is still unclear. Some modern scientists speculate her illness may have been hypokalemic periodic paralysis, a genetic disorder that causes weakness and many of the other symptoms she described.\n\nBarrett Browning's first known poem was written at the age of six or eight, \"On the Cruelty of Forcement to Man\". The manuscript, which protests against impressment, is currently in the Berg Collection of the New York Public Library; the exact date is controversial because the \"2\" in the date 1812 is written over something else that is scratched out.\n\nHer first independent publication was \"Stanzas Excited by Reflections on the Present State of Greece\" in \"The New Monthly Magazine\" of May 1821; followed two months later by \"Thoughts Awakened by Contemplating a Piece of the Palm which Grows on the Summit of the Acropolis at Athens\".\n\nHer first collection of poems, \"An Essay on Mind, with Other Poems,\" was published in 1826 and reflected her passion for Byron and Greek politics. Its publication drew the attention of a blind scholar of the Greek language, Hugh Stuart Boyd, and of another Greek scholar, Uvedale Price, with whom she maintained sustained correspondence. Among other neighbours was Mrs James Martin from Colwall, with whom she also corresponded throughout her life. Later, at Boyd's suggestion, she translated Aeschylus' \"Prometheus Bound\" (published in 1833; retranslated in 1850). During their friendship Barrett studied Greek literature, including Homer, Pindar and Aristophanes.\n\nElizabeth opposed slavery and published two poems highlighting the barbarity of slavers and her support for the abolitionist cause: \"The Runaway Slave at Pilgrim's Point\"; and \"A Curse for a Nation\". In \"Runaway\" she describes a slave woman who is whipped, raped, and made pregnant as she curses the slavers. Elizabeth declared herself glad that the slaves were \"virtually free\" when the Emancipation Act abolishing slavery in British colonies was passed in 1833, despite the fact that her father believed that Abolitionism would ruin his business.\n\nThe date of publication of these poems is in dispute, but her position on slavery in the poems is clear and may have led to a rift between Elizabeth and her father. She wrote to John Ruskin in 1855 \"I belong to a family of West Indian slaveholders, and if I believed in curses, I should be afraid\". After the Jamaican slave uprising of 1831–32, her father and uncle continued to treat the slaves humanely.\n\nIn London, John Kenyon, a distant cousin, introduced Elizabeth to literary figures including William Wordsworth, Mary Russell Mitford, Samuel Taylor Coleridge, Alfred Tennyson and Thomas Carlyle. Elizabeth continued to write, contributing \"The Romaunt of Margaret\", \"The Romaunt of the Page\", \"The Poet's Vow\" and other pieces to various periodicals. She corresponded with other writers, including Mary Russell Mitford, who would become a close friend and who would support Elizabeth's literary ambitions.\n\nIn 1838 \"The Seraphim and Other Poems\" appeared, the first volume of Elizabeth's mature poetry to appear under her own name.\n\n\"Sonnets from the Portuguese\" was published in 1850. There is debate about the origin of the title. Some say it refers to the series of sonnets of the 16th-century Portuguese poet Luís de Camões. However, \"my little Portuguese\" was a pet name that Browning had adopted for Elizabeth and this may have some connection.\n\nThe verse-novel \"Aurora Leigh,\" her most ambitious and perhaps the most popular of her longer poems, appeared in 1856. It is the story of a female writer making her way in life, balancing work and love, and based on Elizabeth's own experiences. \"Aurora Leigh\" was an important influence on Susan B. Anthony's thinking about the traditional roles of women, with regard to marriage versus independent individuality. The \"North American Review\" praised Elizabeth's poem: \"Mrs. Browning's poems are, in all respects, the utterance of a woman — of a woman of great learning, rich experience, and powerful genius, uniting to her woman's nature the strength which is sometimes thought peculiar to a man.\"\n\nMuch of Barrett Browning's work carries a religious theme. She had read and studied such works as Milton's \"Paradise Lost\" and Dante's \"Inferno\". She says in her writing, \"We want the sense of the saturation of Christ's blood upon the souls of our poets, that it may cry through them in answer to the ceaseless wail of the Sphinx of our humanity, expounding agony into renovation. Something of this has been perceived in art when its glory was at the fullest. Something of a yearning after this may be seen among the Greek Christian poets, something which would have been much with a stronger faculty\". She believed that \"Christ's religion is essentially poetry – poetry glorified\". She explored the religious aspect in many of her poems, especially in her early work, such as the sonnets.\n\nShe was interested in theological debate, had learned Hebrew and read the Hebrew Bible. Her seminal \"Aurora Leigh\", for example, features religious imagery and allusion to the apocalypse. The critic Cynthia Scheinberg notes that female characters in \"Aurora Leigh\" and her earlier work \"The Virgin Mary to the Child Jesus\" allude to the female character Miriam from the Hebrew Bible. These allusions to Miriam in both poems mirror the way in which Barrett Browning herself drew from Jewish history, while distancing herself from it, in order to maintain the public appearance of a Christian woman poet of the Victorian Age.\n\nIn the correspondence Barrett Browning kept with the Reverend William Merry from 1843 to 1844 on predestination and salvation by works, she identifies herself as a Congregationalist: \"I am not a Baptist — but a Congregational Christian, — in the holding of my private opinions.\"\n\nIn 1892, Ledbury, Herefordshire, held a design competition to build an Institute in honour of Barrett Browning. Brightwen Binyon beat 44 other designs. It was based on the timber-framed Market House, which was opposite the site. It was completed in 1896. However, Nikolaus Pevsner was not impressed by its style. In 1938, it became a public library. It has been Grade II-listed since 2007.\n\nBarrett Browning was widely popular in the United Kingdom and the United States during her lifetime. Edgar Allan Poe was inspired by her poem \"Lady Geraldine's Courtship\" and specifically borrowed the poem's metre for his poem \"The Raven\". Poe had reviewed Barrett Browning's work in the January 1845 issue of the \"Broadway Journal\", saying that \"her poetic inspiration is the highest – we can conceive of nothing more august. Her sense of Art is pure in itself.\" In return, she praised \"The Raven\", and Poe dedicated his 1845 collection \"The Raven and Other Poems\" to her, referring to her as \"the noblest of her sex\".\n\nBarrett Browning's poetry greatly influenced Emily Dickinson, who admired her as a woman of achievement. Her popularity in the United States and Britain was further advanced by her stands against social injustice, including slavery in the United States, injustice toward Italian citizens by foreign rulers, and child labour.\n\nLilian Whiting published a biography of Barrett Browning (1899) which describes her as \"the most philosophical poet\" and depicts her life as \"a Gospel of applied Christianity\". To Whiting, the term \"art for art's sake\" did not apply to Barrett Browning's work, as each poem, distinctively purposeful, was borne of a more \"honest vision\". In this critical analysis, Whiting portrays Barrett Browning as a poet who uses knowledge of Classical literature with an \"intuitive gift of spiritual divination\". In \"Elizabeth Barrett Browning\", Angela Leighton suggests that the portrayal of Barrett Browning as the \"pious iconography of womanhood\" has distracted us from her poetic achievements. Leighton cites the 1931 play by Rudolf Besier, \"The Barretts of Wimpole Street\", as evidence that 20th-century literary criticism of Barrett Browning's work has suffered more as a result of her popularity than poetic ineptitude. The play was popularized by actress Katharine Cornell, for whom it became a signature role. It was an enormous success, both artistically and commercially, and was revived several times and adapted twice into movies.\n\nThroughout the 20th century, literary criticism of Barrett Browning's poetry remained sparse until her poems were discovered by the women's movement. She once described herself as being inclined to reject several women's rights principles, suggesting in letters to Mary Russell Mitford and her husband that she believed that there was an inferiority of intellect in women. In \"Aurora Leigh\", however, she created a strong and independent woman who embraces both work and love. Leighton writes that because Elizabeth participates in the literary world, where voice and diction are dominated by perceived masculine superiority, she \"is defined only in mysterious opposition to everything that distinguishes the male subject who writes...\" A five-volume scholarly edition of her works was published in 2010, the first in over a century.\n\nBULLET::::- 1820: \"\". Privately printed\nBULLET::::- 1826: \"An Essay on Mind, with Other Poems\". London: James Duncan\nBULLET::::- 1833: \"Prometheus Bound, Translated from the Greek of Aeschylus, and Miscellaneous Poems\". London: A.J. Valpy\nBULLET::::- 1838: \"The Seraphim, and Other Poems\". London: Saunders and Otley\nBULLET::::- 1844: \"Poems\" (UK) / \"A Drama of Exile, and other Poems\" (US). London: Edward Moxon. New York: Henry G. Langley\nBULLET::::- 1850: \"Poems\" (\"New Edition\", 2 vols.) Revision of 1844 edition adding \"Sonnets from the Portuguese\" and others. London: Chapman & Hall\nBULLET::::- 1851: \"Casa Guidi Windows\". London: Chapman & Hall\nBULLET::::- 1853: \"Poems\" (3d ed.). London: Chapman & Hall\nBULLET::::- 1854: \"Two Poems\": \"A Plea for the Ragged Schools of London\" and \"The Twins\". London: Bradbury & Evans\nBULLET::::- 1856: \"Poems\" (4th ed.). London: Chapman & Hall\nBULLET::::- 1856: \"Aurora Leigh\". London: Chapman & Hall\nBULLET::::- 1860: \"Poems Before Congress\". London: Chapman & Hall\nBULLET::::- 1862: \"Last Poems\". London: Chapman & Hall\n\nBULLET::::- 1863: \"The Greek Christian Poets and the English Poets\". London: Chapman & Hall\nBULLET::::- 1877: \"The Earlier Poems of Elizabeth Barrett Browning,\" 1826–1833, ed. Richard Herne Shepherd. London: Bartholomew Robson\nBULLET::::- 1877: \"Letters of Elizabeth Barrett Browning Addressed to Richard Hengist Horne, with comments on contemporaries,\" 2 vols., ed. S.R.T. Mayer. London: Richard Bentley & Son\nBULLET::::- 1897: \"Letters of Elizabeth Barrett Browning,\" 2 vols., ed. Frederic G. Kenyon. London:Smith, Elder,& Co.\nBULLET::::- 1899: \"Letters of Robert Browning and Elizabeth Barrett Barrett 1845–1846,\" 2 vol., ed Robert W. Barrett Browning. London: Smith, Elder & Co.\nBULLET::::- 1914: \"New Poems by Robert Browning and Elizabeth Barrett Browning,\" ed. Frederic G Kenyon. London: Smith, Elder & Co.\nBULLET::::- 1929: \"Elizabeth Barrett Browning: Letters to Her Sister, 1846–1859,\" ed. Leonard Huxley. London: John Murray\nBULLET::::- 1935: \"Twenty-Two Unpublished Letters of Elizabeth Barrett Browning and Robert Browning to Henrietta and Arabella Moulton Barrett\". New York: United Feature Syndicate\nBULLET::::- 1939: \"Letters from Elizabeth Barrett to B.R. Haydon,\" ed. Martha Hale Shackford. New York: Oxford University Press\nBULLET::::- 1954: \"Elizabeth Barrett to Miss Mitford,\" ed. Betty Miller. London: John Murray\nBULLET::::- 1955: \"Unpublished Letters of Elizabeth Barrett Browning to Hugh Stuart Boyd,\" ed. Barbara P. McCarthy. New Heaven, Conn.: Yale University Press\nBULLET::::- 1958: \"Letters of the Brownings to George Barrett,\" ed. Paul Landis with Ronald E. Freeman. Urbana: University of Illinois Press\nBULLET::::- 1974: \"Elizabeth Barrett Browning's Letters to Mrs. David Ogilvy,\" 1849–1861, ed. P. Heydon and P. Kelley. New York: Quadrangle, New York Times Book Co., and Browning Institute\nBULLET::::- 1984: \"The Brownings' Correspondence,\" ed. Phillip Kelley, Ronald Hudson, and Scott Lewis. Winfield, Kansas: Wedgestone Press\n\nBULLET::::- Barrett, Robert Assheton. \"The Barretts of Jamaica – The family of Elizabeth Barrett Browning\" (1927). Armstrong Browning Library of Baylor University, Browning Society, Wedgestone Press in Winfield, Kan, 2000.\nBULLET::::- Elizabeth Barrett Browning. \"Aurora Leigh and Other Poems\", eds. John Robert Glorney Bolton and Julia Bolton Holloway. Harmondsworth: Penguin, 1995.\nBULLET::::- Donaldson, Sandra, et al., eds. \"The Works of Elizabeth Barrett Browning.\" 5 vols. London: Pickering & Chatto, 2010.\nBULLET::::- \"The Complete Works of Elizabeth Barrett Browning\", eds. Charlotte Porter and Helen A. Clarke. New York: Thomas Y. Crowell, 1900.\nBULLET::::- Creston, Dormer. \"Andromeda in Wimpole Street: The Romance of Elizabeth Barrett Browning\". London: Eyre & Spottiswoode, 1929.\nBULLET::::- Everett, Glenn. \"Life of Elizabeth Browning\". The Victorian Web 2002.\nBULLET::::- Forster, Margaret. \"\". New York: Random House, Vintage Classics, 2004.\nBULLET::::- Hayter, Alethea. \"Elizabeth Barrett Browning\" (published for the British Council and the National Book League). London: Longmans, Green & Co., 1965.\nBULLET::::- Kaplan, Cora. \"Aurora Leigh and Other Poems\". London: The Women's Press Limited, 1978.\nBULLET::::- Kelley, Philip et al. (Eds.) \"The Brownings' Correspondence\". 26 vols. to date. (Wedgestone, 1984–) (Complete letters of Elizabeth Barrett Browning and Robert Browning, so far to 1859.)\nBULLET::::- Lewis, Linda. \"Elizabeth Barrett Browning's Spiritual Progress\". Missouri: Missouri University Press. 1997.\nBULLET::::- Mander, Rosalie. \"Mrs Browning: The Story of Elizabeth Barrett\". London: Weidenfeld and Nicolson, 1980.\nBULLET::::- Marks, Jeannette. \"The Family of the Barrett: A Colonial Romance\". London: Macmillan, 1938.\nBULLET::::- Markus, Julia. \"Dared and Done: Marriage of Elizabeth Barrett and Robert Browning\". Ohio University Press, 1995.\nBULLET::::- Meyers, Jeffrey. \"Edgar Allan Poe: His Life and Legacy\". New York City: Cooper Square Press, 1992: 160.\nBULLET::::- Peterson, William S. \"Sonnets from the Portuguese\". Massachusetts: Barre Publishing, 1977\nBULLET::::- Pollock, Mary Sanders. \"Elizabeth Barrett and Robert Browning: A Creative Partnership\". England: Ashgate Publishing Company, 2003.\nBULLET::::- Sova, Dawn B. \"Edgar Allan Poe: A to Z.\" New York City: Checkmark Books, 2001\nBULLET::::- Stephenson Glennis. \"Elizabeth Barrett Browning and the Poetry of Love\". Ann Arbor: UMI Research Press, 1989.\nBULLET::::- Taplin, Gardner B. \"The Life of Elizabeth Browning\". New Haven: Yale University Press, 1957.\nBULLET::::- Thomas, Dwight and David K. Jackson. \"The Poe Log: A Documentary Life of Edgar Allan Poe, 1809–1849\". New York: G. K. Hall & Co., 1987: 591.\nBULLET::::- Works of Elizabeth Barrett Browning at Online Books Page\nBULLET::::- Profile of Elizabeth Barrett Browning at PoetryFoundation.org\nBULLET::::- Elizabeth Barrett Browning profile and poems at Poets.org\nBULLET::::- The Brownings: A Research Guide (Baylor University)\nBULLET::::- Browning Family Collection at the Harry Ransom Center at The University of Texas at Austin\nBULLET::::- Digitized Browning love letters at Baylor University\nBULLET::::- Elizabeth Barrett Browning at the British Library\nBULLET::::- www.florin.ms, website on Florence's 'English' Cemetery, with Elizabeth Barrett Browning's tomb by Frederick, Lord Leighton.\n"}
{"id": "9628", "url": "https://en.wikipedia.org/wiki?curid=9628", "title": "Enlil", "text": "Enlil\n\nEnlil, later known as Elil, is an ancient Mesopotamian god associated with wind, air, earth, and storms. He is first attested as the chief deity of the Sumerian pantheon, but he was later worshipped by the Akkadians, Babylonians, Assyrians, and Hurrians. Enlil's primary center of worship was the Ekur temple in the city of Nippur, which was believed to have been built by Enlil himself and was regarded as the \"mooring-rope\" of heaven and earth. He is also sometimes referred to in Sumerian texts as Nunamnir. According to one Sumerian hymn, Enlil himself was so holy that not even the other gods could look upon him. Enlil rose to prominence during the twenty-fourth century BC with the rise of Nippur. His cult fell into decline after Nippur was sacked by the Elamites in 1230 BC and he was eventually supplanted as the chief god of the Mesopotamian pantheon by the Babylonian national god Marduk. The Babylonian god Bel was a syncretic deity of Enlil, Marduk, and the dying-and-rising/resurrection deity Dumuzid.\n\nEnlil plays a vital role in the Sumerian creation myth; he separates An (heaven) from Ki (earth), thus making the world habitable for humans. In the Sumerian flood myth, Enlil rewards Ziusudra with immortality for having survived the flood and, in the Babylonian flood myth, Enlil is the cause of the flood himself, having sent the flood to exterminate the human race, who made too much noise and prevented him from sleeping. The myth of \"Enlil and Ninlil\" is about Enlil's serial seduction of the goddess Ninlil in various guises, resulting in the conception of the moon-god Nanna and the Underworld deities Nergal, Ninazu, and Enbilulu. Enlil was regarded as the inventor of the mattock and the patron of agriculture. Enlil also features prominently in several myths involving his son Ninurta, including \"Anzû and the Tablet of Destinies\" and \"Lugale\".\n\nEnlil's name comes from ancient Sumerian EN, meaning \"lord\" and LÍL meaning \"wind\". His name therefore literally translates as \"Lord Wind\". Enlil's name is not a genitive construction, indicating that Enlil was seen as the personification of the wind itself rather than merely the cause of wind.\n\nEnlil was the patron god of the Sumerian city-state of Nippur and his main center of worship was the Ekur temple located there. The name of the temple literally means \"Mountain House\" in ancient Sumerian. The Ekur was believed to have been built and established by Enlil himself. It was believed to be the \"mooring-rope\" of heaven and earth, meaning that it was seen as \"a channel of communication between earth and heaven\". A hymn written during the reign of Ur-Nammu, the founder of the Third Dynasty of Ur, describes the E-kur in great detail, stating that its gates were carved with scenes of Imdugud, a lesser deity sometimes shown as a giant bird, slaying a lion and an eagle snatching up a sinner.\n\nThe Sumerians believed that the sole purpose of humanity's existence was to serve the gods. They thought that a god's statue was a physical embodiment of the god himself. As such, cult statues were given constant care and attention and a set of priests were assigned to tend to them. People worshipped Enlil by offering food and other human necessities to him. The food, which was ritually laid out before the god's cult statue in the form of a feast, was believed to be Enlil's daily meal, but, after the ritual, it would be distributed among his priests. These priests were also responsible for changing the cult statue's clothing.\n\nThe Sumerians envisioned Enlil as a benevolent, fatherly deity, who watches over humanity and cares for their well-being. One Sumerian hymn describes Enlil as so glorious that even the other gods could not look upon him. The same hymn also states that, without Enlil, civilization could not exist. Enlil's epithets include titles such as \"the Great Mountain\" and \"King of the Foreign Lands\". Enlil is also sometimes described as a \"raging storm\", a \"wild bull\", and a \"merchant\". The Mesopotamians envisioned him as a creator, a father, a king, and the supreme lord of the universe. He was also known as \"Nunamnir\" and is referred to in at least one text as the \"East Wind and North Wind\".\n\nKings regarded Enlil as a model ruler and sought to emulate his example. Enlil was said to be supremely just and intolerant towards evil. Rulers from all over Sumer would travel to Enlil's temple in Nippur to be legitimized. They would return Enlil's favor by devoting lands and precious objects to his temple as offerings. Nippur was the only Sumerian city-state that never built a palace; this was intended to symbolize the city's importance as the center of the cult of Enlil by showing that Enlil himself was the city's king. Even during the Babylonian Period, when Marduk had superseded Enlil as the supreme god, Babylonian kings still traveled to the holy city of Nippur to seek recognition of their right to rule.\n\nEnlil first rose to prominence during the twenty-fourth century BC, when the importance of the god An began to wane. During this time period, Enlil and An are frequently invoked together in inscriptions. Enlil remained the supreme god in Mesopotamia throughout the Amorite Period, with Amorite monarchs proclaiming Enlil as the source of their legitimacy. Enlil's importance began to wane after the Babylonian king Hammurabi conquered Sumer. The Babylonians worshipped Enlil under the name \"Elil\" and the Hurrians syncretized him with their own god Kumarbi. In one Hurrian ritual, Enlil and Apantu are invoked as \"the father and mother of Išḫara\". Enlil is also invoked alongside Ninlil as a member of \"the mighty and firmly established gods\".\n\nDuring the Kassite Period ( 1592 BC – 1155 BC), Nippur briefly managed to regain influence in the region and Enlil rose to prominence once again. From around 1300 BC onwards, Enlil was syncretized with the Assyrian national god Aššur, who was the most important deity in the Assyrian pantheon. Then, in 1230 BC, the Elamites attacked Nippur and the city fell into decline, taking the cult of Enlil along with it. Approximately one hundred years later, Enlil's role as the head of the pantheon was given to Marduk, the national god of the Babylonians. Enlil's importance in the pantheon significantly declined and he was sometimes assimilated as merely an aspect of Marduk. Nonetheless, his temples continued functioning throughout the Neo-Assyrian period (911 BC — 609 BC) and even the Babylonians saw Anu and Enlil as the ones who bestowed Marduk with his powers. During the first millennium BC, the Babylonians worshipped a deity under the title \"Bel\", meaning \"lord\", who was a syncretization of Enlil, Marduk, and the dying god Dumuzid. Bel held all the cultic titles of Enlil and his status in the Babylonian religion was largely the same. Eventually, Bel came to be seen as the god of order and destiny. Meanwhile, Aššur continued to be known as \"the Assyrian Enlil\" or \"the Enlil of the gods\". After the collapse of the Neo-Assyrian Empire, Enlil's statues were smashed and his temples were destroyed because he had become inextricably associated with the Assyrians, who many conquered peoples hated. Enlil continued to be venerated under the name of Marduk until around 141 BC, when the cult of Marduk fell into terminal decline, and was eventually forgotten entirely.\n\nEnlil was not represented anthropomorphically in Mesopotamian iconography. Instead, he was represented by a horned cap, which consisted of up to seven superimposed pairs of ox-horns. Such crowns were an important symbol of divinity; gods had been shown wearing them ever since the third millennium BC. The horned cap remained consistent in form and meaning from the earliest days of Sumerian prehistory up until the time of the Persian conquest and beyond.\n\nThe Sumerians had a complex numerological system, in which certain numbers were believed to hold special ritual significance. Within this system, Enlil was associated with the number fifty, which was considered sacred to him. Enlil was part of a triad of deities, which also included An and Enki. These three deities together were the embodiment of all the fixed stars in the night sky. An was identified with all the stars of the equatorial sky, Enlil with those of the northern sky, and Enki with those of the southern sky. The path of Enlil's celestial orbit was a continuous, symmetrical circle around the north celestial pole, but those of An and Enki were believed to intersect at various points. Enlil was associated with the constellation Boötes.\n\nThe main source of information about the Sumerian creation myth is the prologue to the epic poem \"Gilgamesh, Enkidu, and the Netherworld\" (ETCSL 1.8.1.4), which briefly describes the process of creation: originally, there was only Nammu, the primeval sea. Then, Nammu gave birth to An, the sky, and Ki, the earth. An and Ki mated with each other, causing Ki to give birth to Enlil. Enlil separated An from Ki and carried off the earth as his domain, while An carried off the sky.\n\n\"Enlil and Ninlil\" (ETCSL 1.2.1) is a nearly complete 152-line Sumerian poem describing the affair between Enlil and the goddess Ninlil. First, Ninlil's mother Nunbarshegunu instructs Ninlil to go bathe in the river. Ninlil goes to the river, where Enlil seduces her and impregnates her with their son, the moon-god Nanna. Because of this, Enlil is banished to Kur, the Sumerian underworld. Ninlil follows Enlil to the underworld, where he impersonates the \"man of the gate\". Ninlil demands to know where Enlil has gone, but Enlil, still impersonating the gatekeeper, refuses to answer. He then seduces Ninlil and impregnates her with Nergal, the god of death. The same scenario repeats, only this time Enlil instead impersonates the \"man of the river of the nether world, the man-devouring river\"; once again, he seduces Ninlil and impregnates her with the god Ninazu. Finally, Enlil impersonates the \"man of the boat\"; once again, he seduces Ninlil and impregnates her with Enbilulu, the \"inspector of the canals\".\n\nThe story of Enlil's courtship with Ninlil is primarily a genealogical myth invented to explain the origins of the moon-god Nanna, as well as the various gods of the Underworld, but it is also, to some extent, a coming-of-age story describing Enlil and Ninlil's emergence from adolescence into adulthood. The story also explains Ninlil's role as Enlil's consort; in the poem, Ninlil declares, \"As Enlil is your master, so am I also your mistress!\" The story is also historically significant because, if the current interpretation of it is correct, it is the oldest known myth in which a god changes shape.\n\nIn the Sumerian version of the flood story (ETCSL 1.7.4), the causes of the flood are unclear because the portion of the tablet recording the beginning of the story has been destroyed. Somehow, a mortal known as Ziusudra manages to survive the flood, likely through the help of the god Enki. The tablet begins in the middle of the description of the flood. The flood lasts for seven days and seven nights before it subsides. Then, Utu, the god of the Sun, emerges. Ziusudra opens a window in the side of the boat and falls down prostrate before the god. Next, he sacrifices an ox and a sheep in honor of Utu. At this point, the text breaks off again. When it picks back up, Enlil and An are in the midst of declaring Ziusudra immortal as an honor for having managed to survive the flood. The remaining portion of the tablet after this point is destroyed.\n\nIn the later Akkadian version of the flood story, recorded in the \"Epic of Gilgamesh\", Enlil actually causes the flood, seeking to annihilate every living thing on earth because the humans, who are vastly overpopulated, make too much noise and prevent him from sleeping. In this version of the story, the hero is Utnapishtim, who is warned ahead of time by Ea, the Babylonian equivalent of Enki, that the flood is coming. The flood lasts for seven days; when it ends, Ishtar, who had mourned the destruction of humanity, promises Utnapishtim that Enlil will never cause a flood again. When Enlil sees that Utnapishtim and his family have survived, he is outraged, but his son Ninurta speaks up in favor of humanity, arguing that, instead of causing floods, Enlil should simply ensure that humans never become overpopulated by reducing their numbers using wild animals and famines. Enlil goes into the boat; Utnapishtim and his wife bow before him. Enlil, now appeased, grants Utnapishtim immortality as a reward for his loyalty to the gods.\n\nA nearly complete 108-line poem from the Early Dynastic Period ( 2900 – 2350 BC) describes Enlil's invention of the mattock, a key agricultural pick, hoe, ax, or digging tool of the Sumerians. In the poem, Enlil conjures the mattock into existence and decrees its fate. The mattock is described as gloriously beautiful; it is made of pure gold and has a head carved from lapis lazuli. Enlil gives the tool over to the humans, who use it to build cities, subjugate their people, and pull up weeds. Enlil was believed to aid in the growth of plants.\n\nThe Sumerian poem \"Enlil Chooses the Farmer-God\" (ETCSL 5.3.3) describes how Enlil, hoping \"to establish abundance and prosperity\", creates two gods Emesh and Enten, a shepherd and a farmer, respectively. The two gods argue and Emesh lays claim to Enten's position. They take the dispute before Enlil, who rules in favor of Enten; the two gods rejoice and reconcile.\n\nIn the Sumerian poem \"Lugale\" (ETCSL 1.6.2), Enlil gives advice to his son, the god Ninurta, advising him on a strategy to slay the demon Asag. This advice is relayed to Ninurta by way of Sharur, his enchanted talking mace, which had been sent by Ninurta to the realm of the gods to seek counsel from Enlil directly.\n\nIn the Old, Middle, and Late Babylonian myth of \"Anzû and the Tablet of Destinies\", the Anzû, a giant, monstrous bird, betrays Enlil and steals the Tablet of Destinies, a sacred clay tablet belonging to Enlil that grants him his authority, while Enlil is preparing for a bath. The rivers dry up and the gods are stripped of their powers. The gods send Adad, Gerra, and Shara to defeat the Anzû, but all of them fail. Finally, Ea proposes that the gods should send Ninurta, Enlil's son. Ninurta successfully defeats the Anzû and returns the Tablet of Destinies to his father. As a reward, Ninurta is a granted a prominent seat on the council of the gods.\n\nA badly damaged text from the Neo-Assyrian Period (911 — 612 BC) describes Marduk leading his army of Anunnaki into the sacred city of Nippur and causing a disturbance. The disturbance causes a flood, which forces the resident gods of Nippur under the leadership of Enlil to take shelter in the Eshumesha temple to Ninurta. Enlil is enraged at Marduk's transgression and orders the gods of Eshumesha to take Marduk and the other Anunnaki as prisoners. The Anunnaki are captured, but Marduk appoints his front-runner Mushteshirhablim to lead a revolt against the gods of Eshumesha and sends his messenger Neretagmil to alert Nabu, the god of literacy. When the Eshumesha gods hear Nabu speak, they come out of their temple to search for him. Marduk defeats the Eshumesha gods and takes 360 of them as prisoners of war, including Enlil himself. Enlil protests that the Eshumesha gods are innocent, so Marduk puts them on trial before the Anunnaki. The text ends with a warning from Damkianna (another name for Ninhursag) to the gods and to humanity, pleading them not to repeat the war between the Anunnaki and the gods of Eshumesha.\n\nBULLET::::- Ancient Mesopotamian religion\nBULLET::::- El\nBULLET::::- Hymn to Enlil\nBULLET::::- Yahweh\n\nBULLET::::- Ancient Mesopotamian Gods and Goddesses: Enlil/Ellil (god)\nBULLET::::- Gateway to Babylon: \"Enlil and Ninlil\", trans. Thorkild Jacobsen.\nBULLET::::- Electronic Text Corpus of Sumerian Literature: \"Enlil and Ninlil\" (original Sumerian) and English translation\nBULLET::::- Electronic Text Corpus of Sumerian Literature: Sumerian Flood myth (original Sumerian) and English translation\n"}
{"id": "9630", "url": "https://en.wikipedia.org/wiki?curid=9630", "title": "Ecology", "text": "Ecology\n\nEcology (from , \"house\", or \"environment\"; , \"study of\") is a branch of biology that studies the interactions among organisms and their biophysical environment, which includes both biotic and abiotic components. Topics of interest include the biodiversity, distribution, biomass, and populations of organisms, as well as cooperation and competition within and between species. Ecosystems are dynamically interacting systems of organisms, the communities they make up, and the non-living components of their environment. Ecosystem processes, such as primary production, pedogenesis, nutrient cycling, and niche construction, regulate the flux of energy and matter through an environment. These processes are sustained by organisms with specific life history traits.\n\nEcology is not synonymous with environmentalism, natural history, or environmental science. It overlaps with the closely related sciences of evolutionary biology, genetics, and ethology. An important focus for ecologists is to improve the understanding of how biodiversity affects ecological function. Ecologists seek to explain:\nBULLET::::- Life processes, interactions, and adaptations\nBULLET::::- The movement of materials and energy through living communities\nBULLET::::- The successional development of ecosystems\nBULLET::::- The abundance and distribution of organisms and biodiversity in the context of the environment.\n\nEcology has practical applications in conservation biology, wetland management, natural resource management (agroecology, agriculture, forestry, agroforestry, fisheries), city planning (urban ecology), community health, economics, basic and applied science, and human social interaction (human ecology). For example, the \"Circles of Sustainability\" approach treats ecology as more than the environment 'out there'. It is not treated as separate from humans. Organisms (including humans) and resources compose ecosystems which, in turn, maintain biophysical feedback mechanisms that moderate processes acting on living (biotic) and non-living (abiotic) components of the planet. Ecosystems sustain life-supporting functions and produce natural capital like biomass production (food, fuel, fiber, and medicine), the regulation of climate, global biogeochemical cycles, water filtration, soil formation, erosion control, flood protection, and many other natural features of scientific, historical, economic, or intrinsic value.\n\nThe word \"ecology\" (\"Ökologie\") was coined in 1866 by the German scientist Ernst Haeckel. Ecological thought is derivative of established currents in philosophy, particularly from ethics and politics. Ancient Greek philosophers such as Hippocrates and Aristotle laid the foundations of ecology in their studies on natural history. Modern ecology became a much more rigorous science in the late 19th century. Evolutionary concepts relating to adaptation and natural selection became the cornerstones of modern ecological theory.\n\nThe scope of ecology contains a wide array of interacting levels of organization spanning micro-level (e.g., cells) to a planetary scale (e.g., biosphere) phenomena. Ecosystems, for example, contain abiotic resources and interacting life forms (i.e., individual organisms that aggregate into populations which aggregate into distinct ecological communities). Ecosystems are dynamic, they do not always follow a linear successional path, but they are always changing, sometimes rapidly and sometimes so slowly that it can take thousands of years for ecological processes to bring about certain successional stages of a forest. An ecosystem's area can vary greatly, from tiny to vast. A single tree is of little consequence to the classification of a forest ecosystem, but critically relevant to organisms living in and on it. Several generations of an aphid population can exist over the lifespan of a single leaf. Each of those aphids, in turn, support diverse bacterial communities. The nature of connections in ecological communities cannot be explained by knowing the details of each species in isolation, because the emergent pattern is neither revealed nor predicted until the ecosystem is studied as an integrated whole. Some ecological principles, however, do exhibit collective properties where the sum of the components explain the properties of the whole, such as birth rates of a population being equal to the sum of individual births over a designated time frame.\n\nThe main subdisciplines of ecology, population (or community) ecology and ecosystem ecology, exhibit a difference not only of scale, but also of two contrasting paradigms in the field. The former focus on organisms' distribution and abundance, while the later focus on materials and energy fluxes.\n\nThe scale of ecological dynamics can operate like a closed system, such as aphids migrating on a single tree, while at the same time remain open with regard to broader scale influences, such as atmosphere or climate. Hence, ecologists classify ecosystems hierarchically by analyzing data collected from finer scale units, such as vegetation associations, climate, and soil types, and integrate this information to identify emergent patterns of uniform organization and processes that operate on local to regional, landscape, and chronological scales.\n\nTo structure the study of ecology into a conceptually manageable framework, the biological world is organized into a nested hierarchy, ranging in scale from genes, to cells, to tissues, to organs, to organisms, to species, to populations, to communities, to ecosystems, to biomes, and up to the level of the biosphere. This framework forms a panarchy and exhibits non-linear behaviors; this means that \"effect and cause are disproportionate, so that small changes to critical variables, such as the number of nitrogen fixers, can lead to disproportionate, perhaps irreversible, changes in the system properties.\"\n\nBiodiversity (an abbreviation of \"biological diversity\") describes the diversity of life from genes to ecosystems and spans every level of biological organization. The term has several interpretations, and there are many ways to index, measure, characterize, and represent its complex organization. Biodiversity includes species diversity, ecosystem diversity, and genetic diversity and scientists are interested in the way that this diversity affects the complex ecological processes operating at and among these respective levels. Biodiversity plays an important role in ecosystem services which by definition maintain and improve human quality of life. Conservation priorities and management techniques require different approaches and considerations to address the full ecological scope of biodiversity. Natural capital that supports populations is critical for maintaining ecosystem services and species migration (e.g., riverine fish runs and avian insect control) has been implicated as one mechanism by which those service losses are experienced. An understanding of biodiversity has practical applications for species and ecosystem-level conservation planners as they make management recommendations to consulting firms, governments, and industry.\n\nThe habitat of a species describes the environment over which a species is known to occur and the type of community that is formed as a result. More specifically, \"habitats can be defined as regions in environmental space that are composed of multiple dimensions, each representing a biotic or abiotic environmental variable; that is, any component or characteristic of the environment related directly (e.g. forage biomass and quality) or indirectly (e.g. elevation) to the use of a location by the animal.\" For example, a habitat might be an aquatic or terrestrial environment that can be further categorized as a montane or alpine ecosystem. Habitat shifts provide important evidence of competition in nature where one population changes relative to the habitats that most other individuals of the species occupy. For example, one population of a species of tropical lizard (\"Tropidurus hispidus\") has a flattened body relative to the main populations that live in open savanna. The population that lives in an isolated rock outcrop hides in crevasses where its flattened body offers a selective advantage. Habitat shifts also occur in the developmental life history of amphibians, and in insects that transition from aquatic to terrestrial habitats. Biotope and habitat are sometimes used interchangeably, but the former applies to a community's environment, whereas the latter applies to a species' environment.\n\nDefinitions of the niche date back to 1917, but G. Evelyn Hutchinson made conceptual advances in 1957 by introducing a widely adopted definition: \"the set of biotic and abiotic conditions in which a species is able to persist and maintain stable population sizes.\" The ecological niche is a central concept in the ecology of organisms and is sub-divided into the \"fundamental\" and the \"realized\" niche. The fundamental niche is the set of environmental conditions under which a species is able to persist. The realized niche is the set of environmental plus ecological conditions under which a species persists. The Hutchinsonian niche is defined more technically as a \"Euclidean hyperspace whose \"dimensions\" are defined as environmental variables and whose \"size\" is a function of the number of values that the environmental values may assume for which an organism has \"positive fitness\".\"\n\nBiogeographical patterns and range distributions are explained or predicted through knowledge of a species' traits and niche requirements. Species have functional traits that are uniquely adapted to the ecological niche. A trait is a measurable property, phenotype, or characteristic of an organism that may influence its survival. Genes play an important role in the interplay of development and environmental expression of traits. Resident species evolve traits that are fitted to the selection pressures of their local environment. This tends to afford them a competitive advantage and discourages similarly adapted species from having an overlapping geographic range. The competitive exclusion principle states that two species cannot coexist indefinitely by living off the same limiting resource; one will always out-compete the other. When similarly adapted species overlap geographically, closer inspection reveals subtle ecological differences in their habitat or dietary requirements. Some models and empirical studies, however, suggest that disturbances can stabilize the co-evolution and shared niche occupancy of similar species inhabiting species-rich communities. The habitat plus the niche is called the ecotope, which is defined as the full range of environmental and biological variables affecting an entire species.\n\nOrganisms are subject to environmental pressures, but they also modify their habitats. The regulatory feedback between organisms and their environment can affect conditions from local (e.g., a beaver pond) to global scales, over time and even after death, such as decaying logs or silica skeleton deposits from marine organisms. The process and concept of ecosystem engineering is related to niche construction, but the former relates only to the physical modifications of the habitat whereas the latter also considers the evolutionary implications of physical changes to the environment and the feedback this causes on the process of natural selection. Ecosystem engineers are defined as: \"organisms that directly or indirectly modulate the availability of resources to other species, by causing physical state changes in biotic or abiotic materials. In so doing they modify, maintain and create habitats.\"\n\nThe ecosystem engineering concept has stimulated a new appreciation for the influence that organisms have on the ecosystem and evolutionary process. The term \"niche construction\" is more often used in reference to the under-appreciated feedback mechanisms of natural selection imparting forces on the abiotic niche. An example of natural selection through ecosystem engineering occurs in the nests of social insects, including ants, bees, wasps, and termites. There is an emergent homeostasis or homeorhesis in the structure of the nest that regulates, maintains and defends the physiology of the entire colony. Termite mounds, for example, maintain a constant internal temperature through the design of air-conditioning chimneys. The structure of the nests themselves are subject to the forces of natural selection. Moreover, a nest can survive over successive generations, so that progeny inherit both genetic material and a legacy niche that was constructed before their time.\n\nBiomes are larger units of organization that categorize regions of the Earth's ecosystems, mainly according to the structure and composition of vegetation. There are different methods to define the continental boundaries of biomes dominated by different functional types of vegetative communities that are limited in distribution by climate, precipitation, weather and other environmental variables. Biomes include tropical rainforest, temperate broadleaf and mixed forest, temperate deciduous forest, taiga, tundra, hot desert, and polar desert. Other researchers have recently categorized other biomes, such as the human and oceanic microbiomes. To a microbe, the human body is a habitat and a landscape. Microbiomes were discovered largely through advances in molecular genetics, which have revealed a hidden richness of microbial diversity on the planet. The oceanic microbiome plays a significant role in the ecological biogeochemistry of the planet's oceans.\n\nThe largest scale of ecological organization is the biosphere: the total sum of ecosystems on the planet. Ecological relationships regulate the flux of energy, nutrients, and climate all the way up to the planetary scale. For example, the dynamic history of the planetary atmosphere's CO and O composition has been affected by the biogenic flux of gases coming from respiration and photosynthesis, with levels fluctuating over time in relation to the ecology and evolution of plants and animals. Ecological theory has also been used to explain self-emergent regulatory phenomena at the planetary scale: for example, the Gaia hypothesis is an example of holism applied in ecological theory. The Gaia hypothesis states that there is an emergent feedback loop generated by the metabolism of living organisms that maintains the core temperature of the Earth and atmospheric conditions within a narrow self-regulating range of tolerance.\n\nPopulation ecology studies the dynamics of species populations and how these populations interact with the wider environment. A population consists of individuals of the same species that live, interact, and migrate through the same niche and habitat.\n\nA primary law of population ecology is the Malthusian growth model which states, \"a population will grow (or decline) exponentially as long as the environment experienced by all individuals in the population remains constant.\" Simplified population models usually start with four variables: death, birth, immigration, and emigration.\n\nAn example of an introductory population model describes a closed population, such as on an island, where immigration and emigration does not take place. Hypotheses are evaluated with reference to a null hypothesis which states that random processes create the observed data. In these island models, the rate of population change is described by:\n\nwhere \"N\" is the total number of individuals in the population, \"b\" and \"d\" are the per capita rates of birth and death respectively, and \"r\" is the per capita rate of population change.\n\nUsing these modelling techniques, Malthus' population principle of growth was later transformed into a model known as the logistic equation:\n\nwhere \"N\" is the number of individuals measured as biomass density, \"a\" is the maximum per-capita rate of change, and \"K\" is the carrying capacity of the population. The formula states that the rate of change in population size (\"dN/dT\") is equal to growth (\"aN\") that is limited by carrying capacity (1 – \"N\"/\"K\").\n\nPopulation ecology builds upon these introductory models to further understand demographic processes in real study populations. Commonly used types of data include life history, fecundity, and survivorship, and these are analysed using mathematical techniques such as matrix algebra. The information is used for managing wildlife stocks and setting harvest quotas. In cases where basic models are insufficient, ecologists may adopt different kinds of statistical methods, such as the Akaike information criterion, or use models that can become mathematically complex as \"several competing hypotheses are simultaneously confronted with the data.\"\n\nThe concept of metapopulations was defined in 1969 as \"a population of populations which go extinct locally and recolonize\". Metapopulation ecology is another statistical approach that is often used in conservation research. Metapopulation models simplify the landscape into patches of varying levels of quality, and metapopulations are linked by the migratory behaviours of organisms. Animal migration is set apart from other kinds of movement; because, it involves the seasonal departure and return of individuals from a habitat. Migration is also a population-level phenomenon, as with the migration routes followed by plants as they occupied northern post-glacial environments. Plant ecologists use pollen records that accumulate and stratify in wetlands to reconstruct the timing of plant migration and dispersal relative to historic and contemporary climates. These migration routes involved an expansion of the range as plant populations expanded from one area to another. There is a larger taxonomy of movement, such as commuting, foraging, territorial behaviour, stasis, and ranging. Dispersal is usually distinguished from migration; because, it involves the one way permanent movement of individuals from their birth population into another population.\n\nIn metapopulation terminology, migrating individuals are classed as emigrants (when they leave a region) or immigrants (when they enter a region), and sites are classed either as sources or sinks. A site is a generic term that refers to places where ecologists sample populations, such as ponds or defined sampling areas in a forest. Source patches are productive sites that generate a seasonal supply of juveniles that migrate to other patch locations. Sink patches are unproductive sites that only receive migrants; the population at the site will disappear unless rescued by an adjacent source patch or environmental conditions become more favourable. Metapopulation models examine patch dynamics over time to answer potential questions about spatial and demographic ecology. The ecology of metapopulations is a dynamic process of extinction and colonization. Small patches of lower quality (i.e., sinks) are maintained or rescued by a seasonal influx of new immigrants. A dynamic metapopulation structure evolves from year to year, where some patches are sinks in dry years and are sources when conditions are more favourable. Ecologists use a mixture of computer models and field studies to explain metapopulation structure.\n\nCommunity ecology is the study of the interactions among a collections of species that inhabit the same geographic area. Community ecologists study the determinants of patterns and processes for two or more interacting species. Research in community ecology might measure species diversity in grasslands in relation to soil fertility. It might also include the analysis of predator-prey dynamics, competition among similar plant species, or mutualistic interactions between crabs and corals.\n\nEcosystems may be habitats within biomes that form an integrated whole and a dynamically responsive system having both physical and biological complexes. Ecosystem ecology is the science of determining the fluxes of materials (e.g. carbon, phosphorus) between different pools (e.g., tree biomass, soil organic material). Ecosystem ecologist attempt to determine the underlying causes of these fluxes. Research in ecosystem ecology might measure primary production (g C/m^2) in a wetland in relation to decomposition and consumption rates (g C/m^2/y). This requires an understanding of the community connections between plants (i.e., primary producers) and the decomposers (e.g., fungi and bacteria),\n\nThe underlying concept of ecosystem can be traced back to 1864 in the published work of George Perkins Marsh (\"Man and Nature\"). Within an ecosystem, organisms are linked to the physical and biological components of their environment to which they are adapted. Ecosystems are complex adaptive systems where the interaction of life processes form self-organizing patterns across different scales of time and space. Ecosystems are broadly categorized as terrestrial, freshwater, atmospheric, or marine. Differences stem from the nature of the unique physical environments that shapes the biodiversity within each. A more recent addition to ecosystem ecology are technoecosystems, which are affected by or primarily the result of human activity.\n\nA food web is the archetypal ecological network. Plants capture solar energy and use it to synthesize simple sugars during photosynthesis. As plants grow, they accumulate nutrients and are eaten by grazing herbivores, and the energy is transferred through a chain of organisms by consumption. The simplified linear feeding pathways that move from a basal trophic species to a top consumer is called the food chain. The larger interlocking pattern of food chains in an ecological community creates a complex food web. Food webs are a type of concept map or a heuristic device that is used to illustrate and study pathways of energy and material flows.\n\nFood webs are often limited relative to the real world. Complete empirical measurements are generally restricted to a specific habitat, such as a cave or a pond, and principles gleaned from food web microcosm studies are extrapolated to larger systems. Feeding relations require extensive investigations into the gut contents of organisms, which can be difficult to decipher, or stable isotopes can be used to trace the flow of nutrient diets and energy through a food web. Despite these limitations, food webs remain a valuable tool in understanding community ecosystems.\n\nFood webs exhibit principles of ecological emergence through the nature of trophic relationships: some species have many weak feeding links (e.g., omnivores) while some are more specialized with fewer stronger feeding links (e.g., primary predators). Theoretical and empirical studies identify non-random emergent patterns of few strong and many weak linkages that explain how ecological communities remain stable over time. Food webs are composed of subgroups where members in a community are linked by strong interactions, and the weak interactions occur between these subgroups. This increases food web stability. Step by step lines or relations are drawn until a web of life is illustrated.\n\nA trophic level (from Greek \"troph\", τροφή, trophē, meaning \"food\" or \"feeding\") is \"a group of organisms acquiring a considerable majority of its energy from the lower adjacent level (according to ecological pyramids) nearer the abiotic source.\" Links in food webs primarily connect feeding relations or trophism among species. Biodiversity within ecosystems can be organized into trophic pyramids, in which the vertical dimension represents feeding relations that become further removed from the base of the food chain up toward top predators, and the horizontal dimension represents the abundance or biomass at each level. When the relative abundance or biomass of each species is sorted into its respective trophic level, they naturally sort into a 'pyramid of numbers'.\n\nSpecies are broadly categorized as autotrophs (or primary producers), heterotrophs (or consumers), and Detritivores (or decomposers). Autotrophs are organisms that produce their own food (production is greater than respiration) by photosynthesis or chemosynthesis. Heterotrophs are organisms that must feed on others for nourishment and energy (respiration exceeds production). Heterotrophs can be further sub-divided into different functional groups, including primary consumers (strict herbivores), secondary consumers (carnivorous predators that feed exclusively on herbivores), and tertiary consumers (predators that feed on a mix of herbivores and predators). Omnivores do not fit neatly into a functional category because they eat both plant and animal tissues. It has been suggested that omnivores have a greater functional influence as predators, because compared to herbivores, they are relatively inefficient at grazing.\n\nTrophic levels are part of the holistic or complex systems view of ecosystems. Each trophic level contains unrelated species that are grouped together because they share common ecological functions, giving a macroscopic view of the system. While the notion of trophic levels provides insight into energy flow and top-down control within food webs, it is troubled by the prevalence of omnivory in real ecosystems. This has led some ecologists to \"reiterate that the notion that species clearly aggregate into discrete, homogeneous trophic levels is fiction.\" Nonetheless, recent studies have shown that real trophic levels do exist, but \"above the herbivore trophic level, food webs are better characterized as a tangled web of omnivores.\"\n\nA keystone species is a species that is connected to a disproportionately large number of other species in the food-web. Keystone species have lower levels of biomass in the trophic pyramid relative to the importance of their role. The many connections that a keystone species holds means that it maintains the organization and structure of entire communities. The loss of a keystone species results in a range of dramatic cascading effects that alters trophic dynamics, other food web connections, and can cause the extinction of other species.\n\nSea otters (\"Enhydra lutris\") are commonly cited as an example of a keystone species; because, they limit the density of sea urchins that feed on kelp. If sea otters are removed from the system, the urchins graze until the kelp beds disappear, and this has a dramatic effect on community structure. Hunting of sea otters, for example, is thought to have led indirectly to the extinction of the Steller's sea cow (\"Hydrodamalis gigas\"). While the keystone species concept has been used extensively as a conservation tool, it has been criticized for being poorly defined from an operational stance. It is difficult to experimentally determine what species may hold a keystone role in each ecosystem. Furthermore, food web theory suggests that keystone species may not be common, so it is unclear how generally the keystone species model can be applied.\n\nComplexity is understood as a large computational effort needed to piece together numerous interacting parts exceeding the iterative memory capacity of the human mind. Global patterns of biological diversity are complex. This biocomplexity stems from the interplay among ecological processes that operate and influence patterns at different scales that grade into each other, such as transitional areas or ecotones spanning landscapes. Complexity stems from the interplay among levels of biological organization as energy, and matter is integrated into larger units that superimpose onto the smaller parts. \"What were wholes on one level become parts on a higher one.\" Small scale patterns do not necessarily explain large scale phenomena, otherwise captured in the expression (coined by Aristotle) 'the sum is greater than the parts'.\n\n\"Complexity in ecology is of at least six distinct types: spatial, temporal, structural, process, behavioral, and geometric.\" From these principles, ecologists have identified emergent and self-organizing phenomena that operate at different environmental scales of influence, ranging from molecular to planetary, and these require different explanations at each integrative level. Ecological complexity relates to the dynamic resilience of ecosystems that transition to multiple shifting steady-states directed by random fluctuations of history. Long-term ecological studies provide important track records to better understand the complexity and resilience of ecosystems over longer temporal and broader spatial scales. These studies are managed by the International Long Term Ecological Network (LTER). The longest experiment in existence is the Park Grass Experiment, which was initiated in 1856. Another example is the Hubbard Brook study, which has been in operation since 1960.\n\nHolism remains a critical part of the theoretical foundation in contemporary ecological studies. Holism addresses the biological organization of life that self-organizes into layers of emergent whole systems that function according to non-reducible properties. This means that higher order patterns of a whole functional system, such as an ecosystem, cannot be predicted or understood by a simple summation of the parts. \"New properties emerge because the components interact, not because the basic nature of the components is changed.\"\n\nEcological studies are necessarily holistic as opposed to reductionistic. Holism has three scientific meanings or uses that identify with ecology: 1) the mechanistic complexity of ecosystems, 2) the practical description of patterns in quantitative reductionist terms where correlations may be identified but nothing is understood about the causal relations without reference to the whole system, which leads to 3) a metaphysical hierarchy whereby the causal relations of larger systems are understood without reference to the smaller parts. Scientific holism differs from mysticism that has appropriated the same term. An example of metaphysical holism is identified in the trend of increased exterior thickness in shells of different species. The reason for a thickness increase can be understood through reference to principles of natural selection via predation without need to reference or understand the biomolecular properties of the exterior shells.\n\nEcology and evolutionary biology are considered sister disciplines of the life sciences. Natural selection, life history, development, adaptation, populations, and inheritance are examples of concepts that thread equally into ecological and evolutionary theory. Morphological, behavioural, and genetic traits, for example, can be mapped onto evolutionary trees to study the historical development of a species in relation to their functions and roles in different ecological circumstances. In this framework, the analytical tools of ecologists and evolutionists overlap as they organize, classify, and investigate life through common systematic principles, such as phylogenetics or the Linnaean system of taxonomy. The two disciplines often appear together, such as in the title of the journal \"Trends in Ecology and Evolution\". There is no sharp boundary separating ecology from evolution, and they differ more in their areas of applied focus. Both disciplines discover and explain emergent and unique properties and processes operating across different spatial or temporal scales of organization. While the boundary between ecology and evolution is not always clear, ecologists study the abiotic and biotic factors that influence evolutionary processes, and evolution can be rapid, occurring on ecological timescales as short as one generation.\n\nAll organisms can exhibit behaviours. Even plants express complex behaviour, including memory and communication. Behavioural ecology is the study of an organism's behaviour in its environment and its ecological and evolutionary implications. Ethology is the study of observable movement or behaviour in animals. This could include investigations of motile sperm of plants, mobile phytoplankton, zooplankton swimming toward the female egg, the cultivation of fungi by weevils, the mating dance of a salamander, or social gatherings of amoeba.\n\nAdaptation is the central unifying concept in behavioural ecology. Behaviours can be recorded as traits and inherited in much the same way that eye and hair colour can. Behaviours can evolve by means of natural selection as adaptive traits conferring functional utilities that increases reproductive fitness.\n\nPredator-prey interactions are an introductory concept into food-web studies as well as behavioural ecology. Prey species can exhibit different kinds of behavioural adaptations to predators, such as avoid, flee, or defend. Many prey species are faced with multiple predators that differ in the degree of danger posed. To be adapted to their environment and face predatory threats, organisms must balance their energy budgets as they invest in different aspects of their life history, such as growth, feeding, mating, socializing, or modifying their habitat. Hypotheses posited in behavioural ecology are generally based on adaptive principles of conservation, optimization, or efficiency. For example, \"[t]he threat-sensitive predator avoidance hypothesis predicts that prey should assess the degree of threat posed by different predators and match their behaviour according to current levels of risk\" or \"[t]he optimal flight initiation distance occurs where expected postencounter fitness is maximized, which depends on the prey's initial fitness, benefits obtainable by not fleeing, energetic escape costs, and expected fitness loss due to predation risk.\"\n\nElaborate sexual displays and posturing are encountered in the behavioural ecology of animals. The birds-of-paradise, for example, sing and display elaborate ornaments during courtship. These displays serve a dual purpose of signalling healthy or well-adapted individuals and desirable genes. The displays are driven by sexual selection as an advertisement of quality of traits among suitors.\n\nCognitive ecology integrates theory and observations from evolutionary ecology and neurobiology, primarily cognitive science, in order to understand the effect that animal interaction with their habitat has on their cognitive systems and how those systems restrict behavior within an ecological and evolutionary framework. \"Until recently, however, cognitive scientists have not paid sufficient attention to the fundamental fact that cognitive traits evolved under particular natural settings. With consideration of the selection pressure on cognition, cognitive ecology can contribute intellectual coherence to the multidisciplinary study of cognition.\" As a study involving the 'coupling' or interactions between organism and environment, cognitive ecology is closely related to enactivism, a field based upon the view that \"...we must see the organism and environment as bound together in reciprocal specification and selection...\".\n\nSocial ecological behaviours are notable in the social insects, slime moulds, social spiders, human society, and naked mole-rats where eusocialism has evolved. Social behaviours include reciprocally beneficial behaviours among kin and nest mates and evolve from kin and group selection. Kin selection explains altruism through genetic relationships, whereby an altruistic behaviour leading to death is rewarded by the survival of genetic copies distributed among surviving relatives. The social insects, including ants, bees, and wasps are most famously studied for this type of relationship because the male drones are clones that share the same genetic make-up as every other male in the colony. In contrast, group selectionists find examples of altruism among non-genetic relatives and explain this through selection acting on the group; whereby, it becomes selectively advantageous for groups if their members express altruistic behaviours to one another. Groups with predominantly altruistic members survive better than groups with predominantly selfish members.\n\nEcological interactions can be classified broadly into a host and an associate relationship. A host is any entity that harbours another that is called the associate. Relationships within a species that are mutually or reciprocally beneficial are called mutualisms. Examples of mutualism include fungus-growing ants employing agricultural symbiosis, bacteria living in the guts of insects and other organisms, the fig wasp and yucca moth pollination complex, lichens with fungi and photosynthetic algae, and corals with photosynthetic algae. If there is a physical connection between host and associate, the relationship is called symbiosis. Approximately 60% of all plants, for example, have a symbiotic relationship with arbuscular mycorrhizal fungi living in their roots forming an exchange network of carbohydrates for mineral nutrients.\n\nIndirect mutualisms occur where the organisms live apart. For example, trees living in the equatorial regions of the planet supply oxygen into the atmosphere that sustains species living in distant polar regions of the planet. This relationship is called commensalism; because, many others receive the benefits of clean air at no cost or harm to trees supplying the oxygen. If the associate benefits while the host suffers, the relationship is called parasitism. Although parasites impose a cost to their host (e.g., via damage to their reproductive organs or propagules, denying the services of a beneficial partner), their net effect on host fitness is not necessarily negative and, thus, becomes difficult to forecast. Co-evolution is also driven by competition among species or among members of the same species under the banner of reciprocal antagonism, such as grasses competing for growth space. The Red Queen Hypothesis, for example, posits that parasites track down and specialize on the locally common genetic defense systems of its host that drives the evolution of sexual reproduction to diversify the genetic constituency of populations responding to the antagonistic pressure.\n\nBiogeography (an amalgamation of \"biology\" and \"geography\") is the comparative study of the geographic distribution of organisms and the corresponding evolution of their traits in space and time. The \"Journal of Biogeography\" was established in 1974. Biogeography and ecology share many of their disciplinary roots. For example, the theory of island biogeography, published by the Robert MacArthur and Edward O. Wilson in 1967 is considered one of the fundamentals of ecological theory.\n\nBiogeography has a long history in the natural sciences concerning the spatial distribution of plants and animals. Ecology and evolution provide the explanatory context for biogeographical studies. Biogeographical patterns result from ecological processes that influence range distributions, such as migration and dispersal. and from historical processes that split populations or species into different areas. The biogeographic processes that result in the natural splitting of species explains much of the modern distribution of the Earth's biota. The splitting of lineages in a species is called vicariance biogeography and it is a sub-discipline of biogeography. There are also practical applications in the field of biogeography concerning ecological systems and processes. For example, the range and distribution of biodiversity and invasive species responding to climate change is a serious concern and active area of research in the context of global warming.\n\nA population ecology concept is r/K selection theory, one of the first predictive models in ecology used to explain life-history evolution. The premise behind the r/K selection model is that natural selection pressures change according to population density. For example, when an island is first colonized, density of individuals is low. The initial increase in population size is not limited by competition, leaving an abundance of available resources for rapid population growth. These early phases of population growth experience \"density-independent\" forces of natural selection, which is called \"r\"-selection. As the population becomes more crowded, it approaches the island's carrying capacity, thus forcing individuals to compete more heavily for fewer available resources. Under crowded conditions, the population experiences density-dependent forces of natural selection, called \"K\"-selection.\n\nIn the \"r/K\"-selection model, the first variable \"r\" is the intrinsic rate of natural increase in population size and the second variable \"K\" is the carrying capacity of a population. Different species evolve different life-history strategies spanning a continuum between these two selective forces. An \"r\"-selected species is one that has high birth rates, low levels of parental investment, and high rates of mortality before individuals reach maturity. Evolution favours high rates of fecundity in \"r\"-selected species. Many kinds of insects and invasive species exhibit \"r\"-selected characteristics. In contrast, a \"K\"-selected species has low rates of fecundity, high levels of parental investment in the young, and low rates of mortality as individuals mature. Humans and elephants are examples of species exhibiting \"K\"-selected characteristics, including longevity and efficiency in the conversion of more resources into fewer offspring.\n\nThe important relationship between ecology and genetic inheritance predates modern techniques for molecular analysis. Molecular ecological research became more feasible with the development of rapid and accessible genetic technologies, such as the polymerase chain reaction (PCR). The rise of molecular technologies and influx of research questions into this new ecological field resulted in the publication \"Molecular Ecology\" in 1992. Molecular ecology uses various analytical techniques to study genes in an evolutionary and ecological context. In 1994, John Avise also played a leading role in this area of science with the publication of his book, \"Molecular Markers, Natural History and Evolution\". Newer technologies opened a wave of genetic analysis into organisms once difficult to study from an ecological or evolutionary standpoint, such as bacteria, fungi, and nematodes. Molecular ecology engendered a new research paradigm for investigating ecological questions considered otherwise intractable. Molecular investigations revealed previously obscured details in the tiny intricacies of nature and improved resolution into probing questions about behavioural and biogeographical ecology. For example, molecular ecology revealed promiscuous sexual behaviour and multiple male partners in tree swallows previously thought to be socially monogamous. In a biogeographical context, the marriage between genetics, ecology, and evolution resulted in a new sub-discipline called phylogeography.\n\nEcology is as much a biological science as it is a human science. Human ecology is an interdisciplinary investigation into the ecology of our species. \"Human ecology may be defined: (1) from a bioecological standpoint as the study of man as the ecological dominant in plant and animal communities and systems; (2) from a bioecological standpoint as simply another animal affecting and being affected by his physical environment; and (3) as a human being, somehow different from animal life in general, interacting with physical and modified environments in a distinctive and creative way. A truly interdisciplinary human ecology will most likely address itself to all three.\" The term was formally introduced in 1921, but many sociologists, geographers, psychologists, and other disciplines were interested in human relations to natural systems centuries prior, especially in the late 19th century.\n\nThe ecological complexities human beings are facing through the technological transformation of the planetary biome has brought on the Anthropocene. The unique set of circumstances has generated the need for a new unifying science called coupled human and natural systems that builds upon, but moves beyond the field of human ecology. Ecosystems tie into human societies through the critical and all encompassing life-supporting functions they sustain. In recognition of these functions and the incapability of traditional economic valuation methods to see the value in ecosystems, there has been a surge of interest in social-natural capital, which provides the means to put a value on the stock and use of information and materials stemming from ecosystem goods and services. Ecosystems produce, regulate, maintain, and supply services of critical necessity and beneficial to human health (cognitive and physiological), economies, and they even provide an information or reference function as a living library giving opportunities for science and cognitive development in children engaged in the complexity of the natural world. Ecosystems relate importantly to human ecology as they are the ultimate base foundation of global economics as every commodity, and the capacity for exchange ultimately stems from the ecosystems on Earth.\n\nEcology is an employed science of restoration, repairing disturbed sites through human intervention, in natural resource management, and in environmental impact assessments. Edward O. Wilson predicted in 1992 that the 21st century \"will be the era of restoration in ecology\". Ecological science has boomed in the industrial investment of restoring ecosystems and their processes in abandoned sites after disturbance. Natural resource managers, in forestry, for example, employ ecologists to develop, adapt, and implement ecosystem based methods into the planning, operation, and restoration phases of land-use. Ecological science is used in the methods of sustainable harvesting, disease, and fire outbreak management, in fisheries stock management, for integrating land-use with protected areas and communities, and conservation in complex geo-political landscapes.\n\nThe environment of ecosystems includes both physical parameters and biotic attributes. It is dynamically interlinked, and contains resources for organisms at any time throughout their life cycle. Like ecology, the term environment has different conceptual meanings and overlaps with the concept of nature. Environment \"includes the physical world, the social world of human relations and the built world of human creation.\" The physical environment is external to the level of biological organization under investigation, including abiotic factors such as temperature, radiation, light, chemistry, climate and geology. The biotic environment includes genes, cells, organisms, members of the same species (conspecifics) and other species that share a habitat.\n\nThe distinction between external and internal environments, however, is an abstraction parsing life and environment into units or facts that are inseparable in reality. There is an interpenetration of cause and effect between the environment and life. The laws of thermodynamics, for example, apply to ecology by means of its physical state. With an understanding of metabolic and thermodynamic principles, a complete accounting of energy and material flow can be traced through an ecosystem. In this way, the environmental and ecological relations are studied through reference to conceptually manageable and isolated material parts. After the effective environmental components are understood through reference to their causes; however, they conceptually link back together as an integrated whole, or \"holocoenotic\" system as it was once called. This is known as the dialectical approach to ecology. The dialectical approach examines the parts, but integrates the organism and the environment into a dynamic whole (or umwelt). Change in one ecological or environmental factor can concurrently affect the dynamic state of an entire ecosystem.\n\nEcosystems are regularly confronted with natural environmental variations and disturbances over time and geographic space. A disturbance is any process that removes biomass from a community, such as a fire, flood, drought, or predation. Disturbances occur over vastly different ranges in terms of magnitudes as well as distances and time periods, and are both the cause and product of natural fluctuations in death rates, species assemblages, and biomass densities within an ecological community. These disturbances create places of renewal where new directions emerge from the patchwork of natural experimentation and opportunity. Ecological resilience is a cornerstone theory in ecosystem management. Biodiversity fuels the resilience of ecosystems acting as a kind of regenerative insurance.\n\nThe Earth was formed approximately 4.5 billion years ago. As it cooled and a crust and oceans formed, its atmosphere transformed from being dominated by hydrogen to one composed mostly of methane and ammonia. Over the next billion years, the metabolic activity of life transformed the atmosphere into a mixture of carbon dioxide, nitrogen, and water vapor. These gases changed the way that light from the sun hit the Earth's surface and greenhouse effects trapped heat. There were untapped sources of free energy within the mixture of reducing and oxidizing gasses that set the stage for primitive ecosystems to evolve and, in turn, the atmosphere also evolved.\n\nThroughout history, the Earth's atmosphere and biogeochemical cycles have been in a dynamic equilibrium with planetary ecosystems. The history is characterized by periods of significant transformation followed by millions of years of stability. The evolution of the earliest organisms, likely anaerobic methanogen microbes, started the process by converting atmospheric hydrogen into methane (4H + CO → CH + 2HO). Anoxygenic photosynthesis reduced hydrogen concentrations and increased atmospheric methane, by converting hydrogen sulfide into water or other sulfur compounds (for example, 2HS + CO + h\"v\" → CHO + HO + 2S). Early forms of fermentation also increased levels of atmospheric methane. The transition to an oxygen-dominant atmosphere (the \"Great Oxidation\") did not begin until approximately 2.4–2.3 billion years ago, but photosynthetic processes started 0.3 to 1 billion years prior.\n\nThe biology of life operates within a certain range of temperatures. Heat is a form of energy that regulates temperature. Heat affects growth rates, activity, behaviour, and primary production. Temperature is largely dependent on the incidence of solar radiation. The latitudinal and longitudinal spatial variation of temperature greatly affects climates and consequently the distribution of biodiversity and levels of primary production in different ecosystems or biomes across the planet. Heat and temperature relate importantly to metabolic activity. Poikilotherms, for example, have a body temperature that is largely regulated and dependent on the temperature of the external environment. In contrast, homeotherms regulate their internal body temperature by expending metabolic energy.\n\nThere is a relationship between light, primary production, and ecological energy budgets. Sunlight is the primary input of energy into the planet's ecosystems. Light is composed of electromagnetic energy of different wavelengths. Radiant energy from the sun generates heat, provides photons of light measured as active energy in the chemical reactions of life, and also acts as a catalyst for genetic mutation. Plants, algae, and some bacteria absorb light and assimilate the energy through photosynthesis. Organisms capable of assimilating energy by photosynthesis or through inorganic fixation of HS are autotrophs. Autotrophs—responsible for primary production—assimilate light energy which becomes metabolically stored as potential energy in the form of biochemical enthalpic bonds.\n\nDiffusion of carbon dioxide and oxygen is approximately 10,000 times slower in water than in air. When soils are flooded, they quickly lose oxygen, becoming hypoxic (an environment with O concentration below 2 mg/liter) and eventually completely anoxic where anaerobic bacteria thrive among the roots. Water also influences the intensity and spectral composition of light as it reflects off the water surface and submerged particles. Aquatic plants exhibit a wide variety of morphological and physiological adaptations that allow them to survive, compete, and diversify in these environments. For example, their roots and stems contain large air spaces (aerenchyma) that regulate the efficient transportation of gases (for example, CO and O) used in respiration and photosynthesis. Salt water plants (halophytes) have additional specialized adaptations, such as the development of special organs for shedding salt and osmoregulating their internal salt (NaCl) concentrations, to live in estuarine, brackish, or oceanic environments. Anaerobic soil microorganisms in aquatic environments use nitrate, manganese ions, ferric ions, sulfate, carbon dioxide, and some organic compounds; other microorganisms are facultative anaerobes and use oxygen during respiration when the soil becomes drier. The activity of soil microorganisms and the chemistry of the water reduces the oxidation-reduction potentials of the water. Carbon dioxide, for example, is reduced to methane (CH) by methanogenic bacteria. The physiology of fish is also specially adapted to compensate for environmental salt levels through osmoregulation. Their gills form electrochemical gradients that mediate salt excretion in salt water and uptake in fresh water.\n\nThe shape and energy of the land is significantly affected by gravitational forces. On a large scale, the distribution of gravitational forces on the earth is uneven and influences the shape and movement of tectonic plates as well as influencing geomorphic processes such as orogeny and erosion. These forces govern many of the geophysical properties and distributions of ecological biomes across the Earth. On the organismal scale, gravitational forces provide directional cues for plant and fungal growth (gravitropism), orientation cues for animal migrations, and influence the biomechanics and size of animals. Ecological traits, such as allocation of biomass in trees during growth are subject to mechanical failure as gravitational forces influence the position and structure of branches and leaves. The cardiovascular systems of animals are functionally adapted to overcome pressure and gravitational forces that change according to the features of organisms (e.g., height, size, shape), their behaviour (e.g., diving, running, flying), and the habitat occupied (e.g., water, hot deserts, cold tundra).\n\nClimatic and osmotic pressure places physiological constraints on organisms, especially those that fly and respire at high altitudes, or dive to deep ocean depths. These constraints influence vertical limits of ecosystems in the biosphere, as organisms are physiologically sensitive and adapted to atmospheric and osmotic water pressure differences. For example, oxygen levels decrease with decreasing pressure and are a limiting factor for life at higher altitudes. Water transportation by plants is another important ecophysiological process affected by osmotic pressure gradients. Water pressure in the depths of oceans requires that organisms adapt to these conditions. For example, diving animals such as whales, dolphins, and seals are specially adapted to deal with changes in sound due to water pressure differences. Differences between hagfish species provide another example of adaptation to deep-sea pressure through specialized protein adaptations.\n\nTurbulent forces in air and water affect the environment and ecosystem distribution, form and dynamics. On a planetary scale, ecosystems are affected by circulation patterns in the global trade winds. Wind power and the turbulent forces it creates can influence heat, nutrient, and biochemical profiles of ecosystems. For example, wind running over the surface of a lake creates turbulence, mixing the water column and influencing the environmental profile to create thermally layered zones, affecting how fish, algae, and other parts of the aquatic ecosystem are structured. Wind speed and turbulence also influence evapotranspiration rates and energy budgets in plants and animals. Wind speed, temperature and moisture content can vary as winds travel across different land features and elevations. For example, the westerlies come into contact with the coastal and interior mountains of western North America to produce a rain shadow on the leeward side of the mountain. The air expands and moisture condenses as the winds increase in elevation; this is called orographic lift and can cause precipitation. This environmental process produces spatial divisions in biodiversity, as species adapted to wetter conditions are range-restricted to the coastal mountain valleys and unable to migrate across the xeric ecosystems (e.g., of the Columbia Basin in western North America) to intermix with sister lineages that are segregated to the interior mountain systems.\n\nPlants convert carbon dioxide into biomass and emit oxygen into the atmosphere. By approximately 350 million years ago (the end of the Devonian period), photosynthesis had brought the concentration of atmospheric oxygen above 17%, which allowed combustion to occur. Fire releases CO and converts fuel into ash and tar. Fire is a significant ecological parameter that raises many issues pertaining to its control and suppression. While the issue of fire in relation to ecology and plants has been recognized for a long time, Charles Cooper brought attention to the issue of forest fires in relation to the ecology of forest fire suppression and management in the 1960s.\n\nNative North Americans were among the first to influence fire regimes by controlling their spread near their homes or by lighting fires to stimulate the production of herbaceous foods and basketry materials. Fire creates a heterogeneous ecosystem age and canopy structure, and the altered soil nutrient supply and cleared canopy structure opens new ecological niches for seedling establishment. Most ecosystems are adapted to natural fire cycles. Plants, for example, are equipped with a variety of adaptations to deal with forest fires. Some species (e.g., \"Pinus halepensis\") cannot germinate until after their seeds have lived through a fire or been exposed to certain compounds from smoke. Environmentally triggered germination of seeds is called serotiny. Fire plays a major role in the persistence and resilience of ecosystems.\n\nSoil is the living top layer of mineral and organic dirt that covers the surface of the planet. It is the chief organizing centre of most ecosystem functions, and it is of critical importance in agricultural science and ecology. The decomposition of dead organic matter (for example, leaves on the forest floor), results in soils containing minerals and nutrients that feed into plant production. The whole of the planet's soil ecosystems is called the pedosphere where a large biomass of the Earth's biodiversity organizes into trophic levels. Invertebrates that feed and shred larger leaves, for example, create smaller bits for smaller organisms in the feeding chain. Collectively, these organisms are the detritivores that regulate soil formation. Tree roots, fungi, bacteria, worms, ants, beetles, centipedes, spiders, mammals, birds, reptiles, amphibians, and other less familiar creatures all work to create the trophic web of life in soil ecosystems. Soils form composite phenotypes where inorganic matter is enveloped into the physiology of a whole community. As organisms feed and migrate through soils they physically displace materials, an ecological process called bioturbation. This aerates soils and stimulates heterotrophic growth and production. Soil microorganisms are influenced by and feed back into the trophic dynamics of the ecosystem. No single axis of causality can be discerned to segregate the biological from geomorphological systems in soils. Paleoecological studies of soils places the origin for bioturbation to a time before the Cambrian period. Other events, such as the evolution of trees and the colonization of land in the Devonian period played a significant role in the early development of ecological trophism in soils.\n\nEcologists study and measure nutrient budgets to understand how these materials are regulated, flow, and recycled through the environment. This research has led to an understanding that there is global feedback between ecosystems and the physical parameters of this planet, including minerals, soil, pH, ions, water, and atmospheric gases. Six major elements (hydrogen, carbon, nitrogen, oxygen, sulfur, and phosphorus; H, C, N, O, S, and P) form the constitution of all biological macromolecules and feed into the Earth's geochemical processes. From the smallest scale of biology, the combined effect of billions upon billions of ecological processes amplify and ultimately regulate the biogeochemical cycles of the Earth. Understanding the relations and cycles mediated between these elements and their ecological pathways has significant bearing toward understanding global biogeochemistry.\n\nThe ecology of global carbon budgets gives one example of the linkage between biodiversity and biogeochemistry. It is estimated that the Earth's oceans hold 40,000 gigatonnes (Gt) of carbon, that vegetation and soil hold 2070 Gt, and that fossil fuel emissions are 6.3 Gt carbon per year. There have been major restructurings in these global carbon budgets during the Earth's history, regulated to a large extent by the ecology of the land. For example, through the early-mid Eocene volcanic outgassing, the oxidation of methane stored in wetlands, and seafloor gases increased atmospheric CO (carbon dioxide) concentrations to levels as high as 3500 ppm.\n\nIn the Oligocene, from twenty-five to thirty-two million years ago, there was another significant restructuring of the global carbon cycle as grasses evolved a new mechanism of photosynthesis, C photosynthesis, and expanded their ranges. This new pathway evolved in response to the drop in atmospheric CO concentrations below 550 ppm. The relative abundance and distribution of biodiversity alters the dynamics between organisms and their environment such that ecosystems can be both cause and effect in relation to climate change. Human-driven modifications to the planet's ecosystems (e.g., disturbance, biodiversity loss, agriculture) contributes to rising atmospheric greenhouse gas levels. Transformation of the global carbon cycle in the next century is projected to raise planetary temperatures, lead to more extreme fluctuations in weather, alter species distributions, and increase extinction rates. The effect of global warming is already being registered in melting glaciers, melting mountain ice caps, and rising sea levels. Consequently, species distributions are changing along waterfronts and in continental areas where migration patterns and breeding grounds are tracking the prevailing shifts in climate. Large sections of permafrost are also melting to create a new mosaic of flooded areas having increased rates of soil decomposition activity that raises methane (CH) emissions. There is concern over increases in atmospheric methane in the context of the global carbon cycle, because methane is a greenhouse gas that is 23 times more effective at absorbing long-wave radiation than CO on a 100-year time scale. Hence, there is a relationship between global warming, decomposition and respiration in soils and wetlands producing significant climate feedbacks and globally altered biogeochemical cycles.\n\nEcology has a complex origin, due in large part to its interdisciplinary nature. Ancient Greek philosophers such as Hippocrates and Aristotle were among the first to record observations on natural history. However, they viewed life in terms of essentialism, where species were conceptualized as static unchanging things while varieties were seen as aberrations of an idealized type. This contrasts against the modern understanding of ecological theory where varieties are viewed as the real phenomena of interest and having a role in the origins of adaptations by means of natural selection. Early conceptions of ecology, such as a balance and regulation in nature can be traced to Herodotus (died \"c\". 425 BC), who described one of the earliest accounts of mutualism in his observation of \"natural dentistry\". Basking Nile crocodiles, he noted, would open their mouths to give sandpipers safe access to pluck leeches out, giving nutrition to the sandpiper and oral hygiene for the crocodile. Aristotle was an early influence on the philosophical development of ecology. He and his student Theophrastus made extensive observations on plant and animal migrations, biogeography, physiology, and on their behaviour, giving an early analogue to the modern concept of an ecological niche.\n\nEcological concepts such as food chains, population regulation, and productivity were first developed in the 1700s, through the published works of microscopist Antoni van Leeuwenhoek (1632–1723) and botanist Richard Bradley (1688?–1732). Biogeographer Alexander von Humboldt (1769–1859) was an early pioneer in ecological thinking and was among the first to recognize ecological gradients, where species are replaced or altered in form along environmental gradients, such as a cline forming along a rise in elevation. Humboldt drew inspiration from Isaac Newton as he developed a form of \"terrestrial physics\". In Newtonian fashion, he brought a scientific exactitude for measurement into natural history and even alluded to concepts that are the foundation of a modern ecological law on species-to-area relationships. Natural historians, such as Humboldt, James Hutton, and Jean-Baptiste Lamarck (among others) laid the foundations of the modern ecological sciences. The term \"ecology\" () was coined by Ernst Haeckel in his book \"Generelle Morphologie der Organismen\" (1866). Haeckel was a zoologist, artist, writer, and later in life a professor of comparative anatomy.\n\nOpinions differ on who was the founder of modern ecological theory. Some mark Haeckel's definition as the beginning; others say it was Eugenius Warming with the writing of Oecology of Plants: An Introduction to the Study of Plant Communities (1895), or Carl Linnaeus' principles on the economy of nature that matured in the early 18th century. Linnaeus founded an early branch of ecology that he called the economy of nature. His works influenced Charles Darwin, who adopted Linnaeus' phrase on the \"economy or polity of nature\" in \"The Origin of Species\". Linnaeus was the first to frame the balance of nature as a testable hypothesis. Haeckel, who admired Darwin's work, defined ecology in reference to the economy of nature, which has led some to question whether ecology and the economy of nature are synonymous.\n\nFrom Aristotle until Darwin, the natural world was predominantly considered static and unchanging. Prior to \"The Origin of Species\", there was little appreciation or understanding of the dynamic and reciprocal relations between organisms, their adaptations, and the environment. An exception is the 1789 publication \"Natural History of Selborne\" by Gilbert White (1720–1793), considered by some to be one of the earliest texts on ecology. While Charles Darwin is mainly noted for his treatise on evolution, he was one of the founders of soil ecology, and he made note of the first ecological experiment in \"The Origin of Species\". Evolutionary theory changed the way that researchers approached the ecological sciences.\n\nModern ecology is a young science that first attracted substantial scientific attention toward the end of the 19th century (around the same time that evolutionary studies were gaining scientific interest). The scientist Ellen Swallow Richards may have first introduced the term \"oekology\" (which eventually morphed into home economics) in the U.S. as early 1892.\n\nIn the early 20th century, ecology transitioned from a more descriptive form of natural history to a more analytical form of \"scientific natural history\". Frederic Clements published the first American ecology book in 1905, presenting the idea of plant communities as a superorganism. This publication launched a debate between ecological holism and individualism that lasted until the 1970s. Clements' superorganism concept proposed that ecosystems progress through regular and determined stages of seral development that are analogous to the developmental stages of an organism. The Clementsian paradigm was challenged by Henry Gleason, who stated that ecological communities develop from the unique and coincidental association of individual organisms. This perceptual shift placed the focus back onto the life histories of individual organisms and how this relates to the development of community associations.\n\nThe Clementsian superorganism theory was an overextended application of an idealistic form of holism. The term \"holism\" was coined in 1926 by Jan Christiaan Smuts, a South African general and polarizing historical figure who was inspired by Clements' superorganism concept. Around the same time, Charles Elton pioneered the concept of food chains in his classical book \"Animal Ecology\". Elton defined ecological relations using concepts of food chains, food cycles, and food size, and described numerical relations among different functional groups and their relative abundance. Elton's 'food cycle' was replaced by 'food web' in a subsequent ecological text. Alfred J. Lotka brought in many theoretical concepts applying thermodynamic principles to ecology.\n\nIn 1942, Raymond Lindeman wrote a landmark paper on the trophic dynamics of ecology, which was published posthumously after initially being rejected for its theoretical emphasis. Trophic dynamics became the foundation for much of the work to follow on energy and material flow through ecosystems. Robert MacArthur advanced mathematical theory, predictions, and tests in ecology in the 1950s, which inspired a resurgent school of theoretical mathematical ecologists. Ecology also has developed through contributions from other nations, including Russia's Vladimir Vernadsky and his founding of the biosphere concept in the 1920s and Japan's Kinji Imanishi and his concepts of harmony in nature and habitat segregation in the 1950s. Scientific recognition of contributions to ecology from non-English-speaking cultures is hampered by language and translation barriers.\n\nEcology surged in popular and scientific interest during the 1960–1970s environmental movement. There are strong historical and scientific ties between ecology, environmental management, and protection. The historical emphasis and poetic naturalistic writings advocating the protection of wild places by notable ecologists in the history of conservation biology, such as Aldo Leopold and Arthur Tansley, have been seen as far removed from urban centres where, it is claimed, the concentration of pollution and environmental degradation is located. Palamar (2008) notes an overshadowing by mainstream environmentalism of pioneering women in the early 1900s who fought for urban health ecology (then called euthenics) and brought about changes in environmental legislation. Women such as Ellen Swallow Richards and Julia Lathrop, among others, were precursors to the more popularized environmental movements after the 1950s.\n\nIn 1962, marine biologist and ecologist Rachel Carson's book \"Silent Spring\" helped to mobilize the environmental movement by alerting the public to toxic pesticides, such as DDT, bioaccumulating in the environment. Carson used ecological science to link the release of environmental toxins to human and ecosystem health. Since then, ecologists have worked to bridge their understanding of the degradation of the planet's ecosystems with environmental politics, law, restoration, and natural resources management.\n\nBULLET::::- Chemical ecology\nBULLET::::- Circles of Sustainability\nBULLET::::- Cultural ecology\nBULLET::::- Dialectical naturalism\nBULLET::::- Ecological death\nBULLET::::- Ecological psychology\nBULLET::::- Ecology movement\nBULLET::::- Ecosophy\nBULLET::::- Ecopsychology\nBULLET::::- Industrial ecology\nBULLET::::- Information ecology\nBULLET::::- Landscape ecology\nBULLET::::- Natural resource\nBULLET::::- Normative science\nBULLET::::- Political ecology\nBULLET::::- Sensory ecology\nBULLET::::- Spiritual ecology\nBULLET::::- Sustainable development\nBULLET::::- Lists\n\nBULLET::::- Glossary of ecology\nBULLET::::- Index of biology articles\nBULLET::::- List of ecologists\nBULLET::::- Outline of biology\n\nBULLET::::- Ecology (Stanford Encyclopedia of Philosophy)\nBULLET::::- The Nature Education Knowledge Project: Ecology\n"}
{"id": "9631", "url": "https://en.wikipedia.org/wiki?curid=9631", "title": "Glossary of country dance terms", "text": "Glossary of country dance terms\n\nAn alphabetic list of modern country dance terminology:\n\nActive couple - for longways sets, the active couple is the couple nearest the head of the set within each \"minor set.\" There are always exactly as many active couples as \"minor sets.\" If the dance is \"duple minor,\" this works out to every other couple, while in a \"triple minor\" it is every third couple. In older dances from the seventeenth and eighteenth centuries, the active couples do more complicated figures than the inactives, whence the name; however, this is not so usual in modern dances. Active couples may also be termed \"first couple\" or \"the Ones,\" while inactives are \"second couple/the Twos\" and (only in a \"triple minor\" dance) \"third couple/the Threes.\"\n\nArm right (or left) - couples link right (or left) arms and move forward in a circle, returning to their starting positions.\n\nBack to back - facing another person, move forward \"passing\" right shoulders and \"fall back\" to place passing left. May also start by passing left and falling back right. Called a do si do in contra dance (and \"dos-à-dos\" in France).\n\nBalance - a \"single,\" generally found in pairs, as \"balance forward and back.\"\n\nBecket formation - a 20th-century variation of the duple minor \"longways set.\" Each couple stands either on the men's line or the women's line, with the lady on the right. Within each minor set, one couple faces the left wall of the hall and the other the right wall, rather than facing the \"head\" or \"foot.\" There are no active or inactive couples. \"Progression\" is accomplished by each couple moving to their own left along their line at the end of each iteration of the dance; thus the couples on the men's line go up, while those on the women's line go down. This was originally a contra dance form but can sometimes be found in English country dance.\n\nBoth hands - two dancers face each other and give hands right to left and left to right.\n\nCast - turn outward and dance up or down outside the set, as directed. The instruction \"cast off\" is frequently synonymous with \"cast down\".\n\nChanges of right and left - like the \"circular hey\", but dancers give hands as they pass (handing hey). The number of changes is given first (e.g. two changes, three changes, etc.).\n\nChassé - slipping step to right or left as directed.\n\nCircular hey - dancers face partners or along the line and \"pass\" right and left alternating a stated number of changes. Usually done without hands, the circular hey may also be done by more than two couples facing alternately and moving in opposite directions - usually to their original places. This name for the figure was invented by Cecil Sharp and does not appear in sources pre-1900. Nonetheless, some early country dances calling for heys have been interpreted in modern times using circular heys. In early dances, where the hey is called a \"double hey\", it works to interpret this as an oval hey, like the modern circular hey but adapted to the straight sides of a longways formation.\n\nClockwise - in a ring, move to one's left. In a \"turn single\" turn to the right.\n\nContrary - your contrary is not your partner. In Playford's original notation, this term meant the same thing that \"Corner\" (or sometimes \"Opposite\") means today.\n\nCorner - in a two-couple \"minor set,\" the dancer diagonally opposite one. The first man and the second woman are \"first corners,\" while the first woman and second man are \"second corners.\" In other dance formations, it has similar meanings.\n\nCounter-clockwise - the opposite of clockwise - in a ring, move right. In a \"turn single\", turn to the left.\n\nCross hands - face and give left to left and right to right.\n\nCross over or pass - change places with another dancer moving forward and passing by the right shoulder, unless otherwise directed.\n\nCross and go below - cross as above and go outside below one couple, ending improper.\n\nDouble - four steps forward or back, closing the feet on the 4th step (see \"Single\" below).\n\nFall (back) - dance backwards.\n\nFigure of 8 - a weaving figure in which a moving couple crosses between a standing couple and casts around them in a figure 8 pattern. To do this once, ending in one's partner's place, is a half figure of 8; to do it twice, returning to one's own place, is a full figure of 8. The right of way in the cross has traditionally been given to the lady; some communities prefer to give it to whichever dancer is coming from the left-hand side. In a double figure of 8, the other couple does not stand still, but performs their own figure of 8 simultaneously; they begin with the cast and end with the cross to avoid collision.\n\nForward - \"lead\" or move in the direction you are facing.\n\nGrand chain - a handing hey (changes of right and left) done in a circle of more than two couples.\n\nGypsy - two dancers move around each other in a circular path while facing each other.\n\nHands across - right or left hands are given to \"corners\", and dancers move in the direction they face. In contra dance, instead of taking one's corner's hand, one grasps the wrist of the next dancer. Also known as a star right/left.\n\nHands three, four etc. - the designated number of dancers form a ring and move around in the direction indicated, usually first to the left and back to the right.\n\nHead and foot - the head of a \"longways set\" is the end with the music; the foot is the other end. Toward the head is \"up,\" and toward the foot is \"down.\"\n\nHey - a weaving figure in which dancers move in single file along a set track, passing one another on alternating sides (see \"circular hey\" and \"straight hey\"). In Scottish country dance, the hey is known as the reel.\n\n\"Hole in the Wall\" cross - a type of \"cross\". In a regular cross, the dancers walk past each other and turn upon reaching the other line; in a \"Hole in the Wall\" cross, they meet in the middle, make a brief half-turn without hands, and back into one another's place, maintaining eye contact the while. Named for \"Hole in the Wall,\" a dance in which it appears.\n\nHonour - couples step forward and right, close, shift weight, and curtsey or bow, then (usually) repeat to their left. In the time of Playford's original manual, a woman's curtsey was similar to the modern one, but a man's honour (or reverence) kept the upper body upright and involved sliding the left leg forward while bending the right knee \n\nImproper - see \"proper\".\n\nLadies' chain - a figure in which ladies dance first with each other in the center of the set and then with the gentlemen on the sides. In its simplest form, two ladies begin in \"second corner\" positions (nearer the head on the women's line and nearer the foot on the men's line). The ladies pass each other by right hand and turn with the gentlemen by left hand, approximately once around, to end with the ladies in each other's place and the gentlemen where they began. The figure can be extended to more couples in a ring, as long as the dancers in the ring are alternating between gentlemen and ladies. If the gentlemen turn the ladies only by left hand, that is an open ladies' chain; if they also place their right hands on the ladies' backs during the turn, that is a closed ladies' chain. In English country dance, both closed and open ladies' chains are to be found, and the gentlemen make a short \"cast\" up or down the set to meet the ladies; in contra dance, only the closed ladies' chain is done, and the gentlemen sidestep to meet the ladies. The men's chain is a simple gender reversal, but is a much rarer figure.\n\nLead - join inside hands and walk in a certain direction. To lead up or down is to walk toward or away from the head of the set; to lead out is to walk away from the other line of dancers.\n\nLink - see \"set and link\".\n\nLongways set - a line of couples dancing together. This is usually \"longways for as many as will,\" indicating that any number of couples may join the longways set—although some dances require a three- or four-couple longways set. If the longways set is not restricted to three or four couples, it will be subdivided into \"minor sets\" of two or three couples each.\n\n\"Mad Robin\" figure - a figure in which one couple dances around their respective neighbours. Men take one step forward and then slide to the right passing in front of their neighbour, then step backward and slide left behind their neighbour. Conversely women take one step backward and then slide to the left passing behind their neighbour, then step forward and slide right in front of their neighbour. In one version, the dancer who is going outside the set at the moment casts out to begin that motion; in the other, the active couple maintains eye contact. The term \"Mad Robin\" comes from the name of the dance which originated the figure. A version involving all four dancers was developed for contra dancing and later readmitted into some modern English dances.\n\nMinor set - a \"longways set\" is subdivided into several minor sets. In a \"duple minor\" dance, every two couples form a minor set. In a \"triple minor\" dance, every three couples form a minor set. The \"active couple\" is always the couple in each minor set who are closest to the head. After every iteration of the dance, the \"progression\" will create new minor sets for the next iteration.\n\nNeighbour - the person you are standing beside, but not your partner.\n\nOpposite - the person you are facing, if you are not facing your partner.\n\nPoussette - two dancers face, give both hands and change places as a couple with two adjacent dancers. One pair moves a \"double\" toward one wall, the other toward the other wall; they shift up or down, respectively, and move into the other couple's place with another \"double.\" This completes a half-poussette; it is repeated for a whole poussette. In a draw poussette, each couple turns instead of reversing direction, so that the same dancer in each couple is always in the lead.\n\nProgression - the process by which every couple will eventually dance with every other couple in the set, if the dance is repeated enough times. In a \"duple minor\" dance with five couples dancing, for example, the couples are initially in this order: Active (couple A)/Inactive (couple B)/Active (couple C)/Inactive (couple D)/Out (couple E). This represents two \"minor sets\" (couples A-B and couples C-D) and one couple (couple E) who are \"standing out\" due to having no one to dance with. After one iteration of the dance, every active couple will have moved below the inactive couple in their \"minor set,\" which in the example would be thus: Inactive (couple B)/Active (couple A)/Inactive (couple D)/Active (couple C)/Out (couple E). For the next iteration, any inactive couple at the top (and any active couple at the bottom) will stand out, while any couple standing out will begin dancing as actives (if at the top) or inactives (if at the bottom). So the next iteration would begin as follows: Out (couple B)/Active (couple A)/Inactive (couple D)/Active (couple C)/Inactive (couple E). The \"minor sets\" now contain couples A-D and couples C-E, while couple B is \"standing out.\" Dances in other forms progress differently, though the \"triple minor\" progression is quite similar.\n\nProgression, double or triple - a longways dance has a double progression if the arrangement of couples into minor sets advances twice during one iteration of the dance instead of just once. A triple-progression dance advances thrice during one iteration.\n\nProper - with the man on the left and the woman on the right, from the perspective of someone facing the music. Improper is the opposite. The terms carry no value judgment, but only indicate whether one is on one's \"home\" side. A dance in duple-minor longways form is termed \"improper\" if the active couples are improper by default; this is the exception in English country dance, but the rule in contra dance.\n\nRight and left - see \"changes of right and left.\"\n\nSet - a dancer steps right, closes with left foot and shifts weight to it, then steps back to the right foot (right-together-step); then repeats the process mirror-image (left-together-step). In some areas, such as the Society for Creative Anachronism, it is done starting to the left. It may be done in place or advancing. Often followed by a turn single. In Scottish country dance there are several variations; in contra dance its place is generally taken by a \"balance right and left.\" Not to be confused with terms indicating groups of dancers, like \"longways set\" or \"minor set.\"\n\nSet and link - a figure done by a pair of dancers and simultaneously by another pair of dancers who are facing them. Most commonly this means that the men do it facing the women, while the women do it facing the men. First, all dancers \"set;\" then the dancer on the left of each pair dances a \"turn single right,\" while also moving to the right, to end in his or her neighbor's place. Meanwhile the dancer on the right of each pair \"casts\" to the left into his or her neighbor's place; thus the men have traded places with each other, and so have the women. This figure is most commonly found in Scottish country dance.\n\nSicilian circle - a type of dance formation, roughly equivalent to a \"longways set\" rolled into a ring. Every couple stands along the line of a large circle, facing another couple; thus half of the couples face clockwise, while the other half face counterclockwise. Since, unlike the \"longways set,\" the Sicilian circle has no place for dancers to \"stand out,\" Sicilian circle dances must be done by an even number of couples. The \"progression\" is similar to that of a \"duple minor,\" but since there is nowhere for couples to reverse direction, every clockwise couple will only dance with the counterclockwise couples (and vice versa).\n\nSiding - two dancers go forward in four counts to meet side by side, then back in four counts to where they started the figure. As depicted by Feuillet, this is done right side by right side the first time, left by left the second time. In Cecil Sharp's reconstruction, the dancers pass by left shoulder (in some versions holding hands), turn to face each other, then return along the same path, passing by right shoulder; this is then repeated. So-called \"Cecil Sharp siding\" is no longer considered historical, but is still used on its own merits. Standard siding is sometimes called \"Pat Shaw siding\" (after its reconstructor) to distinguish it from \"Cecil Sharp siding.\"\n\nSingle - two steps in any direction, closing feet on the second step. The second step tends to be interpreted as a closing action in which weight usually stays on the same foot as before, consistent with descriptions from Renaissance sources.\n\nSlipping circle (left or right) - dancers take hands in a circle (facing in) and chassé left or right.\n\nStar - see \"hands across.\"\n\nStraight hey for four - dancers face alternately, the two in the middle facing out. Dancers pass right shoulders on either end and weave to the end opposite. If the last pass at the end is by the right, the dancer turns right and reenters the line by the same shoulder; vice versa if the last pass was to the left. Dancers end in their original places.\n\nStraight hey for three - the first dancer faces the other two and \"passes\" right shoulders with the second dancer, left shoulder with the third - the other dancers moving and passing the indicated shoulder. On making the last pass, each dancer makes a whole turn on the end, bearing right if the last pass was by the right shoulder or left if last pass was by the left, and reenters the figure returning to place. Each dancer describes a figure of eight pattern.\n\nSwing - a \"turn\" with two hands, but moving faster and making more than one revolution. Several variants exist, including the ballroom swing and the Welsh swing.\n\nTrack figure - a generic term for any composite figure where the dancers involved travel within the set. An example track figure might be \"Ones cast around the Twos, cross, cast around the Threes, and lead back up to place.\" The \"figure of 8\" would be considered a track figure if it were not common enough to have its own name.\n\nTurn both-hands - face, give \"both hands\", and make a complete circular, clockwise turn to place.\n\nTurn by right or left - dancers join right (or left) hands and turn around, separate, and \"fall\" to places.\n\nTurn single - dancers turn around in four steps. \"Turn single right\" is a clockwise turn; \"turn single left\" is a counterclockwise turn. May involve a backward motion, as after a \"set advancing.\"\n\nUp a double and back - common combination in which dancers, usually having linked hands in a line, advance a double and then retire another double.\n"}
{"id": "9632", "url": "https://en.wikipedia.org/wiki?curid=9632", "title": "Ecosystem", "text": "Ecosystem\n\nAn ecosystem is a community of living organisms in conjunction with the nonliving components of their environment, interacting as a system. These biotic and abiotic components are linked together through nutrient cycles and energy flows. Energy enters the system through photosynthesis and is incorporated into plant tissue. By feeding on plants and on one-another, animals play an important role in the movement of matter and energy through the system. They also influence the quantity of plant and microbial biomass present. By breaking down dead organic matter, decomposers release carbon back to the atmosphere and facilitate nutrient cycling by converting nutrients stored in dead biomass back to a form that can be readily used by plants and other microbes.\n\nEcosystems are controlled by external and internal factors. External factors such as climate, parent material which forms the soil and topography, control the overall structure of an ecosystem but are not themselves influenced by the ecosystem. Unlike external factors, internal factors are controlled, for example, decomposition, root competition, shading, disturbance, succession, and the types of species present.\n\nEcosystems are dynamic entities—they are subject to periodic disturbances and are in the process of recovering from some past disturbance. Ecosystems in similar environments that are located in different parts of the world can end up doing things very differently simply because they have different pools of species present. Internal factors not only control ecosystem processes but are also controlled by them and are often subject to feedback loops.\n\nResource inputs are generally controlled by external processes like climate and parent material. Resource availability within the ecosystem is controlled by internal factors like decomposition, root competition or shading. Although humans operate within ecosystems, their cumulative effects are large enough to influence external factors like climate.\n\nBiodiversity affects ecosystem functioning, as do the processes of disturbance and succession. Ecosystems provide a variety of goods and services upon which people depend.\n\nThe term ecosystem was first used in 1935 in a publication by British ecologist Arthur Tansley. Tansley devised the concept to draw attention to the importance of transfers of materials between organisms and their environment. He later refined the term, describing it as \"The whole system, ... including not only the organism-complex, but also the whole complex of physical factors forming what we call the environment\". Tansley regarded ecosystems not simply as natural units, but as \"mental isolates\". Tansley later defined the spatial extent of ecosystems using the term ecotope.\n\nG. Evelyn Hutchinson, a limnologist who was a contemporary of Tansley's, combined Charles Elton's ideas about trophic ecology with those of Russian geochemist Vladimir Vernadsky. As a result, he suggested that mineral nutrient availability in a lake limited algal production. This would, in turn, limit the abundance of animals that feed on algae. Raymond Lindeman took these ideas further to suggest that the flow of energy through a lake was the primary driver of the ecosystem. Hutchinson's students, brothers Howard T. Odum and Eugene P. Odum, further developed a \"systems approach\" to the study of ecosystems. This allowed them to study the flow of energy and material through ecological systems.\n\nEcosystems are controlled both by external and internal factors. External factors, also called state factors, control the overall structure of an ecosystem and the way things work within it, but are not themselves influenced by the ecosystem. The most important of these is climate. Climate determines the biome in which the ecosystem is embedded. Rainfall patterns and seasonal temperatures influence photosynthesis and thereby determine the amount of water and energy available to the ecosystem.\n\nParent material determines the nature of the soil in an ecosystem, and influences the supply of mineral nutrients. Topography also controls ecosystem processes by affecting things like microclimate, soil development and the movement of water through a system. For example, ecosystems can be quite different if situated in a small depression on the landscape, versus one present on an adjacent steep hillside.\n\nOther external factors that play an important role in ecosystem functioning include time and potential biota. Similarly, the set of organisms that can potentially be present in an area can also significantly affect ecosystems. Ecosystems in similar environments that are located in different parts of the world can end up doing things very differently simply because they have different pools of species present. The introduction of non-native species can cause substantial shifts in ecosystem function.\n\nUnlike external factors, internal factors in ecosystems not only control ecosystem processes but are also controlled by them. Consequently, they are often subject to feedback loops. While the resource inputs are generally controlled by external processes like climate and parent material, the availability of these resources within the ecosystem is controlled by internal factors like decomposition, root competition or shading. Other factors like disturbance, succession or the types of species present are also internal factors.\n\nPrimary production is the production of organic matter from inorganic carbon sources. This mainly occurs through photosynthesis. The energy incorporated through this process supports life on earth, while the carbon makes up much of the organic matter in living and dead biomass, soil carbon and fossil fuels. It also drives the carbon cycle, which influences global climate via the greenhouse effect.\n\nThrough the process of photosynthesis, plants capture energy from light and use it to combine carbon dioxide and water to produce carbohydrates and oxygen. The photosynthesis carried out by all the plants in an ecosystem is called the gross primary production (GPP). About half of the GPP is consumed in plant respiration. The remainder, that portion of GPP that is not used up by respiration, is known as the net primary production (NPP). Total photosynthesis is limited by a range of environmental factors. These include the amount of light available, the amount of leaf area a plant has to capture light (shading by other plants is a major limitation of photosynthesis), rate at which carbon dioxide can be supplied to the chloroplasts to support photosynthesis, the availability of water, and the availability of suitable temperatures for carrying out photosynthesis.\n\nEnergy and carbon enter ecosystems through photosynthesis, are incorporated into living tissue, transferred to other organisms that feed on the living and dead plant matter, and eventually released through respiration.\n\nThe carbon and energy incorporated into plant tissues (net primary production) is either consumed by animals while the plant is alive, or it remains uneaten when the plant tissue dies and becomes detritus. In terrestrial ecosystems, roughly 90% of the net primary production ends up being broken down by decomposers. The remainder is either consumed by animals while still alive and enters the plant-based trophic system, or it is consumed after it has died, and enters the detritus-based trophic system.\n\nIn aquatic systems, the proportion of plant biomass that gets consumed by herbivores is much higher.\nIn trophic systems photosynthetic organisms are the primary producers. The organisms that consume their tissues are called primary consumers or secondary producers—herbivores. Organisms which feed on microbes (bacteria and fungi) are termed microbivores. Animals that feed on primary consumers—carnivores—are secondary consumers. Each of these constitutes a trophic level.\n\nThe sequence of consumption—from plant to herbivore, to carnivore—forms a food chain. Real systems are much more complex than this—organisms will generally feed on more than one form of food, and may feed at more than one trophic level. Carnivores may capture some prey which is part of a plant-based trophic system and others that are part of a detritus-based trophic system (a bird that feeds both on herbivorous grasshoppers and earthworms, which consume detritus). Real systems, with all these complexities, form food webs rather than food chains. The food chain usually consists of four levels of consumption which are producers, primary consumers, secondary consumers, and tertiary consumers.\n\nThe carbon and nutrients in dead organic matter are broken down by a group of processes known as decomposition. This releases nutrients that can then be re-used for plant and microbial production and returns carbon dioxide to the atmosphere (or water) where it can be used for photosynthesis. In the absence of decomposition, the dead organic matter would accumulate in an ecosystem, and nutrients and atmospheric carbon dioxide would be depleted. Approximately 90% of terrestrial net primary production goes directly from plant to decomposer.\n\nDecomposition processes can be separated into three categories—leaching, fragmentation and chemical alteration of dead material. As water moves through dead organic matter, it dissolves and carries with it the water-soluble components. These are then taken up by organisms in the soil, react with mineral soil, or are transported beyond the confines of the ecosystem (and are considered lost to it). Newly shed leaves and newly dead animals have high concentrations of water-soluble components and include sugars, amino acids and mineral nutrients. Leaching is more important in wet environments and much less important in dry ones.\n\nFragmentation processes break organic material into smaller pieces, exposing new surfaces for colonization by microbes. Freshly shed leaf litter may be inaccessible due to an outer layer of cuticle or bark, and cell contents are protected by a cell wall. Newly dead animals may be covered by an exoskeleton. Fragmentation processes, which break through these protective layers, accelerate the rate of microbial decomposition. Animals fragment detritus as they hunt for food, as does passage through the gut. Freeze-thaw cycles and cycles of wetting and drying also fragment dead material.\n\nThe chemical alteration of the dead organic matter is primarily achieved through bacterial and fungal action. Fungal hyphae produces enzymes that can break through the tough outer structures surrounding dead plant material. They also produce enzymes which break down lignin, which allows them access to both cell contents and the nitrogen in the lignin. Fungi can transfer carbon and nitrogen through their hyphal networks and thus, unlike bacteria, are not dependent solely on locally available resources.\n\nDecomposition rates vary among ecosystems. The rate of decomposition is governed by three sets of factors—the physical environment (temperature, moisture, and soil properties), the quantity and quality of the dead material available to decomposers, and the nature of the microbial community itself. Temperature controls the rate of microbial respiration; the higher the temperature, the faster the microbial decomposition occurs. It also affects soil moisture, which slows microbial growth and reduces leaching. Freeze-thaw cycles also affect decomposition—freezing temperatures kill soil microorganisms, which allows leaching to play a more important role in moving nutrients around. This can be especially important as the soil thaws in the spring, creating a pulse of nutrients which become available.\n\nDecomposition rates are low under very wet or very dry conditions. Decomposition rates are highest in wet, moist conditions with adequate levels of oxygen. Wet soils tend to become deficient in oxygen (this is especially true in wetlands), which slows microbial growth. In dry soils, decomposition slows as well, but bacteria continue to grow (albeit at a slower rate) even after soils become too dry to support plant growth.\n\nEcosystems continually exchange energy and carbon with the wider environment. Mineral nutrients, on the other hand, are mostly cycled back and forth between plants, animals, microbes and the soil. Most nitrogen enters ecosystems through biological nitrogen fixation, is deposited through precipitation, dust, gases or is applied as fertilizer.\n\nSince most terrestrial ecosystems are nitrogen-limited, nitrogen cycling is an important control on ecosystem production.\n\nUntil modern times, nitrogen fixation was the major source of nitrogen for ecosystems. Nitrogen-fixing bacteria either live symbiotically with plants or live freely in the soil. The energetic cost is high for plants that support nitrogen-fixing symbionts—as much as 25% of gross primary production when measured in controlled conditions. Many members of the legume plant family support nitrogen-fixing symbionts. Some cyanobacteria are also capable of nitrogen fixation. These are phototrophs, which carry out photosynthesis. Like other nitrogen-fixing bacteria, they can either be free-living or have symbiotic relationships with plants. Other sources of nitrogen include acid deposition produced through the combustion of fossil fuels, ammonia gas which evaporates from agricultural fields which have had fertilizers applied to them, and dust. Anthropogenic nitrogen inputs account for about 80% of all nitrogen fluxes in ecosystems.\n\nWhen plant tissues are shed or are eaten, the nitrogen in those tissues becomes available to animals and microbes. Microbial decomposition releases nitrogen compounds from dead organic matter in the soil, where plants, fungi, and bacteria compete for it. Some soil bacteria use organic nitrogen-containing compounds as a source of carbon, and release ammonium ions into the soil. This process is known as nitrogen mineralization. Others convert ammonium to nitrite and nitrate ions, a process known as nitrification. Nitric oxide and nitrous oxide are also produced during nitrification. Under nitrogen-rich and oxygen-poor conditions, nitrates and nitrites are converted to nitrogen gas, a process known as denitrification.\n\nOther important nutrients include phosphorus, sulfur, calcium, potassium, magnesium and manganese. Phosphorus enters ecosystems through weathering. As ecosystems age this supply diminishes, making phosphorus-limitation more common in older landscapes (especially in the tropics). Calcium and sulfur are also produced by weathering, but acid deposition is an important source of sulfur in many ecosystems. Although magnesium and manganese are produced by weathering, exchanges between soil organic matter and living cells account for a significant portion of ecosystem fluxes. Potassium is primarily cycled between living cells and soil organic matter.\n\nBiodiversity plays an important role in ecosystem functioning. The reason for this is that ecosystem processes are driven by the number of species in an ecosystem, the exact nature of each individual species, and the relative abundance organisms within these species. Ecosystem processes are broad generalizations that actually take place through the actions of individual organisms. The nature of the organisms—the species, functional groups and trophic levels to which they belong—dictates the sorts of actions these individuals are capable of carrying out and the relative efficiency with which they do so.\n\nEcological theory suggests that in order to coexist, species must have some level of limiting similarity—they must be different from one another in some fundamental way, otherwise one species would competitively exclude the other. Despite this, the cumulative effect of additional species in an ecosystem is not linear—additional species may enhance nitrogen retention, for example, but beyond some level of species richness, additional species may have little additive effect.\n\nThe addition (or loss) of species that are ecologically similar to those already present in an ecosystem tends to only have a small effect on ecosystem function. Ecologically distinct species, on the other hand, have a much larger effect. Similarly, dominant species have a large effect on ecosystem function, while rare species tend to have a small effect. Keystone species tend to have an effect on ecosystem function that is disproportionate to their abundance in an ecosystem. Similarly, an ecosystem engineer is any organism that creates, significantly modifies, maintains or destroys a habitat.\n\nEcosystems are dynamic entities. They are subject to periodic disturbances and are in the process of recovering from some past disturbance. When a perturbation occurs, an ecosystem responds by moving away from its initial state. The tendency of an ecosystem to remain close to its equilibrium state, despite that disturbance, is termed its resistance. On the other hand, the speed with which it returns to its initial state after disturbance is called it's resilience. Time plays a role in the development of soil from bare rock and the recovery of a community from disturbance.\n\nFrom one year to another, ecosystems experience variation in their biotic and abiotic environments. A drought, a colder than usual winter, and a pest outbreak all are short-term variability in environmental conditions. Animal populations vary from year to year, building up during resource-rich periods and crashing as they overshoot their food supply. These changes play out in changes in net primary production decomposition rates, and other ecosystem processes. Longer-term changes also shape ecosystem processes—the forests of eastern North America still show legacies of cultivation which ceased 200 years ago, while methane production in eastern Siberian lakes is controlled by organic matter which accumulated during the Pleistocene.\n\nDisturbance also plays an important role in ecological processes. F. Stuart Chapin and coauthors define disturbance as \"a relatively discrete event in time and space that alters the structure of populations, communities, and ecosystems and causes changes in resources availability or the physical environment\". This can range from tree falls and insect outbreaks to hurricanes and wildfires to volcanic eruptions. Such disturbances can cause large changes in plant, animal and microbe populations, as well as soil organic matter content. Disturbance is followed by succession, a \"directional change in ecosystem structure and functioning resulting from biotically driven changes in resources supply.\"\n\nThe frequency and severity of disturbance determine the way it affects ecosystem function. A major disturbance like a volcanic eruption or glacial advance and retreat leave behind soils that lack plants, animals or organic matter. Ecosystems that experience such disturbances undergo primary succession. A less severe disturbance like forest fires, hurricanes or cultivation result in secondary succession and a faster recovery. More severe disturbance and more frequent disturbance result in longer recovery times.\n\nEcosystem ecology studies the processes and dynamics of ecosystems, and the way the flow of matter and energy through them structures natural systems. The study of ecosystems can cover 10 orders of magnitude, from the surface layers of rocks to the surface of the planet.\n\nThere is no single definition of what constitutes an ecosystem. German ecologist Ernst-Detlef Schulze and coauthors defined an ecosystem as an area which is \"uniform regarding the biological turnover, and contains all the fluxes above and below the ground area under consideration.\" They explicitly reject Gene Likens' use of entire river catchments as \"too wide a demarcation\" to be a single ecosystem, given the level of heterogeneity within such an area. Other authors have suggested that an ecosystem can encompass a much larger area, even the whole planet. Schulze and coauthors also rejected the idea that a single rotting log could be studied as an ecosystem because the size of the flows between the log and its surroundings are too large, relative to the proportion cycles within the log. Philosopher of science Mark Sagoff considers the failure to define \"the kind of object it studies\" to be an obstacle to the development of theory in ecosystem ecology.\n\nEcosystems can be studied through a variety of approaches—theoretical studies, studies monitoring specific ecosystems over long periods of time, those that look at differences between ecosystems to elucidate how they work and direct manipulative experimentation. Studies can be carried out at a variety of scales, ranging from whole-ecosystem studies to studying or mesocosms (simplified representations of ecosystems). American ecologist Stephen R. Carpenter has argued that microcosm experiments can be \"irrelevant and diversionary\" if they are not carried out in conjunction with field studies done at the ecosystem scale. Microcosm experiments often fail to accurately predict ecosystem-level dynamics.\n\nThe Hubbard Brook Ecosystem Study started in 1963 to study the White Mountains in New Hampshire. It was the first successful attempt to study an entire watershed as an ecosystem. The study used stream chemistry as a means of monitoring ecosystem properties, and developed a detailed biogeochemical model of the ecosystem. Long-term research at the site led to the discovery of acid rain in North America in 1972. Researchers documented the depletion of soil cations (especially calcium) over the next several decades.\n\nHuman activities are important in almost all ecosystems. Although humans exist and operate within ecosystems, their cumulative effects are large enough to influence external factors like climate.\n\nEcosystems provide a variety of goods and services upon which people depend. Ecosystem goods include the \"tangible, material products\" of ecosystem processes such as food, construction material, medicinal plants. They also include less tangible items like tourism and recreation, and genes from wild plants and animals that can be used to improve domestic species.\n\nEcosystem services, on the other hand, are generally \"improvements in the condition or location of things of value\". These include things like the maintenance of hydrological cycles, cleaning air and water, the maintenance of oxygen in the atmosphere, crop pollination and even things like beauty, inspiration and opportunities for research. While material from the ecosystem had traditionally been recognized as being the basis for things of economic value, ecosystem services tend to be taken for granted.\n\nWhen natural resource management is applied to whole ecosystems, rather than single species, it is termed ecosystem management. Although definitions of ecosystem management abound, there is a common set of principles which underlie these definitions. A fundamental principle is the long-term sustainability of the production of goods and services by the ecosystem; \"intergenerational sustainability [is] a precondition for management, not an afterthought\".\n\nWhile ecosystem management can be used as part of a plan for wilderness conservation, it can also be used in intensively managed ecosystems (see, for example, agroecosystem and close to nature forestry).\n\nAs human population and per capita consumption grow, so do the resource demands imposed on ecosystems and the effects of the human ecological footprint. Natural resources are vulnerable and limited. The environmental impacts of anthropogenic actions are becoming more apparent. Problems for all ecosystems include: environmental pollution, climate change and biodiversity loss. For terrestrial ecosystems further threats include air pollution, soil degradation, and deforestation. For aquatic ecosystems threats include also unsustainable exploitation of marine resources (for example overfishing of certain species), marine pollution, microplastics pollution, water pollution, the warming of oceans, and building on coastal areas.\n\nSociety is increasingly becoming aware that ecosystem services are not only limited but also that they are threatened by human activities. The need to better consider long-term ecosystem health and its role in enabling human habitation and economic activity is urgent. To help inform decision-makers, many ecosystem services are being assigned economic values, often based on the cost of replacement with anthropogenic alternatives. The ongoing challenge of prescribing economic value to nature, for example through biodiversity banking, is prompting transdisciplinary shifts in how we recognize and manage the environment, social responsibility, business opportunities, and our future as a species.\n\nBULLET::::- Biosphere\nBULLET::::- Climate change\nBULLET::::- Complex system\nBULLET::::- Earth science\nBULLET::::- Ecocide\nBULLET::::- Ecosystem services\nBULLET::::- Forest ecology\nBULLET::::- Human ecology\nBULLET::::- Nature-based solutions\nBULLET::::- Novel ecosystem\n\nBULLET::::- PDF.\n\nBULLET::::- Millennium Ecosystem Assessment (2005)\nBULLET::::- The State of the Nation's Ecosystems (U.S.)\n"}
{"id": "9633", "url": "https://en.wikipedia.org/wiki?curid=9633", "title": "E (mathematical constant)", "text": "E (mathematical constant)\n\nThe number is a mathematical constant that is the base of the natural logarithm: the unique number whose natural logarithm is equal to one. It is approximately equal to 2.71828, and is the limit of as approaches infinity, an expression that arises in the study of compound interest. It can also be calculated as the sum of the infinite series\n\nThe constant can be characterized in many different ways. For example, it can be defined as the unique positive number such that the graph of the function has unit slope at . The function is called the (natural) exponential function, and is the unique exponential function equal to its own derivative. The natural logarithm, or logarithm to base , is the inverse function to the natural exponential function. The natural logarithm of a number can be defined directly as the area under the curve between and , in which case is the value of \"k\" for which this area equals one (see image). There are alternative characterizations.\n\nThe number is of eminent importance in mathematics, alongside 0, 1, , and . All five of these numbers play important and recurring roles across mathematics, and are the five constants appearing in one formulation of Euler's identity. Like the constant , is irrational: it is not a ratio of integers. Also like , is transcendental: it is not a root of any non-zero polynomial with rational coefficients. The numerical value of truncated to 50 decimal places is\nThe first references to the constant were published in 1618 in the table of an appendix of a work on logarithms by John Napier. However, this did not contain the constant itself, but simply a list of logarithms calculated from the constant. It is assumed that the table was written by William Oughtred. The discovery of the constant itself is credited to Jacob Bernoulli in 1683, who attempted to find the value of the following expression (which is in fact ):\n\nThe first known use of the constant, represented by the letter , was in correspondence from Gottfried Leibniz to Christiaan Huygens in 1690 and 1691. Leonhard Euler introduced the letter as the base for natural logarithms, writing in a letter to Christian Goldbach on 25 November 1731. Euler started to use the letter for the constant in 1727 or 1728, in an unpublished paper on explosive forces in cannons, and the first appearance of in a publication was in Euler's \"Mechanica\" (1736). While in the subsequent years some researchers used the letter , the letter was more common and eventually became standard.\n\nIn mathematics, the standard is to typeset the constant as \"\", in italics; the ISO 80000-2:2009 standard recommends typesetting constants in an upright style, but this has not been validated by scientific community.\n\nJacob Bernoulli discovered this constant in 1683 by studying a question about compound interest:\nIf the interest is credited twice in the year, the interest rate for each 6 months will be 50%, so the initial $1 is multiplied by 1.5 twice, yielding at the end of the year. Compounding quarterly yields , and compounding monthly yields If there are compounding intervals, the interest for each interval will be and the value at the end of the year will be $1.00×.\n\nBernoulli noticed that this sequence approaches a limit (the force of interest) with larger and, thus, smaller compounding intervals. Compounding weekly () yields $2.692597..., while compounding daily () yields $2.714567..., just two cents more. The limit as grows large is the number that came to be known as ; with \"continuous\" compounding, the account value will reach $2.7182818...\n\nMore generally, an account that starts at $1 and offers an annual interest rate of will, after years, yield dollars with continuous compounding. (Here is the decimal equivalent of the rate of interest expressed as a percentage, so for 5% interest, .)\n\nThe number itself also has applications to probability theory, where it arises in a way not obviously related to exponential growth. Suppose that a gambler plays a slot machine that pays out with a probability of one in and plays it times. Then, for large (such as a million) the probability that the gambler will lose every bet is approximately . For it is already approximately 1/2.79.\n\nThis is an example of a Bernoulli trial process. Each time the gambler plays the slots, there is a one in one million chance of winning. Playing one million times is modelled by the binomial distribution, which is closely related to the binomial theorem and Pascal's triangle. The probability of winning times out of a million trials is:\n\nIn particular, the probability of winning zero times () is\n\nThis is very close to the limit\n\nThe normal distribution with zero mean and unit standard deviation is known as the \"standard normal distribution\", given by the probability density function\n\nThe constraint of unit variance (and thus also unit standard deviation) results in the in the exponent, and the constraint of unit total area under the curve results in the factor formula_7. This function is symmetric around , where it attains its maximum value formula_7, and has inflection points at .\n\nAnother application of , also discovered in part by Jacob Bernoulli along with Pierre Raymond de Montmort, is in the problem of derangements, also known as the \"hat check problem\": guests are invited to a party, and at the door, the guests all check their hats with the butler, who in turn places the hats into boxes, each labelled with the name of one guest. But the butler has not asked the identities of the guests, and so he puts the hats into boxes selected at random. The problem of de Montmort is to find the probability that \"none\" of the hats gets put into the right box. The answer is:\n\nAs the number of guests tends to infinity, approaches . Furthermore, the number of ways the hats can be placed into the boxes so that none of the hats are in the right box is rounded to the nearest integer, for every positive .\n\nA stick of length is broken into equal parts. The value of that maximizes the product of the lengths is then either\n\nThe stated result follows because the maximum value of formula_12 occurs at formula_13 (Steiner's problem, discussed below). The quantity formula_12 is a measure of information gleaned from an event occurring with probability formula_15, so that essentially the same optimal division appears in optimal planning problems like the secretary problem.\n\nThe number occurs naturally in connection with many problems involving asymptotics. An example is Stirling's formula for the asymptotics of the factorial function, in which both the numbers and enter:\n\nAs a consequence,\n\nThe principal motivation for introducing the number , particularly in calculus, is to perform differential and integral calculus with exponential functions and logarithms. A general exponential has a derivative, given by a limit:\n\nThe parenthesized limit on the right is independent of the it depends only on the When the base is set this limit is equal and so is symbolically defined by the equation:\n\nConsequently, the exponential function with base is particularly suited to doing calculus. as opposed to some other number, as the base of the exponential function makes calculations involving the derivative much simpler.\n\nAnother motivation comes from considering the derivative of the base- logarithm, i.e., of for :\n\nwhere the substitution was made. The -logarithm of is 1, if equals . So symbolically,\n\nThe logarithm with this special base is called the natural logarithm and is denoted as ; it behaves well under differentiation since there is no undetermined limit to carry through the calculations.\n\nThere are thus two ways in which to select such special numbers . One way is to set the derivative of the exponential function equal to , and solve for . The other way is to set the derivative of the base logarithm to and solve for . In each case, one arrives at a convenient choice of base for doing calculus. It turns out that these two solutions for are actually \"the same\", the number .\n\nOther characterizations of are also possible: one is as the limit of a sequence, another is as the sum of an infinite series, and still others rely on integral calculus. So far, the following two (equivalent) properties have been introduced:\n\nBULLET::::1. The number is the unique positive real number such that formula_22.\nBULLET::::2. The number is the unique positive real number such that formula_23.\n\nThe following four characterizations can be proven equivalent:\n\n</math>\n\nwhere is the factorial of . (By convention formula_25.)\n\nAs in the motivation, the exponential function is important in part because it is the unique nontrivial function (up to multiplication by a constant) which is its own derivative\n\nand therefore its own antiderivative as well:\n\nThe number is the unique real number such that\n\nfor all positive .\n\nAlso, we have the inequality\n\nfor all real , with equality if and only if . Furthermore, is the unique base of the exponential for which the inequality holds for all . This is a limiting case of Bernoulli's inequality.\n\nSteiner's problem asks to find the global maximum for the function\n\nThis maximum occurs precisely at . For proof, the inequality formula_34, from above, evaluated at formula_35 and simplifying gives formula_36. So formula_37 for all positive \"x\".\n\nSimilarly, is where the global minimum occurs for the function\n\ndefined for positive . More generally, for the function\n\nthe global maximum for positive occurs at for any ; and the global minimum occurs at for any .\n\nThe infinite tetration\n\nconverges if and only if (or approximately between 0.0660 and 1.4447), due to a theorem of Leonhard Euler.\n\nThe real number is irrational. Euler proved this by showing that its simple continued fraction expansion is infinite. (See also Fourier's proof that is irrational.)\n\nFurthermore, by the Lindemann–Weierstrass theorem, is transcendental, meaning that it is not a solution of any non-constant polynomial equation with rational coefficients. It was the first number to be proved transcendental without having been specifically constructed for this purpose (compare with Liouville number); the proof was given by Charles Hermite in 1873.\n\nIt is conjectured that is normal, meaning that when is expressed in any base the possible digits in that base are uniformly distributed (occur with equal probability in any sequence of given length).\n\nThe exponential function may be written as a Taylor series\n\nBecause this series is convergent for every complex value of , it is commonly used to extend the definition of to the complex numbers. This, with the Taylor series for and, allows one to derive Euler's formula:\n\nwhich holds for every complex . The special case with is Euler's identity:\n\nfrom which it follows that, in the principal branch of the logarithm,\n\nFurthermore, using the laws for exponentiation,\n\nwhich is de Moivre's formula.\n\nThe expression\n\nis sometimes referred to as .\n\nThe expressions of formula_48 and formula_49 in terms of the exponential function can be deduced:\n\nThe family of functions\n\nwhere is any real number, is the solution to the differential equation\n\nThe number can be represented as a real number in a variety of ways: as an infinite series, an infinite product, a continued fraction, or a limit of a sequence. The chief among these representations, particularly in introductory calculus courses is the limit\n\ngiven above, as well as the series\n\ngiven by evaluating the above power series for at .\n\nLess common is the continued fraction\n\nwhich written out looks like\n\nThis continued fraction for converges three times as quickly:\n\nMany other series, sequence, continued fraction, and infinite product representations of have been developed.\n\nIn addition to exact analytical expressions for representation of , there are stochastic techniques for estimating . One such approach begins with an infinite sequence of independent random variables , ..., drawn from the uniform distribution on [0, 1]. Let be the least number such that the sum of the first observations exceeds 1:\n\nThen the expected value of is : .\n\nThe number of known digits of has increased substantially during the last decades. This is due both to the increased performance of computers and to algorithmic improvements.\n\n+ Number of known decimal digits of \n! Date  Decimal digits  Computation performed by\n\nSince around 2010, the proliferation of modern high-speed desktop computers has made it feasible for most amateurs to compute trillions of digits of \"e\" within acceptable amounts of time.\n\nDuring the emergence of internet culture, individuals and organizations sometimes paid homage to the number .\n\nIn an early example, the computer scientist Donald Knuth let the version numbers of his program Metafont approach . The versions are 2, 2.7, 2.71, 2.718, and so forth.\n\nIn another instance, the IPO filing for Google in 2004, rather than a typical round-number amount of money, the company announced its intention to raise 2,718,281,828 USD, which is billion dollars rounded to the nearest dollar. Google was also responsible for a billboard\nthat appeared in the heart of Silicon Valley, and later in Cambridge, Massachusetts; Seattle, Washington; and Austin, Texas. It read \"{first 10-digit prime found in consecutive digits of }.com\". Solving this problem and visiting the advertised (now defunct) web site led to an even more difficult problem to solve, which in turn led to Google Labs where the visitor was invited to submit a résumé.\nThe first 10-digit prime in is 7427466391, which starts at the 99th digit.\n\nBULLET::::- Maor, Eli; \": The Story of a Number\",\nBULLET::::- Commentary on Endnote 10 of the book \"Prime Obsession\" for another stochastic representation\n\nBULLET::::- [http://gutenberg.org/ebooks/127 The number to 1 million places] and 2 and 5 million places\nBULLET::::- Approximations – Wolfram MathWorld\nBULLET::::- Earliest Uses of Symbols for Constants Jan. 13, 2008\nBULLET::::- \"The story of \", by Robin Wilson at Gresham College, 28 February 2007 (available for audio and video download)\nBULLET::::- Search Engine 2 billion searchable digits of , and\n"}
{"id": "9637", "url": "https://en.wikipedia.org/wiki?curid=9637", "title": "Euler–Maclaurin formula", "text": "Euler–Maclaurin formula\n\nIn mathematics, the Euler–Maclaurin formula is a formula for the difference between an integral and a closely related sum. It can be used to approximate integrals by finite sums, or conversely to evaluate finite sums and infinite series using integrals and the machinery of calculus. For example, many asymptotic expansions are derived from the formula, and Faulhaber's formula for the sum of powers is an immediate consequence.\n\nThe formula was discovered independently by Leonhard Euler and Colin Maclaurin around 1735. Euler needed it to compute slowly converging infinite series while Maclaurin used it to calculate integrals. It was later generalized to Darboux's formula.\n\nIf formula_1 and formula_2 are natural numbers and formula_3 is a complex or real valued continuous function for real numbers formula_4 in the interval formula_5, then the integral\n\ncan be approximated by the sum (or vice versa)\n\n(see rectangle method). The Euler–Maclaurin formula provides expressions for the difference between the sum and the integral in terms of the higher derivatives formula_8 evaluated at the end points of the interval, that is to say when formula_9 and formula_10.\n\nExplicitly, for formula_11 a positive integer and a function formula_3 that is formula_11 times continuously differentiable in the interval formula_14, we have\n\nwhere formula_16 is the formula_17th Bernoulli number (with formula_18) and formula_19 is an error term which depends on formula_2, formula_1, formula_11, and formula_23 and is usually small for suitable values of formula_11.\n\nThe formula is often written with the subscript taking only even values, since the odd Bernoulli numbers are zero except for formula_25. In this case we have\n\nor alternatively\n\nThe remainder term arises because the integral is usually not exactly equal to the sum. The formula may be derived by applying repeated integration by parts to successive intervals formula_28 for formula_29. The boundary terms in these integrations lead to the main terms of the formula, and the leftover integrals form the remainder term.\n\nThe remainder term has an exact expression in terms of the periodized Bernoulli functions formula_30. The Bernoulli polynomials may be defined recursively by formula_31 and, for formula_32,\nThe periodized Bernoulli functions are defined as\nwhere formula_35 denotes the largest integer less than or equal to formula_4 (so that formula_37 always lies in the interval formula_38).\n\nWith this notation, the remainder term formula_19 equals\n\nWhen formula_41, it can be shown that\n\nwhere formula_43 denotes the Riemann zeta function; one approach to prove this inequality is to obtain the Fourier series for the polynomials formula_44. The bound is achieved for even formula_17 when formula_4 is zero. The term formula_47 may be omitted for odd formula_17 but the proof in this case is more complex (see Lehmer). Using this inequality, the size of the remainder term can be estimated as\n\nThe Bernoulli numbers from formula_25 to formula_51 are formula_52 Therefore the low-order cases of the Euler-Maclaurin formula are:\n\nThe Basel problem is to determine the sum\n\nEuler computed this sum to 20 decimal places with only a few terms of the Euler–Maclaurin formula in 1735. This probably convinced him that the sum equals formula_55, which he proved in the same year. \n\nIf formula_23 is a polynomial and formula_11 is big enough, then the remainder term vanishes. For instance, if formula_58, we can choose formula_59 to obtain, after simplification,\n\nThe formula provides a means of approximating a finite integral. Let formula_61 be the endpoints of the interval of integration. Fix formula_62, the number of points to use in the approximation, and denote the corresponding step size by formula_63. Set formula_64, so that formula_65 and formula_66. Then:\n\nThis may be viewed as an extension of the trapezoid rule by the inclusion of correction terms. Note that this asymptotic expansion is usually not convergent; there is some formula_11, depending upon formula_23 and formula_70, such that the terms past order formula_11 increase rapidly. Thus, the remainder term generally demands close attention.\n\nThe Euler–Maclaurin formula is also used for detailed error analysis in numerical quadrature. It explains the superior performance of the trapezoidal rule on smooth periodic functions and is used in certain extrapolation methods. Clenshaw–Curtis quadrature is essentially a change of variables to cast an arbitrary integral in terms of integrals of periodic functions where the Euler–Maclaurin approach is very accurate (in that particular case the Euler–Maclaurin formula takes the form of a discrete cosine transform). This technique is known as a periodizing transformation.\n\nIn the context of computing asymptotic expansions of sums and series, usually the most useful form of the Euler–Maclaurin formula is\n\nwhere formula_73 and formula_74 are integers. Often the expansion remains valid even after taking the limits formula_75 or formula_76 or both. In many cases the integral on the right-hand side can be evaluated in closed form in terms of elementary functions even though the sum on the left-hand side cannot. Then all the terms in the asymptotic series can be expressed in terms of elementary functions. For example,\n\nHere the left-hand side is equal to formula_78, namely the first-order polygamma function defined by formula_79; the gamma function formula_80 is equal to formula_81 if formula_82 is a positive integer. This results in an asymptotic expansion for formula_78. That expansion, in turn, serves as the starting point for one of the derivations of precise error estimates for Stirling's approximation of the factorial function.\n\nIf is an integer greater than 1 we have:\n\nCollecting the constants into a value of the Riemann zeta function, we can write an asymptotic expansion:\n\nFor equal to 2 this simplifies to\nor\n\nWhen , the corresponding technique gives an asymptotic expansion for the harmonic numbers:\nwhere formula_89 is the Euler–Mascheroni constant.\n\nWe outline the argument given in Apostol.\n\nThe Bernoulli polynomials and the periodic Bernoulli functions for were introduced above.\n\nThe first several Bernoulli polynomials are\n\nThe values are the Bernoulli numbers . Notice that for we have\n\nand for ,\n\nThe functions agree with the Bernoulli polynomials on the interval and are periodic with period 1. Furthermore, except when , they are also continuous. Thus,\n\nLet be an integer, and consider the integral\n\nwhere\n\nIntegrating by parts, we get\n\nUsing formula_97, formula_98, and summing the above from to , we get\n\nAdding (\"f\"(\"n\") − \"f\"(0))/2 to both sides and rearranging, we have\n\nThis is the case of the summation formula. To continue the induction, we apply integration by parts to the error term:\n\nwhere\n\nThe result of integrating by parts is\n\nSumming from to and substituting this for the lower order error term results in the case of the formula,\n\nThis process can be iterated. In this way we get a proof of the Euler–Maclaurin summation formula which can be formalized by mathematical induction, in which the induction step relies on integration by parts and on identities for periodic Bernoulli functions.\n\nBULLET::::- Cesàro summation\nBULLET::::- Euler summation\nBULLET::::- Gauss–Kronrod quadrature formula\nBULLET::::- Darboux's formula\nBULLET::::- Euler–Boole summation\n\nBULLET::::- , pp. 16, 806, 886\nBULLET::::- Gourdon, Xavier; Sebah, Pascal \"Introduction on Bernoulli's numbers\", (2002)\n"}
{"id": "9638", "url": "https://en.wikipedia.org/wiki?curid=9638", "title": "Epimenides paradox", "text": "Epimenides paradox\n\nThe Epimenides paradox reveals a problem with self-reference in logic.\n\nIt is named after the Cretan philosopher Epimenides of Knossos (alive circa 600 BC) who is credited with the original statement.\n\nA typical description of the problem is given in the book \"Gödel, Escher, Bach\", by Douglas Hofstadter:\n\nA paradox of self-reference arises when one considers whether it is possible for Epimenides to have spoken the truth.\n\nThomas Fowler (1869) states the paradox as follows: \"Epimenides the Cretan says, 'that all the Cretans are liars,' but Epimenides is himself a Cretan; therefore he is himself a liar. But if he is a liar, what he says is untrue, and consequently, the Cretans are veracious; but Epimenides is a Cretan, and therefore what he says is true; saying the Cretans are liars, Epimenides is himself a liar, and what he says is untrue. Thus we may go on alternately proving that Epimenides and the Cretans are truthful and untruthful.\"\n\nThe Epimenides paradox in this form, however, can be solved. There are two options: it is either true or false. First, assume that it is true, but then Epimenides, being a Cretan, would be a liar, and making the assumption that liars only make false statements, the statement is false. So, assuming the statement is true leads us to conclude that the statement is false. This is a contradiction, so the option of the statement being true is not possible. This leaves the second option: that it is false.\n\nIf we assume the statement is false and that Epimenides is lying about all Cretans being liars, then there must exist at least one Cretan who is honest. This does not lead to a contradiction since it is not required that this Cretan be Epimenides. This means that Epimenides can say the false statement that all Cretans are liars while knowing at least one honest Cretan and lying about this particular Cretan. Hence, from the assumption that the statement is false, it does not follow that the statement is true. So we can avoid a paradox as seeing the statement \"all Cretans are liars\" as a false statement, which is made by a lying Cretan, Epimenides. The mistake made by Thomas Fowler (and many other people) above is to think that the negation of \"all Cretans are liars\" is \"all Cretans are honest\" (a paradox) when in fact the negation is \"there exists a Cretan who is honest\", or \"not all Cretans are liars\". The Epimenides paradox can be slightly modified as to not allow the kind of solution described above, as it was in the first paradox of Eubulides but instead leading to a non-avoidable self-contradiction. Paradoxical versions of the Epimenides problem are closely related to a class of more difficult logical problems, including the liar paradox, Socratic paradox, and the Burali-Forti paradox, all of which have self-reference in common with Epimenides. Indeed, the Epimenides paradox is usually classified as a variation on the liar paradox, and sometimes the two are not distinguished. The study of self-reference led to important developments in logic and mathematics in the twentieth century.\n\nIn other words, it is not a paradox once one realizes \"All Cretans are liars\" being untrue only means \"Not all Cretans are liars\" instead of the assumption that \"All Cretans are honest\".\n\nPerhaps better put, for \"All Cretans are liars\" to be a true statement, it does not mean that all Cretans must lie all the time. In fact, Cretans could tell the truth quite often, but still all be liars in the sense that liars are people prone to deception for dishonest gain. Considering that “All Cretans are liars” has been seen as a paradox only since the 19th century, this seems to resolve the alleged paradox. Of course, if ‘all Cretans are continuous liars’ is actually true, then asking a Cretan if they are honest would always elicit the dishonest answer ‘yes’. So arguably the original proposition is not so much paradoxical as invalid. \n\nA contextual reading of the contradiction may also provide an answer to the paradox. The original phrase, \"The Cretans, always liars, evil beasts, idle bellies!\" asserts not an intrinsic paradox, but rather an opinion of the Cretans from Epimenides. A stereotyping of his people not intended to be an absolute statement about the people as a whole. Rather it is a claim made about their position regarding their religious beliefs and socio-cultural attitudes. Within the context of his poem the phrase is specific to a certain belief, a context that Callimachus repeats in his poem regarding Zeus. Further, a more poignant answer to the paradox is simply that to be a \"liar\" is to state falsehoods, nothing in the statement asserts everything said is false, but rather they're \"always\" lying. This is not an absolute statement of fact and thus we cannot conclude there's a true contradiction made by Epimenides with this statement.\n\nEpimenides was a 6th-century BC philosopher and religious prophet who, against the general sentiment of Crete, proposed that Zeus was immortal, as in the following poem:\nDenying the immortality of Zeus, then, was the lie of the Cretans.\n\nThe phrase \"Cretans, always liars\" was quoted by the poet Callimachus in his \"Hymn to Zeus\", with the same theological intent as Epimenides:\n\nThe logical inconsistency of a Cretan asserting all Cretans are always liars may not have occurred to Epimenides, nor to Callimachus, who both used the phrase to emphasize their point, without irony, perhaps meaning that all Cretans lie routinely, but not exclusively.\n\nIn the 1st century AD, the quote is mentioned by Paul as having been spoken truly by \"one of their own prophets.\"\n\nClement of Alexandria, in the late 2nd century AD, fails to indicate that the concept of logical paradox is an issue:\n\nDuring the early 4th century, Saint Augustine restates the closely related liar paradox in \"Against the Academicians\" (III.13.29), but without mentioning Epimenides.\n\nIn the Middle Ages, many forms of the liar paradox were studied under the heading of insolubilia, but these were not explicitly associated with Epimenides.\n\nFinally, in 1740, the second volume of Pierre Bayle's \"Dictionnaire Historique et Critique\" explicitly connects Epimenides with the paradox, though Bayle labels the paradox a \"sophisme\".\n\nAll of the works of Epimenides are now lost, and known only through quotations by other authors. The quotation from the \"Cretica\" of Epimenides is given by R.N. Longenecker, \"Acts of the Apostles\", in volume 9 of \"The Expositor's Bible Commentary\", Frank E. Gaebelein, editor (Grand Rapids, Michigan: Zondervan Corporation, 1976–1984), page 476. Longenecker in turn cites M.D. Gibson, \"Horae Semiticae X\" (Cambridge: Cambridge University Press, 1913), page 40, \"in Syriac\". Longenecker states the following in a footnote:\n\nAn oblique reference to Epimenides in the context of logic appears in \"The Logical Calculus\" by W. E. Johnson, \"Mind\" (New Series), volume 1, number 2 (April, 1892), pages 235–250. Johnson writes in a footnote,\n\nThe Epimenides paradox appears explicitly in \"Mathematical Logic as Based on the Theory of Types\", by Bertrand Russell, in the \"American Journal of Mathematics\", volume 30, number 3 (July, 1908), pages 222–262, which opens with the following:\n\nIn that article, Russell uses the Epimenides paradox as the point of departure for discussions of other problems, including the Burali-Forti paradox and the paradox now called Russell's paradox. Since Russell, the Epimenides paradox has been referenced repeatedly in logic. Typical of these references is \"Gödel, Escher, Bach\" by Douglas Hofstadter, which accords the paradox a prominent place in a discussion of self-reference.\n"}
{"id": "9640", "url": "https://en.wikipedia.org/wiki?curid=9640", "title": "Engine", "text": "Engine\n\nAn engine or motor is a machine designed to convert one form of energy into mechanical energy. Heat engines, like the internal combustion engine, burn a fuel to create heat which is then used to do work. Electric motors convert electrical energy into mechanical motion, pneumatic motors use compressed air, and clockwork motors in wind-up toys use elastic energy. In biological systems, molecular motors, like myosins in muscles, use chemical energy to create forces and ultimately motion.\n\nThe word \"engine\" derives from Old French \"engin\", from the Latin \"ingenium\"–the root of the word \"ingenious\". Pre-industrial weapons of war, such as catapults, trebuchets and battering rams, were called \"siege engines\", and knowledge of how to construct them was often treated as a military secret. The word \"gin\", as in \"cotton gin\", is short for \"engine\". Most mechanical devices invented during the industrial revolution were described as engines—the steam engine being a notable example. However, the original steam engines, such as those by Thomas Savery, were not mechanical engines but pumps. In this manner, a fire engine in its original form was merely a water pump, with the engine being transported to the fire by horses.\n\nIn modern usage, the term \"engine\" typically describes devices, like steam engines and internal combustion engines, that burn or otherwise consume fuel to perform mechanical work by exerting a torque or linear force (usually in the form of thrust). Devices converting heat energy into motion are commonly referred to simply as \"engines\". Examples of engines which exert a torque include the familiar automobile gasoline and diesel engines, as well as turboshafts. Examples of engines which produce thrust include turbofans and rockets.\n\nWhen the internal combustion engine was invented, the term \"motor\" was initially used to distinguish it from the steam engine—which was in wide use at the time, powering locomotives and other vehicles such as steam rollers. The term \"motor\" derives from the Latin verb \"\" which means to set in motion, or maintain motion. Thus a motor is a device that imparts motion.\n\n\"Motor\" and \"engine\" are interchangeable in standard English. In some engineering jargons, the two words have different meanings, in which \"engine\" is a device that burns or otherwise consumes fuel, changing its chemical composition, and a motor is a device driven by electricity, air, or hydraulic pressure, which does not change the chemical composition of its energy source. However, rocketry uses the term rocket motor, even though they consume fuel.\n\nA heat engine may also serve as a \"prime mover\"—a component that transforms the flow or changes in pressure of a fluid into mechanical energy. An automobile powered by an internal combustion engine may make use of various motors and pumps, but ultimately all such devices derive their power from the engine. Another way of looking at it is that a motor receives power from an external source, and then converts it into mechanical energy, while an engine creates power from pressure (derived directly from the explosive force of combustion or other chemical reaction, or secondarily from the action of some such force on other substances such as air, water, or steam).\n\nSimple machines, such as the club and oar (examples of the lever), are prehistoric. More complex engines using human power, animal power, water power, wind power and even steam power date back to antiquity. Human power was focused by the use of simple engines, such as the capstan, windlass or treadmill, and with ropes, pulleys, and block and tackle arrangements; this power was transmitted usually with the forces multiplied and the speed reduced. These were used in cranes and aboard ships in Ancient Greece, as well as in mines, water pumps and siege engines in Ancient Rome. The writers of those times, including Vitruvius, Frontinus and Pliny the Elder, treat these engines as commonplace, so their invention may be more ancient. By the 1st century AD, cattle and horses were used in mills, driving machines similar to those powered by humans in earlier times.\n\nAccording to Strabo, a water powered mill was built in Kaberia of the kingdom of Mithridates during the 1st century BC. Use of water wheels in mills spread throughout the Roman Empire over the next few centuries. Some were quite complex, with aqueducts, dams, and sluices to maintain and channel the water, along with systems of gears, or toothed-wheels made of wood and metal to regulate the speed of rotation. More sophisticated small devices, such as the Antikythera Mechanism used complex trains of gears and dials to act as calendars or predict astronomical events. In a poem by Ausonius in the 4th century AD, he mentions a stone-cutting saw powered by water. Hero of Alexandria is credited with many such wind and steam powered machines in the 1st century AD, including the Aeolipile and the vending machine, often these machines were associated with worship, such as animated altars and automated temple doors.\n\nMedieval Muslim engineers employed gears in mills and water-raising machines, and used dams as a source of water power to provide additional power to watermills and water-raising machines. In the medieval Islamic world, such advances made it possible to mechanize many industrial tasks previously carried out by manual labour.\n\nIn 1206, al-Jazari employed a crank-conrod system for two of his water-raising machines. A rudimentary steam turbine device was described by Taqi al-Din in 1551 and by Giovanni Branca in 1629.\n\nIn the 13th century, the solid rocket motor was invented in China. Driven by gunpowder, this simplest form of internal combustion engine was unable to deliver sustained power, but was useful for propelling weaponry at high speeds towards enemies in battle and for fireworks. After invention, this innovation spread throughout Europe.\n\nThe Watt steam engine was the first type of steam engine to make use of steam at a pressure just above atmospheric to drive the piston helped by a partial vacuum. Improving on the design of the 1712 Newcomen steam engine, the Watt steam engine, developed sporadically from 1763 to 1775, was a great step in the development of the steam engine. Offering a dramatic increase in fuel efficiency, James Watt's design became synonymous with steam engines, due in no small part to his business partner, Matthew Boulton. It enabled rapid development of efficient semi-automated factories on a previously unimaginable scale in places where waterpower was not available. Later development led to steam locomotives and great expansion of railway transportation.\n\nAs for internal combustion piston engines, these were tested in France in 1807 by de Rivaz and independently, by the Niépce brothers. They were theoretically advanced by Carnot in 1824. In 1853–57 Eugenio Barsanti and Felice Matteucci invented and patented an engine using the free-piston principle that was possibly the first 4-cycle engine.\n\nThe invention of an internal combustion engine which was later commercially successful was made during 1860 by Etienne Lenoir.\n\nIn 1877 the Otto cycle was capable of giving a far higher power to weight ratio than steam engines and worked much better for many transportation applications such as cars and aircraft.\n\nThe first commercially successful automobile, created by Karl Benz, added to the interest in light and powerful engines. The lightweight petrol internal combustion engine, operating on a four-stroke Otto cycle, has been the most successful for light automobiles, while the more efficient Diesel engine is used for trucks and buses. However, in recent years, turbo Diesel engines have become increasingly popular, especially outside of the United States, even for quite small cars.\n\nIn 1896, Karl Benz was granted a patent for his design of the first engine with horizontally opposed pistons. His design created an engine in which the corresponding pistons move in horizontal cylinders and reach top dead center simultaneously, thus automatically balancing each other with respect to their individual momentum. Engines of this design are often referred to as flat engines because of their shape and lower profile. They were used in the Volkswagen Beetle, the Citroën 2CV, some Porsche and Subaru cars, many BMW and Honda motorcycles, and propeller aircraft engines.\n\nContinuance of the use of the internal combustion engine for automobiles is partly due to the improvement of engine control systems (onboard computers providing engine management processes, and electronically controlled fuel injection). Forced air induction by turbocharging and supercharging have increased power outputs and engine efficiencies. Similar changes have been applied to smaller diesel engines giving them almost the same power characteristics as petrol engines. This is especially evident with the popularity of smaller diesel engine propelled cars in Europe. Larger diesel engines are still often used in trucks and heavy machinery, although they require special machining not available in most factories. Diesel engines produce lower hydrocarbon and emissions, but greater particulate and pollution, than gasoline engines. Diesel engines are also 40% more fuel efficient than comparable gasoline engines.\n\nIn the first half of the 20th century, a trend of increasing engine power occurred, particularly in the U.S models. Design changes incorporated all known methods of increasing engine capacity, including increasing the pressure in the cylinders to improve efficiency, increasing the size of the engine, and increasing the rate at which the engine produces work. The higher forces and pressures created by these changes created engine vibration and size problems that led to stiffer, more compact engines with V and opposed cylinder layouts replacing longer straight-line arrangements.\n\nThe design principles favoured in Europe, because of economic and other restraints such as smaller and twistier roads, leant toward smaller cars and corresponding to the design principles that concentrated on increasing the combustion efficiency of smaller engines. This produced more economical engines with earlier four-cylinder designs rated at 40 horsepower (30 kW) and six-cylinder designs rated as low as 80 horsepower (60 kW), compared with the large volume V-8 American engines with power ratings in the range from 250 to 350 hp, some even over 400 hp (190 to 260 kW).\n\nEarlier automobile engine development produced a much larger range of engines than is in common use today. Engines have ranged from 1- to 16-cylinder designs with corresponding differences in overall size, weight, engine displacement, and cylinder bores. Four cylinders and power ratings from 19 to 120 hp (14 to 90 kW) were followed in a majority of the models. Several three-cylinder, two-stroke-cycle models were built while most engines had straight or in-line cylinders. There were several V-type models and horizontally opposed two- and four-cylinder makes too. Overhead camshafts were frequently employed. The smaller engines were commonly air-cooled and located at the rear of the vehicle; compression ratios were relatively low. The 1970s and 1980s saw an increased interest in improved fuel economy, which caused a return to smaller V-6 and four-cylinder layouts, with as many as five valves per cylinder to improve efficiency. The Bugatti Veyron 16.4 operates with a W16 engine, meaning that two V8 cylinder layouts are positioned next to each other to create the W shape sharing the same crankshaft.\n\nThe largest internal combustion engine ever built is the Wärtsilä-Sulzer RTA96-C, a 14-cylinder, 2-stroke turbocharged diesel engine that was designed to power the \"Emma Mærsk\", the largest container ship in the world when launched in 2006. This engine has a mass of 2,300 tonnes, and when running at 102 RPM (1.7 Hz) produces over 80 MW, and can use up to 250 tonnes of fuel per day.\n\nAn engine can be put into a category according to two criteria: the form of energy it accepts in order to create motion, and the type of motion it outputs.\n\nCombustion engines are heat engines driven by the heat of a combustion process.\n\nThe \"internal combustion engine\" is an engine in which the combustion of a fuel (generally, fossil fuel) occurs with an oxidizer (usually air) in a combustion chamber. In an internal combustion engine the expansion of the high temperature and high pressure gases, which are produced by the combustion, directly applies force to components of the engine, such as the pistons or turbine blades or a nozzle, and by moving it over a distance, generates mechanical work.\n\nAn \"external combustion engine\" (EC engine) is a heat engine where an internal working fluid is heated by combustion of an external source, through the engine wall or a heat exchanger. The fluid then, by expanding and acting on the mechanism of the engine produces motion and usable work. The fluid is then cooled, compressed and reused (closed cycle), or (less commonly) dumped, and cool fluid pulled in (open cycle air engine).\n\n\"Combustion\" refers to burning fuel with an oxidizer, to supply the heat. Engines of similar (or even identical) configuration and operation may use a supply of heat from other sources such as nuclear, solar, geothermal or exothermic reactions not involving combustion; but are not then strictly classed as external combustion engines, but as external thermal engines.\n\nThe working fluid can be a gas as in a Stirling engine, or steam as in a steam engine or an organic liquid such as n-pentane in an Organic Rankine cycle. The fluid can be of any composition; gas is by far the most common, although even single-phase liquid is sometimes used. In the case of the steam engine, the fluid changes phases between liquid and gas.\n\n\"Air-breathing combustion engines\" are combustion engines that use the oxygen in atmospheric air to oxidise ('burn') the fuel, rather than carrying an oxidiser, as in a rocket. Theoretically, this should result in a better specific impulse than for rocket engines.\n\nA continuous stream of air flows through the air-breathing engine. This air is compressed, mixed with fuel, ignited and expelled as the exhaust gas.\n\nBULLET::::- Examples\nTypical air-breathing engines include:\nBULLET::::- Reciprocating engine\nBULLET::::- Steam engine\nBULLET::::- Gas turbine\nBULLET::::- Pulse detonation engine\nBULLET::::- Pulse jet\nBULLET::::- Ramjet\nBULLET::::- Scramjet\nBULLET::::- Liquid air cycle engine/Reaction Engines SABRE.\n\nThe operation of engines typically has a negative impact upon air quality and ambient sound levels. There has been a growing emphasis on the pollution producing features of automotive power systems. This has created new interest in alternate power sources and internal-combustion engine refinements. Though a few limited-production battery-powered electric vehicles have appeared, they have not proved competitive owing to costs and operating characteristics. In the 21st century the diesel engine has been increasing in popularity with automobile owners. However, the gasoline engine and the Diesel engine, with their new emission-control devices to improve emission performance, have not yet been significantly challenged. A number of manufacturers have introduced hybrid engines, mainly involving a small gasoline engine coupled with an electric motor and with a large battery bank, but these too have yet to make much of an inroad into the market shares of gasoline and Diesel engines.\n\nExhaust gas from a spark ignition engine consists of the following: nitrogen 70 to 75% (by volume), water vapor 10 to 12%, carbon dioxide 10 to 13.5%, hydrogen 0.5 to 2%, oxygen 0.2 to 2%, carbon monoxide: 0.1 to 6%, unburnt hydrocarbons and partial oxidation products (e.g. aldehydes) 0.5 to 1%, nitrogen monoxide 0.01 to 0.4%, nitrous oxide <100 ppm, sulfur dioxide 15 to 60 ppm, traces of other compounds such as fuel additives and lubricants, also halogen and metallic compounds, and other particles. Carbon monoxide is highly toxic, and can cause carbon monoxide poisoning, so it is important to avoid any build-up of the gas in a confined space. Catalytic converters can reduce toxic emissions, but not completely eliminate them. Also, resulting greenhouse gas emissions, chiefly carbon dioxide, from the widespread use of engines in the modern industrialized world is contributing to the global greenhouse effect – a primary concern regarding global warming.\n\nSome engines convert heat from noncombustive processes into mechanical work, for example a nuclear power plant uses the heat from the nuclear reaction to produce steam and drive a steam engine, or a gas turbine in a rocket engine may be driven by decomposing hydrogen peroxide. Apart from the different energy source, the engine is often engineered much the same as an internal or external combustion engine. Another group of noncombustive engines includes thermoacoustic heat engines (sometimes called \"TA engines\") which are thermoacoustic devices which use high-amplitude sound waves to pump heat from one place to another, or conversely use a heat difference to induce high-amplitude sound waves. In general, thermoacoustic engines can be divided into standing wave and travelling wave devices.\n\nNon-thermal motors usually are powered by a chemical reaction, but are not heat engines. Examples include:\nBULLET::::- Molecular motor – motors found in living things\nBULLET::::- Synthetic molecular motor.\n\nAn \"electric motor\" uses electrical energy to produce mechanical energy, usually through the interaction of magnetic fields and current-carrying conductors. The reverse process, producing electrical energy from mechanical energy, is accomplished by a generator or dynamo. Traction motors used on vehicles often perform both tasks. Electric motors can be run as generators and vice versa, although this is not always practical.\nElectric motors are ubiquitous, being found in applications as diverse as industrial fans, blowers and pumps, machine tools, household appliances, power tools, and disk drives. They may be powered by direct current (for example a battery powered portable device or motor vehicle), or by alternating current from a central electrical distribution grid. The smallest motors may be found in electric wristwatches. Medium-size motors of highly standardized dimensions and characteristics provide convenient mechanical power for industrial uses. The very largest electric motors are used for propulsion of large ships, and for such purposes as pipeline compressors, with ratings in the thousands of kilowatts. Electric motors may be classified by the source of electric power, by their internal construction, and by their application.\n\nThe physical principle of production of mechanical force by the interactions of an electric current and a magnetic field was known as early as 1821. Electric motors of increasing efficiency were constructed throughout the 19th century, but commercial exploitation of electric motors on a large scale required efficient electrical generators and electrical distribution networks.\n\nTo reduce the electric energy consumption from motors and their associated carbon footprints, various regulatory authorities in many countries have introduced and implemented legislation to encourage the manufacture and use of higher efficiency electric motors. A well-designed motor can convert over 90% of its input energy into useful power for decades. When the efficiency of a motor is raised by even a few percentage points, the savings, in kilowatt hours (and therefore in cost), are enormous. The electrical energy efficiency of a typical industrial induction motor can be improved by: 1) reducing the electrical losses in the stator windings (e.g., by increasing the cross-sectional area of the conductor, improving the winding technique, and using materials with higher electrical conductivities, such as copper), 2) reducing the electrical losses in the rotor coil or casting (e.g., by using materials with higher electrical conductivities, such as copper), 3) reducing magnetic losses by using better quality magnetic steel, 4) improving the aerodynamics of motors to reduce mechanical windage losses, 5) improving bearings to reduce friction losses, and 6) minimizing manufacturing tolerances. \"For further discussion on this subject, see Premium efficiency.)\"\n\nBy convention, \"electric engine\" refers to a railroad electric locomotive, rather than an electric motor.\n\nSome motors are powered by potential or kinetic energy, for example some funiculars, gravity plane and ropeway conveyors have used the energy from moving water or rocks, and some clocks have a weight that falls under gravity. Other forms of potential energy include compressed gases (such as pneumatic motors), springs (clockwork motors) and elastic bands.\n\nHistoric military siege engines included large catapults, trebuchets, and (to some extent) battering rams were powered by potential energy.\n\nA \"pneumatic motor\" is a machine that converts potential energy in the form of compressed air into mechanical work. Pneumatic motors generally convert the compressed air to mechanical work through either linear or rotary motion. Linear motion can come from either a diaphragm or piston actuator, while rotary motion is supplied by either a vane type air motor or piston air motor. Pneumatic motors have found widespread success in the hand-held tool industry and continual attempts are being made to expand their use to the transportation industry. However, pneumatic motors must overcome efficiency deficiencies before being seen as a viable option in the transportation industry.\n\nA \"hydraulic motor\" is one that derives its power from a pressurized fluid. This type of engine can be used to move heavy loads or produce motion.\n\nGiven that the majority of engines for which a speed is defined rotate, engine speed is measured in revolutions per minute (RPM). Engines may be classified as low-speed, medium-speed or high-speed, but these terms are always relative and depend on the type of engine being described. Generally, diesel engines operate at lower speeds (~1500–4000 RPM for an automotive diesel) compared to gasoline engines (~2200–6000 RPM for an automotive gasoline engine). Electric motors and turboshafts are capable of very high speeds (~10,000 RPM or more), generally constrained only by the bulk modulus and intended service life of the parts constituting the rotor, which must bear the brunt of the centrifugal force.\n\nThrust is the force arising from the interaction between two masses which exert equal but opposite forces on each other due to their speed. The force can be measured either in newtons (N, SI units) or more rarely in pounds-thrust (lb, imperial units).\n\nTorque is the force being exerted on a theoretical lever connected to the output shaft of an engine. This is expressed by the formula:\nwhere is the length of the lever, is the force applied on it, and is the vector cross product.\nTorque is typically measured in newton-metres (N·m, SI units) and a few countries use the older foot-pounds (ft·lb, imperial units).\n\nPower is the amount of work being done, or energy being produced, per unit of time. This is expressed by the formula:\n\nWith a quick demonstration, it can be shown that:\n\nThis formula with linear forces and speeds can be used equally well for both engines outputting thrust and engines exerting torque.\n\nWhen considering propulsive engines, typically only the raw force of the core mass flow is considered, leading to such engines having their 'power' rated in any of the units discussed above for forces.\n\nIf the engine in question outputs its power on a shaft, then:\n\nThis is the reason why any engine outputting its power on a rotating shaft is usually quoted, along with its rated power, the rotational speed at which that rated power is developed.\n\nDepending on the type of engine employed, different rates of efficiency are attained.\n\nFor heat engines, efficiency cannot be greater than the Carnot efficiency.\n\nIn the case of sound levels, engine operation is of greatest impact with respect to mobile sources such as automobiles and trucks. Engine noise is a particularly large component of mobile source noise for vehicles operating at lower speeds, where aerodynamic and tire noise is less significant. Generally speaking, petrol (gasoline) and diesel engines emit less noise than turboshafts of equivalent power output; electric motors very often emit less noise than their fossil fuel-powered equivalents. Thrust-outputting engines, such as turbofans, turbojets and rockets emit the greatest amount of noise because their method of producing thrust is directly related to the production of sound.\nVarious methods have been devised to reduce noise. Petrol and diesel engines are fitted with mufflers (silencers); newer turbofans often have outsized fans (the so-called high-bypass technology) in order to reduce the proportion of noisy, hot exhaust from the integrated turboshaft in the exhaust stream, and hushkits exist for older, low-bypass turbofans. No known methods exist for reducing the noise output of rockets without a corresponding reduction in thrust.\n\nParticularly notable kinds of engines include:\n\nBULLET::::- Aircraft engine\nBULLET::::- Automobile engine\nBULLET::::- Model engine\nBULLET::::- Motorcycle engine\nBULLET::::- Marine propulsion engines such as Outboard motor\nBULLET::::- Non-road engine is the term used to define engines that are not used by vehicles on roadways.\nBULLET::::- Railway locomotive engine\nBULLET::::- Spacecraft propulsion engines such as Rocket engine\nBULLET::::- Traction engine\n\nBULLET::::- Aircraft engine\nBULLET::::- Automobile engine replacement\nBULLET::::- Electric motor\nBULLET::::- Engine cooling\nBULLET::::- Engine swap\nBULLET::::- Gasoline engine\nBULLET::::- HCCI engine\nBULLET::::- Hesselman engine\nBULLET::::- Hot bulb engine\nBULLET::::- IRIS engine\nBULLET::::- Multifuel\nBULLET::::- Reaction engine\nBULLET::::- Solid-state engine\nBULLET::::- Timeline of heat engine technology\nBULLET::::- Timeline of motor and engine technology\n\nBULLET::::- J.G. Landels, \"Engineering in the Ancient World\",\n\nBULLET::::- Detailed Engine Animations\nBULLET::::- Working 4-Stroke Engine – Animation\nBULLET::::- Animated illustrations of various engines\nBULLET::::- 5 Ways to Redesign the Internal Combustion Engine\nBULLET::::- Article on Small SI Engines.\nBULLET::::- Article on Compact Diesel Engines.\n"}
{"id": "9643", "url": "https://en.wikipedia.org/wiki?curid=9643", "title": "Economic and monetary union", "text": "Economic and monetary union\n\nAn economic and monetary union (MCU) is a type of trade bloc that features a combination of a common market, customs union, and monetary union. Established via a trade pact, an MCU constitutes the sixth of seven stages in the process of economic integration. An MCU agreement usually combines a customs union with a common market. A typical MCU establishes free trade and a common external tariff throughout its jurisdiction. It is also designed to protect freedom in the movement of goods, services, and people. This arrangement is distinct from a monetary union (e.g., the Latin Monetary Union), which does not usually involve a common market. As with the economic and monetary union established among the 28 member states of the European Union, an MCU may affect different parts of its jurisdiction in different ways. Some areas are subject to separate customs regulations from other areas subject to the MCU. These various arrangements may be established in a formal agreement, or they may exist on a \"de facto\" basis. For example, not all MU member states use the Euro established by its currency union, and not all MU member states are part of the Schengen Area. Some nations participate in both unions, and some in neither.\n\nTerritories of the United States, Australian External Territories and New Zealand territories share a currency, and for the most part, the market of their respective mainland states. However, they are generally not part of the same customs territories.\n\nSeveral countries initially decided to attempt the formation of an MCU at the Hague Summit in 1969. Afterward, a \"draft plan\" was announced. During this time, the main member presiding over this decision was Pierre Werner, Prime Minister of Luxembourg. The decision to form the EMU was accepted in December 1991, which later became part of the Maastricht Treaty (the Treaty on European Union).\n\nThe European Union MCU involves four main activities. \n\nThe first responsibility is to be in charge of implementing effective monetary policy for the euro area with price stability. There is a group of economists whose only role is studying how to improve the monetary policy while maintaining price stability. They conduct research, and their results are presented to the leaders of the MCU. Thereafter, the role of the leaders is to find a suitable way to implement the economists' work into their country's policies. Maintaining price stability is a long-term goal for all states in the MCU, due to the effects it might have on the Euro as a currency.\n\nSecondly, the MCU must coordinate economic and fiscal policies in MCU countries. They must find an equilibrium between the implementation of monetary and fiscal policies. They will advise countries to have greater coordination, even if that means having countries tightly coupled with looser monetary and tighter fiscal policy. Not coordinating the monetary market could result in risking an unpredictable situation. The MCU will also have to deliberate on a mixed policy option, which has been shown to be beneficial in some empirical studies.\n\nThirdly, the MCU ensures that the single market runs smoothly. The member countries respect the decisions made by the MCU and ensure that their actions will be in favor of a stable market.\n\nFinally, regulations of the MCU aid in supervising and monitoring financial institutions. There is an imperative need for all members of the MCU to act in unison. Therefore, the MCU has to have institutions supervising all the member states to protect the main aim of the MCU.\n\nBULLET::::1. Control fiscal policy that concerns government budgets\nBULLET::::2. Control tax policies that determine how income is raised\nBULLET::::3. Control structural policies that determine pension systems, labor, and capital-market regulations\n\nBULLET::::- Economic and Monetary Union of the European Union (1999/2002) with the Euro for the Eurozone members\nBULLET::::- \"de facto\" the OECS Eastern Caribbean Currency Union with the East Caribbean dollar in the CSME (2006)\nBULLET::::- \"de facto\" Switzerland–Liechtenstein\n\n! Community\n! Currency\n! Region\n! Target date\n! width=30% Notes\nEconomic and Monetary Community of Central Africa (CEMAC)\nCentral African CFA franc\nAfrica \nNot yet functioning common market\nWest African Economic and Monetary Union (UEMOA)\nWest African CFA franc\nAfrica \nNot yet functioning common market\n\nBULLET::::- Monetary union of the Belgium–Luxembourg Economic Union (1922–2002), superseded by the European EMU.\n\nBULLET::::- North American Union and North American Currency Union (Amero)\nBULLET::::- Pacific Union (one proposal for Australian dollar)\n\nBULLET::::- Acocella, N. and Di Bartolomeo, G. and Tirelli, P. [2007], ‘\"Fiscal leadership and coordination in the EMU\"’, in: ‘\"Open Economies Review\"’, 18(3): 281-9.\n\nBULLET::::- African monetary union inches closer\nBULLET::::- United States of Southern Africa?\nBULLET::::- East Africa's first steps towards union\nBULLET::::- West Africa opts for currency union\nBULLET::::- Gulf States push for single currency\nBULLET::::- 'Limited gains' from Gulf single currency\nBULLET::::- Do the Mercosur Countries Form an Optimum Currency Area?\nBULLET::::- Argentina plans monetary union\nBULLET::::- Quadrant Magazine article on the Pacific\nBULLET::::- Economist – Antipodean currencies (Australia and New Zealand)\nBULLET::::- Three Perspectives on an Australasian Monetary Union\nBULLET::::- Reasons for the collapse of the Rouble Zone\nBULLET::::- In Search of the \"Ruble Zone\"\nBULLET::::- OECD Development Centre – the Rand Zone\nBULLET::::- A single African currency in our time?\nBULLET::::- South Africa proposes adoption of the rand as provisional SADC common currency\n"}
{"id": "9644", "url": "https://en.wikipedia.org/wiki?curid=9644", "title": "European Environment Agency", "text": "European Environment Agency\n\nThe European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment.\n\nThe European Environment Agency (EEA) is the agency of the European Union (EU) which provides independent information on the environment. \nIts goal is to help those involved in developing, implementing and evaluating environmental policy, and to inform the general public.\n\nThe EEA was established by the European Economic Community (EEC) Regulation 1210/1990 (amended by EEC Regulation 933/1999 and EC Regulation 401/2009) and became operational in 1994, headquartered in Copenhagen, Denmark.\n\nThe agency is governed by a management board composed of representatives of the governments of its 33 member states, a European Commission representative and two scientists appointed by the European Parliament, assisted by a committee of scientists.\nThe current Executive Director of the agency is Professor Hans Bruyninckx, who has been appointed for a five-year term. He is the successor of Professor Jacqueline McGlade.\n\nThe member states of the union are members; however other states may become members of it by means of agreements concluded between them and the EU.\n\nIt was the first EU body to open its membership to the 13 candidate countries (pre-2004 enlargement).\n\nThe EEA has 33 member countries and six cooperating countries. The 33 member countries include the 28 European Union member states together with Iceland, Liechtenstein, Norway, Switzerland and Turkey.\n\nThe six Western Balkan countries are cooperating countries: Albania, Bosnia and Herzegovina, Montenegro, North Macedonia, Serbia as well as Kosovo under the UN Security Council Resolution 1244/99. These cooperation activities are integrated into Eionet and are supported by the EU under the \"Instrument for Pre-Accession Assistance\".\n\nThe EEA is an active member of the EPA Network.\n! EU Member countries !! non-EU Member countries !! Cooperating countries \n\nThe European Environment Agency (EEA) reported in 2017 that climate-related extreme events accounted ca €400 billion ($430 billion) of economic losses in EEA area from 1980 to 2013, and were responsible for 85,000 deaths during 1980-2013.\n\n \nThe European environment information and observation network (Eionet) is a partnership network of the EEA and the countries. The EEA is responsible for developing the network and coordinating its activities. To do so, the EEA works closely together with national focal points (NFP´s), typically national environment agencies or environment ministries which are responsible for coordinating national networksof the National Reference Centres (NRCs) involving many institutions (about 350 in all).\n\nApart from the NFPs and NRCs, Eionet covers six European Topic Centres (ETCs) in the areas of air and climate change, biological diversity, climate change impacts, vulnerability and adaptation, water, land use and spatial information and analysis and sustainable consumption and production.\n\nIn February 2012, the European Parliament's Committee on Budgetary Control published a draft report, identifying areas of concern in the use of funds and its influence for the 2010 budget such as a 26% budget increase from 2009 to 2010 to €50 600 000. and questioned that maximum competition and value-for-money principles were honored in hiring, also possible fictitious employees.\n\nThe EEA's Executive Director refuted allegations of irregularities in a public hearing.\n\nOn 27 March 2012 Members of the European Parliament (MEPs) voted on the report and commended the cooperation between the Agency and NGOs working in the environmental area. On 23 October 2012, the European Parliament voted and granted the discharge to the European Environment Agency for its 2010 budget.\n\nIn April 2013, the MEPs voted and granted the discharge to the EEA for its 2011 budget.\n\n! Name\n! Nationality\n! Term(s)\nDomingo Jiménez-Beltrán  Spain  1994 – 2003\nJacqueline McGlade  United Kingdom 2003 – 2013\nHans Bruyninckx  Belgium  2013 –\n\nIn addition to its 33 members and six Balkan cooperating countries, the EEA also cooperates and fosters partnerships with its neighbours and other countries and regions, mostly in the context of the European Neighbourhood Policy:\nBULLET::::- EaP states: Belarus, Ukraine, Moldova, Armenia, Azerbaijan, Georgia\nBULLET::::- UfM states: Algeria, Egypt, Israel, Jordan, Lebanon, Libya, Morocco, Palestinian Authority, Syria, Tunisia\nBULLET::::- other ENPI states: Russia\nBULLET::::- Central Asia states: Kazakhstan, Kyrgyzstan, Tajikistan, Turkmenistan, Uzbekistan\nAdditionally the EEA cooperates with multiple international organizations and the corresponding agencies of the following countries:\nBULLET::::- United States of America (Environmental Protection Agency)\nBULLET::::- Canada (Environment Canada)\nBULLET::::- PR China (State Environmental Protection Administration)\n\nThe 26 official languages used by the EEA are: Bulgarian, Czech, Croatian, Danish, German, Greek, English, Spanish, Estonian, Finnish, French, Hungarian, Icelandic, Italian, Lithuanian, Latvian, Malti, Dutch, Norwegian, Polish, Portuguese, Romanian, Slovak, Slovene, Swedish and Turkish.\n\nBULLET::::- Agencies of the European Union\nBULLET::::- Citizen Science, cleanup projects that people can take part in.\nBULLET::::- EU environmental policy\nBULLET::::- List of atmospheric dispersion models\nBULLET::::- List of environmental organizations\nBULLET::::- Confederation of European Environmental Engineering Societies\nBULLET::::- Coordination of Information on the Environment\nBULLET::::- European Agency for Safety and Health at Work\nBULLET::::- Environment Agency\n\nBULLET::::- European Environment Agency website\nBULLET::::- European Topic Centre on Land Use and Spatial Information (ETC LUSI)\nBULLET::::- European Topic Centre on Air and Climate Change(ETC/ACC)\nBULLET::::- European Topic Centre on Biological Diversity(ETC/BD)\nBULLET::::- Model Documentation System (MDS)\nBULLET::::- The European Environment Agency's near real-time ozone map (ozoneweb)\nBULLET::::- The European Climate Adaptation Platform Climate-ADAPT\nBULLET::::- EnviroWindows\n"}
{"id": "9645", "url": "https://en.wikipedia.org/wiki?curid=9645", "title": "EV", "text": "EV\n\nEv or EV may refer to:\nBULLET::::- Electro-Voice, a United States manufacturer of amplifiers, microphones, other audio equipment and speakers\nBULLET::::- Expressjet Airlines (IATA designator)\nBULLET::::- Atlantic Southeast Airlines (IATA designator)\n\nBULLET::::- Embedded value, the present value of future profits for a life insurance company\nBULLET::::- Enterprise value, an economic measure reflecting the market value of a whole business\nBULLET::::- Equivalent variation, a measure of how much more money a consumer would pay before a price increase to avert the price increase\n\nBULLET::::- Ev (given name)\n\nBULLET::::- Electronvolt (eV), in physics, a unit of energy\nBULLET::::- Electric vehicle, a vehicle using an electric motor instead of an internal combustion engine\nBULLET::::- Evolution-Data Optimized, a telecommunications standard for the wireless transmission of data through radio signals\nBULLET::::- Expected value, the mean of a random variable's probability distribution\nBULLET::::- Exposure value, a combination of shutter speed and aperture in photography\nBULLET::::- Extended Validation Certificate, a type of X.509 Certificate used in securing computer communications\nBULLET::::- Extracellular vesicle, a membrane-bound vesicle\nBULLET::::- Stereo-4, also known as EV (Electro-Voice), a quadraphonic sound system developed in 1970\nBULLET::::- Exploration vessel (E/V), a type of marine vessel\n\nBULLET::::- Land of Ev, a fictional country in the Oz books of L. Frank Baum and his successors\nBULLET::::- Eesti Vabariik, Estonian for Republic of Estonia\nBULLET::::- \"Eingetragener Verein\" (\"registered association\"), a legal status for a registered voluntary association in Germany and Austria\nBULLET::::- Enterprise Village, an educational program co-managed by the Stavros Institute in Pinellas County, Florida\nBULLET::::- \"Era vulgaris\", Latin for the Common Era\nBULLET::::- EuroVelo, a network of long-distance cycling routes in Europe\n"}
