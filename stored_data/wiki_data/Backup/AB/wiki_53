{"id": "15067", "url": "https://en.wikipedia.org/wiki?curid=15067", "title": "Internetworking", "text": "Internetworking\n\nInternetworking is \"the concept of interconnecting different types of networks to build a large, global network\" such that any pair of connected hosts can exchange packets. To build an internetwork, the following are needed: A standardized scheme to address packets to any host on any participating network; a standardized protocol defining format and handling of transmitted packets; components interconnecting the participating networks by routing packets to their destinations based on standardized addresses.\n\nThe resulting system of interconnected networks are called an \"internetwork\", or simply an \"internet\". Internetworking is a combination of the words \"inter\" (\"between\") and networking; not \"internet-working\" or \"international-network\".\n\nThe most notable example of internetworking is the Internet, a network of networks based on many underlying hardware technologies. For the Internet, the Internet Protocol defines a unified, global address format and provides rules for format and handling of packets, and routers are the components that interconnect participating networks.\n\nThe smallest amount of effort to create an internet (an internetwork, not \"the\" Internet), is to have two LANs of computers connected to each other via a router. Simply using either a switch or a hub to connect two local area networks together doesn't imply internetworking; it just expands the original LAN.\n\nInternetworking started as a way to connect disparate types of networking technology, but it became widespread through the developing need to connect two or more local area networks via some sort of wide area network. The original term for an internetwork was catenet.\n\nThe definition of an internetwork today includes the connection of other types of computer networks such as personal area networks.\nThe network elements used to connect individual networks in the ARPANET, the predecessor of the Internet, were originally called gateways, but the term has been deprecated in this context, because of possible confusion with functionally different devices. Today the interconnecting gateways are called routers.\n\nAnother type of interconnection of networks often occurs within enterprises at the Link Layer of the networking model, i.e. at the hardware-centric layer below the level of the TCP/IP logical interfaces. Such interconnection is accomplished with network bridges and network switches. This is sometimes incorrectly termed internetworking, but the resulting system is simply a larger, single subnetwork, and no internetworking protocol, such as Internet Protocol, is required to traverse these devices. However, a single computer network may be converted into an internetwork by dividing the network into segments and logically dividing the segment traffic with routers.\nThe Internet Protocol is designed to provide an unreliable (not guaranteed) packet service across the network. The architecture avoids intermediate network elements maintaining any state of the network. Instead, this function is assigned to the endpoints of each communication session. To transfer data reliably, applications must utilize an appropriate Transport Layer protocol, such as Transmission Control Protocol (TCP), which provides a reliable stream. Some applications use a simpler, connection-less transport protocol, User Datagram Protocol (UDP), for tasks which do not require reliable delivery of data or that require real-time service, such as video streaming or voice chat.\n\nTwo architectural models are commonly used to describe the protocols and methods used in internetworking.\n\nThe Open System Interconnection (OSI) reference model was developed under the auspices of the International Organization for Standardization (ISO) and provides a rigorous description for layering protocol functions from the underlying hardware to the software interface concepts in user applications. Internetworking is implemented in the Network Layer (Layer 3) of the model.\n\nThe Internet Protocol Suite, also called the TCP/IP model of the Internet was not designed to conform to the OSI model and does not refer to it in any of the normative specifications in Requests for Comment and Internet standards. Despite similar appearance as a layered model, it uses a much less rigorous, loosely defined architecture that concerns itself only with the aspects of logical networking. It does not discuss hardware-specific low-level interfaces, and assumes availability of a Link Layer interface to the local network link to which the host is connected. Internetworking is facilitated by the protocols of its Internet Layer.\n\nBULLET::::- History of the Internet\n"}
{"id": "15068", "url": "https://en.wikipedia.org/wiki?curid=15068", "title": "Infantry", "text": "Infantry\n\nInfantry is a military specialization that engages in military combat on foot, distinguished from cavalry, artillery, and tank forces. Also known as foot soldiers or infantrymen, infantry traditionally relies on moving by foot between combats as well, but may also use mounts, military vehicles, or other transport. Infantry make up a large portion of all armed forces in most nations, and typically bear the largest brunt in warfare, as measured by casualties, deprivation, or physical and psychological stress.\n\nThe first military forces in history were infantry. In antiquity, infantry were armed with an early melee weapon such as a spear, axe or sword, or an early ranged weapon like a javelin, sling, or bow, with a few infantrymen having both a melee and a ranged weapon. With the development of gunpowder, infantry began converting to primarily firearms. By the time of Napoleonic warfare, infantry, cavalry, and artillery formed a basic triad of ground forces, though infantry usually remained the most numerous. With armoured warfare, armoured fighting vehicles have replaced the horses of cavalry, and airpower has added a new dimension to ground combat, but infantry remains pivotal to all modern combined arms operations.\n\nInfantry have much greater local situational awareness than other military forces, due to their inherent intimate contact with the battlefield (\"boots on the ground\"); this is vital for engaging and infiltrating enemy positions, holding and defending ground (any military objectives), securing battlefield victories, maintaining military area control and security both at and behind the front lines, for capturing ordnance or materiel, taking prisoners, and military occupation. Infantry can more easily recognise, adapt and respond to local conditions, weather, and changing enemy weapons or tactics. They can operate in a wide range of terrain inaccessible to military vehicles, and can operate with a lower logistical burden. Infantry are the most easily delivered forces to ground combat areas, by simple and reliable marching, or by trucks, sea or air transport; they can also be inserted directly into combat by amphibious landing, or for air assault by parachute (airborne infantry) or helicopter (airmobile infantry). They can be augmented with a variety of crew-served weapons, armoured personnel carriers, and infantry fighting vehicles.\n\nIn English, use of the term \"infantry\" began about the 1570s, describing soldiers who march and fight on foot. The word derives from Middle French \"infanterie\", from older Italian (also Spanish) \"infanteria\" (foot soldiers too inexperienced for cavalry), from Latin \"īnfāns\" (without speech, newborn, foolish), from which English also gets \"infant\". The individual-soldier term infantryman was not coined until 1837. In modern usage, foot soldiers of any era are now considered infantry and infantrymen. In Spain, \"infanteria\" was commanded by \"infantes\", those princes who were not heirs to the throne.\n\nFrom the mid-18th century until 1881 the British Army named its infantry as numbered regiments \"of Foot\" to distinguish them from cavalry and dragoon regiments (see List of Regiments of Foot).\n\nInfantry equipped with special weapons were often named after that weapon, such as grenadiers for their grenades, or fusiliers for their \"fusils\". These names can persist long after the weapon speciality; examples of infantry units that retained such names are the Royal Irish Fusiliers and the Grenadier Guards.\n\nMore commonly in modern times, infantry with special tactics are named for their roles, such as commandos, rangers, snipers, marines, (who all have additional training) and militia (who have limited training); they are still infantry due to their expectation to fight as infantry when they enter combat.\n\nDragoons were created as mounted infantry, with horses for travel between battles; they were still considered infantry since they dismounted before combat. However, if light cavalry was lacking in an army, any available dragoons might be assigned their duties; this practise increased over time, and dragoons eventually received all the weapons and training as both infantry and cavalry, and could be classified as both. Conversely, starting about the mid-19th century, regular cavalry have been forced to spend more of their time dismounted in combat due to the ever-increasing effectiveness of enemy infantry firearms. Thus most cavalry transitioned to mounted infantry. As with grenadiers, the \"dragoon\" and \"cavalry\" designations can be retained long after their horses, such as in the Royal Dragoon Guards, Royal Lancers, and King's Royal Hussars.\n\nSimilarly, motorised infantry have trucks and other unarmed vehicles for non-combat movement, but are still infantry since they leave their vehicles for any combat. Most modern infantry have vehicle transport, to the point where infantry being motorised is generally assumed, and the few exceptions might be identified as modern \"light infantry\", or \"leg infantry\" colloquially. Mechanised infantry go beyond motorised, having transport vehicles with combat abilities, armoured personnel carriers (APCs), providing at least some options for combat without leaving their vehicles. In modern infantry, some APCs have evolved to be infantry fighting vehicles (IFVs), which are transport vehicles with more substantial combat abilities, approaching those of light tanks. Some well-equipped mechanised infantry can be designated as \"armoured infantry\". Given that infantry forces typically also have some tanks, and given that most armoured forces have more mechanised infantry units than tank units in their organisation, the distinction between mechanised infantry and armour forces has blurred.\n\nThe terms \"infantry\", \"armour\", and \"cavalry\" used in the official names for military units like divisions, brigades, or regiments might be better understood as a description of their expected balance of defensive, offensive, and mobility roles, rather than just use of vehicles. Some modern mechanised infantry units are termed \"cavalry\" or \"armoured cavalry\", even though they never had horses, to emphasise their combat mobility.\n\nIn the modern US Army, about 15% of soldiers are officially \"Infantry\". The basic training for all new US Army soldiers includes use of infantry weapons and tactics, even for tank crews, artillery crews, and base and logistical personnel.\n\nThe first warriors, adopting hunting weapons or improvised melee weapons, before the existence of any organised military, likely started essentially as loose groups without any organisation or formation. But this changed sometime before recorded history; the first ancient empires (2500–1500 BC) are shown to have some soldiers with standardised military equipment, and the training and discipline required for battlefield formations and manoeuvres: regular infantry. Though the main force of the army, these forces were usually kept small due to their cost of training and upkeep, and might be supplemented by local short-term mass-conscript forces using the older irregular infantry weapons and tactics; this remained a common practice almost up to modern times.\n\nBefore the adoption of the chariot to create the first mobile fighting forces , all armies were pure infantry. Even after, with a few exceptions like the Mongol Empire, infantry has been the largest component of most armies in history.\n\nIn the Western world, from Classical Antiquity through the Middle Ages ( 8th century BC to 15th century AD), infantry are categorised as either heavy infantry or light infantry. Heavy infantry, such as Greek hoplites, Macedonian phalangites, and Roman legionaries, specialised in dense, solid formations driving into the main enemy lines, using weight of numbers to achieve a decisive victory, and were usually equipped with heavier weapons and armour to fit their role. Light infantry, such as Greek peltasts, Balearic slingers, and Roman velites, using open formations and greater manoeuvrability, took on most other combat roles: scouting, screening the army on the march, skirmishing to delay, disrupt, or weaken the enemy to prepare for the main forces' battlefield attack, protecting them from flanking manoeuvers, and then afterwards either pursuing the fleeing enemy or covering their army's retreat.\n\nAfter the fall of Rome, the quality of heavy infantry declined, and warfare was dominated by heavy cavalry, such as knights, forming small elite units for decisive shock combat, supported by peasant infantry militias and assorted light infantry from the lower classes. Towards the end of Middle Ages, this began to change, where more professional and better trained light infantry could be effective against knights, such as the English longbowmen in the Hundred Years' War. By the start of the Renaissance, the infantry began to return to dominance, with Swiss pikemen and German Landsknechts filling the role of heavy infantry again, using dense formations of pikes to drive off any cavalry.\n\nDense formations are vulnerable to ranged weapons. Technological developments allowed the raising of large numbers of light infantry units armed with ranged weapons, without the years of training expected for traditional high-skilled archers and slingers. This started slowly, first with crossbowmen, then hand cannoneers and arquebusiers, each with increasing effectiveness, marking the beginning of early modern warfare, when firearms rendered the use of heavy infantry obsolete. The introduction of musketeers using bayonets in the mid 17th century began replacement of the pike with the infantry square replacing the pike square.\n\nTo maximise their firepower, musketeer infantry were trained to fight in wide lines facing the enemy, creating line infantry. These fulfilled the central battlefield role of earlier heavy infantry, using ranged weapons instead of melee weapons. To support these lines, smaller infantry formations using dispersed skirmish lines were created, called light infantry, fulfilling the same multiple roles as earlier light infantry. Their arms were no lighter than line infantry; they were distinguished by their skirmish formation and flexible tactics.\n\nThe modern rifleman infantry became the primary force for taking and holding ground on battlefields worldwide, a vital element of combined arms combat. As firepower continued to increase, use of infantry lines diminished, until all infantry became light infantry in practice.\n\nModern classifications of infantry have expanded to reflect modern equipment and tactics, such as motorised infantry, mechanised or armoured infantry, mountain infantry, marine infantry, and airborne infantry.\n\nAn infantryman's equipment is of vital concern both for the man and the military. The needs of the infantryman to maintain fitness and effectiveness must be constantly balanced against being overburdened. While soldiers in other military branches can use their mount or vehicle for carrying equipment, and tend to operate together as crews serving their vehicle or ordnance, infantrymen must operate more independently; each infantryman usually having much more personal equipment to use and carry. This encourages searching for ingenious combinations of effective, rugged, serviceable and adaptable, yet light, compact, and handy infantry equipment.\n\nBeyond their main arms and armour, each infantryman's \"military kit\" includes combat boots, battledress or combat uniform, camping gear, heavy weather gear, survival gear, secondary weapons and ammunition, weapon service and repair kits, health and hygiene items, mess kit, rations, filled water canteen, and all other consumables each infantryman needs for the expected duration of time operating away from their unit's base, plus any special mission-specific equipment. One of the most valuable pieces of gear is the entrenching tool—basically a folding spade—which can be employed not only to dig important defences, but also in a variety of other daily tasks, and even sometimes as a weapon. Infantry typically have shared equipment on top of this, like tents or heavy weapons, where the carrying burden is spread across several infantrymen. In all, this can reach for each soldier on the march. Such heavy infantry burdens have changed little over centuries of warfare; in the late Roman Republic, legionaries were nicknamed \"Marius' mules\" as their main activity seemed to be carrying the weight of their legion around on their backs.\n\nWhen combat is expected, infantry typically switch to \"packing light\", meaning reducing their equipment to weapons, ammo, and bare essentials, and leaving the rest with their transport or baggage train, at camp or rally point, in temporary hidden caches, or even (in emergencies) discarding whatever may slow them down. Additional specialised equipment may be required, depending on the mission or to the particular terrain or environment, including satchel charges, demolition tools, mines, barbed wire, carried by the infantry or attached specialists.\n\nHistorically, infantry have suffered high casualty rates from disease, exposure, exhaustion and privation — often in excess of the casualties suffered from enemy attacks. Better infantry equipment to support their health, energy, and protect from environmental factors greatly reduces these rates of loss, and increase their level of effective action. Health, energy, and morale are greatly influenced by how the soldier is fed, so militaries often standardised field rations, starting from hardtack, to US K-rations, to modern MREs.\n\nCommunications gear has become a necessity, as it allows effective command of infantry units over greater distances, and communication with artillery and other support units. Modern infantry can have GPS, encrypted individual communications equipment, surveillance and night vision equipment, advanced intelligence and other high-tech mission-unique aids.\n\nArmies have sought to improve and standardise infantry gear to reduce fatigue for extended carrying, increase freedom of movement, accessibility, and compatibility with other carried gear, such as the US All-purpose Lightweight Individual Carrying Equipment (ALICE).\n\nInfantrymen are defined by their primary arms – the personal weapons and body armour for their own individual use. The available technology, resources, history, and society can produce quite different weapons for each military and era, but common infantry weapons can be distinguished in a few basic categories.\n\nBULLET::::- Ranged combat weapons: javelins, slings, blowguns, bows, crossbows, hand cannons, arquebuses, muskets, grenades, flamethrowers.\nBULLET::::- Close combat weapons: bludgeoning weapons like clubs, flails and maces; bladed weapons like swords, daggers, and axes; pole weapons like spears, halberds, naginata, and pikes.\nBULLET::::- Both ranged and close weapons: the bayonet fixed to a firearm allows infantrymen to use the same weapon for both ranged combat and close combat. This started with muskets and continued with rifles to automatic firearms. Use of the bayonet has declined with modern automatic firearms, but still generally kept as a weapon of last resort.\n\nInfantrymen often carry secondary or back-up weapons, sometimes called a sidearm or ancillary weapons in modern terminology, either issued officially as an addition to the soldier's standard arms, or acquired unofficially by any other means as an individual preference. Such weapons are used when the primary weapon is no longer effective, such it becoming damaged, running out of ammunition, malfunction, or in a change of tactical situation where another weapon is preferred, such as going from ranged to close combat. Infantry with ranged or pole weapons often carried a sword or dagger for possible hand-to-hand combat. The \"pilum\" was a javelin of the Roman legionaries threw just before drawing their primary weapon, the \"gladius\" (short sword), and closing with the enemy line.\n\nModern infantrymen now treat the bayonet as a backup weapon, but may also have handguns or pistols. They may also deploy anti-personnel mines, booby traps, incendiary or explosive devices defensively before combat.\n\nSome non-weapon equipment are designed for close combat shock effects, to get and psychological edge before melee, such as battle flags, war drums, brilliant uniforms, fierce body paint or tattoos, and even battle cries. These have become mostly only ceremonial since the decline of close combat military tactics.\n\nInfantry have employed many different methods of protection from enemy attacks, including various kinds of armour and other gear, and tactical procedures.\n\nThe most basic is personal armour. This includes shields, helmets and many types of armour – padded linen, leather, lamellar, mail, plate, and kevlar. Initially, armour was used to defend both from ranged and close combat; even a fairly light shield could help defend against most slings and javelins, though high-strength bows and crossbows might penetrate common armour at very close range. Infantry armour had to compromise between protection and coverage, as a full suit of attack-proof armour would be too heavy to wear in combat.\n\nAs firearms improved, armour for ranged defence had to be thicker and stronger. With the introduction of the heavy arquebus designed to pierce standard steel armour, it was proven easier to make heavier firearms than heavier armour; armour transitioned to be only for close combat purposes. Pikemen armour tended to be just steel helmets and breastplates, and gunners little or no armour. By the time of the musket, the dominance of firepower shifted militaries away from any close combat, and use of armour decreased, until infantry typically went without any armour.\n\nHelmets were added back during World War I as artillery began to dominate the battlefield, to protect against their fragmentation and other blast effects beyond a direct hit. Modern developments in bullet-proof composite materials like kevlar have started a return to body armour for infantry, though the extra weight is a notable burden.\n\nIn modern times, infantrymen must also often carry protective measures against chemical and biological attack, including gas masks, counter-agents, and protective suits. All of these protective measures add to the weight an infantryman must carry, and may decrease combat efficiency. Modern militaries are struggling to balance the value of personal body protection versus the weight burden and ability to function under such weight.\n\nEarly crew-served weapons were siege weapons, like the ballista, trebuchet, and battering ram. Modern versions include machine guns, anti-tank missiles, and infantry mortars.\n\nBeginning with the development the first regular military forces, close-combat regular infantry fought less as unorganised groups of individuals and more in coordinated units, maintaining a defined tactical formation during combat, for increased battlefield effectiveness; such infantry formations and the arms they used developed together, starting with the spear and the shield.\n\nA spear has decent attack abilities with the additional advantage keeping opponents at distance; this advantage can be increased by using longer spears, but this could allow the opponent to side-step the point of the spear and close for hand-to-hand combat where the longer spear is near useless. This can be avoided when each spearman stays side-by-side with the others in close formation, each covering the ones next to him, presenting a solid wall of spears to the enemy that they cannot get around.\n\nSimilarly, a shield has decent defence abilities, but is literally hit-or-miss; an attack from an unexpected angle can bypass it completely. Larger shields can cover more, but are also heavier and less manoeuvrable, making unexpected attacks even more of a problem. This can be avoided by having shield-armed soldiers stand close together, side-by-side, each protecting both themselves and their immediate comrades, presenting a solid shield wall to the enemy.\n\nThe opponents for these first formations, the close-combat infantry of more tribal societies, or any military without regular infantry (so called \"barbarians\") used arms that focused on the individual – weapons using personal strength and force, such as larger swinging swords, axes, and clubs. These take more room and individual freedom to swing and wield, necessitating a more loose organisation. While this may allow for a fierce running attack (an initial shock advantage) the tighter formation of the heavy spear and shield infantry gave them a local manpower advantage where several might be able to fight each opponent.\n\nThus tight formations heightened advantages of heavy arms, and gave greater local numbers in melee. To also increase their staying power, multiple rows of heavy infantrymen were added. This also increased their shock combat effect; individual opponents saw themselves literally lined-up against several heavy infantryman each, with seemingly no chance of defeating all of them. \"Heavy infantry\" developed into huge solid block formations, up to a hundred meters wide and a dozen rows deep.\n\nMaintaining the advantages of heavy infantry meant maintaining formation; this became even more important when two forces with heavy infantry met in battle; the solidity of the formation became the deciding factor. Intense discipline and training became paramount. Empires formed around their military.\n\nThe organization of military forces into regular military units is first noted in Egyptian records of the Battle of Kadesh (). Soldiers were grouped into units of 50, which were in turn grouped into larger units of 250, then 1,000, and finally into units of up to 5,000 – the largest independent command. Several of these Egyptian \"divisions\" made up an army, but operated independently, both on the march and tactically, demonstrating sufficient military command and control organisation for basic battlefield manoeuvres. Similar hierarchical organizations have been noted in other ancient armies, typically with approximately 10 to 100 to 1,000 ratios (even where base 10 was not common), similar to modern sections (squads), companies, and regiments.\n\nThe training of the infantry has differed drastically over time and from place to place. The cost of maintaining an army in fighting order and the seasonal nature of warfare precluded large permanent armies.\n\nThe antiquity saw everything from the well-trained and motivated citizen armies of Greek and Rome, the tribal host assembled from farmers and hunters with only passing acquaintance with warfare and masses of lightly armed and ill-trained militia put up as a last ditch effort.\n\nIn medieval times the foot soldiers varied from peasant levies to semi-permanent companies of mercenaries, foremost among them the Swiss, English, Aragonese and German, to men-at-arms who went into battle as well-armoured as knights, the latter of which at times also fought on foot.\n\nThe creation of standing armies—permanently assembled for war or defence—saw increase in training and experience. The increased use of firearms and the need for drill to handle them efficiently.\n\nThe introduction of national and mass armies saw an establishment of minimum requirements and the introduction of special troops (first of them the engineers going back to medieval times, but also different kinds of infantry adopted to specific terrain, bicycle, motorcycle, motorised and mechanised troops) culminating with the introduction of highly trained special forces during the first and second World War.\n\nAs a branch of the armed forces, the role of the infantry in warfare is to engage, fight, and kill the enemy at close range—using either a firearm (rifle, pistol, machine gun), an edged-weapon (knife, bayonet), or bare hands (close quarters combat)—as required by the mission to hand; thus\nBULLET::::- in the Australian Army and New Zealand Army the role of the infantry is \"to seek out and close with the enemy, to kill or capture him, to seize and hold ground, to repel attack, by day or night, regardless of season, weather or terrain\".\nBULLET::::- in the Canadian Army, the role of the infantry is \"to close with, and destroy the enemy\".\nBULLET::::- in the U.S. Army, the \"infantry closes with the enemy, by means of fire and maneuver, in order to destroy or capture him, or to repel his assault by fire, close combat, and counterattack\".\nBULLET::::- in the U.S. Marine Corps, the role of the infantry is to \"locate, close with, and destroy the enemy with fire and maneuver, and to repel the enemy assault by fire and close combat\".\n\nBeginning with the Napoleonic Wars of the early 19th century, artillery has become an increasingly dominant force on the battlefield. Since World War I, combat aircraft and armoured vehicles have also become dominant. However, the most effective method for locating all enemy forces on a battlefield is still the infantry patrol, and it is the presence or absence of infantry that ultimately determines whether a particular piece of ground has been captured or held. In 20th and 21st century warfare, infantry functions most effectively as part of a combined arms team including artillery, armour, and combat aircraft. Studies have shown that of all casualties, 50% or more were caused by artillery; about 10% were caused by machine guns; 2–5% by rifle fire; and 1% or less by hand grenades, bayonets, knives, and unarmed combat combined. Several infantry divisions both Allied and Axis in the European theatre of WWII suffered higher than 100% combat and non combat casualties and some above 200%, meaning that the number of service personnel that became casualties was greater than the sum of the divisions' available service positions at full strength.\n\nAttack operations are the most basic role of the infantry, and along with defence, form the main stances of the infantry on the battlefield. Traditionally, in an open battle, or meeting engagement, two armies would manoeuvre to contact, at which point they would form up their infantry and other units opposite each other. Then one or both would advance and attempt to defeat the enemy force. The goal of an attack remains the same: to advance into an enemy-held \"objective,\" most frequently a hill, river crossing, city or other dominant terrain feature, and dislodge the enemy, thereby establishing control of the objective.\n\nAttacks are often feared by the infantry conducting them because of the high number of casualties suffered while advancing to close with and destroy the enemy while under enemy fire. In mechanised infantry the armoured personnel carrier (APC) is considered the assaulting position. These APCs can deliver infantrymen through the front lines to the battle and—in the case of infantry fighting vehicles—contribute supporting firepower to engage the enemy. Successful attacks rely on sufficient force, preparative reconnaissance and battlefield preparation with bomb assets. Retention of discipline and cohesion throughout the attack is paramount to success. A subcategory of attacks is the ambush, where infantrymen lie in wait for enemy forces before attacking at a vulnerable moment. This gives the ambushing infantrymen the combat advantage of surprise, concealment and superior firing positions, and causes confusion. The ambushed unit does not know what it is up against, or where they are attacking from.\n\nPatrolling is the most common infantry mission. Full-scale attacks and defensive efforts are occasional, but patrols are constant. Patrols consist of small groups of infantry moving about in areas of possible enemy activity to locate the enemy and destroy them when found. Patrols are used not only on the front-lines, but in rear areas where enemy infiltration or insurgencies are possible.\n\nPursuit is a role that the infantry often assumes. The objective of pursuit operations is the destruction of withdrawing enemy forces which are not capable of effectively engaging friendly units, before they can build their strength to the point where they are effective. Infantry traditionally have been the main force to overrun these units in the past, and in modern combat are used to pursue enemy forces in constricted terrain (urban areas in particular), where faster forces, such as armoured vehicles are incapable of going or would be exposed to ambush.\n\nDefence operations are the natural counter to attacks, in which the mission is to hold an objective and defeat enemy forces attempting to dislodge the defender. Defensive posture offers many advantages to the infantry, including the ability to use terrain and constructed fortifications to advantage; these reduce exposure to enemy fire compared with advancing forces. Effective defence relies on minimising losses to enemy fire, breaking the enemy's cohesion before their advance is completed, and preventing enemy penetration of defensive positions.\n\nEscorting consists of protecting support units from ambush, particularly from hostile infantry forces. Combat support units (a majority of the military) are not as well armed or trained as infantry units and have a different mission. Therefore, they need the protection of the infantry, particularly when on the move. This is one of the most important roles for the modern infantry, particularly when operating alongside armoured vehicles. In this capacity, infantry essentially conducts patrol on the move, scouring terrain which may hide enemy infantry waiting to ambush friendly vehicles, and identifying enemy strong points for attack by the heavier units.\n\nInfantry units are tasked to protect certain areas like command posts or airbases. Units assigned to this job usually have a large number of military police attached to them for control of checkpoints and prisons.\n\nManeouvering consumes much of an infantry unit's time. Infantry, like all combat arms units, are often manoeuvred to meet battlefield needs, and often must do so under enemy attack. The infantry must maintain their cohesion and readiness during the move to ensure their usefulness when they reach their objective. Traditionally, infantry have relied on their own legs for mobility, but mechanised or armoured infantry often uses trucks and armoured vehicles for transport. These units can quickly disembark and transition to light infantry, without vehicles, to access terrain which armoured vehicles can't effectively access.\n\nSurveillance operations are often carried out with the employment of small recon units or sniper teams which gather information about the enemy, reporting on characteristics such as size, activity, location, unit and equipment. These infantry units typically are known for their stealth and ability to operate for periods of time within close proximity of the enemy without being detected. They may engage high-profile targets, or be employed to hunt down terrorist cells and insurgents within a given area. These units may also entice the enemy to engage a located recon unit, thus disclosing their location to be destroyed by more powerful friendly forces.\n\nSome assignments for infantry units involve deployment behind the front, although patrol and security operations are usually maintained in case of enemy infiltration. This is usually the best time for infantry units to integrate replacements into units and to maintain equipment. Additionally, soldiers can be rested and general readiness should improve. However, the unit must be ready for deployment at any point.\n\nThis can be undertaken either in reserve or on the front, but consists of using infantry troops as labor for construction of field positions, roads, bridges, airfields, and all other manner of structures. The infantry is often given this assignment because of the physical quantity of strong men within the unit, although it can lessen a unit's morale and limit the unit's ability to maintain readiness and perform other missions. More often, such jobs are given to specialist engineering corps.\n\nInfantry units are trained to quickly mobilise, infiltrate, enter and neutralise threat forces when appropriate combat intelligence indicates to secure a location, rescue or capture high-profile targets.\n\nUrban combat poses unique challenges to the combat forces. It is one of the most complicated type of operations an infantry unit will undertake. With many places for the enemy to hide and ambush from, infantry units must be trained in how to enter a city, and systematically clear the buildings, which most likely will be booby trapped, in order to kill or capture enemy personnel within the city. Care must be taken to differentiate innocent civilians who often hide and support the enemy from the non-uniformed armed enemy forces. Civilian and military casualties both are usually very high.\n\nBecause of an infantryman's duties with firearms, explosives, physical and emotional stress, and physical violence, casualties and deaths are not uncommon in both war and in peacetime training or operations. It is a highly dangerous and demanding combat service; in World War II, military doctors concluded that even physically unwounded soldiers were psychologically worn out after about 200 days of combat.\n\nThe physical, mental, and environmental operating demands of the infantryman are high. All of the combat necessities such as ammunition, weapon systems, food, water, clothing, and shelter are carried on the backs of the infantrymen, at least in light role as opposed to mounted/mechanised. Combat loads of over 36 kg (80 lbs) are standard, and greater loads in excess of 45 kg (100 lbs) are very common. These heavy loads, combined with long foot patrols of over a day, in any climate from in temperature, require the infantryman to be in good physical and mental condition. Infantrymen live, fight and die outdoors in all types of brutal climates, often with no physical shelter. Poor climate conditions adds misery to this already demanding existence. Disease epidemics, frostbite, heat stroke, trench foot, insect and wild animal bites are common along with stress disorders and these have sometimes caused more casualties than enemy action.\n\nInfantrymen are expected to continue with their combat missions despite the death and injury of friends, fear, despair, fatigue, and bodily injury.\n\nSome infantry units are considered Special Forces. The earliest Special Forces commando units were more highly trained infantrymen, with special weapons, equipment, and missions. Special Forces units recruit heavily from regular infantry units to fill their ranks.\n\nForeign and domestic militaries typically have a slang term for their infantrymen. In the U.S. military, the slang term among both Marine and Army infantrymen for themselves is \"grunt.\" In the British Army, they are the \"squaddies.\" The infantry is a small close-knit community, and the slang names are terms of endearment that convey mutual respect and shared experiences.\n\nNaval infantry, commonly known as marines, are primarily a category of infantry that form part of the naval forces of states and perform roles on land and at sea, including amphibious operations, as well as other, naval roles. They also perform other tasks, including land warfare, separate from naval operations.\n\nAir force infantry and base defence forces, such as the Royal Air Force Regiment, Royal Australian Air Force Airfield Defence Guards, and Indonesian Air Force Paskhas Corps, are used primarily for ground-based defence of air bases and other air force facilities. They also have a number of other, specialist roles. These include, among others, Chemical, Biological, Radiological and Nuclear (CBRN) defence and training other airmen in basic ground defence tactics.\n\nBULLET::::- \"Ah, yes, mere infantry—poor beggars. ...\" — Plautus, Roman playwright\nBULLET::::- \"Let us be clear about three facts: First, all battles and all wars are won, in the end, by the infantryman. Secondly, the infantryman always bears the brunt; his casualties are heavier, he suffers greater extremes of discomfort and fatigue than the other [combat] arms. Thirdly, the art of the infantryman is less stereotyped, and far harder to acquire in modern war, than that of any other arm.\" — Field Marshal Earl Wavell (1945)\nBULLET::::- \"I love the infantry, because they are the underdogs. They are the mud-rain-frost-and-wind boys. They have no comforts, and they even learn to live without the necessities; and, in the end, they are the guys that wars can't be won without.\" — Ernie Pyle\nBULLET::::- \"I’m convinced that the infantry is the group in the army which gives more, and gets less, than anybody else.\" — \"Up Front\" (1945), by Bill Mauldin\nBULLET::::- \"Never think that war, no matter how necessary, nor how justified, is not a crime. Ask the infantry, and ask the dead.\" — Ernest Hemingway\nBULLET::::- \"The infantry doesn't change. We're the only arm [of the army] where the weapon is the man, himself.\" —C.T. Shortis\nBULLET::::- \"The army's infantry is its most essential component. Even today, no army can take and hold any ground without the use of infantry.\" — George Nafziger\n\nBULLET::::- Air assault\nBULLET::::- Airborne infantry\nBULLET::::- Armoured infantry\nBULLET::::- Infantry of the British Army\nBULLET::::- Foot guards\nBULLET::::- Fusiliers\nBULLET::::- Grenadiers\nBULLET::::- Indonesian Army infantry battalions\nBULLET::::- Infantry Branch (United States)\nBULLET::::- Infantry tactics\nBULLET::::- Line infantry\nBULLET::::- List of national infantry training schools\nBULLET::::- Marines\nBULLET::::- Mechanized infantry\nBULLET::::- Medium infantry\nBULLET::::- Motorised infantry\nBULLET::::- Mounted infantry\nBULLET::::- Naval infantry\nBULLET::::- United States Army Rangers\nBULLET::::- Riflemen\nBULLET::::- Royal Canadian Infantry Corps\nBULLET::::- Special forces\nBULLET::::- Pathfinder (military)\n\nBULLET::::- English, John A., Gudmundsson, Bruce I., \"On Infantry\", (Revised edition), The Military Profession series, Praeger Publishers, London, 1994. .\nBULLET::::- \"The Times\", Earl Wavell, Thursday, 19 April 1945 In Praise of Infantry.\nBULLET::::- Tobin, James, \"Ernie Pyle's War: America's Eyewitness to World War II\", Free Press, 1997.\nBULLET::::- Mauldin, Bill, Ambrose, Stephen E., \"Up Front\", W. W. Norton, 2000.\nBULLET::::- Trogdon, Robert W., \"Ernest Hemingway: A Literary Reference\", Da Capo Press, 2002.\nBULLET::::- \"The New York Times\", Maj Gen C T Shortis, British Director of Infantry, 4 February 1985.\nBULLET::::- Heinl, Robert Debs, \"Dictionary of Military and Naval Quotations\", Plautus in \"The Braggart Captain\" (3rd century CE), Naval Institute Press, Annapolis, 1978.\nBULLET::::- Nafziger, George, \"Napoleon's Invasion of Russia\", Presidio Press, 1998.\nBULLET::::- McManus, John C. \"Grunts: inside the American infantry combat experience, World War II through Iraq\" New York, NY: NAL Caliber. 2010 plus Webcast Author Lecture at the Pritzker Military Library on 29 September 2010.\nBULLET::::- Historic films and photos showing Infantries in World War I at europeanfilmgateway.eu\nBULLET::::- In Praise of Infantry, by Field-Marshal Earl Wavell; First published in \"The Times,\" Thursday, 19 April 1945.\nBULLET::::- The Lagunari \"Serenissima\" Regiment KFOR: KFOR Chronicle.\nBULLET::::- Web Version of U.S. Army Field Manual 3-21.8 – The Infantry Rifle Platoon and Squad.\n"}
{"id": "15069", "url": "https://en.wikipedia.org/wiki?curid=15069", "title": "Identity function", "text": "Identity function\n\nIn mathematics, an identity function, also called an identity relation or identity map or identity transformation, is a function that always returns the same value that was used as its argument. That is, for being identity, the equality holds for all .\n\nFormally, if is a set, the identity function on is defined to be that function with domain and codomain which satisfies\n\nIn other words, the function value in (that is, the codomain) is always the same input element of (now considered as the domain). The identity function on is clearly an injective function as well as a surjective function, so it is also bijective.\n\nThe identity function on is often denoted by .\n\nIn set theory, where a function is defined as a particular kind of binary relation, the identity function is given by the identity relation, or \"diagonal\" of .\n\nIf is any function, then we have (where \"∘\" denotes function composition). In particular, is the identity element of the monoid of all functions from to .\n\nSince the identity element of a monoid is unique, one can alternately define the identity function on to be this identity element. Such a definition generalizes to the concept of an identity morphism in category theory, where the endomorphisms of need not be functions.\n\nBULLET::::- The identity function is a linear operator, when applied to vector spaces.\nBULLET::::- The identity function on the positive integers is a completely multiplicative function (essentially multiplication by 1), considered in number theory.\nBULLET::::- In an -dimensional vector space the identity function is represented by the identity matrix , regardless of the basis.\nBULLET::::- In a metric space the identity is trivially an isometry. An object without any symmetry has as symmetry group the trivial group only containing this isometry (symmetry type ).\nBULLET::::- In a topological space, the identity function is always continuous.\n\nBULLET::::- Inclusion map\n"}
{"id": "15070", "url": "https://en.wikipedia.org/wiki?curid=15070", "title": "Intel 80386", "text": "Intel 80386\n\nThe Intel 80386, also known as i386 or just 386, is a 32-bit microprocessor introduced in 1985. The first versions had 275,000 transistors and were the CPU of many workstations and high-end personal computers of the time. As the original implementation of the 32-bit extension of the 80286 architecture, the 80386 instruction set, programming model, and binary encodings are still the common denominator for all 32-bit x86 processors, which is termed the \"i386-architecture\", \"x86\", or \"IA-32\", depending on context.\n\nThe 32-bit 80386 can correctly execute most code intended for the earlier 16-bit processors such as 8086 and 80286 that were ubiquitous in early PCs. (Following the same tradition, modern 64-bit x86 processors are able to run most programs written for older x86 CPUs, all the way back to the original 16-bit 8086 of 1978.) Over the years, successively newer implementations of the same architecture have become several hundreds of times faster than the original 80386 (and thousands of times faster than the 8086). A 33 MHz 80386 was reportedly measured to operate at about 11.4 MIPS.\n\nThe 80386 was introduced in October 1985, while manufacturing of the chips in significant quantities commenced in June 1986. Mainboards for 80386-based computer systems were cumbersome and expensive at first, but manufacturing was rationalized upon the 80386's mainstream adoption. The first personal computer to make use of the 80386 was designed and manufactured by Compaq and marked the first time a fundamental component in the IBM PC compatible de facto standard was updated by a company other than IBM.\n\nIn May 2006, Intel announced that 80386 production would stop at the end of September 2007. Although it had long been obsolete as a personal computer CPU, Intel and others had continued making the chip for embedded systems. Such systems using an 80386 or one of many derivatives are common in aerospace technology and electronic musical instruments, among others. Some mobile phones also used (later fully static CMOS variants of) the 80386 processor, such as BlackBerry 950 and Nokia 9000 Communicator. Linux would continue to support 80386 processors until December 11, 2012; when the kernel cut 386-specific instructions in version 3.8.\n\nalign=\"center\" \"Intel 80386 registers\"\n\ncolspan=\"8\"  Main registers \"(8/16/32 bits)\"\ncolspan=\"8\"  Index registers \"(16/32 bits)\"\ncolspan=\"8\"  Program counter \"(16/32 bits)\"\ncolspan=\"8\"  Segment selectors \"(16 bits)\"\n\ncolspan=\"20\"  Status register\n\nThe processor was a significant evolution in the x86 architecture, and extended a long line of processors that stretched back to the Intel 8008. The predecessor of the 80386 was the Intel 80286, a 16-bit processor with a segment-based memory management and protection system. The 80386 added a three-stage instruction pipeline, extended the architecture from 16-bits to 32-bits, and added an on-chip memory management unit. This paging translation unit made it much easier to implement operating systems that used virtual memory. It also offered support for register debugging.\n\nThe 80386 featured three operating modes: real mode, protected mode and virtual mode. The protected mode, which debuted in the 286, was extended to allow the 386 to address up to 4 GB of memory. The all new virtual 8086 mode (or \"VM86\") made it possible to run one or more real mode programs in a protected environment, although some programs were not compatible.\n\nThe ability for a 386 to be set up to act like it had a flat memory model in protected mode despite the fact that it uses a segmented memory model in all modes would arguably be the most important feature change for the x86 processor family until AMD released x86-64 in 2003.\n\nSeveral new instructions have been added to 386: BSF, BSR, BT, BTS, BTR, BTC, CDQ, CWDE, LFS, LGS, LSS, MOVSX, MOVZX, SETcc, SHLD, SHRD.\n\nTwo new segment registers have been added (FS and GS) for general-purpose programs, single Machine Status Word of 286 grew into eight control registers CR0–CR7. Debug registers DR0–DR7 were added for hardware breakpoints. New forms of MOV instruction are used to access them.\n\nChief architect in the development of the 80386 was John H. Crawford. He was responsible for extending the 80286 architecture and instruction set to 32-bit, and then led the microprogram development for the 80386 chip.\n\nThe 80486 and P5 Pentium line of processors were descendants of the 80386 design.\n\nThe following data types are directly supported and thus implemented by one or more 80386 machine instructions; these data types are briefly described here.:\nBULLET::::- \"Bit\" (boolean value), \"bit field\" (group of up to 32 bits) and \"bit string\" (up to 4 Gbit in length).\nBULLET::::- \"8-bit integer (byte)\", either signed (range −128..127) or unsigned (range 0..255).\nBULLET::::- \"16-bit integer\", either signed (range −32,768..32,767) or unsigned (range 0..65,535).\nBULLET::::- \"32-bit integer\", either signed (range −2..2−1) or unsigned (range 0..2−1).\nBULLET::::- \"64-bit integer\", either signed (range −2..2−1) or unsigned (range 0..2−1).\nBULLET::::- \"Offset\", a 16- or 32-bit displacement referring to a memory location (using any addressing mode).\nBULLET::::- \"Pointer\", a 16-bit selector together with a 16- or 32-bit offset.\nBULLET::::- \"Character\" (8-bit character code).\nBULLET::::- \"String\", a sequence of 8-, 16- or 32-bit words (up to 4 Gbit in length).\nBULLET::::- \"BCD\", decimal digits (0..9) represented by unpacked bytes.\nBULLET::::- \"Packed BCD\", two BCD digits in one byte (range 0..99).\n\nThe following 80386 assembly source code is for a subroutine named codice_1 that copies a null-terminated ASCIIZ character string from one location to another, converting all alphabetic characters to lower case. The string is copied one byte (8-bit character) at a time.\n\nThe example code uses the EBP (base pointer) register to establish a call frame, an area on the stack that contains all of the parameters and local variables for the execution of the subroutine. This kind of calling convention supports reentrant and recursive code and has been used by Algol-like languages since the late 1950s. A flat memory model is assumed, specifically, that the DS and ES segments address the same region of memory.\n\nIn 1988, Intel introduced the 80386SX, most often referred to as the 386SX, a cut-down version of the 80386 with a 16-bit data bus mainly intended for lower-cost PCs aimed at the home, educational, and small-business markets, while the 386DX would remain the high-end variant used in workstations, servers, and other demanding tasks. The CPU remained fully 32-bit internally, but the 16-bit bus was intended to simplify circuit-board layout and reduce total cost. The 16-bit bus simplified designs but hampered performance. Only 24 pins were connected to the address bus, therefore limiting addressing to 16 MB, but this was not a critical constraint at the time. Performance differences were due not only to differing data-bus widths, but also due to performance-enhancing cache memories often employed on boards using the original chip.\n\nThe original 80386 was subsequently renamed 80386DX to avoid confusion. However, Intel subsequently used the \"DX\" suffix to refer to the floating-point capability of the 80486DX. The 80387SX was an 80387 part that was compatible with the 386SX (i.e. with a 16-bit databus). The 386SX was packaged in a surface-mount QFP and sometimes offered in a socket to allow for an upgrade.\n\nThe i386SL was introduced as a power-efficient version for laptop computers. The processor offered several power-management options (e.g. SMM), as well as different \"sleep\" modes to conserve battery power. It also contained support for an external cache of 16 to 64 kB. The extra functions and circuit implementation techniques caused this variant to have over 3 times as many transistors as the i386DX. The i386SL was first available at 20 MHz clock speed, with the 25 MHz model later added.\n\nThe first company to design and manufacture a PC based on the Intel 80386 was Compaq. By extending the 16/24-bit IBM PC/AT standard into a natively 32-bit computing environment, Compaq became the first third party to implement a major technical hardware advance on the PC platform. IBM was offered use of the 80386, but had manufacturing rights for the earlier 80286. IBM therefore chose to rely on that processor for a couple more years. The early success of the Compaq 386 PC played an important role in legitimizing the PC \"clone\" industry and in de-emphasizing IBM's role within it.\n\nPrior to the 386, the difficulty of manufacturing microchips and the uncertainty of reliable supply made it desirable that any mass-market semiconductor be multi-sourced, that is, made by two or more manufacturers, the second and subsequent companies manufacturing under license from the originating company. The 386 was for \"a time\" (4.7 years) only available from Intel, since Andy Grove, Intel's CEO at the time, made the decision not to encourage other manufacturers to produce the processor as second sources. This decision was ultimately crucial to Intel's success in the market. The 386 was the first significant microprocessor to be single-sourced. Single-sourcing the 386 allowed Intel greater control over its development and substantially greater profits in later years.\n\nAMD introduced its compatible Am386 processor in March 1991 after overcoming legal obstacles, thus ending Intel's 4.7-year monopoly on 386-compatible processors. From 1991 IBM also manufactured 386 chips under license for use only in IBM PCs and boards.\n\nBULLET::::- The AMD Am386SX and Am386DX were almost exact clones of the 80386SX and 80386DX. Legal disputes caused production delays for several years, but AMD's 40 MHz part eventually became very popular with computer enthusiasts as a low-cost and low-power alternative to the 25 MHz 486SX. The power draw was further reduced in the \"notebook models\" (Am386 DXL/SXL/DXLV/SXLV), which could operate with 3.3 V and were implemented in fully static CMOS circuitry.\nBULLET::::- Chips and Technologies Super386 38600SX and 38600DX were developed using reverse engineering. They sold poorly, due to some technical errors and incompatibilities, as well as their late appearance on the market. They were therefore short-lived products.\nBULLET::::- Cyrix Cx486SLC/Cx486DLC could be (simplistically) described as a kind of 386/486 hybrid chip that included a small amount of on-chip cache. It was popular among computer enthusiasts but did poorly with OEMs. The Cyrix Cx486SLC and Cyrix Cx486DLC processors were pin-compatible with 80386SX and 80386DX respectively. These processors were also manufactured and sold by Texas Instruments.\nBULLET::::- IBM 386SLC and 486SLC/DLC were variants of Intel's design which contained a large amount of on-chip cache (8 kB, and later 16 kB). The agreement with Intel limited their use to IBM's own line of computers and upgrade boards only, so they were not available on the open market.\n\nIntel originally intended for the 80386 to debut at 16 MHz. However, due to poor yields, it was instead introduced at 12 MHz.\n\nEarly in production, Intel discovered a marginal circuit that could cause a system to return incorrect results from 32-bit multiply operations. Not all of the processors already manufactured were affected, so Intel tested its inventory. Processors that were found to be bug-free were marked with a double sigma (ΣΣ), and affected processors were marked \"16 BIT S/W ONLY\". These latter processors were sold as good parts, since at the time 32-bit capability was not relevant for most users. Such chips are now extremely rare and became collectible.\n\nThe i387 math coprocessor was not ready in time for the introduction of the 80386, and so many of the early 80386 motherboards instead provided a socket and hardware logic to make use of an 80287. In this configuration the FPU would operate asynchronously to the CPU, usually with a clock rate of 10 MHz. The original Compaq Deskpro 386 is an example of such design. However, this was an annoyance to those who depended on floating-point performance, as the performance advantages of the 80387 over the 80287 were significant.\n\nIntel later offered a modified version of its 80486DX in 80386 packaging, branded as the Intel RapidCAD. This provided an upgrade path for users with 80386-compatible hardware. The upgrade was a pair of chips that replaced both the 80386 and 80387. Since the 80486DX design contained an FPU, the chip that replaced the 80386 contained the floating-point functionality, and the chip that replaced the 80387 served very little purpose. However, the latter chip was necessary in order to provide the FERR signal to the mainboard and appear to function as a normal floating-point unit.\n\nThird parties offered a wide range of upgrades, for both SX and DX systems. The most popular ones were based on the Cyrix 486DLC/SLC core, which typically offered a substantial speed improvement due to its more efficient instruction pipeline and internal L1 SRAM cache. The cache was usually 1 kB, or sometimes 8 kB in the TI variant. Some of these upgrade chips (such as the 486DRx2/SRx2) were marketed by Cyrix themselves, but they were more commonly found in kits offered by upgrade specialists such as Kingston, Evergreen and Improve-It Technologies. Some of the fastest CPU upgrade modules featured the IBM SLC/DLC family (notable for its 16 kB L1 cache), or even the Intel 486 itself. Many 386 upgrade kits were advertised as being simple drop-in replacements, but often required complicated software to control the cache or clock doubling. Part of the problem was that on most 386 motherboards, the A20 line was controlled entirely by the motherboard with the CPU being unaware, which caused problems on CPUs with internal caches.\n\nOverall, it was very difficult to configure upgrades to produce the results advertised on the packaging, and upgrades were often not very stable or not fully compatible.\n\nOriginal version, released in October 1985.\nBULLET::::- Capable of working with 16- or 32-bit external busses\nBULLET::::- Cache: depends on mainboard\nBULLET::::- Package: PGA-132 or PQFP-132\nBULLET::::- Process: First types CHMOS III, 1.5 µm, later CHMOS IV, 1 µm\nBULLET::::- Die size: 104 mm² (ca. 10 mm × 10 mm) in CHMOS III and 39 mm² (6 mm × 6.5 mm) in CHMOS IV.\nBULLET::::- Transistor count: 275,000\nBULLET::::- Specified max clock: 12 MHz (early models), later 16, 20, 25 and 33 MHz\n\nA specially packaged Intel 486DX and a dummy floating point unit (FPU) designed as pin-compatible replacements for an Intel 80386 processor and 80387 FPU.\n\nThis was an embedded version of the 80386SX which did not support real mode and paging in the MMU.\n\nSystem and power management and built in peripheral and support functions: Two 82C59A interrupt controllers; Timer, Counter (3 channels); Asynchronous SIO (2 channels); Synchronous SIO (1 channel); Watchdog timer (Hardware/Software); PIO. Usable with 80387SX or i387SL FPUs.\nBULLET::::- Data/address bus: 16 / 26 bits\nBULLET::::- Package: PQFP-132, SQFP-144 and PGA-168\nBULLET::::- Process: CHMOS V, 0.8 µm\nBULLET::::- Specified max clock:\nBULLET::::- i386EX: 16 MHz @2.7~3.3 volt or 20 MHz @3.0~3.6 volt or 25 MHz @4.5~5.5 volt\nBULLET::::- i386EXTB: 20 MHz @2.7~3.6 volt or 25 MHz @3.0~3.6 volt\nBULLET::::- i386EXTC: 25 MHz @4.5~5.5 volt or 33 MHz @4.5~5.5 volt\n\nTransparent power management mode, integrated MMU and TTL compatible inputs (only 386SXSA). Usable with i387SX or i387SL FPUs.\nBULLET::::- Data/address bus: 16 / 26 bits (24 bits for i386SXSA)\nBULLET::::- Package: BQFP-100\nBULLET::::- Voltage: 4.5~5.5 volt (25 and 33 MHz); 4.75~5.25 volt (40 MHz)\nBULLET::::- Process: CHMOS V, 0.8 µm\nBULLET::::- Specified max clock: 25, 33, 40 MHz\n\nTransparent power management mode and integrated MMU. Usable with i387SX or i387SL FPUs.\nBULLET::::- Data/address bus: 16 / 26 bits\nBULLET::::- Package: BQFP-100\nBULLET::::- Voltage: 3.0 volt (16 MHz) or 3.3 volt (25 MHz)\nBULLET::::- Process: CHMOS V, 0.8 µm\nBULLET::::- Specified max clock: 16, 25 MHz\n\nBULLET::::- List of Intel microprocessors\n\nBULLET::::- Intel 80386 Programmer's Reference Manual 1986\nBULLET::::- Intel 80386 processor family\nBULLET::::- Intel 231746-001 Introduction to the 80386 Apr86 (April 1986) and Including the 80386 Data Sheet Intel 231630-002 80386 HIGH PERFORMANCE 32-BIT MICROPROCESSOR WITH INTEGRATED MEMORY MANAGEMENT—Data Sheet for 80386-12 and 80386-16\nBULLET::::- 1988 Intel Microprocessors and Peripheral Handbook Volume 1 Microprocessor including 80386 HIGH PERFORMANCE 32-BIT CHMOS MICROPROCESSOR WITH INTEGRATED MEMORY MANAGEMENT October 1987 Order Number: 231630-004\nBULLET::::- 1989 Intel Microprocessor and Peripheral Handbook Vol 1 Microprocessor including 386™ MICROPROCESSOR HIGH PERFORMANCE 32-BIT CHMOS MICROPROCESSOR WITH INTEGRATED MEMORY MANAGEMENT November 1988 Order Number: 231630-005\nBULLET::::- Detailed list of early 80386 steppings (revisions)\n"}
{"id": "15072", "url": "https://en.wikipedia.org/wiki?curid=15072", "title": "Instruction register", "text": "Instruction register\n\nIn computing, the instruction register (IR) or current instruction register (CIR) is the part of a CPU's control unit that holds the instruction currently being executed or decoded. In simple processors, each instruction to be executed is loaded into the instruction register, which holds it while it is decoded, prepared and ultimately executed, which can take several steps.\n\nSome of the complicated processors use a pipeline of instruction registers where each stage of the pipeline does part of the decoding, preparation or execution and then passes it to the next stage for its step. Modern processors can even do some of the steps out of order as decoding on several instructions is done in parallel.\n\nDecoding the op-code in the instruction register includes determining the instruction, determining where its operands are in memory, retrieving the operands from memory, allocating processor resources to execute the command (in super scalar processors), etc.\n\nThe output of the IR is available to control circuits, which generate the timing signals that control the various processing elements involved in executing the instruction.\n\nIn the instruction cycle, the instruction is loaded into the instruction register after the processor fetches it from the memory location pointed to by the program counter.\n\nBULLET::::- M. Mano, Computer System Architecture (Prentice Hall, 3rd Ed, 1992)\n"}
{"id": "15073", "url": "https://en.wikipedia.org/wiki?curid=15073", "title": "Lists of islands", "text": "Lists of islands\n\nThis is a list of lists of islands in the world grouped by oceans, by continents, and by other classifications. For rank-order lists, see the other lists of islands below.\n\nBy ocean:\nOther bodies of water:\nBULLET::::- Lake islands\nBULLET::::- Great Lakes (North America)\nBULLET::::- River islands\nBULLET::::- Danube River\n"}
{"id": "15075", "url": "https://en.wikipedia.org/wiki?curid=15075", "title": "INTERCAL", "text": "INTERCAL\n\nThe Compiler Language With No Pronounceable Acronym, abbreviated INTERCAL, is an esoteric programming language that was created as a parody by Don Woods and James M. Lyon, two Princeton University students, in 1972. It satirizes aspects of the various programming languages at the time, as well as the proliferation of proposed language constructs and notations in the 1960s.\n\nThere are two currently maintained versions of INTERCAL: C-INTERCAL, maintained by Eric S. Raymond, and CLC-INTERCAL, maintained by Claudio Calvelli.\n\nAccording to the original manual by the authors,\n\nThe original Princeton implementation used punched cards and the EBCDIC character set. To allow INTERCAL to run on computers using ASCII, substitutions for two characters had to be made: $ substituted for ¢ as the \"mingle\" operator, \"represent[ing] the increasing cost of software in relation to hardware\", and ? was substituted for ⊻ as the unary exclusive-or operator to \"correctly express the average person's reaction on first encountering exclusive-or\". In recent versions of C-INTERCAL, the older operators are supported as alternatives; INTERCAL programs may now be encoded in ASCII, Latin-1, or UTF-8.\n\nINTERCAL was intended to be completely different from all other computer languages. Common operations in other languages have cryptic and redundant syntax in INTERCAL. From the INTERCAL Reference Manual:\n\nINTERCAL has many other features designed to make it even more aesthetically unpleasing to the programmer: it uses statements such as \"READ OUT\", \"IGNORE\", \"FORGET\", and modifiers such as \"PLEASE\". This last keyword provides two reasons for the program's rejection by the compiler: if \"PLEASE\" does not appear often enough, the program is considered insufficiently polite, and the error message says this; if too often, the program could be rejected as excessively polite. Although this feature existed in the original INTERCAL compiler, it was undocumented.\n\nDespite the language's intentionally obtuse and wordy syntax, INTERCAL is nevertheless Turing-complete: given enough memory, INTERCAL can solve any problem that a Universal Turing machine can solve. Most implementations of INTERCAL do this very slowly, however. A Sieve of Eratosthenes benchmark, computing all prime numbers less than 65536, was tested on a Sun SPARCstation 1. In C, it took less than half a second; the same program in INTERCAL took over seventeen hours.\n\nThe INTERCAL Reference Manual contains many paradoxical, nonsensical, or otherwise humorous instructions:\n\nThe manual also contains a \"tonsil\", as explained in this footnote: \"4) Since all other reference manuals have Appendices, it was decided that the INTERCAL manual should contain some other type of removable organ.\"\n\nThe INTERCAL manual gives unusual names to all non-alphanumeric ASCII characters: single and double quotes are \"sparks\" and \"rabbit ears\" respectively. (The exception is the ampersand: as the Jargon File states, \"what could be sillier?\") The assignment operator, represented as an equals sign (INTERCAL's \"half mesh\") in many other programming languages, is in INTERCAL a left-arrow, codice_1, made up of an \"angle\" and a \"worm\", obviously read as \"gets\".\n\nInput (using the codice_2 instruction) and output (using the codice_3 instruction) do not use the usual formats; in INTERCAL-72, WRITE IN inputs a number written out as digits in English (such as SIX FIVE FIVE THREE FIVE), and READ OUT outputs it in \"butchered\" Roman numerals. More recent versions have their own I/O systems.\n\nComments can be achieved by using the inverted statement identifiers involving NOT or N'T; these cause lines to be initially ABSTAINed so that they have no effect. (A line can be ABSTAINed from even if it doesn't have valid syntax; syntax errors happen at runtime, and only then when the line is un-ABSTAINed.)\n\nINTERCAL-72 (the original version of INTERCAL) had only four data types: the 16-bit integer (represented with a codice_4, called a \"spot\"), the 32-bit integer (codice_5, a \"twospot\"), the array of 16-bit integers (codice_6, a \"tail\"), and the array of 32-bit integers (codice_7, a \"hybrid\"). There are 65535 available variables of each type, numbered from codice_8 to codice_9 for 16-bit integers, for instance. However, each of these variables has its own stack on which it can be pushed and popped (STASHed and RETRIEVEd, in INTERCAL terminology), increasing the possible complexity of data structures. More modern versions of INTERCAL have by and large kept the same data structures, with appropriate modifications; TriINTERCAL, which modifies the radix with which numbers are represented, can use a 10-trit type rather than a 16-bit type, and CLC-INTERCAL implements many of its own data structures, such as \"classes and lectures\", by making the basic data types store more information rather than adding new types. Arrays are dimensioned by assigning to them as if they were a scalar variable. Constants can also be used, and are represented by a codice_10 (\"mesh\") followed by the constant itself, written as a decimal number; only integer constants from 0 to 65535 are supported.\n\nThere are only five operators in INTERCAL-72. Implementations vary in which characters represent which operation, and many accept more than one character, so more than one possibility is given for many of the operators.\n\n+ INTERCAL operators\n! Operator\n! INTERCAL-72 characters\n! C-INTERCAL characters\n! CLC-INTERCAL characters\n\nContrary to most other languages, AND, OR, and XOR are unary operators, which work on consecutive bits of their argument; the most significant bit of the result is the operator applied to the least significant and most significant bits of the input, the second-most-significant bit of the result is the operator applied to the most and second-most significant bits, the third-most-significant bit of the result is the operator applied to the second-most and third-most bits, and so on. The operator is placed between the punctuation mark specifying a variable name or constant and the number that specifies which variable it is, or just inside grouping marks (i.e. one character later than it would be in programming languages like C.) SELECT and INTERLEAVE (which is also known as MINGLE) are infix binary operators; SELECT takes the bits of its first operand that correspond to \"1\" bits of its second operand and removes the bits that correspond to \"0\" bits, shifting towards the least significant bit and padding with zeroes (so 51 (110011 in binary) SELECT 21 (10101 in binary) is 5 (101 in binary)); MINGLE alternates bits from its first and second operands (in such a way that the least significant bit of its second operand is the least significant bit of the result). There is no operator precedence; grouping marks must be used to disambiguate the precedence where it would otherwise be ambiguous (the grouping marks available are codice_36 (\"spark\"), which matches another spark, and codice_37 (\"rabbit ears\"), which matches another rabbit ears; the programmer is responsible for using these in such a way that they make the expression unambiguous).\n\nINTERCAL statements all start with a \"statement identifier\"; in INTERCAL-72, this can be codice_38, codice_39, or codice_40, all of which mean the same to the program (but using one of these too heavily causes the program to be rejected, an undocumented feature in INTERCAL-72 that was mentioned in the C-INTERCAL manual), or an inverted form (with codice_41 or codice_42 appended to the identifier). Backtracking INTERCAL, a modern variant, also allows variants using codice_43 (possibly combined with PLEASE or DO) as a statement identifier, which introduces a choice-point. Before the identifier, an optional line number (an integer enclosed in parentheses) can be given; after the identifier, a percent chance of the line executing can be given in the format codice_44, which defaults to 100%.\n\nIn INTERCAL-72, the main control structures are NEXT, RESUME, and FORGET. codice_45 branches to the line specified, remembering the next line that would be executed if it weren't for the NEXT on a call stack (other identifiers than DO can be used on any statement, DO is given as an example); codice_46 removes \"expression\" entries from the top of the call stack (this is useful to avoid the error that otherwise happens when there are more than 80 entries), and codice_47 removes \"expression\" entries from the call stack and jumps to the last line remembered.\n\nC-INTERCAL also provides the COME FROM instruction, written codice_48; CLC-INTERCAL and the most recent C-INTERCAL versions also provide computed COME FROM (codice_49 and NEXT FROM, which is like COME FROM but also saves a return address on the NEXT STACK.\n\nAlternative ways to affect program flow, originally available in INTERCAL-72, are to use the IGNORE and REMEMBER instructions on variables (which cause writes to the variable to be silently ignored and to take effect again, so that instructions can be disabled by causing them to have no effect), and the ABSTAIN and REINSTATE instructions on lines or on types of statement, causing the lines to have no effect or to have an effect again respectively.\n\nThe traditional \"Hello, world!\" program demonstrates how different INTERCAL is from standard programming languages. In C, it could read as follows:\n\nThe equivalent program in C-INTERCAL is longer and harder to read:\n\nThe original Woods–Lyon INTERCAL was very limited in its input/output capabilities: the only acceptable input were numbers with the digits spelled out, and the only output was an extended version of Roman numerals.\n\nThe C-INTERCAL reimplementation, being available on the Internet, has made the language more popular with devotees of esoteric programming languages. The C-INTERCAL dialect has a few differences from original INTERCAL and introduced a few new features, such as a COME FROM statement and a means of doing text I/O based on the Turing Text Model.\n\nThe authors of C-INTERCAL also created the TriINTERCAL variant, based on the Ternary numeral system and generalizing INTERCAL's set of operators.\n\nA more recent variant is Threaded Intercal, which extends the functionality of COME FROM to support multithreading.\nIn early 2017 a .NET Implementation targeting the .NET Framework appeared on GitHub. This implementation supports the creation of standalone binary libraries and interop with other programming languages. \n\nIn the article \"A Box, Darkly: Obfuscation, Weird Languages, and Code Aesthetics\", INTERCAL is described under the heading \"Abandon all sanity, ye who enter here: INTERCAL\". The compiler and commenting strategy are among the \"weird\" features described:\n\nIn \"Technomasochism\", Lev Bratishenko characterizes the INTERCAL compiler as a dominatrix:\n\nBULLET::::- Official website of C-INTERCAL\nBULLET::::- INTERCAL Resources on the Web, including several implementations\nBULLET::::- Computerworld Interview with Don Woods on INTERCAL\nBULLET::::- Paper on Abstraction and Modularity in INTERCAL\n"}
{"id": "15076", "url": "https://en.wikipedia.org/wiki?curid=15076", "title": "International Data Encryption Algorithm", "text": "International Data Encryption Algorithm\n\nIn cryptography, the International Data Encryption Algorithm (IDEA), originally called Improved Proposed Encryption Standard (IPES), is a symmetric-key block cipher designed by James Massey of ETH Zurich and Xuejia Lai and was first described in 1991. The algorithm was intended as a replacement for the Data Encryption Standard (DES). IDEA is a minor revision of an earlier cipher Proposed Encryption Standard (PES).\n\nThe cipher was designed under a research contract with the Hasler Foundation, which became part of Ascom-Tech AG. The cipher was patented in a number of countries but was freely available for non-commercial use. The name \"IDEA\" is also a trademark. The last patents expired in 2012, and IDEA is now patent-free and thus completely free for all uses.\n\nIDEA was used in Pretty Good Privacy (PGP) v2.0 and was incorporated after the original cipher used in v1.0, BassOmatic, was found to be insecure. IDEA is an optional algorithm in the OpenPGP standard.\n\nIDEA operates on 64-bit blocks using a 128-bit key and consists of a series of 8 identical transformations (a \"round\", see the illustration) and an output transformation (the \"half-round\"). The processes for encryption and decryption are similar. IDEA derives much of its security by interleaving operations from different groups — modular addition and multiplication, and bitwise eXclusive OR (XOR) — which are algebraically \"incompatible\" in some sense. In more detail, these operators, which all deal with 16-bit quantities, are:\nBULLET::::- Bitwise XOR (exclusive OR) (denoted with a blue circled plus ).\nBULLET::::- Addition modulo 2 (denoted with a green boxed plus ).\nBULLET::::- Multiplication modulo 2 + 1, where the all-zero word (0x0000) in inputs is interpreted as 2, and 2 in output is interpreted as the all-zero word (0x0000) (denoted by a red circled dot ).\n\nAfter the 8 rounds comes a final “half-round”, the output transformation illustrated below (the swap of the middle two values cancels out the swap at the end of the last round, so that there is no net swap):\n\nThe overall structure of IDEA follows the Lai–Massey scheme. XOR is used for both subtraction and addition. IDEA uses a key-dependent half-round function. To work with 16-bit words (meaning 4 inputs instead of 2 for the 64-bit block size), IDEA uses the Lai–Massey scheme twice in parallel, with the two parallel round functions being interwoven with each other. To ensure sufficient diffusion, two of the sub-blocks are swapped after each round.\n\nEach round uses 6 16-bit sub-keys, while the half-round uses 4, a total of 52 for 8.5 rounds. The first 8 sub-keys are extracted directly from the key, with K1 from the first round being the lower 16 bits; further groups of 8 keys are created by rotating the main key left 25 bits between each group of 8. This means that it is rotated less than once per round, on average, for a total of 6 rotations.\n\nDecryption works like encryption, but the order of the round keys is inverted, and the subkeys for the odd rounds are inversed. For instance, the values of subkeys K1–K4 are replaced by the inverse of K49–K52 for the respective group operation, K5 and K6 of each group should be replaced by K47 and K48 for decryption.\n\nThe designers analysed IDEA to measure its strength against differential cryptanalysis and concluded that it is immune under certain assumptions. No successful linear or algebraic weaknesses have been reported. , the best attack applied to all keys could break IDEA reduced to 6 rounds (the full IDEA cipher uses 8.5 rounds). Note that a \"break\" is any attack that requires less than 2 operations; the 6-round attack requires 2 known plaintexts and 2 operations.\n\nBruce Schneier thought highly of IDEA in 1996, writing: \"In my opinion, it is the best and most secure block algorithm available to the public at this time.\" (\"Applied Cryptography\", 2nd ed.) However, by 1999 he was no longer recommending IDEA due to the availability of faster algorithms, some progress in its cryptanalysis, and the issue of patents.\n\nIn 2011 full 8.5-round IDEA was broken using a meet-in-the-middle attack. Independently in 2012, full 8.5-round IDEA was broken using a narrow-bicliques attack, with a reduction of cryptographic strength of about 2 bits, similar to the effect of the previous bicliques attack on AES; however, this attack does not threaten the security of IDEA in practice.\n\nThe very simple key schedule makes IDEA subject to a class of weak keys; some keys containing a large number of 0 bits produce weak encryption. These are of little concern in practice, being sufficiently rare that they are unnecessary to avoid explicitly when generating keys randomly. A simple fix was proposed: XORing each subkey with a 16-bit constant, such as 0x0DAE.\n\nLarger classes of weak keys were found in 2002.\n\nThis is still of negligible probability to be a concern to a randomly chosen key, and some of the problems are fixed by the constant XOR proposed earlier, but the paper is not certain if all of them are. A more comprehensive redesign of the IDEA key schedule may be desirable.\n\nA patent application for IDEA was first filed in Switzerland (CH A 1690/90) on May 18, 1990, then an international patent application was filed under the Patent Cooperation Treaty on May 16, 1991. Patents were eventually granted in Austria, France, Germany, Italy, the Netherlands, Spain, Sweden, Switzerland, the United Kingdom, (, filed May 16, 1991, issued June 22, 1994 and expired May 16, 2011), the United States (, issued May 25, 1993 and expired January 7, 2012) and Japan (JP 3225440) (expired May 16, 2011).\n\nMediaCrypt AG is now offering a successor to IDEA and focuses on its new cipher (official release on May 2005) IDEA NXT, which was previously called FOX.\n\nBULLET::::- Hüseyin Demirci, Erkan Türe, Ali Aydin Selçuk, A New Meet in the Middle Attack on The IDEA Block Cipher, 10th Annual Workshop on Selected Areas in Cryptography, 2004.\nBULLET::::- Xuejia Lai and James L. Massey, A Proposal for a New Block Encryption Standard, EUROCRYPT 1990, pp. 389–404\nBULLET::::- Xuejia Lai and James L. Massey and S. Murphy, Markov ciphers and differential cryptanalysis, \"Advances in Cryptology — Eurocrypt '91\", Springer-Verlag (1992), pp. 17–38.\n\nBULLET::::- RSA FAQ on Block Ciphers\nBULLET::::- SCAN entry for IDEA\nBULLET::::- IDEA in 448 bytes of 80x86\nBULLET::::- IDEA Applet\nBULLET::::- Java source code\n"}
{"id": "15077", "url": "https://en.wikipedia.org/wiki?curid=15077", "title": "Indoor rower", "text": "Indoor rower\n\nAn indoor rower, or rowing machine, is a machine used to simulate the action of watercraft rowing for the purpose of exercise or training for rowing. Indoor rowing has become established as a sport in its own right. The term \"indoor rower\" also refers to a participant in this sport.\n\nModern indoor rowers are often known as ergometers (colloquially erg or ergo), an ergometer being a device which measures the amount of work performed. The indoor rower is calibrated to measure the amount of energy the rower is using through their use of the equipment. Typically the display of the ergometer (e.g. on a concept2) will show the time it takes to row 500m at each strokes power. This is known as the split rate, or split. The decision to show the time to complete 500m is due to the standard rowing distance is 2000m, which is 4 stretches of 500m. \n\nChabrias, an Athenian admiral of the 4th century BC, introduced the first rowing machines as supplemental military training devices. \"To train inexperienced oarsmen, Chabrias built wooden rowing frames on shore where beginners could learn technique and timing before they went on board ship.\"\n\nEarly rowing machines are known to have existed from the mid-1800s, a US patent being issued to W.B. Curtis in 1872 for a particular hydraulic based damper design. Machines using linear pneumatic resistance were common around 1900—one of the most popular was the Narragansett hydraulic rower, manufactured in Rhode Island from around 1900–1960. However they did not simulate actual rowing very accurately nor measure power output.\n\nIn the 1950s and 1960s, coaches in many countries began using specially made rowing machines for training and improved power measurement. One original design incorporated a large, heavy, solid iron flywheel with a mechanical friction brake, developed by John Harrison of Leichhardt Rowing Club in Sydney, later to become a professor of mechanical engineering at the University of New South Wales. Harrison, a dual Australian champion beach sprinter who went on to row in the coxless four at the 1956 Melbourne Olympics, had been introduced to rowing after a chance meeting with one of the fathers of modern athletic physiological training and testing, and the coach of the Leichhardt \"Guinea Pigs\", Professor Frank Cotton. Cotton had produced a rudimentary friction-based machine for evaluating potential rowers by exhausting them, without any pretence of accurately measuring power output. Harrison realised the importance of using a small braking area with a non-absorbent braking material, combined with a large flywheel. The advantage of this design (produced by Ted Curtain Engineering, Curtain being a fellow Guinea Pig) was the virtual elimination of factors able to interfere with accurate results—for instance ambient humidity or temperature. The Harrison-Cotton machine represents the very first piece of equipment able to accurately quantify human power output; power calculation within an accuracy range as achieved by his machine of less than 1% remains an impressive result today. The friction brake was adjusted according to a rower's weight to give an accurate appraisal of boat-moving ability (drag on a boat is proportional to weight). Inferior copies of Harrison's machine were produced in several countries utilising a smaller flywheel and leather straps—unfortunately the leather straps were sensitive to humidity, and the relatively large braking area made results far less accurate than Harrison's machine. The weight correction factor tended to make them unpopular among rowers of the time. Harrison, arguably the father of modern athletic power evaluation, died in February 2012.\nIn the 1970s, the Gjessing-Nilson ergometer from Norway used a friction brake mechanism with industrial strapping applied over the broad rim of the flywheel. Weights hanging from the strap ensured that an adjustable and predictable friction could be calculated. The cord from the handle mechanism ran over a helical pulley with varying radius, thereby adjusting the gearing and speed of the handle in a similar way to the changing mechanical gearing of the oar through the stroke, derived from changes in oar angle and other factors. This machine was for many years the internationally accepted standard for measurement.\n\nThe first air resistance ergometers were introduced around 1980 by Repco.\n\nIn 1981, Peter and Richard Dreissigacker, and Jonathan Williams, filed for U.S. patent protection, as joint inventors of a \"Stationary Rowing Unit\". The patent was granted in 1983 (US 4396188A). The first commercial embodiment of the Concept2 \"rowing ergometer\" (as it came to be known) was the Model A, a fixed-frame sliding-seat design using a bicycle wheel with fins attached for air resistance. The Model B, introduced in 1986, introduced a solid cast flywheel (now enclosed by a cage) and the first digital performance monitor, which proved revolutionary. This machine's capability of accurate calibration combined with easy transportability spawned the sport of competitive indoor rowing, and revolutionised training and selection procedures for watercraft rowing. Later models were the C (1993) and D (2003).\n\nIn 1995, Casper Rekers, a Dutch engineer, was granted a U.S. patent for a (US 5382210A) \"Dynamically Balanced Rowing Simulator\". This device differed from the prior art in that the flywheel and footrests are fixed to a carriage, the carriage being free to slide fore and aft on a rail or rails integral to the frame. The seat is also free to slide fore and aft on a rail or rails integral to the frame. From the patent Abstract: \"During exercise, the independent seat and energy dissipating unit move apart and then together in a co-ordinated manner as a function of the stroke cycle of the oarsman.\"\n\nAll rowing-machine designs consist of an energy damper or braking mechanism connected to a chain, strap, belt and/or handle. Footrests are attached to the same mounting as the energy damper. Most include a rail which either the seat or the mechanism slide upon. Different machines have a variety of layouts and damping mechanisms, each of which have certain advantages and disadvantages.\n\nCurrently available ergometer (flywheel-type) rowing machines use a spring or elastic cord to take up the pull chain/strap and return the handle. Advances in elastic cord and spring technology have contributed to the longevity and reliability of this strategy, but it still has disadvantages. With time and usage, an elastic element loses its strength and elasticity. Occasionally it will require adjustment, and eventually it will no longer take up the chain with sufficient vigour, and will need to be replaced. The resilience of an elastic cord is also directly proportional to temperature. In an unheated space in a cold climate, an elastic cord equipped rowing ergometer is unusable because the chain take-up is too sluggish. Thus, as the result of several factors, the force required to stretch the elastic cord is a variable, not a constant. This is of little consequence if the exercise device is used for general fitness, but it is an unacknowledged problem, the \"dirty little secret\", of indoor rowing competitions. The electronic monitor only measures the user input to the flywheel. It does not measure the energy expenditure to stretch the elastic cord. A claim of a \"level playing field\" cannot be made when a resistance variable exists (that of the elastic cord) which is not measured or monitored in any way (see more on this in \"Competitions\" section).\n\nIn the patent record, means are disclosed whereby the chain/cable take-up and handle return are accomplished without the use of a spring or elastic cord, thereby avoiding the stated disadvantages and defects of this broadly used method. One example is the Gjessing-Nilson device described above. Partially discernable in the thumbnail photo, it utilizes a cable wrapped around a helical pulley on the flywheel shaft, the ends of this cable being connected to opposite ends of a long pole to which a handle is fixed. The obvious disadvantage of this system is the forward space requirement to accommodate the extension of the handle pole at the \"catch\" portion of the stroke. The advantage is that, except for small transmission losses, all of the user's energy output is imparted to the flywheel, where it can be accurately measured, not split between the flywheel and an elastic cord of variable, unmeasured resistance. If a similar system were installed on all rowing ergometers used in indoor rowing competitions, consistency between machines would be guaranteed because the variability factor of elastic cord resistance would be eliminated, and this would therefore ensure that the monitor displayed actual user energy input.\n\nIn a 1988 US patent (US 4772013A), Elliot Tarlow discloses another non-elastic chain/cable take-up and handle return strategy. Described and depicted is a continuous chain/cable loop that passes around the flywheel sprocket and around and between fixed pulleys and sprockets positioned fore and aft on the device. The handle is secured in the middle of the exposed upper horizontal section of the chain/cable loop. Although somewhat lacking in aesthetics, the Tarlow device does eliminate the stated disadvantages and defects of the ubiquitous elastic cord handle return. Tarlow further argues that the disclosed method provides an improved replication of rowing because in actual rowing the rower is not assisted by the contraction of a spring or elastic cord during the \"recovery\" portion of the stroke. The rower must push the oar handle forward against wind and oarlock resistance in preparation for the next stroke. Tarlow asserts that the invention replicates that resistance.\n\nA third non-elastic handle return strategy is disclosed in US patent, \"Gravity Return Rowing Exercise Device\" (US9878200 B2, 2018) granted to Robert Edmondson. As stated in the patent document, the utilization of gravity (i.e.: a weight) to take up the chain and return the handle eliminates the inevitable variability of handle return force associated with an elastic cord system and thereby ensures consistency between machines.\n\nMachines with a digital display calculate the user's power by measuring the speed of the flywheel during the stroke and then recording the rate at which it decelerates during the recovery. Using this and the known moment of inertia of the flywheel, the computer is able to calculate speed, power, distance and energy usage. Some ergometers can be connected to a personal computer using software, and data on individual exercise sessions can be collected and analysed. In addition, some software packages allows users to connect multiple ergometers either directly or over the internet for virtual races and workouts.\n\nAt the current state of the art, indoor rowers which utilize flywheel resistance can be categorized into two motion types. In both types, the rowing movement of the user causes the footrests and the seat to move further and closer apart in co-ordination with the user's stroke. The difference between the two types is in the movement, or absence of movement, of the footrests relative to ground.\n\nThe first type is characterized by the Dreissigacker/Williams device (referenced above). With this type the flywheel and footrests are fixed to a stationary frame, and the seat is free to slide fore and aft on a rail or rails integral to the stationary frame. Therefore, during use, the seat moves relative to the footrests and also relative to ground, while the flywheel and footrests remain stationary relative to ground.\n\nThe second type is characterized by the Rekers device (referenced above). With this type, both the seat and the footrests are free to slide fore and aft on a rail or rails integral to a stationary frame. Therefore, during use, the seat and the footrests move relative to each other, and both also move relative to ground.\n\nPiston resistance comes from hydraulic cylinders that are attached to the handles of the rowing machine. The length of the rower handles on this class of rower is typically adjustable, however, during the row the handle length is fixed which in turn fixes the trajectory that the hands must take on the stroke and return, thus making the stroke less accurate than is possible on the other types of resistance models where it is possible to emulate the difference in hand height on the stroke and return. Furthermore, many models in this class have a fixed seat position that eliminates the leg drive which is the foundation of competitive on water rowing technique. Because of the compact size of the pistons and mechanical simplicity of design, these models are typically not as large or as expensive as the others types.\n\nBraked flywheel resistance models comprise magnetic, air and water resistance rowers. These machines are mechanically similar since all three types use a handle connected to a flywheel by rope, chain, or strap to provide resistance to the user – the types differ only in braking mechanism. Because the handle is attached to the resistance source by rope or similarly flexible media, the trajectory of the hands in the vertical plane is free making it possible for the rower to emulate the hand height difference between the stroke and the return. Most of these models have the characteristic sliding seat typical of competitive on-the-water boats.\n\nMagnetic resistance models control resistance by means of permanent magnets or electromagnets. A rotary plate, made of non-magnetic, electrical conducting material such as aluminum or copper, and either integral with, or independent of the flywheel, cuts through the magnetic field of the permanent magnet or the electromagnet, resulting in induced eddy currents which generate a retarding force that opposes the motion of the rotary plate. Resistance is adjusted with the permanent magnet system by changing the position of the permanent magnet relative to the rotary plate. Resistance is adjusted with the electromagnetic system by varying the strength of the electromagnetic field through which the rotary plate moves. The magnetic braking system is quieter than the other braked flywheel types and energy can be accurately measured on this type of rower. The drawback of this type of resistance mechanism is that the resistance is constant for any given setting. Rowers using air or water resistance more accurately simulate actual rowing, where the resistance increases the harder the handle is pulled. Some rowing machines incorporate both air and magnetic resistance.\n\nAir resistance models use vanes on the flywheel to provide the flywheel braking needed to generate resistance. As the flywheel is spun faster, the air resistance increases. An adjustable vent can be used to control the volume of air moved by the vanes of the rotating flywheel, therefore a larger vent opening results in a higher resistance, and a smaller vent opening results in a lower resistance. The energy dissipated can be accurately calculated given the known moment of inertia of the flywheel and a tachometer to measure the deceleration of the flywheel. Air resistance rowing machines are most often used by sport rowers (particularly during the off season and inclement weather) and competitive indoor rowers. \n\nWater resistance models consist of a paddle revolving in an enclosed tank of water. The mass and drag of the moving water creates the resistance. Proponents claim that this approach results in a more realistic action than possible with air or magnetic type machines. \"WaterRower\" was the first company to manufacturer this type of rowing machine. The company was formed in the 1980s by John Duke, a US National Team rower, and inventor of the device (1989 US Patent ). At that time, in the patent record, there were a few prior art fluid resistance rowing machines, but they lacked the simplicity and elegance of the Duke design. From the 1989 patent Abstract: \"... rowing machine features a hollow container that holds a supply of water. Pulling on a drive cord during a pulling segment of a stroke rotates a paddle or like mechanism within the container to provide a momentum effect.\"\n\nIndoor rowing primarily works the cardiovascular systems with typical workouts consisting of steady pieces of 20–40 minutes, although the standard trial distance for record attempts is 2000 m, which can take from five and a half minutes (best elite rowers) to nine minutes or more. Like other forms of cardio focused exercise, interval training is also commonly used in indoor rowing. While cardio-focused, rowing also stresses many muscle groups throughout the body anaerobically, thus rowing is often referred to as a strength-endurance sport.\n\nThe standard measurement of speed on an ergometer is generally known as the \"split\", or the amount of time in minutes and seconds required to travel at the current pace — a split of 2:00 represents a speed of two minutes per 500 metres, or about .\n\nAlthough ergometer tests are used by rowing coaches to evaluate rowers and are part of athlete selection for many senior and junior national rowing teams, \"the data suggest that physiological and performance tests performed on a rowing ergometer are not good indicators of on water performance\".\n\nRowing technique on the erg broadly follows the same pattern as that of a normal rowing stroke on water, but with minor modifications: it is not necessary to \"tap down\" at the finish, since there are no blades to extract from water; but many who also row on water do this anyway. Also, the rigid, single-piece handle enables neither a sweep nor a sculling stroke. The oar handle during a sweep stroke follows a long arc, while the oar handles during a sculling stroke follow two arcs. The standard handle does neither. But regardless of this, to reduce the chance of injury, an exercise machine should enable a bio-mechanically correct movement of the user. The handle is the interface between the human and the machine, and should adapt to the natural movement of the user, not the user to the machine, as is now the case. During competitions an exaggerated finish is often used, whereby the hands are pulled further up the chest than would be possible on the water, resulting in a steep angulation of the wrists - but even with a normal stroke, stop-action images show wrist angulation at the finish, evidence that the standard rigid, single-piece handle does not allow the user to maintain a bio-mechanically correct alignment of hands, wrists, and forearms in the direction of applied force. On the Concept 2 website \"Forum\", many regular users of the indoor rower have complained of chronic wrist pain. Some have rigged handgrips with flexible straps to enable their hands, wrists, and forearms to maintain proper alignment, and thereby reduce the possibility of repetitive strain injury. Rowing machine manufacturers have ignored this problem.\n\nRowing on an ergometer requires four basic phases to complete one stroke; the catch, the drive, the finish and the recovery. The catch is the initial part of the stroke. The drive is where the power from the rower is generated while the finish is the final part of the stroke. Then, the recovery is the initial phase to begin taking a new stroke. The phases repeat until a time duration or a distance is completed.\n\nKnees are bent with the shins in a vertical position. The back should be roughly parallel to the thigh without hyperflexion (leaning forward too far). The arms and shoulders should be extended forward and relaxed. The arms should be level.\n\nThe drive is initiated by the extension of the legs; the body remains in the catch posture at this point of the drive. As the legs continue to full extension, the rower engages the core to begin the motion of the body levering backward, adding to the work of the legs. When the legs are flat, the rower begins to pull the handle toward the chest with their arms while keeping their arms straight and parallel to the floor.\n\nThe legs are at full extension and flat. The shoulders are slightly behind the pelvis, and the arms are in full contraction with the elbows bent and hands against the chest below the nipples. The back of the rower is still maintained in an upright posture and wrists should be flat.\n\nThe recovery is a slow slide back to the initial part of the stroke, it gives the rower time to recover from the previous stroke. During the recovery the actions are in reverse order of the drive. The arms are fully extended so that they are straight. The torso is engaged to move forward back over the pelvis. Weight transfers from the back of the seat to the front of the seat at this time. When the hands come over the knees, the legs contract back towards the foot stretcher. Slowly the back becomes more parallel to the thighs until the recovery becomes the catch.\n\nThe first indoor rowing competition was held in Cambridge, MA in February 1982 with participation of 96 on-water rowers who called themselves the \"Charles River Association of Sculling Has-Beens\". Thus the acronym, \"CRASH-B\". A large number of indoor rowing competitions are now held worldwide, including the indoor rowing world championships (still known as CRASH-B Sprints) held in Boston, Massachusetts, United States in February and the British Indoor Rowing Championships held in Birmingham, England in November, or in more recent years the Lee Valley VeloPark London in December; both are rowed on Concept2s. The core event for most competitions is the individual 2000-m; less common are the mile (e.g., Evesham), the 2500 meter (e.g., Basingstoke—also the original distance of the CRASH-B Sprints). Many competitions also include a sprint event (100–500m) and sometimes team relay events.\n\nMost competitions are organized into categories based on sex, age, and weight class. While the fastest times are generally achieved by rowers between 20 and 40 years old, teenagers and rowers over 90 are common at competitions. There is a nexus between performance on-water and performance on the ergometer, with open events at the World Championships often being dominated by elite on-water rowers. Former men's Olympic single scull champions Pertti Karppinen and Rob Waddell and five-time gold medalist Sir Steven Redgrave have all won world championships or set world records in indoor rowing. The British Graham Benton and the Italian Emanuele Romoli are two of the main \"non-rower\" that won several indoor rowing competitions.\n\nIn addition to live venue competitions, many erg racers compete by internet, either offline by posting scores to challenges, or live online races facilitated by computer connection. Online Challenges sponsored by Concept2 include the annual ultra-rowing challenge, the Virtual Team Challenge.\n\nBULLET::::- Rowbike\nBULLET::::- Rowing\nBULLET::::- Rowing tank\n"}
{"id": "15078", "url": "https://en.wikipedia.org/wiki?curid=15078", "title": "Internetwork Packet Exchange", "text": "Internetwork Packet Exchange\n\nInternetwork Packet Exchange (IPX) is the network layer protocol in the IPX/SPX protocol suite. IPX is derived from Xerox Network Systems' IDP. It may act as a transport layer protocol as well.\n\nThe IPX/SPX protocol suite was very popular through the late 1980s into the mid-1990s because it was used by the Novell NetWare network operating system. Because of Novell NetWare popularity, the IPX became a prominent internetworking protocol.\n\nA big advantage of IPX was a small memory footprint of the IPX driver, which was vital for DOS and Windows up to the version Windows 95 because of limited size of the conventional memory. Another IPX advantage is an easy configuration of the client computers. However, IPX does not scale well for large networks such as the Internet, and as such, IPX usage decreased as the boom of the Internet made TCP/IP nearly universal. Computers and networks can run multiple network protocols, so almost all IPX sites will be running TCP/IP as well to allow Internet connectivity. It is also possible to run later Novell products without IPX, with the beginning of full support for both IPX and TCP/IP by NetWare version 5 in late 1998.\n\nA big advantage of IPX protocol is its little or no need for configuration. In the time when protocols for dynamic host configuration did not exist and the BOOTP protocol for centralized assigning of addresses was not common, the IPX network could be configured almost automatically. A client computer uses the MAC address of its network card as the node address and learns what it needs to know about the network topology from the servers or routers – routes are propagated by Routing Information Protocol, services by Service Advertising Protocol.\n\nA small IPX network administrator had to care only\nBULLET::::- to assign all servers in the same network the same network number,\nBULLET::::- to assign different network numbers to different frame formats in the same network,\nBULLET::::- to assign different network numbers to different interfaces of servers with multiple network cards (Novell NetWare server with multiple network cards worked automatically as a router),\nBULLET::::- to assign different network numbers to servers in different interconnected networks,\nBULLET::::- to start router process on nodes with multiple network cards in more complex networks.\n\nEach IPX packet begins with a header with the following structure:\n\n! Octets !! Field\n\nThe Packet Type values are:\n\n! Value !! Meaning/Protocol\n\nAn IPX address has the following structure:\n\n! Octets !! Field\n\nThe network number allows to address (and communicate with) the IPX nodes which do not belong to the same network or \"cabling system\". The cabling system is a network in which a data link layer protocol can be used for communication. To allow communication between different networks, they must be connected with IPX routers. A set of interconnected networks is called an internetwork. Any Novell NetWare server may serve as an IPX router. Novell also supplied stand-alone routers. Multiprotocol routers of other vendors often support IPX routing. Using different frame formats in one cabling system is possible, but it works similarly as if separate cabling systems were used (i.e. different network numbers must be used for different frame formats even in the same cabling system and a router must be used to allow communication between nodes using different frame formats in the same cabling system).\n\nBULLET::::- Logical networks are assigned a unique 32-bit address in the range 0x1 to 0xFFFFFFFE (hexadecimal).\nBULLET::::- Hosts have a 48-bit node address, which is by default set to the last 4 bytes of the network interface card MAC address. The node address is appended to the network number to create a unique network address for the host on the network.\nBULLET::::- Network number 00:00:00:00 means current network.\nBULLET::::- Broadcast network number is FF:FF:FF:FF.\n\nThe node number is used to address an individual computer (or more exactly, a network interface) in the network. Client stations use its network interface card MAC address as the node number.\n\nThe value FF:FF:FF:FF:FF:FF may be used as a node number in a destination address to broadcast a packet to \"all nodes in the current network\".\n\nThe socket number serves to select a process or application in the destination node.\nThe presence of a socket number in the IPX address allows the IPX to act as a transport layer protocol, comparable with the User Datagram Protocol (UDP) in the Internet protocol suite.\n\n! Socket number !! Protocol\n\nThe IPX network number is conceptually identical to the network part of the IP address (the parts with netmask bits set to 1); the node number has the same meaning as the bits of IP address with netmask bits set to 0. The difference is that the boundary between network and node part of address in IP is variable, while in IPX it is fixed. As the node address is usually identical to the MAC address of the network adapter, the Address Resolution Protocol is not needed in IPX.\n\nFor routing, the entries in the IPX routing table are similar to IP routing tables; routing is done by network address, and for each network address a network:node of the next router is specified in a similar fashion an IP address/netmask is specified in IP routing tables.\n\nThere are three routing protocols available for IPX networks. In early IPX networks, a version of Routing Information Protocol (RIP) was the only available protocol to exchange routing information. Unlike RIP for IP, it uses delay time as the main metric, retaining the hop count as a secondary metric. Since NetWare 3, the NetWare Link Services Protocol (NLSP) based on IS-IS is available, which is more suitable for larger networks. Cisco routers implement an IPX version of EIGRP protocol as well.\n\nIPX can be transmitted over Ethernet using one of the following 4 frame formats or encapsulation types:\n\nBULLET::::- 802.3 (raw) encapsulation comprises an IEEE 802.3 frame header (destination MAC, source MAC, length) immediately followed by IPX data. It is used in legacy systems, and can be distinguished by the first two bytes of the IPX header always containing a value of 0xFFFF, which cannot be interpreted as valid LLC Destination and Source Service Access Points in this location of the frame.\nBULLET::::- 802.2 (LLC or Novell) comprises an IEEE 802.3 frame header (destination MAC, source MAC, length) followed by an LLC header (DSAP 0xE0, SSAP 0xE0, control 0x03) followed by IPX data. The 0xE0 fields of the LLC header indicate \"NetWare\".\nBULLET::::- 802.2 (SNAP) comprises an IEEE 802.3 frame header, an LLC header (DSAP 0xAA, SSAP 0xAA, control 0x03), a SNAP header (OUI 0x000000, type 0x8137), and IPX data. The 0xAA fields of the LLC header indicate \"SNAP\", and the OUI 0x000000 in the SNAP header indicates an encapsulated EtherType.\nBULLET::::- Ethernet II encapsulation comprises an Ethernet II frame header (destination MAC, source MAC, EtherType 0x8137) followed by IPX data.\n\nIn non-Ethernet networks only 802.2 and SNAP frame types are available.\n\nBULLET::::- RFC 1132 - A Standard for the Transmission of 802.2 Packets over IPX Networks\nBULLET::::- Ethernet Frame Types: Don Provan's Definitive Answer\n"}
{"id": "15079", "url": "https://en.wikipedia.org/wiki?curid=15079", "title": "International human rights instruments", "text": "International human rights instruments\n\nInternational human rights instruments are the treaties and other international texts that serve as legal sources for international human rights law and the protection of human rights in general. There are many varying types, but most can be classified into two broad categories: \"declarations\", adopted by bodies such as the United Nations General Assembly, which are by nature declaratory, so not legally-binding although they may be politically authoritative and very well-respected soft law;, and often express guiding principles; and \"conventions\" that are multi-party treaties that are designed to become legally binding, usually include prescriptive and very specific language, and usually are concluded by a long procedure that frequently requires ratification by each states' legislature. Lesser known are some \"recommendations\" which are similar to conventions in being multilaterally agreed, yet cannot be ratified, and serve to set common standards. There may also be administrative guidelines that are agreed multilaterally by states, as well as the statutes of tribunals or other institutions. A specific prescription or principle from any of these various international instruments can, over time, attain the status of customary international law whether it is specifically accepted by a state or not, just because it is well-recognized and followed over a sufficiently long time.\n\nInternational human rights instruments can be divided further into \"global instruments\", to which any state in the world can be a party, and \"regional instruments\", which are restricted to states in a particular region of the world.\n\nMost conventions and recommendations (but few declarations) establish mechanisms for monitoring and establish bodies to oversee their implementation. In some cases these bodies that may have relatively little political authority or legal means, and may be ignored by member states; in other cases these mechanisms have bodies with great political authority and their decisions are almost always implemented. A good example of the latter is the European Court of Human Rights.\n\nMonitoring mechanisms also vary as to the degree of individual access to expose cases of abuse and plea for remedies. Under some conventions or recommendations – e.g. the European Convention on Human Rights – individuals or states are permitted, subject to certain conditions, to take individual cases to a full-fledged tribunal at international level. Sometimes, this can be done in national courts because of universal jurisdiction.\n\nThe Universal Declaration of Human Rights, the International Covenant on Civil and Political Rights, and the International Covenant on Economic, Social and Cultural Rights together with other international human rights instruments are sometimes referred to as the \"international bill of rights\". International human rights instruments are identified by the OHCHR and most are referenced on the OHCHR website.\n\nBULLET::::- Declaration of the Rights of the Child 1923\nBULLET::::- Universal Declaration of Human Rights (UN, 1948)\nBULLET::::- Declaration on the Rights of Disabled Persons (UN, 1975)\nBULLET::::- Declaration on the Right to Development (UN, 1986)\nBULLET::::- Vienna Declaration and Programme of Action (World Conference on Human Rights, 1993)\nBULLET::::- Declaration of Human Duties and Responsibilities (UNESCO, 1998)\nBULLET::::- Universal Declaration on Cultural Diversity (UNESCO, 2001)\nBULLET::::- Declaration on the Rights of Indigenous Peoples (UN, 2007)\nBULLET::::- UN declaration on sexual orientation and gender identity (UN, 2008)\n\nBULLET::::- American Declaration of the Rights and Duties of Man (OAS, 1948)\n\nBULLET::::- ASEAN Human Rights Declaration (ASEAN, 2009)\n\nBULLET::::- Cairo Declaration of Human Rights in Islam (OIC,1990)\n\nAccording to OHCHR, there are 9 \"core\" international human rights instruments and several optional protocols. The core instruments are:\n\nBULLET::::- Convention on the Elimination of All Forms of Racial Discrimination (ICERD, 21 December 1965)\nBULLET::::- International Covenant on Civil and Political Rights (ICCPR, 16 December 1966)\nBULLET::::- International Covenant on Economic, Social, and Cultural Rights (ICESCR, 16 December 1966)\nBULLET::::- Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW, 18 December 1979)\nBULLET::::- Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (CAT, 10 December 1984)\nBULLET::::- Convention on the Rights of the Child (CRC, 20 November 1989)\nBULLET::::- International Convention on the Protection of the Rights of All Migrant Workers and Members of Their Families (ICMW, 18 December 1990)\nBULLET::::- International Convention for the Protection of All Persons from Enforced Disappearance (CPED, 20 December 2006)\nBULLET::::- Convention on the Rights of Persons with Disabilities (CRPD, 13 December 2006)\n\nSeveral more human rights instruments exist. A few examples:\n\nBULLET::::- International Convention on the Suppression and Punishment of the Crime of Apartheid (ICSPCA)\nBULLET::::- Convention Relating to the Status of Refugees and Protocol Relating to the Status of Refugees\nBULLET::::- Convention on the Reduction of Statelessness\nBULLET::::- Convention on the Prevention and Punishment of the Crime of Genocide\nBULLET::::- Indigenous and Tribal Peoples Convention, 1989 (ILO 169)\n\nBULLET::::- African Charter on Human and Peoples' Rights (June, 1981)\nBULLET::::- African Charter on the Rights and Welfare of the Child (1990)\nBULLET::::- Maputo Protocol (11 July 2003)\n\nBULLET::::- American Convention on Human Rights\nBULLET::::- Inter-American Convention to Prevent and Punish Torture\nBULLET::::- Inter-American Convention on Forced Disappearance of Persons\nBULLET::::- Inter-American Convention on the Prevention, Punishment, and Eradication of Violence against Women\nBULLET::::- Inter-American Convention on the Elimination of All Forms of Discrimination against Persons with Disabilities\n\nBULLET::::- Charter of Fundamental Rights of the European Union\nBULLET::::- Convention on Action against Trafficking in Human Beings\nBULLET::::- European Convention on Nationality\nBULLET::::- European Charter for Regional or Minority Languages (ECRML)\nBULLET::::- European Convention on Human Rights (ECHR)\nBULLET::::- European Convention for the Prevention of Torture and Inhuman or Degrading Treatment or Punishment (CPT)\nBULLET::::- European Social Charter (ESC), and Revised Social Charter\nBULLET::::- Framework Convention for the Protection of National Minorities (FCNM)\n\nBULLET::::- Arab Charter on Human Rights (ACHR) (22 May 2004)\n\nBULLET::::- Universal jurisdiction\nBULLET::::- Rule of Law in Armed Conflicts Project (RULAC)\nBULLET::::- International Criminal Court (established in 2002)\nBULLET::::- International human rights law\nBULLET::::- Human rights treaty bodies\nBULLET::::- List of human rights organizations\nBULLET::::- List of indigenous rights organizations\nBULLET::::- Rule of law\nBULLET::::- Rule According to Higher Law\n\nBULLET::::- International Human Rights Instruments - U.N. list\nBULLET::::- International Justice Resource Center News and resources for international human rights law\n"}
{"id": "15080", "url": "https://en.wikipedia.org/wiki?curid=15080", "title": "Indian removal", "text": "Indian removal\n\nIndian removal was a forced migration in the 19th century whereby Native Americans were forced by the United States government to leave their ancestral homelands in the eastern United States to lands west of the Mississippi River, specifically to a designated Indian Territory (roughly, modern Oklahoma). The Indian Removal Act, the key law that forced the removal of the Indians, was signed by Andrew Jackson in 1830. Jackson took a hard line on Indian removal, but the law was put into effect primarily under the Martin van Buren administration.\n\nIndian removal was a consequence of actions first by European settlers to North America in the colonial period, then by the United States government and its citizens until the mid-20th century. The policy traced its direct origins to the administration of James Monroe, though it addressed conflicts between European Americans and Native Americans that had been occurring since the 17th century, and were escalating into the early 19th century as white settlers were continually pushing westward.\n\nAmerican leaders in the Revolutionary and Early National era debated whether the American Indians should be treated officially as individuals or as nations in their own right. Some of these views are summarized below.\n\nIn a draft, \"Proposed Articles of Confederation\", presented to the Continental Congress on May 10, 1775, Benjamin Franklin called for a \"perpetual Alliance\" with the Indians for the nation about to take birth, especially with the Six Nations of the Iroquois Confederacy:\nIn his Notes on the State of Virginia (1785), Thomas Jefferson defended American Indian culture and marveled at how the tribes of Virginia \"never submitted themselves to any laws, any coercive power, any shadow of government\" due to their \"moral sense of right and wrong\". He would later write to the Marquis de Chastellux in 1785, \"I believe the Indian then to be in body and mind equal to the whiteman\". His desire, as interpreted by Francis Paul Prucha, was for the Native Americans to intermix with European Americans and to become one people. To achieve that end, Jefferson would, as president, offer U.S. citizenship to some Indian nations, and propose offering credit to them to facilitate their trade.\n\nPresident George Washington, in his address to the Seneca nation in 1790, describing the pre-Constitutional Indian land sale difficulties as \"evils\", asserted that the case was now entirely altered, and publicly pledged to uphold their \"just rights\". In March and April 1792, Washington met with 50 tribal chiefs in Philadelphia—including the Iroquois—to discuss closer friendship between them and the United States. Later that same year, in his Fourth Annual Message to Congress, Washington stressed the need for building peace, trust, and commerce with America's Indian neighbors:\n\nIn 1795, in his Seventh Annual Message to Congress, Washington intimated that if the U.S. government wanted peace with the Indians, then it must give peace to them, and that if the U.S. wanted raids by Indians to stop, then raids by American \"frontier inhabitants\" must also stop.\n\nThe Confederation Congress passed the Northwest Ordinance of 1787, which would serve broadly as a precedent for the manner in which the United States' territorial expansion would occur for years to come, calling for the protection of Indians' \"property, rights, and liberty\": The U.S. Constitution of 1787 (Article I, Section 8) makes Congress responsible for regulating commerce with the Indian tribes. In 1790, the new U.S. Congress passed the Indian Nonintercourse Act (renewed and amended in 1793, 1796, 1799, 1802, and 1834) to protect and codify the land rights of recognized tribes.\n\nAs president, Thomas Jefferson developed a far-reaching Indian policy that had two primary goals. First, the security of the new United States was paramount, so Jefferson wanted to assure that the Native nations were tightly bound to the United States, and not other foreign nations. Second, he wanted \"to civilize\" them into adopting an agricultural, rather than a hunter-gatherer lifestyle. These goals would be achieved through the development of trade and the signing of treaties.\n\nJefferson initially promoted an American policy that encouraged Native Americans to become assimilated, or \"civilized\". As president, Jefferson made sustained efforts to win the friendship and cooperation of many Native American tribes, repeatedly articulating his desire for a united nation of both whites and Indians, as in a letter to the Seneca spiritual leader, Handsome Lake, dated November 3, 1802:\n\nWhen a delegation from the Upper Towns of the Cherokee Nation lobbied Jefferson for the full and equal citizenship George Washington had promised to Indians living in American territory, his response indicated that he was willing to accommodate citizenship for those Indian nations that sought it. In his Eighth Annual Message to Congress on November 8, 1808, he presented to the nation a vision of white and Indian unity:\nAs some of Jefferson's other writings illustrate, however, he was ambivalent about Indian assimilation, even going so far as to use the words \"exterminate\" and \"extirpate\" regarding tribes that resisted American expansion and were willing to fight to defend their lands. Jefferson's intention was to change Indian lifestyles from hunter-gatherering to farming, largely through \"the decrease of game rendering their subsistence by hunting insufficient\". He expected that the switch to agriculture would make them dependent on white Americans for trade goods and therefore more likely to give up their land in exchange, or else be removed to lands west of the Mississippi. In a private 1803 letter to William Henry Harrison, Jefferson wrote:\nElsewhere in the same letter, Jefferson spoke of protecting the Indians from injustices perpetrated by whites:\nBy the terms of the treaty of February 27, 1819, the U.S. government would again offer citizenship to the Cherokees who lived east of the Mississippi River, along with 640 acres of land per family. Native American land was sometimes purchased, either via a treaty or under duress. The idea of land exchange, that is, that Native Americans would give up their land east of the Mississippi in exchange for a similar amount of territory west of the river, was first proposed by Jefferson in 1803 and had first been incorporated in treaties in 1817, years after the Jefferson presidency. The Indian Removal Act of 1830 incorporated this concept.\n\nUnder President James Monroe, Secretary of War John C. Calhoun devised the first plans for Indian removal. By late 1824, Monroe approved Calhoun's plans and in a special message to the Senate on January 27, 1825, requested the creation of the Arkansaw Territory and Indian Territory. The Indians east of the Mississippi were to voluntarily exchange their lands for lands west of the river. The Senate accepted Monroe's request and asked Calhoun to draft a bill, which was killed in the House of Representatives by the Georgia delegation. President John Quincy Adams assumed the Calhoun–Monroe policy and was determined to remove the Indians by non-forceful means, but Georgia refused to submit to Adams' request, forcing Adams to make a treaty with the Cherokees granting Georgia the Cherokee lands. On July 26, 1827, the Cherokee Nation adopted a written constitution modeled after that of the United States which declared they were an independent nation with jurisdiction over their own lands. Georgia contended that it would not countenance a sovereign state within its own territory, and proceeded to assert its authority over Cherokee territory. When Andrew Jackson became president as the candidate of the newly organized Democratic Party, he agreed that the Indians should be forced to exchange their eastern lands for western lands and relocate to them, and enforced Indian removal policy vigorously.\n\nWhen Andrew Jackson assumed office as president of the United States in 1829, his government took a hard line on Indian Removal policy. Jackson abandoned the policy of his predecessors of treating different Indian groups as separate nations. Instead, he aggressively pursued plans against all Indian tribes which claimed constitutional sovereignty and independence from state laws, and which were based east of the Mississippi River. They were to be removed to reservations in Indian Territory west of the Mississippi (now Oklahoma), where their laws could be sovereign without any state interference. At Jackson's request, the United States Congress opened a debate on an Indian Removal Bill. After fierce disagreements, the Senate passed the measure 28–19, the House 102–97. Jackson signed the legislation into law May 30, 1830.\n\nIn 1830, the majority of the \"Five Civilized Tribes\"—the Chickasaw, Choctaw, Creek, Seminole, and Cherokee—were living east of the Mississippi. The Indian Removal Act of 1830 implemented the federal government's policy towards the Indian populations, which called for moving Native American tribes living east of the Mississippi River to lands west of the river. While it did not authorize the forced removal of the indigenous tribes, it authorized the president to negotiate land exchange treaties with tribes located in lands of the United States.\n\nOn September 27, 1830, the Choctaw signed the Treaty of Dancing Rabbit Creek and by concession, became the first Native American tribe to be removed. The agreement represented one of the largest transfers of land that was signed between the U.S. Government and Native Americans without being instigated by warfare. By the treaty, the Choctaw signed away their remaining traditional homelands, opening them up for European-American settlement in Mississippi Territory. When the Choctaw reached Little Rock, a Choctaw chief referred to the trek as a \"trail of tears and death\".\n\nIn 1831, Alexis de Tocqueville, the French historian and political thinker, witnessed an exhausted group of Choctaw men, women and children emerging from the forest during an exceptionally cold winter near Memphis, Tennessee, on their way to the Mississippi to be loaded onto a steamboat, and wrote:\n\nWhile the Indian Removal Act made the move of the tribes voluntary, it was often abused by government officials. The best-known example is the Treaty of New Echota, which was negotiated and signed by a small faction of only twenty Cherokee tribal members, not the tribal leadership, on December 29, 1835. Most of the Cherokees later blamed them and the treaty for the forced relocation of the tribe in 1838. An estimated 4,000 Cherokees died in the march, now known as the Trail of Tears. Missionary organizer Jeremiah Evarts urged the Cherokee Nation to take their case to the U.S. Supreme Court.\n\nThe Marshall court heard the case in \"Cherokee Nation v. Georgia\" (1831), but declined to rule on its merits, instead declaring that the Native American tribes were not sovereign nations, and had no status to \"maintain an action\" in the courts of the United States. In \"Worcester v. Georgia\" (1832), the court held, in an opinion written by Chief Justice Marshall, that individual states had no authority in American Indian affairs.\n\nYet the state of Georgia defied the Supreme Court ruling, and the desire of white settlers and land speculators for Indian lands continued unabated. Some whites claimed that the Indian presence was a threat to peace and security; the Georgia legislature passed a law that after March 31, 1831, forbade whites from living on Indian territory without a license from the state, in order to exclude white missionaries who opposed Indian removal.\n\nIn 1835, the Seminole people refused to leave their lands in Florida, leading to the Second Seminole War. Osceola was a war leader of the Seminole in their fight against removal. Based in the Everglades of Florida, Osceola and his band used surprise attacks to defeat the U.S. Army in many battles. In 1837, Osceola was seized by deceit upon the orders of U.S. General Thomas Jesup when Osceola came under a flag of truce to negotiate a peace near Fort Peyton. Osceola died in prison of illness. The war would result in over 1,500 U.S. deaths and cost the government $20 million. Some Seminole traveled deeper into the Everglades, while others moved west. Removal continued out west and numerous wars ensued over land.\n\nIn the aftermath of the Treaty of Fort Jackson and the Treaty of Washington, the Muscogee were confined to a small strip of land in present-day east central Alabama. Following the Indian Removal Act, in 1832 the Creek National Council signed the Treaty of Cusseta, ceding their remaining lands east of the Mississippi to the U.S., and accepting relocation to the Indian Territory. Most Muscogee were removed to Indian Territory during the Trail of Tears in 1834, although some remained behind.\n\nUnlike other tribes who exchanged land grants, the Chickasaw were to receive mostly financial compensation of $3 million from the United States for their lands east of the Mississippi River. In 1836, the Chickasaw reached an agreement that purchased land from the previously removed Choctaw after a bitter five-year debate, paying them $530,000 for the westernmost part of Choctaw land. Most of the Chickasaw moved in 1837–1838. The $3,000,000 that the U.S. owed the Chickasaw went unpaid for nearly 30 years.\n\nAs a result, the Five Civilized Tribes were resettled in the new Indian Territory in modern-day Oklahoma. The Cherokee occupied the northeast corner of the Territory, as well as a strip of land seventy miles wide in Kansas on the border between the two. Some indigenous nations resisted forced migration more strongly. Those few that stayed behind eventually formed tribal groups, including the Eastern Band of Cherokee based in North Carolina, the Mississippi Band of Choctaw Indians, the Seminole Tribe of Florida, and the Creeks in Alabama, including the Poarch Band.\n\nTribes in the Old Northwest were far smaller and more fragmented than the Five Civilized Tribes, so the treaty and emigration process was more piecemeal. Bands of Shawnee, Ottawa, Potawatomi, Sauk, and Meskwaki (Fox) signed treaties and relocated to the Indian Territory. In 1832, a Sauk leader named Black Hawk led a band of Sauk and Fox back to their lands in Illinois; in the ensuing Black Hawk War, the U.S. Army and Illinois militia defeated Black Hawk and his warriors, resulting in the Sauk and Fox being relocated into what would become present day Iowa.\n\nTribes further to the east, such as the already displaced Lenape (or Delaware tribe), as well as the Kickapoo and Shawnee, were removed from Indiana, Michigan, and Ohio in the 1820s. The Potawatomi were forced out in late 1838 and resettled in Kansas Territory. Many Miami were resettled to Indian Territory in the 1840s. Communities in present-day Ohio were forced to move to Louisiana, which was then controlled by Spain.\n\nBy the terms of the Second Treaty of Buffalo Creek (1838), the Senecas transferred all their land in New York, excepting one small reservation, in exchange for 200,000 acres of land in Indian Territory. The U.S. federal government would be responsible for the removal of those Senecas who opted to go west, while the Ogden Land company would acquire their lands in New York. The lands were sold by government officials, however, and the money deposited in the U.S. Treasury. The Senecas asserted that they had been defrauded, and sued for redress in the U.S. Court of Claims. The case was not resolved until 1898, when the United States awarded $1,998,714.46 in compensation to \"the New York Indians\". In 1842 and 1857, the U.S. signed treaties with the Senecas and the Tonawanda Senecas, respectively. Under the treaty of 1857, the Tonawandas renounced all claim to lands west of the Mississippi in exchange for the right to buy back the lands of the Tonawanda reservation from the Ogden Land Company. Over a century later, the Senecas purchased a nine-acre plot (part of their original reservation) in downtown Buffalo to build the \"Seneca Buffalo Creek Casino\".\n\nThe following is a compilation of the statistics, many containing rounded figures, regarding the Southern removals.\n! Nation\n! Population east of the Mississippi before removal treaty\n! Removal treaty& year signed\n! Years of major emigration\n! Total number emigrated or forcibly removed\n! Number stayed in Southeast\n! Deaths during removal\n! Deaths from warfare\nChoctaw\n19,554 + white citizens of the Choctaw Nation + 500 black slaves\nDancing Rabbit Creek (1830)\n1831–1836\n12,500\n7,000\n2,000–4,000+ (Cholera)\nnone\nCreek\n22,700 + 900 black slaves\nCusseta (1832)\n1834–1837\n19,600\n100s\n3,500 (disease after removal)\n? (Second Creek War)\nChickasaw\nPontotoc Creek (1832)\n1837–1847\nover 4,000\n100s\n500–800\nnone\nCherokee\n21,500 + 2,000 black slaves\nNew Echota (1835)\n1836–1838\n20,000 + 2,000 slaves\n1,000\n2,000–8,000\nnone\nSeminole\n5,000 + fugitive slaves\nPayne's Landing (1832)\n1832–1842\n2,833\n250500\n700 (Second Seminole War)\n\nHistorical views regarding the Indian Removal have been re-evaluated since that time. Widespread acceptance at the time of the policy, due in part to an embracing of the concept of Manifest destiny by the general populace, have since given way to somewhat harsher views. Descriptions such as \"paternalism\", ethnic cleansing, and even genocide have been ascribed by historians past and present to the motivation behind the Removals.\n\nAndrew Jackson's reputation took a blow for his treatment of the Indians. Historians who admire Jackson's strong presidential leadership, such as Arthur Schlesinger, Jr., would skip over the Indian question with a footnote. Writing in 1969, Francis Paul Prucha argued that Jackson's removal of the Five Civilized Tribes from the very hostile white environment in the Old South to Oklahoma probably saved their very existence. In the 1970s, however, Jackson came under sharp attack from writers, such as Michael Paul Rogin and Howard Zinn, chiefly on this issue. Zinn called him \"exterminator of Indians\"; Paul R. Bartrop and Steven Leonard Jacobs argue that Jackson's policies did not meet the criterion for genocide or cultural genocide.\n\nBULLET::::- Internal colonialism\nBULLET::::- Daniel Sabin Butrick, Trail of Tears participant\nBULLET::::- Western European colonialism and colonization\n\nBULLET::::- Black, Jason Edward (2006). \"US Governmental and Native Voices in the Nineteenth Century: Rhetoric in the Removal and Allotment of American Indians\". (PhD dissertation), College Park, MD: University of Maryland. See, for instance, the bibliography on pp. 571–615.\nBULLET::::- Ehle, John (1988). \"Trail of Tears: The Rise and Fall of the Cherokee Nation\". New York, NY: Doubleday. .\nBULLET::::- Jahoda, Gloria (1975). \"The Trail of Tears: The Story of the American Indian Removals 1813–1855\". New York, NY: Holt, Rinehart and Winston. .\nBULLET::::- Strickland, William M. (1982). \"Southern Speech Communication Journal\" 47(3): 292–309.\n\nBULLET::::- PBS article on Indian Removal\nBULLET::::- Critical Resources: Text of the Removal Act and other documents.\nBULLET::::- Indian Removal from \"Digital History\" by S. Mintz\n"}
{"id": "15081", "url": "https://en.wikipedia.org/wiki?curid=15081", "title": "Green Party (Ireland)", "text": "Green Party (Ireland)\n\nThe Green Party - An Comhaontas Glas (, literally \"Green Alliance\") is a green political party that operates in Ireland—both the Republic of Ireland and Northern Ireland. It was founded as the Ecology Party of Ireland in 1981 by Dublin teacher Christopher Fettes. The party became the Green Alliance in 1983 and adopted its current English name in 1987 while the Irish name was kept unchanged. Its leader is Eamon Ryan, its deputy leader is Catherine Martin and its chairman is Roderic O'Gorman. Green Party candidates have been elected to most levels of representation: local (in the Republic), Dáil Éireann, Northern Ireland Assembly and European Parliament.\n\nThe Green Party first entered the Dáil in 1989. It has served in the Irish government once, from 2007 to 2011 as junior partner in a coalition with Fianna Fáil. The party suffered a wipeout in the February 2011 election, losing all six of its TDs. In the February 2016 election, it returned to the Dáil with two seats. Following this, Grace O'Sullivan was elected to the Seanad on 26 April that year of 2016 and Joe O'Brien was elected to Dáil Éireann in the 2019 Dublin Fingal by-election.\n\nThe party gained its first representation in the Northern Ireland Assembly in 2007, the Green Party in Northern Ireland having become a regional branch of the party the previous year. It currently has two representatives in the Assembly.\n\nThe party's first electoral outing was at the November 1982 general election when seven candidates contested under the \"Ecology Party\" banner, winning 0.2% of the vote. Following a name change, it contested the 1984 European elections, with party founder Roger Garland winning 1.9% in the Dublin constituency. The following year, it won its first election when Marcus Counihan was elected to Killarney Urban District Council at the 1985 local elections. The party nationally ran 34 candidates and won 0.6% of the vote.\n\nThe party continued to struggle until the 1989 general election when the Green Party (as it was now named) won its first seat in Dáil Éireann, when Roger Garland was elected in Dublin South. Garland lost his seat at the 1992 general election, while Trevor Sargent gained a seat in Dublin North. In the 1994 European election, Patricia McKenna topped the poll in the Dublin constituency and Nuala Ahern won a seat in Leinster. They retained their European Parliament seats in the 1999 European election, although the party lost five councillors in local elections held that year despite an increase in its vote. At the 1997 general election, the party gained a seat when John Gormley won a Dáil seat in Dublin South-East.\n\nAt the 2002 general election the party made a breakthrough, getting six Teachtaí Dála (TDs) elected to the Dáil with 4% of the national vote. However, in the 2004 European election, the party lost both of its European Parliament seats. In the 2004 local elections, it increased its number of councillors at county level from 8 to 18 (out of 883) and at town council level from 5 to 14 (out of 744).\n\nThe Green Party entered government for the first time after the 2007 general election, held on 24 May. Although its share of first-preference votes increased at the election, the party failed to increase the number of TDs returned. Mary White won a seat for the first time in Carlow–Kilkenny; however, Dan Boyle lost his seat in Cork South-Central.\n\nThe party had approached the 2007 general election on an independent platform, ruling out no coalition partners while expressing its preference for an alternative to the outgoing coalition of Fianna Fáil and the Progressive Democrats. Neither the outgoing government nor an alternative of Fine Gael, Labour and the Green Party had sufficient seats to form a majority. Fine Gael ruled out a coalition arrangement with Sinn Féin, opening the way for Green Party negotiations with Fianna Fáil.\n\nBefore the negotiations began, Ciarán Cuffe TD wrote on his blog that \"a deal with Fianna Fáil would be a deal with the devil… and [the Green Party would be] decimated as a Party\". The negotiations were undertaken by Donall Geoghegan (the party's general secretary), Dan Boyle and the then party Chair John Gormley. The Green Party walked out after six days; this, Geoghegan later said, was owing to there not being \"enough in [the deal] to allow [the Green Party] to continue\". The negotiations restarted on 11 June; a draft programme for government was agreed the next day, which under party rules needed 66% of members to endorse it at a special convention. On 13 June 2007, Green members at the Mansion House in Dublin voted 86% in favour (441 to 67; with 2 spoilt votes) of entering coalition with Fianna Fáil. The following day, the six Green Party TDs voted for the re-election of Bertie Ahern as Taoiseach.\n\nNew party leader John Gormley was appointed as Minister for the Environment, Heritage and Local Government and Eamon Ryan was appointed as Minister for Communications, Energy and Natural Resources. Trevor Sargent was named Minister of State for Food and Horticulture.\n\nBefore its entry into government, the Green Party had been a vocal supporter of the Shell to Sea movement, the campaign to reroute the M3 motorway away from Tara and (to a lesser extent) the campaign to end United States military use of Shannon Airport. After the party entered government there were no substantive changes in government policy on these issues, which meant that Eamon Ryan oversaw the Corrib gas project while he was in office. The Green Party had, at its last annual conference, made an inquiry into the irregularities surrounding the project (see Corrib gas controversy) a precondition of entering government but changed its stance during post-election negotiations with Fianna Fáil.\n\nThe 2008 budget, announced on 6 December 2007, did not include a carbon levy on fuels such as petrol, diesel and home heating oil, which the Green Party had sought before the election. A carbon levy was, however, introduced in the 2010 Budget. The 2008 budget did include a separate carbon budget announced by Gormley, which introduced new energy efficiency tax credit, a ban on incandescent bulbs from January 2009, a tax scheme incentivising commuters' purchases of bicycles and a new scale of vehicle registration tax based on carbon emissions.\n\nAt a special convention on whether to support the Treaty of Lisbon on 19 January 2008, the party voted 63.5% in favour of supporting the Treaty; this fell short of the party's two-third majority requirement for policy issues. As a result, the Green Party did not have an official campaign in the first Lisbon Treaty referendum, although individual members were involved on different sides. The referendum did not pass in 2008, and following the Irish government's negotiation with EU member states of additional legal guarantees and assurances, the Green Party held another special convention meeting in Dublin on 18 July 2009 to decide its position on the second Lisbon referendum. Precisely two-thirds of party members present voted to campaign for a 'Yes' in the referendum. This was the first time in the party's history that it had campaigned in favour of a European treaty.\n\nThe government's response to the post-2008 banking crisis significantly affected the party's support, and it suffered at the 2009 local elections, returning with only three County Council seats in total and losing its entire traditional Dublin base, with the exception of a Town Council seat in Balbriggan.\n\nDéirdre de Búrca, one of two Green Senators nominated by Taoiseach Bertie Ahern in 2007, resigned from the party and her seat in 2010, in part owing to the party's inability to secure her a job in the European Commission. On 23 February 2010, Trevor Sargent resigned as Minister of State for Food and Horticulture owing to allegations over contacting Gardaí about a criminal case involving a constituent. On 23 March 2010, Ciarán Cuffe was appointed as Minister for Horticulture, Sustainable Travel, Planning and Heritage while the party gained a junior ministerial position with Mary White appointed as Minister for Equality, Human Rights and Integration.\n\nThe Green Party supported the passage legislation for EC–ECB–IMF financial support for Ireland's bank bailout. On 19 January, the party derailed Taoiseach Brian Cowen's plans to reshuffle his cabinet when it refused to endorse Cowen's intended replacement ministers, forcing Cowen to redistribute the vacant portfolios among incumbent ministers. The Greens were angered at not having been consulted about this effort, and went as far as to threaten to pull out of the coalition unless Cowen set a firm date for an election due that spring. He ultimately set the date for 11 March.\n\nOn 23 January 2011, the Green Party met with Cowen following his resignation as leader of senior coalition partner Fianna Fáil the previous afternoon. The Green Party then announced it was breaking off the coalition and going into opposition with immediate effect. Green Party leader John Gormley said at a press conference announcing the withdrawal: The government ministerial posts of Gormley and Ryan were reassigned to Fianna Fáil ministers Éamon Ó Cuív and Pat Carey respectively. Green Ministers of State Ciarán Cuffe and Mary White also resigned from their roles.\n\nIn almost four years in Government, from 2007 to 2011, the Green Party contributed to the passage of civil partnership for same-sex couples, the introduction of major planning reform, a major increase in renewable energy output, progressive budgets, and a nationwide scheme of home insulation retrofitting.\n\nThe party suffered a wipeout at the 2011 general election, with all of its six TDs losing their seats, including those of former Ministers John Gormley and Eamon Ryan. Three of their six incumbent TDs lost their deposits. The party's share of the vote fell below 2%, meaning that they could not reclaim election expenses, and their lack of parliamentary representation led to the ending of state funding for the party.\n\nThe party candidates in the 2011 election to the Seanad were Dan Boyle and Niall Ó Brolcháin; neither was elected, and as a result, for the first time since 1989 the Green Party had no representatives in the Oireachtas.\n\nEamon Ryan was elected as party leader on 27 May 2011, succeeding John Gormley. Catherine Martin, a former Carrickmacross town councillor, was later appointed deputy leader, while Ciarán Cuffe and Mark Dearey were also placed on the party's front bench.\n\nIn the 2014 European election the party received 4.9% of the vote nationally (an increase of 3% on the 2009 result), failing to return a candidate to the European Parliament. In the 2014 local elections the party received 1.6% of the vote nationally. 12 candidates were elected to County Councils, an increase of nine.\n\nAt the 2016 general election the Green Party gained two seats, becoming the first Irish political party to lose all seats at an election and win seats at the subsequent election. In the subsequent election to Seanad Éireann, Grace O'Sullivan became the first elected Green Party Senator, winning a seat of the Agricultural Panel. She established the Civil Engagement group with five Independent Senators. On 30 May 2016, the Green Party joined the Social Democrats to form a technical group in the Dáil.\n\nIn the 2019 local elections the Green Party saw significant gains, increasing their number of councillors from 12 to 49 and becoming the second largest party on Dublin City Council. At the concurrent 2019 European Parliament election the party received 11.4% of the vote nationally (an increase of 6.5% on the 2014 result), the highest share they have won at any election to date. As a result, the Greens are represented in the European Parliament for the first time since 2004 by two MEPs - former TD Ciarán Cuffe in Dublin and Senator Grace O'Sullivan in South.\n\nOn 1 November 2019, Pippa Hackett was elected to Seanad Éireann. She filled the seat left vacant by Grace O'Sullivan after the 2019 European Parliament election.\n\nJoe O'Brien was elected to Dáil Éireann on 29 November 2019 in the 2019 Dublin Fingal by-election. He became the party's first TD to win a by-election and the party's third TD in the 32nd Dáil.\n\nWhile strongly associated with environmentalist policies, the party also has policies covering all other key areas. These include: protection of the Irish language, lowering the voting age in Ireland to 16, a directly elected Seanad, support for universal healthcare, and a constitutional amendment which guarantees that the water of Ireland will never be privatised.\n\nThe party also advocates that terminally ill people should have the right to legally choose assisted dying, on which subject it believes \"provisions should apply only to those with a terminal illness which is likely to result in death within six months\". It also states that \"such a right would only apply where the person has a clear and settled intention to end their own life which is proved by making, and signing, a written declaration to that effect. Such a declaration must be countersigned by two qualified doctors\".\n\nThe National Executive Committee is the organising committee of the party. It comprises the party leader Eamon Ryan, the deputy leader Catherine Martin, the Chair Roderic O'Gorman, the Young Greens representative, the Treasurer and ten members elected annually at the party convention.\n\nThe party did not have a national leader until 2001. At a special \"Leadership Convention\" in Kilkenny on 6 October 2001, Trevor Sargent was elected the first official leader of the Green Party. He was re-elected to this position in 2003 and again in 2005. The party's constitution requires that a leadership election be held within six months of a general election.\n\nSargent resigned the leadership in the wake of the 2007 general election to the 30th Dáil. During the campaign, Sargent had promised that he would not lead the party into Government with Fianna Fáil. At the election the party retained six Dáil seats, making it the most likely partner for Fianna Fáil. Sargent and the party negotiated a coalition government; at the 12 June 2007 membership meeting to approve the agreement, he announced his resignation as leader.\n\nIn the subsequent leadership election, John Gormley became the new leader on 17 July 2007, defeating Patricia McKenna by 478 votes to 263. Mary White was subsequently elected as the deputy Leader. Gormley served as Minister for the Environment, Heritage and Local Government from July 2007 until the Green Party's decision to exit government in December 2010.\n\nFollowing the election defeats of 2011, Gormley announced his intention not to seek another term as Green Party leader. Eamon Ryan was elected as the new party leader, over party colleagues Phil Kearney and Cllr Malcolm Noonan in a postal ballot election of party members in May 2011. Monaghan-based former councillor Catherine Martin defeated Down-based Dr John Barry and former Senator Mark Dearey to the post of deputy leader on 11 June 2011 during the party's annual convention. Roderic O'Gorman was elected party chairperson.\n\nThe Green Party lost all its Dáil seats in the 2011 general election. Party Chairman Dan Boyle and Déirdre de Búrca were nominated by the Taoiseach to Seanad Éireann after the formation of the Fianna Fáil–Progressive Democrats–Green Party government in 2007, and Niall Ó Brolcháin was elected in December 2009. De Búrca resigned in February 2010, and was replaced by Mark Dearey. Neither Boyle nor O'Brolchain was re-elected to Seanad Éireann in the Seanad election of 2011, leaving the Green Party without Oireachtas representation until the 2016 general election, in which it regained two Dáil seats.\n\nThe Green Party is organised throughout the island of Ireland, with regional structures in both the Republic of Ireland and Northern Ireland. The Green Party in Northern Ireland voted to become a regional partner of the Green Party in Ireland in 2005 at its annual convention, and again in a postal ballot in March 2006. Brian Wilson, formerly a councillor for the Alliance Party, won the Green Party's first seat in the Northern Ireland Assembly in the 2007 election. Steven Agnew held that seat in the 2011 election.\n\n! Election\n! Seats won\n! Position\n! First-pref. votes\n! Government\n! Leader\n!1982 (Nov)\n!1987\n!1989\n!1992\n!1997\n!2002\n!2007\n!2011\n!2016\n\n! Election\n! Seats won\n! First-pref. votes\n\n!1985\n!1991\n!1999\n!2004\n!2009\n!2014\n!2019\n\n! Election\n! Body\n! Seats won\n! Position\n! First-pref. votes\n! Government\n! Leader\n!1996\nForum\n!1998\nrowspan=6Assembly\n!2003\n!2007\n!2011\n!2016\n!2017\n\n! Election\n! Seats (in NI)\n! Position\n! Total votes\n! % (in NI)\n! % (in UK)\n! Government\n!1983\n!1987\n!1997\n!2010\n!2015\n!2017\n\n! Election\n! Seats won\n! Position\n! First-pref. votes\n! Leader\n!1984\n!1989\n!1994\n!1999\n!2004\n!2009\n!2014\n!2019\n\nBULLET::::- Young Greens\nBULLET::::- List of environmental organisations\n\nBULLET::::- Green Party 2007 election manifesto (from the Wayback Machine)\n"}
{"id": "15085", "url": "https://en.wikipedia.org/wiki?curid=15085", "title": "Iconoclasm", "text": "Iconoclasm\n\nIconoclasm is the social belief in the importance of the destruction of icons and other images or monuments, most frequently for religious or political reasons. People who engage in or support iconoclasm are called iconoclasts, a term that has come to be figuratively applied to any individual who challenges \"cherished beliefs or venerated institutions on the grounds that they are erroneous or pernicious\".\n\nConversely, one who reveres or venerates religious images is called (by iconoclasts) an \"iconolater\"; in a Byzantine context, such a person is called an \"iconodule\" or \"iconophile.\"\n\nThe term does not generally encompass the specific destruction of images of a ruler after his death or overthrow (\"damnatio memoriae\").\n\nIconoclasm may be carried out by adherents of a different religion, but it is more often the result of sectarian disputes between factions of the same religion. Within Christianity, iconoclasm has generally been motivated by those who adopt a strict interpretation of the Ten Commandments, which forbid the making and worshipping of \"graven images or any likeness of anything\". The later Church Fathers identified Jews, fundamental iconoclasts, with heresy and saw deviations from orthodox Christianity and opposition to the veneration of images as heresies that were essentially \"Jewish in spirit\". Degrees of iconoclasm vary greatly among religions and their branches. Islam, in general, tends to be more iconoclastic than Christianity, with Sunni Islam being more iconoclastic than Shia Islam.\n\nIn the Bronze Age, the most significant episode of iconoclasm occurred in Egypt during the Amarna Period, when Akhenaten, based in his new capital of Akhetaten, instituted a significant shift in Egyptian artistic styles alongside a campaign of intolerance towards the traditional gods and a new emphasis on a state monolatristic tradition focused on the god Aten, the Sun disk— many temples and monuments were destroyed as a result:\n\nIn rebellion against the old religion and the powerful priests of Amun, Akhenaten ordered the eradication of all of Egypt's traditional gods. He sent royal officials to chisel out and destroy every reference to Amun and the names of other deities on tombs, temple walls, and cartouches to instill in the people that the Aten was the one true god.\n\nPublic references to Akhenaten were destroyed soon after his death.\n\nComparing the ancient Egyptians with the Israelites, Jan Assmann writes:\n\nFor Egypt, the greatest horror was the destruction or abduction of the cult images. In the eyes of the Israelites, the erection of images meant the destruction of divine presence; in the eyes of the Egyptians, this same effect was attained by the destruction of images. In Egypt, iconoclasm was the most terrible religious crime; in Israel, the most terrible religious crime was idolatry. In this respect Osarseph alias Akhenaten, the iconoclast, and the Golden Calf, the paragon of idolatry, correspond to each other inversely, and it is strange that Aaron could so easily avoid the role of the religious criminal. It is more than probable that these traditions evolved under mutual influence. In this respect, Moses and Akhenaten became, after all, closely related.\n\nAlthough widespread use of Christian iconography only began as Christianity increasingly spread among gentiles after the legalization of Christianity by Roman Emperor Constantine (c. 312 AD), scattered expressions of opposition to the use of images were reported (e.g. the Spanish Synod of Elvira). The period after the reign of Byzantine Emperor Justinian (527–565) evidently saw a huge increase in the use of images, both in volume and quality, and a gathering aniconic reaction.\n\nOne notable change within the Byzantine Empire came in 695, when Justinian II's government added a full-face image of Christ on the obverse of imperial gold coins. The change caused the Caliph Abd al-Malik to stop his earlier adoption of Byzantine coin types. He started a purely Islamic coinage with lettering only. A letter by the Patriarch Germanus written before 726 to two Iconoclast bishops says that \"now whole towns and multitudes of people are in considerable agitation over this matter\" but there is little written evidence of the debate.\n\nGovernment-led iconoclasm began with Byzantine Emperor Leo III, who issued a series of edicts against the veneration of images between 726 and 730. The religious conflict created political and economic divisions in Byzantine society. It was generally supported by the Eastern, poorer, non-Greek peoples of the Empire who had to deal frequently with raids from the new Muslim Empire. On the other hand, the wealthier Greeks of Constantinople and the peoples of the Balkan and Italian provinces strongly opposed iconoclasm.\n\nThe first iconoclastic wave happened in Wittenberg in the early 1520s under reformers Thomas Müntzer and Andreas Karlstadt. It prompted Martin Luther, then concealing as \"Junker Jörg\", to intervene. Luther argued that the mental picturing of Christ when reading the Scriptures was similar in character to artistic renderings of Christ.\n\nIn contrast to the Lutherans who favoured sacred art in their churches and homes, the Reformed (Calvinist) leaders, in particular Andreas Karlstadt, Huldrych Zwingli and John Calvin, encouraged the removal of religious images by invoking the Decalogue's prohibition of idolatry and the manufacture of graven (sculpted) images of God. As a result, individuals attacked statues and images. However, in most cases, civil authorities removed images in an orderly manner in the newly Reformed Protestant cities and territories of Europe.\n\nSignificant iconoclastic riots took place in Basel (in 1529), Zurich (1523), Copenhagen (1530), Münster (1534), Geneva (1535), Augsburg (1537), Scotland (1559), Rouen (1560) and Saintes and La Rochelle (1562). Calvinist iconoclasm in Europe \"provoked reactive riots by Lutheran mobs\" in Germany and \"antagonized the neighbouring Eastern Orthodox\" in the Baltic region.\n\nThe Seventeen Provinces (now the Netherlands, Belgium and parts of Northern France) were disrupted by widespread Calvinist iconoclasm in the summer of 1566. This is called the \"Beeldenstorm\" and began with the destruction of the statuary of the Monastery of Saint Lawrence in Steenvoorde after a \"\"Hagenpreek\"\", or field sermon, by Sebastiaan Matte. Hundreds of other attacks included the sacking of the Monastery of Saint Anthony after a sermon by Jacob de Buysere. The \"Beeldenstorm\" marked the start of the revolution against the Spanish forces and the Catholic Church.\n\nThe iconoclastic belief caused havoc throughout Europe. In 1523, specifically due to the Swiss reformer Huldrych Zwingli, a vast number of his followers viewed themselves as being involved in a spiritual community that in matters of faith should obey neither the visible Church nor lay authorities. According to Peter George Wallace:\n\nDuring the Reformation in England started during the reign of Anglican monarch Henry VIII, and urged on by reformers such as Hugh Latimer and Thomas Cranmer, limited official action was taken against religious images in churches in the late 1530s. Henry's young son, Edward VI, came to the throne in 1547 and, under Cranmer's guidance, issued Injunctions for Religious Reforms in the same year and in 1550, an Act of Parliament \"for the abolition and putting away of divers books and images\". During the English Civil War, Bishop Joseph Hall of Norwich described the events of 1643 when troops and citizens, encouraged by a Parliamentary ordinance against superstition and idolatry, behaved thus:\n\nLord what work was here! What clattering of glasses! What beating down of walls! What tearing up of monuments! What pulling down of seats! What wresting out of irons and brass from the windows! What defacing of arms! What demolishing of curious stonework! What tooting and piping upon organ pipes! And what a hideous triumph in the market-place before all the country, when all the mangled organ pipes, vestments, both copes and surplices, together with the leaden cross which had newly been sawn down from the Green-yard pulpit and the service-books and singing books that could be carried to the fire in the public market-place were heaped together.\n\nProtestant Christianity was not uniformly hostile to the use of religious images. Martin Luther taught the \"importance of images as tools for instruction and aids to devotion\", stating: \"If it is not a sin but good to have the image of Christ in my heart, why should it be a sin to have it in my eyes?\" Lutheran churches retained ornate church interiors with a prominent crucifix, reflecting their high view of the real presence of Christ in Eucharist. As such, \"Lutheran worship became a complex ritual choreography set in a richly furnished church interior.\" For Lutherans, \"the Reformation renewed rather than removed the religious image.\"\n\nLutheran scholar Jeremiah Ohl writes:\n\nThe Ottoman Sultan Suleiman the Magnificent, who had pragmatic reasons to support the Dutch Revolt (the rebels, like himself, were fighting against Spain) also completely approved of their act of \"destroying idols\", which accorded well with Muslim teachings.\n\nA bit later in Dutch history, in 1627 the artist Johannes van der Beeck was arrested and tortured, charged with being a religious non-conformist and a blasphemer, heretic, atheist, and Satanist. The 25 January 1628 judgment from five noted advocates of The Hague pronounced him guilty of \"blasphemy against God and avowed atheism, at the same time as leading a frightful and pernicious lifestyle. At the court's order his paintings were burned, and only a few of them survive \"\n\nIn the history of Islam the act of removing idols from the Ka'ba in Mecca has great symbolic and historic importance for all believers.\n\nIn general, Muslim societies have avoided the depiction of living beings (animals and humans) within such sacred spaces as mosques and madrasahs. This opposition to figural representation is based not on the Qur'an, but on traditions contained within the Hadith. The prohibition of figuration has not always been extended to the secular sphere, and a robust tradition of figural representation exists within Muslim art.\nHowever, Western authors have tended to perceive \"a long, culturally determined, and unchanging tradition of violent iconoclastic acts\" within Islamic society.\n\nBULLET::::- Early Islam in Arabia\nThe first act of Muslim iconoclasm dates to the beginning of Islam, in 630, when the various statues of Arabian deities housed in the Kaaba in Mecca were destroyed. There is a tradition that Muhammad spared a fresco of Mary and Jesus. This act was intended to bring an end to the idolatry which, in the Muslim view, characterized Jahiliyya.\n\nThe destruction of the idols of Mecca did not, however, determine the treatment of other religious communities living under Muslim rule after the expansion of the caliphate. Most Christians under Muslim rule, for example, continued to produce icons and to decorate their churches as they wished. A major exception to this pattern of tolerance in early Islamic history was the \"Edict of Yazīd\", issued by the Umayyad caliph Yazid II in 722–723.\nThis edict ordered the destruction of crosses and Christian images within the territory of the caliphate. Researchers have discovered evidence that the order was followed, particularly in present-day Jordan, where archaeological evidence shows the removal of images from the mosaic floors of some, although not all, of the churches that stood at this time. But, Yazīd's iconoclastic policies were not continued by his successors, and Christian communities of the Levant continued to make icons without significant interruption from the sixth century to the ninth.\n\nBULLET::::- Egypt\nAl-Maqrīzī, writing in the 15th century, attributes the missing nose on the Great Sphinx of Giza to iconoclasm by Muhammad Sa'im al-Dahr, a Sufi Muslim in the mid-1300s. He was reportedly outraged by local Muslims making offerings to the Great Sphinx in the hope of controlling the flood cycle, and he was later executed for vandalism. However, whether this was actually the cause of the missing nose has been debated by historians. Mark Lehner who performed an archaeological study concluded that it was broken with instruments at an earlier unknown time between the 3rd and 10th centuries.\n\nBULLET::::- Ottoman conquests\nCertain conquering Muslim armies have used local temples or houses of worship as mosques. An example is Hagia Sophia in Istanbul (formerly Constantinople), which was converted into a mosque in 1453. Most icons were desecrated and the rest were covered with plaster. In the 1920s, Hagia Sophia was converted to a museum, and the restoration of the mosaics was undertaken by the American Byzantine Institute beginning in 1932.\n\nBULLET::::- Recent events\n\nCertain Muslim denominations continue to pursue iconoclastic agendas. There has been much controversy within Islam over the recent and apparently on-going destruction of historic sites by Saudi Arabian authorities, prompted by the fear they could become the subject of \"idolatry\".\n\nA recent act of iconoclasm was the 2001 destruction of the giant Buddhas of Bamyan by the then-Taliban government of Afghanistan. The act generated worldwide protests and was not supported by other Muslim governments and organizations. It was widely perceived in the Western media as a result of the Muslim prohibition against figural decoration. Such an account overlooks \"the coexistence between the Buddhas and the Muslim population that marveled at them for over a millennium\" before their destruction. The Buddhas had twice in the past been attacked by Nadir Shah and Aurengzeb. According to the art historian F.B. Flood, analysis of the Taliban's statements regarding the Buddhas suggest that their destruction was motivated more by political than by theological concerns. Taliban spokespeople have given many different explanations of the motives for the destruction.\n\nDuring the Tuareg rebellion of 2012, the radical Islamist militia Ansar Dine destroyed various Sufi shrines from the 15th and 16th centuries in the city of Timbuktu, Mali. In 2016, the International Criminal Court (ICC) sentenced Ahmad al-Faqi al-Mahdi, a former member of Ansar Dine, to nine years in prison for this destruction of cultural world heritage. This was the first time that the ICC convicted a person for such a crime.\n\nThe short-lived Islamic State of Iraq and the Levant carried out iconoclastic attacks such as the destruction of Shia mosques and shrines. Notable incidents include blowing up the Mosque of the Prophet Yunus (Jonah) and destroying the Shrine to Seth in Mosul.\n\nIn early medieval India, there were numerous recorded instances of temple desecration by Indian kings against rival Indian kingdoms, involving conflict between devotees of different Hindu deities, as well as between Hindus, Buddhists and Jains. In 642, the Pallava king Narasimhavarman I looted a Ganesha temple in the Chalukyan capital of Vatapi. \"Circa\" 692, Chalukya armies invaded northern India where they looted temples of Ganga and Yamuna. In the 8th century, Bengali troops from the Buddhist Pala Empire desecrated temples of Vishnu Vaikuntha, the state deity of Lalitaditya's kingdom in Kashmir. In the early 9th century, Indian Hindu kings from Kanchipuram and the Pandyan king Srimara Srivallabha looted Buddhist temples in Sri Lanka. In the early 10th century, the Pratihara king Herambapala looted an image from a temple in the Sahi kingdom of Kangra, which in the 10th century was looted by the Pratihara king Yasovarman.\n\nIn the early 11th century, the Chola king Rajendra I looted from temples in a number of neighbouring kingdoms, including Durga and Ganesha temples in the Chalukya Kingdom; Bhairava, Bhairavi and Kali temples in the Kalinga kingdom; a Nandi temple in the Eastern Chalukya kingdom; and a Siva temple in Pala Bengal. In the mid-11th century, the Chola king Rajadhiraja plundered a temple in Kalyani. In the late 11th century, the Hindu king Harsha of Kashmir plundered temples as an institutionalised activity. In the late 12th to early 13th centuries, the Paramara dynasty attacked and plundered Jain temples in Gujarat. In the 1460s, Suryavamshi Gajapati dynasty founder Kapilendra sacked the Saiva and Vaishnava temples in the Cauvery delta in the course of wars of conquest in the Tamil country. Vijayanagara king Krishnadevaraya looted a Balakrishna temple in Udayagiri in 1514, and he looted a Vittala temple in Pandharpur in 1520.\n\nSome of the most dramatic cases of iconoclasm by Muslims are found in parts of India where Hindu and Buddhist temples were razed and mosques erected in their place. Aurangzeb, the 6th Mughal Emperor, destroyed the famous Hindu temples at Varanasi and Mathura.\n\nIn modern India, the most high-profile case of iconoclasm was from 1992. Hindu extremists, led by the Vishva Hindu Parishad and Bajrang Dal, destroyed the 430-year-old Islamic Babri Mosque in Ayodhya.\n\nBULLET::::- According to the Hebrew Bible, the Israelites entering the Promised Land were instructed by God to 'destroy all [the] engraved stones, destroy all [the] molded images, and demolish all [the] high places' of the Canaanite indigenous population.\nBULLET::::- In Judaism, King Hezekiah purged Solomon's Temple in Jerusalem and the Land of Israel of figures, including the Nehushtan, as recorded in the Second Book of Kings. His reforms were reversed in the reign of his son Manasseh.\nBULLET::::- In 305–306, the Synod of Elvira appeared to endorse iconoclasm. Canon 36 states, \"Pictures are not to be placed in churches, so that they do not become objects of worship and adoration.\" Proscription ceased after the destruction of pagan temples.\nBULLET::::- During the process of Christianisation under Constantine, Christian groups destroyed the images and sculptures expressive of the Roman Empire's polytheist state religion.\nBULLET::::- Many of the moai of Easter Island were toppled during the 18th century in the iconoclasm of civil wars before any European encounter. Other instances of iconoclasm may have occurred throughout Eastern Polynesia during its conversion to Christianity in the 19th century.\n\nBULLET::::- After the Second Vatican Council in the late twentieth century, some Roman Catholic parish churches discarded much of their traditional imagery, art, and architecture.\nBULLET::::- According to an article in \"Buddhist-Christian Studies\": \"Over the course of the last decade [1990s] a fairly large number of Buddhist temples in South Korea have been destroyed or damaged by fire by Christian fundamentalists. More recently, Buddhist statues have been identified as idols, and attacked and decapitated in the name of Jesus. Arrests are hard to effect, as the arsonists and vandals work by stealth of night.\"\n\nRevolutions and changes of regime, whether through uprising of the local population, foreign invasion, or a combination of both, are often accompanied by the public destruction of statues and monuments identified with the previous regime. This may also be known as \"damnatio memoriae\", the ancient Roman practice of official obliteration of the memory of a specific individual. Stricter definitions of \"iconoclasm\" exclude both types of action, reserving the term for religious or more widely cultural destruction. In many cases, such as Revolutionary Russia or Ancient Egypt, this distinction can be hard to make.\n\nAmong Roman emperors and other political figures subject to decrees of \"damnatio memoriae\" were Sejanus, Publius Septimius Geta, and Domitian. Several Emperors, such as Domitian and Commodus had during their reigns erected numerous statues of themselves, which were pulled down and destroyed when they were overthrown.\n\nThroughout the radical phase of the French Revolution, iconoclasm was supported by members of the government as well as the citizenry. Numerous monuments, religious works, and other historically significant pieces were destroyed in an attempt to eradicate any memory of the Old Regime. At the same time, the republican government felt responsible to preserve these works for their historical, aesthetic, and cultural value. One way the republican government succeeded in their paradoxical mission of preserving and destroying symbols of the Old Regime was through the development of museums.\n\nDuring the Revolution, a statue of King Louis XV in the Paris square which until then bore his name, was pulled down and destroyed. This was a prelude to the guillotining of his successor Louis XVI in the same site, renamed \"Place de la Révolution\" (at present Place de la Concorde).\n\nThe statue of Napoleon on the column at Place Vendôme, Paris was also the target of iconoclasm several times: destroyed after the Bourbon Restoration, restored by Louis-Philippe, destroyed during the Paris Commune and restored by Adolphe Thiers.\nRecords from the campaign recorded in the \"Chach Nama\" record the destruction of temples during the early eighth century when the Umayyad governor of Damascus, al-Hajjaj ibn Yusuf, mobilized an expedition of 6000 cavalry under Muhammad bin Qasim in 712.\n\nThe historian Upendra Thakur records the persecution of Hindus and Buddhists:\n\nIn 725 Junayad, the governor of Sind, sent his armies to destroy the second Somnath. In 1024, the temple was again destroyed by Mahmud of Ghazni, who raided the temple from across the Thar Desert. The wooden structure was replaced by Kumarapala (r. 1143–72), who rebuilt the temple out of stone.\n\nSultan Sikandar Butshikan of Kashmir (1389–1413) ordered the breaking of all \"golden and silver images\". Firishta states, \"After the emigration of the Bramins, Sikundur ordered all the temples in Kashmeer to be thrown down. Having broken all the images in Kashmeer, (Sikandar) acquired the title of 'Destroyer of Idols'\".\n\nThere have been a number of anti-Buddhist campaigns in Chinese history that led to the destruction of Buddhist temples and images. One of the most notable of these campaigns was the Great Anti-Buddhist Persecution of the Tang dynasty.\n\nDuring and after the Xinhai Revolution, there was widespread destruction of religious and secular images in China.\n\nDuring the Northern Expedition in Guangxi in 1926, Kuomintang General Bai Chongxi led his troops in destroying Buddhist temples and smashing Buddhist images, turning the temples into schools and Kuomintang party headquarters. It was reported that almost all of the viharas in Guangxi were destroyed and the monks were removed. Bai also led a wave of anti-foreignism in Guangxi, attacking Americans, Europeans, and other foreigners, and generally making the province unsafe for foreigners and missionaries. Westerners fled from the province and some Chinese Christians were also attacked as imperialist agents. The three goals of the movement were anti-foreignism, anti-imperialism and anti-religion. Bai led the anti-religious movement against superstition. Huang Shaohong, also a Kuomintang member of the New Guangxi clique, supported Bai's campaign. The anti-religious campaign was agreed upon by all Guangxi Kuomintang members.\n\nThere was extensive destruction of religious and secular imagery in Tibet after it was invaded and occupied by China.\n\nMany religious and secular images were destroyed during the Cultural Revolution of 1966-1976, ostensibly because they were a holdover from China's traditional past (which the Communist regime led by Mao Zedong reviled). The Cultural Revolution included widespread destruction of historic artworks in public places and private collections, whether religious or secular. Objects in state museums were mostly left intact.\n\nDuring and after the October Revolution, widespread destruction of religious and secular imagery took place, as well as the destruction of imagery related to the Imperial family. The Revolution was accompanied by destruction of monuments of past tsars, as well as the destruction of imperial eagles at various locations throughout Russia. According to Christopher Wharton, \"In front of a Moscow cathedral, crowds cheered as the enormous statue of Tsar Alexander III was bound with ropes and gradually beaten to the ground. After a considerable amount of time, the statue was decapitated and its remaining parts were broken into rubble\".\n\nThe Soviet Union actively destroyed religious sites, including Russian Orthodox churches and Jewish cemeteries, in order to discourage religious practice and curb the activities of religious groups.\nDuring the Hungarian Revolution of 1956 and during the Revolutions of 1989, protesters often attacked and took down sculptures and images of Joseph Stalin, such as the Stalin Monument in Budapest. The fall of Communism in 1989-1991 was also followed by the destruction or removal of statues of Vladimir Lenin and other Communist leaders in the former Soviet Union and in other Eastern Bloc countries. Particularly well-known was the destruction of \"Iron Felix\", the statue of Felix Dzerzhinsky outside the KGB's headquarters. Another statue of Dzerzhinsky was destroyed in a Warsaw square that was named after him during communist rule, but which is now called Bank Square.\n\nOther examples of political destruction of images include:\nBULLET::::- During the American Revolution, the Sons of Liberty pulled down and destroyed the gilded lead statue of George III of the United Kingdom on Bowling Green (New York City), melting it down to be recast as ammunition. Similar acts have accompanied the independence of most ex-colonial territories. Sometimes relatively intact monuments are moved to a collected display in a less prominent place, as in India and also post-Communist countries.\nBULLET::::- From the 16th through the 19th centuries, many of the polytheistic religious deities and texts of pre-colonial Americas, Oceania and Africa were destroyed by Christian missionaries and their converts, such as during the Spanish conquest of the Aztec Empire and the Spanish conquest of the Inca Empire.\nBULLET::::- There have been several cases of removing symbols of past rulers in Malta's history. Many Hospitaller coats of arms on buildings were defaced during the French occupation of Malta in 1798–1800; a few of these were subsequently replaced by British coats of arms in the early 19th century. Some British symbols were also removed by the government after Malta became a republic in 1974. These include royal cyphers being ground off from post boxes, and British coats of arms such as that on the Main Guard building being temporarily obscured (but not destroyed).\nBULLET::::- With the entry of the Ottoman Empire to the First World War, the Ottoman Army destroyed the Russian victory monument erected in San Stefano (the modern Yeşilköy quarter of Istanbul) to commemorate the Russian victory in the Russo-Turkish War of 1877–1878. The demolition was filmed by former army officer Fuat Uzkınay, producing \"Ayastefanos'taki Rus Abidesinin Yıkılışı\" - the oldest known Turkish-made film.\nBULLET::::- In the late 18th century, the Brabant Revolutionaries sacked Brussels' Grand Place, destroying statues of nobility and symbols of Christianity.. In the 19th Century, the place was renovated and many new statues added. In 1911, a marble commemoration for the Spanish freethinker and educator Francisco Ferrer, executed two years earlier and widely considered a martyr, was erected in the Grand Place. The statue depicted a nude man holding the Torch of Enlightenment. The Imperial German military, which occupied Belgium during the First World War, disliked the monument and destroyed it in 1915. It was restored in 1926 by the International Free Thought Movement .\nBULLET::::- In 1942 the pro-Nazi Vichy Government of France took down and melted Clothilde Roch's statue of the 16th-century dissident intellectual Michael Servetus, who had been burned at the stake in Geneva at the instigation of Calvin. The Vichy authorities disliked the statue, as it was a celebration of freedom of conscience. In 1960, having found the original molds, the municipality of Annemasse had it recast and returned the statue to its previous place.\nBULLET::::- The Taliban destroyed two ancient Buddhas of Bamiyan in Bamyan, Afghanistan in March 2001.\nBULLET::::- The Battle of Baghdad symbolically ended with the Firdos Square statue destruction, a US military-staged event in April 2003 where a prominent statue of Saddam Hussein was pulled down.\nBULLET::::- In 2016, paintings from the University of Cape Town were burned in student protests as symbols of colonialism.\nBULLET::::- In August 2017 a statue of a Confederate soldier dedicated to \"the boys who wore the gray\" was pulled down from its pedestal in front of Durham County Courthouse in North Carolina by protesters. This followed the events at the 2017 Unite the Right rally in response to growing calls to remove Confederate monuments and memorials across the U.S.\n\nBULLET::::- Aniconism\nBULLET::::- Censorship by religion\nBULLET::::- Iconolatry\nBULLET::::- Lost artworks\nBULLET::::- Natural theology\nBULLET::::- Slighting\n\nBULLET::::- Alloa, Emmanuel (2013). Visual Studies in Byzantium, in: Journal of Visual Culture 12.1 (2013) 3–29 (on the conceptual background of Byzantine iconoclasm)\nBULLET::::- Aston, Margaret. \"England's Iconoclasts: Volume I: Laws Against Images\" (1988)\nBULLET::::- Aston, Margaret. \"Broken Idols of the English Reformation\" (Cambridge UP, 2016).\nBULLET::::- Balafrej, Lamia. \"Islamic Iconoclasm, Visual Communication and the Persistence of the Image,\" \"Interiors\" 6, 3 (2015): 351-366. https://doi.org/10.1080/20419112.2015.1125659\nBULLET::::- Boldrick, Stacy, Leslie Brubaker, and Richard Clay, eds. \"Striking Images, Iconoclasms Past and Present\" (Ashgate, 2014) 236 pages; scholarly studies of the destruction of images from prehistory to the Taliban\nBULLET::::- Reprinted in\nBULLET::::- Karahan, Anne (2014). \"Byzantine Iconoclasm: Ideology and Quest for Power\". In: Eds. K. Kolrud and M. Prusac, \"Iconoclasm from Antiquity to Modernity\", Ashgate Publishing Ltd: Farnham, Surrey, pp. 75–94. .\nBULLET::::- Arun Shourie, Sita Ram Goel, Harsh Narain, Jay Dubashi and Ram Swarup. Hindu Temples - What Happened to Them Vol. I, (A Preliminary Survey) (1990)\nBULLET::::- Spicer, Andrew. \"Iconoclasm,\" \"Renaissance Quarterly\" 70#3 (Fall 2017): 1007-1022. https://doi.org/10.1086/693887\nBULLET::::- Velikov, Yuliyan (2011). \"Image of the Invisible. Image Veneration and Iconoclasm in the Eighth Century.\" Veliko Turnovo University Press. (in Bulgarian)\nBULLET::::- Antonio Calisi, I Difensori Dell'icona: La Partecipazione Dei Vescovi Dell'Italia Meridionale Al Concilio Di Nicea II 787, Createspace Independent Pub 2017,\n\nBULLET::::- Iconclasm in England, Holy Cross College (UK)\nBULLET::::- Design as Social Agent at the ICA by Kerry Skemp, April 5, 2009\nBULLET::::- Hindu temples destroyed by Muslim rulers in India\n"}
{"id": "15086", "url": "https://en.wikipedia.org/wiki?curid=15086", "title": "IWW (disambiguation)", "text": "IWW (disambiguation)\n\nIWW, or Industrial Workers of the World (known as the Wobblies), are an international union founded in 1905.\n\nIWW may also refer to:\nBULLET::::- Inland waterway, a navigable river, canal, or sound\nBULLET::::- Irish Whip Wrestling, an Irish-owned independent professional wrestling promotion established in 2002\n\nBULLET::::- \"It Was Written\", the second studio album by American rapper Nas\n"}
{"id": "15087", "url": "https://en.wikipedia.org/wiki?curid=15087", "title": "Imbolc", "text": "Imbolc\n\nImbolc or Imbolg (), also called (Saint) Brigid's Day (, , ), is a Gaelic traditional festival marking the beginning of spring. It is held on 1 February, or about halfway between the winter solstice and the spring equinox. Historically, it was widely observed throughout Ireland, Scotland and the Isle of Man. It is one of the four Gaelic seasonal festivals—along with Beltane, Lughnasadh and Samhain—and corresponds to the Welsh \". For Christians, especially in Ireland, it is the feast day of Saint Brigid.\n\nImbolc, or Imbolic as it is sometimes spelled, is mentioned in early Irish literature, and there is evidence suggesting it was also an important date in ancient times. It is believed that Imbolic was originally a pagan festival associated with the goddess Brigid, and that it was Christianized as a festival of Saint Brigid, who is thought to be a Christianization of the goddess. At Imbolc, Brigid's crosses and a doll-like figure of Brigid–called a \"–were made. The figure would then be paraded from house-to-house by girls, and sometimes accompanied by 'strawboys'. Brigid was said to visit one's home at Imbolc. To receive her blessings, people would make a bed for Brigid and leave her food and drink, and items of clothing would be left outside for her to bless. Brigid was also invoked to protect homes and livestock. People participated in special feasts and visits to holy wells, and it was a time for divination.\n\nAlthough many of its customs died out in the 20th century, it is still observed and in some places it has been revived as a cultural event. Since the latter 20th century, Celtic neopagans and Wiccans have observed Imbolc as a religious holiday.\n\nThe etymology of Imbolc/Imbolg is unclear. The most common explanation is that is comes from the Old Irish \"i mbolc\" (Modern Irish \"i mbolg\"), meaning \"in the belly\", and refers to the pregnancy of ewes. Another possible origin is the Old Irish \"imb-fholc\", \"to wash/cleanse oneself\", referring to a ritual cleansing. Eric P. Hamp derives it from a Proto-Indo-European root meaning both \"milk\" and \"cleansing\". Professor Alan Ward derives it from the Proto-Celtic \"*embibolgon\", \"budding\". The 10th century Cormac's Glossary derives it from \"oimelc\", \"ewe milk\", but many scholars see this as a folk etymology. Nevertheless, some Neopagans have adopted \"Oimelc\" as a name for the festival.\n\nSince Imbolc is immediately followed (on 2 February) by Candlemas (Irish \"Lá Fhéile Muire na gCoinneal\" \"feast day of Mary of the Candles\", Welsh \"Gŵyl Fair y Canhwyllau\"), Irish \"Imbolc\" is sometimes translated into English as \"Candlemas\"; e.g. \"iar n-imbulc, ba garb a ngeilt\" translated as \"after Candlemas, rough was their herding\".\n\nThe date of Imbolc is thought to have been significant in Ireland since the Neolithic period. Some passage tombs in Ireland are aligned with the sunrise around the times of Imbolc and Samhain. This includes the Mound of the Hostages on the Hill of Tara, and Cairn L at Slieve na Calliagh.\n\nIn Gaelic Ireland, Imbolc was the \"feis\" or festival marking the beginning of spring, during which great feasts were held. It is attested in some of the earliest Old Irish literature, from the 10th century onward. It was one of four Gaelic seasonal festivals: Samhain (~1 November), Imbolc (~1 February), Beltane (~1 May) and Lughnasadh (~1 August).\n\nFrom the 18th century to the mid 20th century, many accounts of Imbolc or St Brigid's Day were recorded by folklorists and other writers. They tell us how it was celebrated then, and shed light on how it may have been celebrated in the past.\nImbolc has traditionally been celebrated on 1 February. However, because the day was deemed to begin and end at sunset, the celebrations would start on what is now 31 January. It has also been argued that the timing of the festival was originally more fluid and based on seasonal changes. It has been associated with the onset of the lambing season (which could vary by as much as two weeks before or after 1 February), the beginning of the spring sowing, and the blooming of blackthorn.\n\nThe holiday was a festival of the hearth and home, and a celebration of the lengthening days and the early signs of spring. Celebrations often involved hearthfires, special foods, divination or watching for omens, candles or a bonfire if the weather permitted. Fire and purification were an important part of the festival. The lighting of candles and fires represented the return of warmth and the increasing power of the Sun over the coming months. A spring cleaning was also customary.\n\nHoly wells were visited at Imbolc, and at the other Gaelic festivals of Beltane and Lughnasa. Visitors to holy wells would pray for health while walking 'sunwise' around the well. They would then leave offerings, typically coins or clooties (see clootie well). Water from the well was used to bless the home, family members, livestock and fields.\n\nDonald Alexander Mackenzie also recorded that offerings were made \"to earth and sea\". The offering could be milk poured into the ground or porridge poured into the water, as a libation.\n\nImbolc is strongly associated with Saint Brigid (, modern Irish: ', modern Scottish Gaelic: ' or \"\", anglicised \"Bridget\"). Saint Brigid is thought to have been based on Brigid, a Gaelic goddess. The festival, which celebrates the onset of spring, is thought to be linked with Brigid in her role as a fertility goddess.\n\nOn Imbolc Eve, Brigid was said to visit virtuous households and bless the inhabitants. As Brigid represented the light half of the year, and the power that will bring people from the dark season of winter into spring, her presence was very important at this time of year.\n\nFamilies would have a special meal or supper on Imbolc Eve. This typically included food such as colcannon, sowans, dumplings, barmbrack and/or bannocks. Often, some of the food and drink would be set aside for Brigid.\n\nBrigid would be symbolically invited into the house and a bed would often be made for her. In the north of Ireland a family member, representing Brigid, would circle the home three times carrying rushes. They would then knock the door three times, asking to be let in. On the third attempt they are welcomed in, the meal is had, and the rushes are then made into a bed or crosses. In 18th century Mann, the custom was to stand at the door with a bundle of rushes and say \"Brede, Brede, come to my house tonight. Open the door for Brede and let Brede come in\". The rushes were then strewn on the floor as a carpet or bed for Brigid. In the 19th century, some old Manx women would make a bed for Brigid in the barn with food, ale, and a candle on a table. In the Hebrides in the late 18th century, a bed of hay would be made for Brigid and someone would then call out three times: \"'\" (\", come in; thy bed is ready\"). A white wand, usually made of birch, would be set by the bed. It represented the wand that Brigid was said to use to make the vegetation start growing again. In the 19th century, women in the Hebrides would dance while holding a large cloth and calling out \"'\" (\", come over and make your bed\"). However, by this time the bed itself was rarely made.\n\nBefore going to bed, people would leave items of clothing or strips of cloth outside for Brigid to bless. Ashes from the fire would be raked smooth and, in the morning, they would look for some kind of mark on the ashes as a sign that Brigid had visited. The clothes or strips of cloth would be brought inside, and believed to now have powers of healing and protection.\n\nIn Ireland and Scotland, a representation of Brigid would be paraded around the community by girls and young women. Usually it was a doll-like figure known as a ' (also called a 'Breedhoge' or 'Biddy'). It would be made from rushes or reeds and clad in bits of cloth, flowers and/or shells. In the Hebrides of Scotland, a bright shell or crystal called the ' (guiding star of Brigid) was set on its chest. The girls would carry it in procession while singing a hymn to Brigid. All wore white with their hair unbound as a symbol of purity and youth. They visited every house in the area, where they received either food or more decoration for the . Afterwards, they feasted in a house with the set in a place of honour, and put it to bed with lullabies. In the late 17th century, Catholic families in the Hebrides would make a bed for the out of a basket. When the meal was done, the local young men humbly asked for admission, made obeisance to the , and joined the girls in dancing and merrymaking. In many places, only unwed girls could carry the , but in some both boys and girls carried it. Sometimes, rather than carrying a , a girl impersonated Brigid. Escorted by other girls, she went house-to-house wearing 'Brigid's crown' and carrying 'Brigid's shield' and 'Brigid's cross', all of which were made from rushes. The procession in some places included 'strawboys', who wore conical straw hats, masks and played folk music; much like the wrenboys. Up until the mid-20th century, children in Ireland still went house-to-house asking for pennies for \"poor Biddy\", or money for the poor. In County Kerry, men in white robes went from house to house singing.\n\nIn Ireland, Brigid's crosses (\"pictured on the right\") were made at Imbolc. A Brigid's cross usually consists of rushes woven into a four-armed equilateral cross, although three-armed crosses have also been recorded. They were often hung over doors, windows and stables to welcome Brigid and for protection against fire, lightning, illness and evil spirits. The crosses were generally left there until the next Imbolc. In western , people would make a \"\" ('s girdle); a great ring of rushes with a cross woven in the middle. Young boys would carry it around the village, inviting people to step through it and so be blessed.\n\nToday, some people still make Brigid's crosses and s or visit holy wells dedicated to St Brigid on 1 February. Brigid's Day parades have been revived in the town of Killorglin, County Kerry, which holds a yearly \"Biddy's Day Festival\". Men and women wearing elaborate straw hats and masks visit public houses carrying a to bring good luck for the coming year. They play folk music, dance and sing. The highlight of this festival is a torchlight parade through the town followed by a song and dance contest.\n\nImbolc was traditionally a time of weather divination, and the old tradition of watching to see if serpents or badgers came from their winter dens may be a forerunner of the North American Groundhog Day. A Scottish Gaelic proverb about the day is:\nImbolc was believed to be when the —the divine hag of Gaelic tradition—gathers her firewood for the rest of the winter. Legend has it that if she wishes to make the winter last a good while longer, she will make sure the weather on Imbolc is bright and sunny, so she can gather plenty of firewood. Therefore, people would be relieved if Imbolc is a day of foul weather, as it means the is asleep and winter is almost over. At Imbolc on the Isle of Man, where she is known as \"\", the is said to take the form of a gigantic bird carrying sticks in her beak.\n\nImbolc or Imbolc-based festivals are held by some Neopagans. As there are many kinds of Neopaganism, their Imbolc celebrations can be very different despite the shared name. Some try to emulate the historic festival as much as possible. Other Neopagans base their celebrations on many sources, with historic accounts of Imbolc being only one of them.\n\nNeopagans usually celebrate Imbolc on 1 February in the Northern Hemisphere and 1 August in the Southern Hemisphere. Some Neopagans celebrate it at the astronomical midpoint between the winter solstice and spring equinox (or the full moon nearest this point). In the Northern Hemisphere, this is usually on 3 or 4 February. Other Neopagans celebrate Imbolc when the primroses, dandelions, and other spring flowers emerge.\n\nCeltic Reconstructionists strive to reconstruct the pre-Christian religions of the Celts. Their religious practices are based on research and historical accounts, but may be modified slightly to suit modern life. They avoid syncretism (i.e. combining practises from different cultures). They usually celebrate the festival when the first stirrings of spring are felt, or on the full moon nearest this. Many use traditional songs and rites from sources such as \"The Silver Bough\" and \"The Carmina Gadelica\". It is a time of honouring the Goddess Brigid, and many of her dedicants choose this time of year for rituals to her.\n\nWiccans and Neo-Druids celebrate Imbolc as one of the eight Sabbats in their Wheel of the Year, following Midwinter and preceding Ostara. In Wicca, Imbolc is commonly associated with the goddess Brigid and as such it is sometimes seen as a \"women's holiday\" with specific rites only for female members of a coven. Among Dianic Wiccans, Imbolc is the traditional time for initiations.\n\nBULLET::::- Vasant Panchami\nBULLET::::- Candlemas\nBULLET::::- Irish calendar\nBULLET::::- Wheel of the Year\n\nBULLET::::- Carmichael, Alexander (1992) \"Carmina Gadelica: Hymns and Incantations\" (with illustrative notes on wards, rites, and customs dying and obsolete/ orally collected in the Highlands and Islands of Scotland) Hudson, NY, Lindisfarne Press,\nBULLET::::- Chadwick, Nora (1970) \"The Celts\" London, Penguin.\nBULLET::::- Danaher, Kevin (1972) \"The Year in Ireland\". Dublin, Mercier.\nBULLET::::- McNeill, F. Marian (1959) \"The Silver Bough\", Vol. 1–4. William MacLellan, Glasgow\nBULLET::::- Ó Catháin, Séamas (1995) \"Festival of Brigit\"\n\nBULLET::::- Introduction to Celtic Majesty of Brigid – The Feast of Imbolg\nBULLET::::- The Festival of Brigit the Holy Woman (\"Oiche Fhéile Bríde agus Lá Lúnasa\")\nBULLET::::- Imbolc lore from the \"Carmina Gadelica\"\nBULLET::::- Imbolc (Imbolg) and Candlemas – Witches' Sabbat and Pagan Tradition\nBULLET::::- Lá Féile Bríde – Kildare Education Centre\nBULLET::::- Lá Fhéile Bríde – Celtic Reconstructionist Imbolg Ritual\nBULLET::::- Saint Brigid & Spring – bilingual, Irish folklore\n\nBULLET::::- Imbolc Fire Festival – Marsden, Huddersfield by Gary Stevenson\nBULLET::::- Imbolc – Inspiration for the Year – Conference \"as gaeilge\", Ionad Cultúrtha, Ballyvourney, Co. Cork.\n"}
{"id": "15088", "url": "https://en.wikipedia.org/wiki?curid=15088", "title": "Isaiah", "text": "Isaiah\n\nIsaiah was the 8th-century BCE Israelite prophet after whom the Book of Isaiah is named. \n\nWithin the text of the Book of Isaiah, Isaiah himself is referred to as \"the prophet\", but the exact relationship between the Book of Isaiah and any such historical Isaiah is complicated. The traditional view is that all 66 chapters of the book of Isaiah were written by one man, Isaiah, possibly in two periods between 740 BC and c. 686 BC, separated by approximately 15 years, and includes dramatic prophetic declarations of Cyrus the Great in the Bible, acting to restore the nation of Israel from Babylonian captivity. Another widely held view is that parts of the first half of the book (chapters 1–39) originated with the historical prophet, interspersed with prose commentaries written in the time of King Josiah a hundred years later, and that the remainder of the book dates from immediately before and immediately after the end of the exile in Babylon, almost two centuries after the time of the historical prophet.\n\nThe first verse of the Book of Isaiah states that Isaiah prophesied during the reigns of Uzziah (or Azariah), Jotham, Ahaz, and Hezekiah, the kings of Judah (). Uzziah's reign was 52 years in the middle of the 8th century BC, and Isaiah must have begun his ministry a few years before Uzziah's death, probably in the 740s BC. Isaiah lived until the fourteenth year of Hezekiah's reign (who died 698 BC). He may have been contemporary for some years with Manasseh. Thus Isaiah may have prophesied for as long as 64 years.\n\nAccording to some modern interpretations, Isaiah's wife was called \"the prophetess\" (), either because she was endowed with the prophetic gift, like Deborah () and Huldah (), or simply because she was the \"wife of the prophet\". They had three sons, naming the eldest Shear-jashub, meaning \"A remnant shall return\" (), the next Immanuel, meaning \"God with us\" (), and the youngest, Maher-Shalal-Hash-Baz, meaning, \"Spoil quickly, plunder speedily\" ().\nSoon after this, Shalmaneser V determined to subdue the kingdom of Israel, taking over and destroying Samaria (722 BC). So long as Ahaz reigned, the kingdom of Judah was untouched by the Assyrian power. But when Hezekiah gained the throne, he was encouraged to rebel \"against the king of Assyria\" (), and entered into an alliance with the king of Egypt (). The king of Assyria threatened the king of Judah, and at length invaded the land. Sennacherib (701 BC) led a powerful army into Judah. Hezekiah was reduced to despair, and submitted to the Assyrians (). But after a brief interval, war broke out again. Again Sennacherib led an army into Judah, one detachment of which threatened Jerusalem (; ). Isaiah on that occasion encouraged Hezekiah to resist the Assyrians (), whereupon Sennacherib sent a threatening letter to Hezekiah, which he \"spread before the LORD\" ().\n\nAccording to the account in 2 Kings 19 (and its derivative account in 2 Chronicles 32) an angel of God fell on the Assyrian army and 185,000 of its men were killed in one night. \"Like Xerxes in Greece, Sennacherib never recovered from the shock of the disaster in Judah. He made no more expeditions against either the Southern Levant or Egypt.\"\n\nThe remaining years of Hezekiah's reign were peaceful (). Isaiah probably lived to its close, and possibly into the reign of Manasseh. The time and manner of his death are not specified in either the Bible or other primary sources. The Talmud [Yevamot 49b] says that he suffered martyrdom by being sawn in two under the orders of Manasseh. According to rabbinic literature, Isaiah was the maternal grandfather of Manasseh.\n\nThe book of Isaiah, along with the book of Jeremiah, is distinctive in the Hebrew bible for its direct portrayal of the \"wrath of the Lord\" as presented, for example, in Isaiah 9:19 stating, \"Through the wrath of the Lord of hosts is the land darkened, and the people shall be as the fuel of the fire.\"\n\nThe prophet Isaiah lived around 700 years before Jesus Christ.\n\nThe Ascension of Isaiah, a pseudepigraphical Christian text dated to sometime between the end of the 1st century to the beginning of the 3rd, gives a detailed story of Isaiah confronting an evil false prophet and ending with Isaiah being martyred – none of which is attested in the original Biblical account. \n\nGregory of Nyssa (c. 335–395), believed that the Prophet Isaiah \"knew more perfectly than all others the mystery of the religion of the Gospel\". Jerome (c. 342–420) also lauds the Prophet Isaiah, saying, \"He was more of an Evangelist than a Prophet, because he described all of the Mysteries of the Church of Christ so vividly that you would assume he was not prophesying about the future, but rather was composing a history of past events.\" Of specific note are the songs of the Suffering Servant, which Christians say are a direct prophetic revelation of the nature, purpose, and detail of the death of Jesus Christ.\n\nThe Book of Isaiah is quoted many times by New Testament writers. Ten of those references are about the Suffering Servant, how he will suffer and die to save many from their sins, be buried in a rich man's tomb, and be a light to the Gentiles. The Gospel of John says that Isaiah \"saw Jesus’ glory and spoke about him.\"\n\nThe Eastern Orthodox Church celebrates Saint Isaiah the Prophet on May 9.\n\nThe Book of Mormon quotes Jesus Christ as stating that \"great are the words of Isaiah\", and that all things prophesied by Isaiah have been and will be fulfilled. The Book of Mormon and Doctrine and Covenants also quote Isaiah more than any other prophet from the Old Testament. Additionally, members of The Church of Jesus Christ of Latter-day Saints consider the founding of the church by Joseph Smith in the 19th century to be a fulfillment of Isaiah 11, the translation of the Book of Mormon to be a fulfillment of Isaiah 29, and the building of Latter-day Saint temples as a fulfillment of Isaiah 2:2.\n\nIsaiah, or his Arabic name أشعياء (transliterated: \"Ashiʻyā), is not mentioned by name in the Qur'an or the Hadith, but appears frequently as a prophet in Islamic sources, such as Qisas Al-Anbiya and Tafsir. Tabari (310/923) provides the typical accounts for Islamic traditions regarding Isaiah. He is further mentioned and accepted as a prophet by other Islamic scholars such as Ibn Kathir, Al-Tha`labi and Kisa'i and also modern scholars such as Muhammad Asad and Abdullah Yusuf Ali. Isaiah is notable for his predictions of the coming of Jesus and Muhammad. Isaiah's narrative in Islamic literature can be divided into three sections. The first establishes Isaiah as a prophet of Israel during the reign of Hezekiah; the second relates Isaiah's actions during the siege of Jerusalem by Sennacherib; and the third warns the nation of coming doom. \nParalleling the Hebrew Bible, Islamic tradition states that Hezekiah was king in Jerusalem during Isaiah's time. Hezekiah heard and obeyed Isaiah's advice, but could not quell the turbulence in Israel. This tradition maintains that Hezekiah was a righteous man and that the turbulence worsened after him. After the death of the king, Isaiah told the people not to forsake God, and warned Israel to cease from its persistent sin and disobedience. Muslim tradition maintains that the unrighteous of Israel in their anger sought to kill Isaiah. In a death that resembles that attributed to Isaiah in \"Lives of the Prophets\", Muslim exegesis recounts that Isaiah was martyred by Israelites by being sawn in two.\n\nIn the courts of Al-Ma'mun, the seventh Abbasid caliph, Ali al-Ridha, the great grandson of Muhammad and prominent scholar (Imam) of his era, was questioned by the High Jewish Rabbi to prove through the Torah that both Jesus and Muhammad were prophets. Among his several proofs, the Imam references the Book of Isaiah, stating \"Sha‘ya (Isaiah), the Prophet, said in the Torah concerning what you and your companions say: ‘I have seen two riders to whom (He) illuminated earth. One of them was on a donkey and the other was on a camel. Who is the rider of the donkey, and who is the rider of the camel?'\" The Rabbi was unable to answer with certainty. Al-Ridha goes on to state that \"As for the rider of the donkey, he is ‘Isa (Jesus); and as for the rider of the camel, he is Muhammad, may Allah bless him and his family. Do you deny that this (statement) is in the Torah?\" The Rabbi responds \"No, I do not deny it.\" \n\nAccording to the rabbinic literature, Isaiah was a descendant of the royal house of Judah and Tamar (Sotah 10b). He was the son of Amoz (not to be confused with Prophet Amos), who was the brother of King Amaziah of Judah. (Talmud tractate Megillah 15a).\n\nIn February 2018 archaeologist Eilat Mazar announced that she and her team had discovered a small seal impression which reads \"[belonging] to Isaiah nvy\" (could be reconstructed and read as \"[belonging] to Isaiah the prophet\") during the Ophel excavations, just south of the Temple Mount in Jerusalem. The tiny bulla was found \"only 10 feet away\" from where an intact bulla bearing the inscription \"[belonging] to King Hezekiah of Judah\" was discovered in 2015 by the same team. Although the name \"Isaiah\" in Paleo-Hebrew alphabet is unmistakable, the damage on the bottom left part of the seal causes difficulties in confirming the word \"prophet\" or a common Hebrew name \"Navi\", casting some doubts whether this seal really belongs to the prophet Isaiah.\n\n\n"}
{"id": "15089", "url": "https://en.wikipedia.org/wiki?curid=15089", "title": "Interpreted language", "text": "Interpreted language\n\nAn interpreted language is a type of programming language for which most of its implementations execute instructions directly and freely, without previously compiling a program into machine-language instructions. The interpreter executes the program directly, translating each statement into a sequence of one or more subroutines, and then into another language (often machine code).\n\nThe terms \"interpreted language\" and \"compiled language\" are not well defined because, in theory, any programming language can be either interpreted or compiled. In modern programming language implementation, it is increasingly popular for a platform to provide both options.\n\nInterpreted languages can also be contrasted with machine languages. Functionally, both execution and interpretation mean the same thing — fetching the next instruction/statement from the program and executing it. Although interpreted byte code is additionally identical to machine code in form and has an assembler representation, the term \"interpreted\" is sometimes reserved for \"software processed\" languages (by virtual machine or emulator) on top of the native (i.e. hardware) processor.\n\nIn principle, programs in many languages may be compiled or interpreted, emulated or executed natively, so this designation is applied solely based on common implementation practice, rather than representing an essential property of a language.\n\nMany languages have been implemented using both compilers and interpreters, including BASIC, C, Lisp, and Pascal. Java and C# are compiled into bytecode, the virtual-machine-friendly interpreted language. Lisp implementations can freely mix interpreted and compiled code.\n\nThe distinction between a compiler and an interpreter is not always well defined, and many language processors do a combination of both.\n\nIn the early days of computing, language design was heavily influenced by the decision to use compiling or interpreting as a mode of execution. For example, Smalltalk (1980), which was designed to be interpreted at run-time, allows generic objects to dynamically interact with each other.\n\nInitially, interpreted languages were compiled line-by-line; that is, each line was compiled as it was about to be executed, and if a loop or subroutine caused certain lines to be executed multiple times, they would be recompiled every time. This has become much less common. Most so-called interpreted languages use an intermediate representation, which combines compiling and interpreting.\n\nExamples include: \nBULLET::::- JavaScript\nBULLET::::- Perl\nBULLET::::- Python\nBULLET::::- BASIC\nBULLET::::- Forth\n\nThe intermediate representation can be compiled once and for all (as in Java), each time before execution (as in Ruby), or each time a change in the source is detected before execution (as in Python).\n\nInterpreting a language gives implementations some additional flexibility over compiled implementations. Features that are often easier to implement in interpreters than in compilers include:\nBULLET::::- platform independence (Java's byte code, for example)\nBULLET::::- reflection and reflective use of the evaluator (e.g. a first-order eval function)\nBULLET::::- dynamic typing\nBULLET::::- smaller executable program size (since implementations have flexibility to choose the instruction code)\nBULLET::::- dynamic scoping\n\nFurthermore, source code can be read and copied, giving users more freedom.\n\nDisadvantages of interpreted languages are:\nBULLET::::- Without static type-checking, which is usually performed by a compiler, programs can be less reliable, because type checking eliminates a class of programming errors (though type-checking of the code can be done by using additional stand-alone tools. See TypeScript for instance)\nBULLET::::- Interpreters can be susceptible to Code injection attacks.\nBULLET::::- Slower execution compared to direct native machine code execution on the host CPU. A technique used to improve performance is just-in-time compilation which converts frequently executed sequences of interpreted instruction to host machine code. JIT is most often combined with compilation to byte-code as in Java.\nBULLET::::- Source code can be read and copied (e.g. JavaScript in web pages), or more easily reverse engineered through reflection in applications where intellectual property has a commercial advantage. In some cases, obfuscation is used as a partial defense against this.\n\nSeveral criteria can be used to determine whether a particular language is likely to be called compiled or interpreted by its users:\n\nBULLET::::- If a subroutine can be invoked prior to where it's defined in the source code, the entire source is likely being compiled to an intermediate representation before execution. Examples: Perl, Java\nBULLET::::- If an intermediate representation (e.g. bytecode) is typically created and invoked directly as a separate step when executing the code, the language is likely to be considered compiled. Examples: Java, C\nBULLET::::- If a syntax error in the source code doesn't prevent prior statements from being executed, it's likely an interpreted paradigm. Examples: Unix shell languages\n\nThese are not definitive. Compiled languages can have interpreter-like properties and vice versa.\n\nBULLET::::- APL A vector oriented language using an unusual character set\nBULLET::::- J An APL variant in which tacit definition provides some of the benefits of compiling\nBULLET::::- BASIC (although the original version, Dartmouth BASIC, was compiled, as are many modern BASICs)\nBULLET::::- Equation manipulation and solving systems\nBULLET::::- GNU Octave\nBULLET::::- Interactive Data Language (IDL)\nBULLET::::- TK Solver\nBULLET::::- Mathematica\nBULLET::::- MATLAB\nBULLET::::- Euphoria Interpreted or compiled.\nBULLET::::- GameMaker Language Bytecode after GameMaker: Studio.\nBULLET::::- JavaScript\nBULLET::::- Forth\nBULLET::::- Lava\nBULLET::::- Lisp\nBULLET::::- Logo\nBULLET::::- Scheme\nBULLET::::- MUMPS\nBULLET::::- PHP\nBULLET::::- PostScript\nBULLET::::- PowerShell\nBULLET::::- Ruby\nBULLET::::- REXX\nBULLET::::- Seed7\nBULLET::::- Smalltalk\nBULLET::::- Spreadsheets\nBULLET::::- Excel\nBULLET::::- S\nBULLET::::- R\nBULLET::::- Tcl\nBULLET::::- Unix shell\nBULLET::::- XOTcl\nBULLET::::- VBScript\nBULLET::::- XMLmosaic – an xml contained C# like programming language interpreted by a console application written in Visual Basic .NET\n\nMany languages are first compiled to bytecode. Sometimes, bytecode can also be compiled to a native binary using an AOT compiler or executed natively, by hardware processor.\nBULLET::::- AppleScript\nBULLET::::- Erlang (compiled into Erlang bytecode and interpreted by the BEAM VM)\nBULLET::::- Elixir (runs on the Erlang VM)\nBULLET::::- Java (is compiled into Java bytecode to be interpreted by JVM)\nBULLET::::- Clojure\nBULLET::::- Groovy\nBULLET::::- Kotlin\nBULLET::::- ColdFusion\nBULLET::::- Scala\nBULLET::::- .NET Framework languages (translated to bytecode, called CIL).\nBULLET::::- C++/CLI\nBULLET::::- C#\nBULLET::::- Visual Basic .NET\nBULLET::::- F#\nBULLET::::- Lisp\nBULLET::::- Lua\nBULLET::::- Perl\nBULLET::::- Pike\nBULLET::::- Python (compiled into Python bytecode and interpreted by CPython)\nBULLET::::- Squeak Smalltalk\nBULLET::::- Visual FoxPro\n\nBULLET::::- List of interpreted languages\nBULLET::::- Compiled language\nBULLET::::- Executable\nBULLET::::- Managed code\nBULLET::::- Scripting language\n"}
{"id": "15095", "url": "https://en.wikipedia.org/wiki?curid=15095", "title": "Intifada", "text": "Intifada\n\nAn intifada ( \"\") is a rebellion or uprising, or a resistance movement. It is a key concept in contemporary Arabic usage referring to a legitimate uprising against oppression.\n\n\"Intifada\" is an Arabic word literally meaning, as a noun, \"tremor\", \"shivering\", \"shuddering\". It is derived from an Arabic term \"nafada\" meaning \"to shake\", \"shake off\", \"get rid of\", as a dog might shrug off water, or as one might shake off sleep, or dirt from one's sandals.\n\nThe concept intifada was first utilized in modern times in 1952 within the Kingdom of Iraq, when socialist and communist parties took to the streets to protest the Hashemite monarchy, with inspiration of the 1952 Egyptian Revolution. \n\nThe concept was adopted in Western Sahara, with the gradual withdrawal of Spanish forces in the 1970s as the Zemla Intifada, but was essentially rooted into the Western Sahara conflict with the First Sahrawi Intifada - protests by Sahrawi activists in the Western Sahara, south of Morocco (1999–2004), Independence Intifada (Western Sahara) or Second Sahrawi Intifada and finally the Gdeim Izik protests in 2011.\n\nIn the Palestinian context, the word refers to attempts to \"shake off\" the Israeli occupation of the West Bank and Gaza Strip in the First and Second Intifadas, where it was originally chosen to connote \"aggressive nonviolent resistance\", a meaning it bore among Palestinian students in struggles in the 1980s and which they adopted as less confrontational than terms in earlier militant rhetoric since it bore no nuance of violence.\n\nIntifada may be used to refer to these events:\nBULLET::::- Iraqi Intifada, a series of strikes and riots in Iraq in 1952, aimed against the Hashemite monarchy rule\nBULLET::::- October Revolution, a series of strikes, riots, and demonstrations in Sudan, that ended with the dissolution of the Abbud military regime and the beginning of second civilian rule in 1964\nBULLET::::- March Intifada, a leftist uprising against the British colonial presence in Bahrain in March 1965\nBULLET::::- Zemla Intifada, against Spanish colonial rule in then Spanish Sahara, in June 1970\nBULLET::::- In Lebanese internal conflicts:\nBULLET::::- February 6 Intifada (1984), during the Lebanese Civil War\nBULLET::::- Cedar Revolution or \"Intifada of Independence\", the events in Lebanon after Rafic Hariri's 2005 assassination\nBULLET::::- In the Israeli–Palestine conflict:\nBULLET::::- First Intifada, a Palestinian uprising against the Israeli occupation lasting from December 1987 to 1993\nBULLET::::- Al-Aqsa Intifada, a period of intensified Israeli-Palestinian violence, which began in late September 2000 and ended around 2005\nBULLET::::- 2014 Jerusalem unrest, a series of violent acts and attacks in Jerusalem in 2014 sometimes referred to as \"Intifada\"\nBULLET::::- Israeli–Palestinian conflict (2015) – 2015 escalation in Israeli–Palestinian conflict, sometimes referred to as \"Al-Quds Intifada\" or \"Jerusalem Intifada\" or \"Knife Intifada\"\nBULLET::::- 1990s uprising in Bahrain, an uprising demanding a return to democratic rule, also known as the \"1990s Intifada\"\nBULLET::::- 1991 uprisings in Iraq, an armed uprising against Saddam Hussein in Iraq, also known as \"Iraqi Intifada of 1991\"\nBULLET::::- In the Western Sahara conflict:\nBULLET::::- First Sahrawi Intifada, protests by Sahrawi activists in the Western Sahara, south of Morocco (1999–2004)\nBULLET::::- Independence Intifada (Western Sahara) or Second Sahrawi Intifada, demonstrations and riots in Western Sahara, south of Morocco, beginning in May 2005\nBULLET::::- Gdeim Izik protests, also referred as Third Sahrawi Intifada or simply Third Inifada\nBULLET::::- 2005 French riots often referred as \"French Intifada\"\nBULLET::::- Arab Spring, a revolutionary wave which began on 18 December 2010 in Tunisia, sometimes referred to as \"Intifada\":\nBULLET::::- Tunisian Revolution, or Tunisian Intifada\nBULLET::::- 2011 Yemeni Revolution, or Yemeni Intifada\nBULLET::::- Egyptian Revolution of 2011, or Egyptian Intifada\nBULLET::::- Protests in Sudan (2011–13), or Sudanese Intifada\nBULLET::::- 2018–19 Arab protests\nBULLET::::- 2019 Lebanese protests, nicknamed the Tax Intifada\nBULLET::::- October 2019 Iraqi protests, nicknamed Iraqi Intifada\n\nBULLET::::- \" The Electronic Intifada\", an online publication which covers the Israeli–Palestinian conflict from a Palestinian perspective\n\nBULLET::::- Andrew Hussey, book 'The French Intifada: how the Arab banlieues are fighting the French state,' The Guardian 23 February 2014\n"}
{"id": "15097", "url": "https://en.wikipedia.org/wiki?curid=15097", "title": "Ionosphere", "text": "Ionosphere\n\nThe ionosphere () is the ionized part of Earth's upper atmosphere, from about to altitude, a region that includes the thermosphere and parts of the mesosphere and exosphere. The ionosphere is ionized by solar radiation. It plays an important role in atmospheric electricity and forms the inner edge of the magnetosphere. It has practical importance because, among other functions, it influences radio propagation to distant places on the Earth. The region below the ionosphere is called neutral atmosphere, or neutrosphere.\n\nAs early as 1839, the German mathematician and physicist Carl Friedrich Gauss postulated that an electrically conducting region of the atmosphere could account for observed variations of Earth's magnetic field. Sixty years later, Guglielmo Marconi received the first trans-Atlantic radio signal on December 12, 1901, in St. John's, Newfoundland (now in Canada) using a kite-supported antenna for reception. The transmitting station in Poldhu, Cornwall, used a spark-gap transmitter to produce a signal with a frequency of approximately 500 kHz and a power of 100 times more than any radio signal previously produced. The message received was three dits, the Morse code for the letter S. To reach Newfoundland the signal would have to bounce off the ionosphere twice. Dr. Jack Belrose has contested this, however, based on theoretical and experimental work. However, Marconi did achieve transatlantic wireless communications in Glace Bay, Nova Scotia, one year later.\n\nIn 1902, Oliver Heaviside proposed the existence of the Kennelly–Heaviside layer of the ionosphere which bears his name. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. . Also in 1902, Arthur Edwin Kennelly discovered some of the ionosphere's radio-electrical properties.\n\nIn 1912, the U.S. Congress imposed the Radio Act of 1912 on amateur radio operators, limiting their operations to frequencies above 1.5 MHz (wavelength 200 meters or smaller). . This led to the discovery of HF radio propagation via the ionosphere in 1923.\n\nIn 1926, Scottish physicist Robert Watson-Watt introduced the term \"ionosphere\" in a letter published only in 1969 in \"Nature\":\n\nIn the early 1930s, test transmissions of Radio Luxembourg inadvertently provided evidence of the first radio modification of the ionosphere; HAARP ran a series of experiments in 2017 using the eponymous Luxembourg Effect.\n\nEdward V. Appleton was awarded a Nobel Prize in 1947 for his confirmation in 1927 of the existence of the ionosphere. Lloyd Berkner first measured the height and density of the ionosphere. This permitted the first complete theory of short-wave radio propagation. Maurice V. Wilkes and J. A. Ratcliffe researched the topic of radio propagation of very long radio waves in the ionosphere. Vitaly Ginzburg has developed a theory of electromagnetic wave propagation in plasmas such as the ionosphere.\n\nIn 1962, the Canadian satellite Alouette 1 was launched to study the ionosphere. Following its success were Alouette 2 in 1965 and the two ISIS satellites in 1969 and 1971, further AEROS-A and -B in 1972 and 1975, all for measuring the ionosphere.\n\nOn July 26, 1963 the first operational geosynchronous satellite Syncom 2 was launched. The board radio beacons on this satellite (and its successors) enabled – for the first time – the measurement of total electron content (TEC) variation along a radio beam from geostationary orbit to an earth receiver. (The rotation of the plane of polarization directly measures TEC along the path.) Australian geophysicist Elizabeth Essex-Cohen from 1969 onwards was using this technique to monitor the atmosphere above Australia and Antarctica.\n\nThe ionosphere is a shell of electrons and electrically charged atoms and molecules that surrounds the Earth, stretching from a height of about to more than . It exists primarily due to ultraviolet radiation from the Sun.\n\nThe lowest part of the Earth's atmosphere, the troposphere extends from the surface to about . Above that is the stratosphere, followed by the mesosphere. In the stratosphere incoming solar radiation creates the ozone layer. At heights of above , in the thermosphere, the atmosphere is so thin that free electrons can exist for short periods of time before they are captured by a nearby positive ion. The number of these free electrons is sufficient to affect radio propagation. This portion of the atmosphere is partially \"ionized\" and contains a plasma which is referred to as the ionosphere.\n\nUltraviolet (UV), X-ray and shorter wavelengths of solar radiation are \"ionizing,\" since photons at these frequencies contain sufficient energy to dislodge an electron from a neutral gas atom or molecule upon absorption. In this process the light electron obtains a high velocity so that the temperature of the created electronic gas is much higher (of the order of thousand K) than the one of ions and neutrals. The reverse process to ionization is recombination, in which a free electron is \"captured\" by a positive ion. Recombination occurs spontaneously, and causes the emission of a photon carrying away the energy produced upon recombination. As gas density increases at lower altitudes, the recombination process prevails, since the gas molecules and ions are closer together. The balance between these two processes determines the quantity of ionization present.\n\nIonization depends primarily on the Sun and its activity. The amount of ionization in the ionosphere varies greatly with the amount of radiation received from the Sun. Thus there is a diurnal (time of day) effect and a seasonal effect. The local winter hemisphere is tipped away from the Sun, thus there is less received solar radiation. The activity of the Sun is associated with the sunspot cycle, with more radiation occurring with more sunspots. Radiation received also varies with geographical location (polar, auroral zones, mid-latitudes, and equatorial regions). There are also mechanisms that disturb the ionosphere and decrease the ionization. There are disturbances such as solar flares and the associated release of charged particles into the solar wind which reaches the Earth and interacts with its geomagnetic field.\n\nAt night the F layer is the only layer of significant ionization present, while the ionization in the E and D layers is extremely low. During the day, the D and E layers become much more heavily ionized, as does the F layer, which develops an additional, weaker region of ionisation known as the F layer. The F layer persists by day and night and is the main region responsible for the refraction and reflection of radio waves.\n\nThe D layer is the innermost layer, to above the surface of the Earth. Ionization here is due to Lyman series-alpha hydrogen radiation at a wavelength of 121.6 nanometre (nm) ionizing nitric oxide (NO). In addition, high solar activity can generate hard X-rays (wavelength ) that ionize N and O. Recombination rates are high in the D layer, so there are many more neutral air molecules than ions.\n\nMedium frequency (MF) and lower high frequency (HF) radio waves are significantly attenuated within the D layer, as the passing radio waves cause electrons to move, which then collide with the neutral molecules, giving up their energy. Lower frequencies experience greater absorption because they move the electrons farther, leading to greater chance of collisions. This is the main reason for absorption of HF radio waves, particularly at 10 MHz and below, with progressively less absorption at higher frequencies. This effect peaks around noon and is reduced at night due to a decrease in the D layer's thickness; only a small part remains due to cosmic rays. A common example of the D layer in action is the disappearance of distant AM broadcast band stations in the daytime.\n\nDuring solar proton events, ionization can reach unusually high levels in the D-region over high and polar latitudes. Such very rare events are known as Polar Cap Absorption (or PCA) events, because the increased ionization significantly enhances the absorption of radio signals passing through the region. In fact, absorption levels can increase by many tens of dB during intense events, which is enough to absorb most (if not all) transpolar HF radio signal transmissions. Such events typically last less than 24 to 48 hours.\n\nThe E layer is the middle layer, to above the surface of the Earth. Ionization is due to soft X-ray (1–10 nm) and far ultraviolet (UV) solar radiation ionization of molecular oxygen (O). Normally, at oblique incidence, this layer can only reflect radio waves having frequencies lower than about 10 MHz and may contribute a bit to absorption on frequencies above. However, during intense sporadic E events, the E layer can reflect frequencies up to 50 MHz and higher. The vertical structure of the E layer is primarily determined by the competing effects of ionization and recombination. At night the E layer weakens because the primary source of ionization is no longer present. After sunset an increase in the height of the E layer maximum increases the range to which radio waves can travel by reflection from the layer.\n\nThis region is also known as the Kennelly–Heaviside layer or simply the Heaviside layer. Its existence was predicted in 1902 independently and almost simultaneously by the American electrical engineer Arthur Edwin Kennelly (1861–1939) and the British physicist Oliver Heaviside (1850–1925). However, it was not until 1924 that its existence was detected by Edward V. Appleton and Miles Barnett.\n\nThe E layer (sporadic E-layer) is characterized by small, thin clouds of intense ionization, which can support reflection of radio waves, rarely up to 225 MHz. Sporadic-E events may last for just a few minutes to several hours. Sporadic E propagation makes VHF-operating radio amateurs very excited, as propagation paths that are generally unreachable can open up. There are multiple causes of sporadic-E that are still being pursued by researchers. This propagation occurs most frequently during the summer months when high signal levels may be reached. The skip distances are generally around . Distances for one hop propagation can be anywhere from to . Double-hop reception over is possible.\n\nThe F layer or region, also known as the Appleton–Barnett layer, extends from about to more than above the surface of Earth. It is the layer with the highest electron density, which implies signals penetrating this layer will escape into space. Electron production is dominated by extreme ultraviolet (UV, 10–100 nm) radiation ionizing atomic oxygen. The F layer consists of one layer (F) at night, but during the day, a secondary peak (labelled F) often forms in the electron density profile. Because the F layer remains by day and night, it is responsible for most skywave propagation of radio waves and long distance high frequency (HF, or shortwave) radio communications.\n\nAbove the F layer, the number of oxygen ions decreases and lighter ions such as hydrogen and helium become dominant. This region above the F layer peak and below the plasmasphere is called the topside ionosphere.\n\nFrom 1972 to 1975 NASA launched the AEROS and AEROS B satellites to study the F region.\n\nAn ionospheric model is a mathematical description of the ionosphere as a function of location, altitude, day of year, phase of the sunspot cycle and geomagnetic activity. Geophysically, the state of the ionospheric plasma may be described by four parameters: \"electron density, electron and ion temperature\" and, since several species of ions are present, \"ionic composition\". Radio propagation depends uniquely on electron density.\n\nModels are usually expressed as computer programs. The model may be based on basic physics of the interactions of the ions and electrons with the neutral atmosphere and sunlight, or it may be a statistical description based on a large number of observations or a combination of physics and observations. One of the most widely used models is the International Reference Ionosphere (IRI), which is based on data and specifies the four parameters just mentioned. The IRI is an international project sponsored by the Committee on Space Research (COSPAR) and the International Union of Radio Science (URSI). The major data sources are the worldwide network of ionosondes, the powerful incoherent scatter radars (Jicamarca, Arecibo, Millstone Hill, Malvern, St Santin), the ISIS and Alouette topside sounders, and in situ instruments on several satellites and rockets. IRI is updated yearly. IRI is more accurate in describing the variation of the electron density from bottom of the ionosphere to the altitude of maximum density than in describing the total electron content (TEC). Since 1999 this model is \"International Standard\" for the terrestrial ionosphere (standard TS16457).\n\nIonograms allow deducing, via computation, the true shape of the different layers. Nonhomogeneous structure of the electron/ion-plasma produces rough echo traces, seen predominantly at night and at higher latitudes, and during disturbed conditions.\n\nAt mid-latitudes, the F layer daytime ion production is higher in the summer, as expected, since the Sun shines more directly on the Earth. However, there are seasonal changes in the molecular-to-atomic ratio of the neutral atmosphere that cause the summer ion loss rate to be even higher. The result is that the increase in the summertime loss overwhelms the increase in summertime production, and total F ionization is actually lower in the local summer months. This effect is known as the winter anomaly. The anomaly is always present in the northern hemisphere, but is usually absent in the southern hemisphere during periods of low solar activity.\n\nWithin approximately ± 20 degrees of the \"magnetic equator\", is the \"equatorial anomaly\". It is the occurrence of a trough in the ionization in the F layer at the equator and crests at about 17 degrees in magnetic latitude. The Earth's magnetic field lines are horizontal at the magnetic equator. Solar heating and tidal oscillations in the lower ionosphere move plasma up and across the magnetic field lines. This sets up a sheet of electric current in the E region which, with the horizontal magnetic field, forces ionization up into the F layer, concentrating at ± 20 degrees from the magnetic equator. This phenomenon is known as the \"equatorial fountain\".\n\nThe worldwide solar-driven wind results in the so-called Sq (solar quiet) current system in the E region of the Earth's ionosphere (ionospheric dynamo region) ( altitude). Resulting from this current is an electrostatic field directed west–east (dawn–dusk) in the equatorial day side of the ionosphere. At the magnetic dip equator, where the geomagnetic field is horizontal, this electric field results in an enhanced eastward current flow within ± 3 degrees of the magnetic equator, known as the equatorial electrojet.\n\nWhen the Sun is active, strong solar flares can occur that hit the sunlit side of Earth with hard X-rays. The X-rays penetrate to the D-region, releasing electrons that rapidly increase absorption, causing a high frequency (3–30 MHz) radio blackout. During this time very low frequency (3–30 kHz) signals will be reflected by the D layer instead of the E layer, where the increased atmospheric density will usually increase the absorption of the wave and thus dampen it. As soon as the X-rays end, the sudden ionospheric disturbance (SID) or radio black-out ends as the electrons in the D-region recombine rapidly and signal strengths return to normal.\n\nAssociated with solar flares is a release of high-energy protons. These particles can hit the Earth within 15 minutes to 2 hours of the solar flare. The protons spiral around and down the magnetic field lines of the Earth and penetrate into the atmosphere near the magnetic poles increasing the ionization of the D and E layers. PCA's typically last anywhere from about an hour to several days, with an average of around 24 to 36 hours. Coronal mass ejections can also release energetic protons that enhance D-region absorption in the polar regions.\n\nA geomagnetic storm is a temporary intense disturbance of the Earth's magnetosphere.\nBULLET::::- During a geomagnetic storm the F₂ layer will become unstable, fragment, and may even disappear completely.\nBULLET::::- In the Northern and Southern pole regions of the Earth aurorae will be observable in the sky.\n\nLightning can cause ionospheric perturbations in the D-region in one of two ways. The first is through VLF (very low frequency) radio waves launched into the magnetosphere. These so-called \"whistler\" mode waves can interact with radiation belt particles and cause them to precipitate onto the ionosphere, adding ionization to the D-region. These disturbances are called \"lightning-induced electron precipitation\" (LEP) events.\n\nAdditional ionization can also occur from direct heating/ionization as a result of huge motions of charge in lightning strikes. These events are called early/fast.\n\nIn 1925, C. T. R. Wilson proposed a mechanism by which electrical discharge from lightning storms could propagate upwards from clouds to the ionosphere. Around the same time, Robert Watson-Watt, working at the Radio Research Station in Slough, UK, suggested that the ionospheric sporadic E layer (E) appeared to be enhanced as a result of lightning but that more work was needed. In 2005, C. Davis and C. Johnson, working at the Rutherford Appleton Laboratory in Oxfordshire, UK, demonstrated that the E layer was indeed enhanced as a result of lightning activity. Their subsequent research has focused on the mechanism by which this process can occur.\n\nDue to the ability of ionized atmospheric gases to refract high frequency (HF, or shortwave) radio waves, the ionosphere can reflect radio waves directed into the sky back toward the Earth. Radio waves directed at an angle into the sky can return to Earth beyond the horizon. This technique, called \"skip\" or \"skywave\" propagation, has been used since the 1920s to communicate at international or intercontinental distances. The returning radio waves can reflect off the Earth's surface into the sky again, allowing greater ranges to be achieved with multiple hops. This communication method is variable and unreliable, with reception over a given path depending on time of day or night, the seasons, weather, and the 11-year sunspot cycle. During the first half of the 20th century it was widely used for transoceanic telephone and telegraph service, and business and diplomatic communication. Due to its relative unreliability, shortwave radio communication has been mostly abandoned by the telecommunications industry, though it remains important for high-latitude communication where satellite-based radio communication is not possible. Some broadcasting stations and automated services still use shortwave radio frequencies, as do radio amateur hobbyists for private recreational contacts.\n\nWhen a radio wave reaches the ionosphere, the electric field in the wave forces the electrons in the ionosphere into oscillation at the same frequency as the radio wave. Some of the radio-frequency energy is given up to this resonant oscillation. The oscillating electrons will then either be lost to recombination or will re-radiate the original wave energy. Total refraction can occur when the collision frequency of the ionosphere is less than the radio frequency, and if the electron density in the ionosphere is great enough.\n\nA qualitative understanding of how an electromagnetic wave propagates through the ionosphere can be obtained by recalling geometric optics. Since the ionosphere is a plasma, it can be shown that the refractive index is less than unity. Hence, the electromagnetic \"ray\" is bent away from the normal rather than toward the normal as would be indicated when the refractive index is greater than unity. It can also be shown that the refractive index of a plasma, and hence the ionosphere, is frequency-dependent, see Dispersion (optics).\n\nThe critical frequency is the limiting frequency at or below which a radio wave is reflected by an ionospheric layer at vertical incidence. If the transmitted frequency is higher than the plasma frequency of the ionosphere, then the electrons cannot respond fast enough, and they are not able to re-radiate the signal. It is calculated as shown below:\n\nwhere N = electron density per m and f is in Hz.\n\nThe Maximum Usable Frequency (MUF) is defined as the upper frequency limit that can be used for transmission between two points at a specified time.\n\nwhere formula_3 = angle of attack, the angle of the wave relative to the horizon, and sin is the sine function.\n\nThe cutoff frequency is the frequency below which a radio wave fails to penetrate a layer of the ionosphere at the incidence angle required for transmission between two specified points by refraction from the layer.\n\nThe open system electrodynamic tether, which uses the ionosphere, is being researched. The space tether uses plasma contactors and the ionosphere as parts of a circuit to extract energy from the Earth's magnetic field by electromagnetic induction.\n\nScientists explore the structure of the ionosphere by a wide variety of methods. They include:\nBULLET::::- passive observations of optical and radio emissions generated in the ionosphere\nBULLET::::- bouncing radio waves of different frequencies from it\nBULLET::::- incoherent scatter radars such as the EISCAT, Sondre Stromfjord, Millstone Hill, Arecibo, Advanced Modular Incoherent Scatter Radar (AMISR) and Jicamarca radars\nBULLET::::- coherent scatter radars such as the Super Dual Auroral Radar Network (SuperDARN) radars,\nBULLET::::- special receivers to detect how the reflected waves have changed from the transmitted waves.\n\nA variety of experiments, such as HAARP (High Frequency Active Auroral Research Program), involve high power radio transmitters to modify the properties of the ionosphere. These investigations focus on studying the properties and behavior of ionospheric plasma, with particular emphasis on being able to understand and use it to enhance communications and surveillance systems for both civilian and military purposes. HAARP was started in 1993 as a proposed twenty-year experiment, and is currently active near Gakona, Alaska.\n\nThe SuperDARN radar project researches the high- and mid-latitudes using coherent backscatter of radio waves in the 8 to 20 MHz range. Coherent backscatter is similar to Bragg scattering in crystals and involves the constructive interference of scattering from ionospheric density irregularities. The project involves more than 11 different countries and multiple radars in both hemispheres.\n\nScientists are also examining the ionosphere by the changes to radio waves, from satellites and stars, passing through it. The Arecibo radio telescope located in Puerto Rico, was originally intended to study Earth's ionosphere.\n\nIonograms show the virtual heights and critical frequencies of the ionospheric layers and which are measured by an ionosonde. An ionosonde sweeps a range of frequencies, usually from 0.1 to 30 MHz, transmitting at vertical incidence to the ionosphere. As the frequency increases, each wave is refracted less by the ionization in the layer, and so each penetrates further before it is reflected. Eventually, a frequency is reached that enables the wave to penetrate the layer without being reflected. For ordinary mode waves, this occurs when the transmitted frequency just exceeds the peak plasma, or critical, frequency of the layer. Tracings of the reflected high frequency radio pulses are known as ionograms. Reduction rules are given in: \"URSI Handbook of Ionogram Interpretation and Reduction\", edited by William Roy Piggott and Karl Rawer, Elsevier Amsterdam, 1961 (translations into Chinese, French, Japanese and Russian are available).\n\nIncoherent scatter radars operate above the critical frequencies. Therefore, the technique allows probing the ionosphere, unlike ionosondes, also above the electron density peaks. The thermal fluctuations of the electron density scattering the transmitted signals lack coherence, which gave the technique its name. Their power spectrum contains information not only on the density, but also on the ion and electron temperatures, ion masses and drift velocities.\n\nRadio occultation is a remote sensing technique where a GNSS signal tangentially scrapes the Earth, passing through the atmosphere, and is received by a Low Earth Orbit (LEO) satellite. As the signal passes through the atmosphere, it is refracted, curved and delayed. An LEO satellite samples the total electron content and bending angle of many such signal paths as it watches the GNSS satellite rise or set behind the Earth. Using an Inverse Abel's transform, a radial profile of refractivity at that tangent point on earth can be reconstructed.\n\nMajor GNSS radio occultation missions include the GRACE, CHAMP, and COSMIC.\n\nIn empirical models of the ionosphere such as Nequick, the following indices are used as indirect indicators of the state of the ionosphere.\n\nF10.7 and R12 are two indices commonly used in ionospheric modelling. Both are valuable for their long historical records covering multiple solar cycles. F10.7 is a measurement of the intensity of solar radio emissions at a frequency of 2800 MHz made using a ground radio telescope. R12 is a 12 months average of daily sunspot numbers. Both indices have been shown to be correlated to each other.\n\nHowever, both indices are only indirect indicators of solar ultraviolet and X-ray emissions, which are primarily responsible for causing ionization in the Earth's upper atmosphere. We now have data from the GOES spacecraft that measures the background X-ray flux from the Sun, a parameter more closely related to the ionization levels in the ionosphere.\n\nBULLET::::- The \"A\"- and \"K\"-indices are a measurement of the behavior of the horizontal component of the geomagnetic field. The \"K\"-index uses a scale from 0 to 9 to measure the change in the horizontal component of the geomagnetic field. A new \"K\"-index is determined at the Boulder Geomagnetic Observatory.\nBULLET::::- The geomagnetic activity levels of the Earth are measured by the fluctuation of the Earth's magnetic field in SI units called teslas (or in non-SI gauss, especially in older literature). The Earth's magnetic field is measured around the planet by many observatories. The data retrieved is processed and turned into measurement indices. Daily measurements for the entire planet are made available through an estimate of the \"A\"-index, called the \"planetary A-index\" (PAI).\n\nThere are a number of models used to understand the effects of the ionosphere global navigation satellite systems. The Klobuchar model is currently used to compensate for ionospheric effects in GPS. This model was developed at the US Air Force Geophysical Research Laboratory circa 1974 by John (Jack) Klobuchar. The Galileo navigation system uses the NeQuick model.\n\nObjects in the Solar System that have appreciable atmospheres (i.e., all of the major planets and many of the larger natural satellites) generally produce ionospheres. Planets known to have ionospheres include Venus,\nUranus, Mars and Jupiter.\n\nThe atmosphere of Titan includes an ionosphere that ranges from about to in altitude and contains carbon compounds.\n\nBULLET::::- Geophysics\nBULLET::::- International Reference Ionosphere\nBULLET::::- Ionospheric dynamo region\nBULLET::::- Magnetospheric electric convection field\nBULLET::::- Protonosphere\nBULLET::::- Schumann resonances\nBULLET::::- Van Allen radiation belt\nBULLET::::- Radio\nBULLET::::- Earth–ionosphere waveguide\nBULLET::::- Fading\nBULLET::::- Ionospheric absorption\nBULLET::::- Ionospheric scintillation\nBULLET::::- Line-of-sight propagation\nBULLET::::- Sferics\n\nBULLET::::- Related\nBULLET::::- Canadian Geospace Monitoring\nBULLET::::- High Frequency Active Auroral Research Program\nBULLET::::- International Geophysical Year\nBULLET::::- Ionospheric heater\nBULLET::::- \"New Horizons\"\nBULLET::::- Nozomi\nBULLET::::- Pioneer Venus project\nBULLET::::- S4 Index\nBULLET::::- Soft gamma repeater\nBULLET::::- Upper-atmospheric lightning\nBULLET::::- Sura Ionospheric Heating Facility\nBULLET::::- Tether propulsion\nBULLET::::- TIMED (Thermosphere Ionosphere Mesosphere Energetics and Dynamics)\nBULLET::::- Lists\nBULLET::::- List of astronomical topics\nBULLET::::- List of electronics topics\nBULLET::::- List of plasma (physics) articles\nBULLET::::- J. Lilensten, P.-L. Blelly: \"Du Soleil à la Terre, Aéronomie et météorologie de l'espace\", Collection Grenoble Sciences, Université Joseph Fourier Grenoble I, 2000. .\nBULLET::::- P.-L. Blelly, D. Alcaydé: \"Ionosphere\", in: Y. Kamide, A. Chian, \"Handbook of the Solar-Terrestrial Environment\", Springer-Verlag Berlin Heidelberg, pp. 189–220, 2007.\n\nBULLET::::- Gehred, Paul, and Norm Cohen, \"SWPC's Radio User's Page\".\nBULLET::::- Amsat-Italia project on Ionospheric propagation (ESA SWENET website)\nBULLET::::- NZ4O Solar Space Weather & Geomagnetic Data Archive\nBULLET::::- NZ4O 160 Meter (Medium Frequency)Radio Propagation Theory Notes Layman Level Explanations Of \"Seemingly\" Mysterious 160 Meter (MF/HF) Propagation Occurrences\nBULLET::::- USGS Geomagnetism Program\nBULLET::::- Encyclopædia Britannica, Ionosphere and magnetosphere\nBULLET::::- Current Space Weather Conditions\nBULLET::::- Current Solar X-Ray Flux\nBULLET::::- Super Dual Auroral Radar Network\nBULLET::::- European Incoherent Scatter radar system\n"}
{"id": "15100", "url": "https://en.wikipedia.org/wiki?curid=15100", "title": "Interlingua", "text": "Interlingua\n\nInterlingua (; ISO 639 language codes \"ia\", \"ina\") is an Italic international auxiliary language (IAL), developed between 1937 and 1951 by the International Auxiliary Language Association (IALA). It ranks among the top most widely used IALs (along with Esperanto and Ido), and is the most widely used naturalistic IAL: in other words, its vocabulary, grammar and other characteristics are derived from natural languages, rather than being centrally planned. Interlingua was developed to combine a simple, mostly regular grammar with a vocabulary common to the widest possible range of western European languages, making it unusually easy to learn, at least for those whose native languages were sources of Interlingua's vocabulary and grammar. Conversely, it is used as a rapid introduction to many natural languages.\n\nInterlingua literature maintains that (written) Interlingua is comprehensible to the hundreds of millions of people who speak Romance languages, though it is actively spoken by only a few hundred.\n\nThe name Interlingua comes from the Latin words ', meaning \"between\", and ', meaning \"tongue\" or \"language\". These morphemes are identical in Interlingua. Thus, \"Interlingua\" would mean \"between language\".\n\nThe expansive movements of science, technology, trade, diplomacy, and the arts, combined with the historical dominance of the Greek and Latin languages have resulted in a large common vocabulary among European languages. With Interlingua, an objective procedure is used to extract and standardize the most widespread word or words for a concept found in a set of \"control languages\": English, French, Italian, Spanish and Portuguese, with German and Russian as secondary references. Words from any language are eligible for inclusion, so long as their internationality is shown by their presence in these control languages. Hence, Interlingua includes such diverse word forms as Japanese \"geisha\" and \"samurai\", Arabic \"califa\", Guugu Yimithirr \"gangurru\" (Interlingua: kanguru), and Finnish \"sauna\".\n\nInterlingua combines this pre-existing vocabulary with a minimal grammar based on the control languages. People with a good knowledge of a Romance language, or a smattering of a Romance language plus a good knowledge of the \"international scientific vocabulary\" can frequently understand it immediately on reading or hearing it. The immediate comprehension of Interlingua, in turn, makes it unusually easy to learn. Speakers of other languages can also learn to speak and write Interlingua in a short time, thanks to its simple grammar and regular word formation using a small number of roots and affixes.\n\nOnce learned, Interlingua can be used to learn other related languages quickly and easily, and in some studies, even to understand them immediately. Research with Swedish students has shown that, after learning Interlingua, they can translate elementary texts from Italian, Portuguese, and Spanish. In one 1974 study, an Interlingua class translated a Spanish text that students who had taken 150 hours of Spanish found too difficult to understand. Gopsill has suggested that Interlingua's freedom from irregularities allowed the students to grasp the mechanisms of language quickly.\n\nThe American heiress Alice Vanderbilt Morris (1874–1950) became interested in linguistics and the international auxiliary language movement in the early 1920s, and in 1924, Morris and her husband, Dave Hennen Morris, established the non-profit International Auxiliary Language Association (IALA) in New York City. Their aim was to place the study of IALs on a scientific basis. Morris developed the research program of IALA in consultation with Edward Sapir, William Edward Collinson, and Otto Jespersen.\n\nThe IALA became a major supporter of mainstream American linguistics, funding, for example, numerous studies by Sapir, Collinson, and Morris Swadesh in the 1930s and 1940s. Alice Morris edited several of these studies and provided much of IALA's financial support. IALA also received support from such prestigious groups as the Carnegie Corporation, the Ford Foundation, the Research Corporation, and the Rockefeller Foundation.\n\nIn its early years, IALA concerned itself with three tasks: finding other organizations around the world with similar goals; building a library of books about languages and interlinguistics; and comparing extant IALs, including Esperanto, Esperanto II, Ido, Peano's Interlingua (Latino sine flexione), Novial, and Interlingue (Occidental). In pursuit of the last goal, it conducted parallel studies of these languages, with comparative studies of national languages, under the direction of scholars at American and European universities. It also arranged conferences with proponents of these IALs, who debated features and goals of their respective languages. With a \"concession rule\" that required participants to make a certain number of concessions, early debates at IALA sometimes grew from heated to explosive.\n\nAt the Second International Interlanguage Congress, held in Geneva in 1931, IALA began to break new ground; 27 recognized linguists signed a testimonial of support for IALA's research program. An additional eight added their signatures at the third congress, convened in Rome in 1933. That same year, Herbert N. Shenton and Edward L. Thorndike became influential in IALA's work by authoring key studies in the interlinguistic field.\n\nThe first steps towards the finalization of Interlingua were taken in 1937, when a committee of 24 eminent linguists from 19 universities published \"Some Criteria for an International Language and Commentary\". However, the outbreak of World War II in 1939 cut short the intended biannual meetings of the committee.\n\nOriginally, the association had not set out to create its own language. Its goal was to identify which auxiliary language already available was best suited for international communication, and how to promote it most effectively. However, after ten years of research, more and more members of IALA concluded that none of the existing interlanguages were up to the task. By 1937, the members had made the decision to create a new language, to the surprise of the world's interlanguage community.\n\nTo that point, much of the debate had been equivocal on the decision to use naturalistic (e.g., Peano's Interlingua, Novial and Interlingue) or systematic (e.g., Esperanto and Ido) words. During the war years, proponents of a naturalistic interlanguage won out. The first support was Thorndike's paper; the second was a concession by proponents of the systematic languages that thousands of words were already present in many, or even a majority, of the European languages. Their argument was that systematic derivation of words was a Procrustean bed, forcing the learner to unlearn and re-memorize a new derivation scheme when a usable vocabulary was already available. This finally convinced supporters of the systematic languages, and IALA from that point assumed the position that a naturalistic language would be best.\n\nAt the outbreak of World War II, IALA's research activities were moved from Liverpool to New York, where E. Clark Stillman established a new research staff. Stillman, with the assistance of Alexander Gode, developed a \"prototyping\" technique – an objective methodology for selecting and standardizing vocabulary based on a comparison of \"control languages\".\n\nIn 1943 Stillman left for war work and Gode became Acting Director of Research. IALA began to develop models of the proposed language, the first of which were presented in Morris's \"General Report\" in 1945.\n\nFrom 1946 to 1948, French linguist André Martinet was Director of Research. During this period IALA continued to develop models and conducted polling to determine the optimal form of the final language. In 1946, IALA sent an extensive survey to more than 3,000 language teachers and related professionals on three continents.\n\nFour models were canvassed:\n\nThe results of the survey were striking. The two more schematic models were rejected – K overwhelmingly. Of the two naturalistic models, M received somewhat more support than P. IALA decided on a compromise between P and M, with certain elements of C.\n\nMartinet took up a position at Columbia University in 1948, and Gode took on the last phase of Interlingua's development. The vocabulary and grammar of Interlingua were first presented in 1951, when IALA published the finalized \"\" and the 27,000-word \"Interlingua–English Dictionary\" (IED). In 1954, IALA published an introductory manual entitled \"Interlingua a Prime Vista\" (\"Interlingua at First Sight\").\n\nInterlingua as presented by the IALA is very close to Peano's Interlingua (Latino sine flexione), both in its grammar and especially in its vocabulary. Accordingly, the very name \"Interlingua\" was kept, yet a distinct abbreviation was adopted: IA instead of IL.\n\nAn early practical application of Interlingua was the scientific newsletter \"Spectroscopia Molecular\", published from 1952 to 1980. In 1954, Interlingua was used at the Second World Cardiological Congress in Washington, D.C. for both written summaries and oral interpretation. Within a few years, it found similar use at nine further medical congresses. Between the mid-1950s and the late 1970s, some thirty scientific and especially medical journals provided article summaries in Interlingua. Science Service, the publisher of \"Science Newsletter\" at the time, published a monthly column in Interlingua from the early 1950s until Gode's death in 1970. In 1967, the International Organization for Standardization, which normalizes terminology, voted almost unanimously to adopt Interlingua as the basis for its dictionaries.\n\nThe IALA closed its doors in 1953 but was not formally dissolved until 1956 or later. Its role in promoting Interlingua was largely taken on by Science Service, which hired Gode as head of its newly formed Interlingua Division. Hugh E. Blair, Gode's close friend and colleague, became his assistant. A successor organization, the Interlingua Institute, was founded in 1970 to promote Interlingua in the US and Canada. The new institute supported the work of other linguistic organizations, made considerable scholarly contributions and produced Interlingua summaries for scholarly and medical publications. One of its largest achievements was two immense volumes on phytopathology produced by the American Phytopathological Society in 1976 and 1977.\n\nInterlingua had attracted many former adherents of other international-language projects, notably Occidental and Ido. The former Occidentalist Ric Berger founded The Union Mundial pro Interlingua (UMI) in 1955, and by the late 1950s, interest in Interlingua in Europe had already begun to overtake that in North America.\n\nBeginning in the 1980s, UMI has held international conferences every two years (typical attendance at the earlier meetings was 50 to 100) and launched a publishing programme that eventually produced over 100 volumes. Other Interlingua-language works were published by university presses in Sweden and Italy, and in the 1990s, Brazil and Switzerland. Several Scandinavian schools undertook projects that used Interlingua as a means of teaching the international scientific and intellectual vocabulary.\n\nIn 2000, the Interlingua Institute was dissolved amid funding disputes with the UMI; the American Interlingua Society, established the following year, succeeded the institute and responded to new interest emerging in Mexico.\n\nInterlingua was spoken and promoted in the Soviet bloc, despite attempts to suppress the language. In the German Democratic Republic, government officials confiscated the letters and magazines that the UMI sent to Walter Rädler, the Interlingua representative there.\n\nIn Czechoslovakia, Július Tomin published his first article on Interlingua in the Slovak magazine \"Príroda a spoločnosť\" (Nature and Society) in 1971, after which he received several anonymous threatening letters. He went on to become the Czech Interlingua representative, teach Interlingua in the school system, and publish a series of articles and books.\n\nToday, interest in Interlingua has expanded from the scientific community to the general public. Individuals, governments, and private companies use Interlingua for learning and instruction, travel, online publishing, and communication across language barriers. Interlingua is promoted internationally by the Union Mundial pro Interlingua. Periodicals and books are produced by many national organizations, such as the Societate American pro Interlingua, the Svenska Sällskapet för Interlingua, and the Union Brazilian pro Interlingua.\n\nIt is not certain how many people have an active knowledge of Interlingua. As noted above, Interlingua is claimed to be the most widely spoken naturalistic auxiliary language.\n\nInterlingua's greatest advantage is that it is the most widely \"understood\" international auxiliary language besides Interlingua (IL) de A.p.I. by virtue of its naturalistic (as opposed to schematic) grammar and vocabulary, allowing those familiar with a Romance language, and educated speakers of English, to read and understand it without prior study.\n\nInterlingua has active speakers on all continents, especially in South America and in Eastern and Northern Europe, most notably Scandinavia; also in Russia and Ukraine. There are copious Interlingua web pages, including editions of Wikipedia and Wiktionary, and a number of periodicals, including \"Panorama in Interlingua\" from the Union Mundial pro Interlingua (UMI) and magazines of the national societies allied with it. There are several active mailing lists, and Interlingua is also in use in certain Usenet newsgroups, particularly in the europa.* hierarchy. Interlingua is presented on CDs, radio, and television.\n\nInterlingua is taught in many high schools and universities, sometimes as a means of teaching other languages quickly, presenting interlinguistics, or introducing the international vocabulary. The University of Granada in Spain, for example, offers an Interlingua course in collaboration with the Centro de Formación Continua.\n\nEvery two years, the UMI organizes an international conference in a different country. In the year between, the Scandinavian Interlingua societies co-organize a conference in Sweden. National organizations such as the Union Brazilian pro Interlingua also organize regular conferences.\n\n, Google Keyboard supports Interlingua.\n\nInterlingua has a largely phonemic orthography.\n\nInterlingua uses the 26 letters of the ISO basic Latin alphabet with no diacritics. The alphabet, pronunciation in IPA and letter name in Interlingua are:\n\n+ Interlingua alphabet\n! Number 1234567891011121314151617181920212223242526\n\"Letters (upper case)\" A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U  V  W  X  Y  Z\n\"Letters (lower case)\" a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y  z\n\"IPA\"   ,      ,            ,  ,    ,    \n\"Names\" a  be  ce  de  e  ef  ge  ha  i  jota  ka  el  em  en  o  pe  cu  er  es  te  u  ve  duple ve  ix  ypsilon  zeta\n\nBULLET::::1. \"c\" is pronounced (or optionally ) before \"e, i, y\"\nBULLET::::1. \"ch\" is pronounced /ʃ/ in words of French origin e.g. 'chef' = /ʃef/ meaning \"chief\" or \"chef\", /k/ in words of Greek and Italian origin e.g. \"choro\" = /koro/ meaning \"chorus\" and more rarely /t͡ʃ/ in words of English or Spanish origin as in \"Chile\" /t͡ʃile/ (the country, Chile). Ch may be pronounced either /t͡ʃ/ or /ʃ/ depending on the speaker in many cases e.g. \"chocolate\" may be pronounced either /t͡ʃokolate/ or /ʃokolate/.\nBULLET::::2. \"q\" only appears in the digraph \"qu\", which is pronounced (but in the conjunction and pronoun \"que\" and pronoun \"qui\" and in terms derived from them such as \"anque\" and \"proque\")\nBULLET::::3. \"t\" is generally , but \"ti\" followed by a vowel, unless stressed or preceded by \"s\", is pronounced (or optionally )\nBULLET::::4. \"g\" = /g/\nBULLET::::1. but in -age = /ʒ/ (i.e. like 'j') and in several words of French origin \"orange\" = /oranʒe/ and \"mangiar\" = /manʒar/\n\nThe book \"Grammar of Interlingua\" defines in §15 a \"collateral orthography\".\n\nInterlingua is primarily a written language, and the pronunciation is not entirely settled. The sounds in parentheses are not used by all speakers.\n\n!\n! colspan=\"2\"  Labial\n! colspan=\"2\"  Alveolar\n! colspan=\"2\"  Post-<br>alveolar\n! Palatal\n! colspan=\"2\"  Velar\n! Glottal\n! Nasal\n\n! Plosive\n\n! Affricate\n\n! Fricative\n\n! Approximant\n\n! Rhotic\n\n!\n! Front\n! Back\n! Close\n! Close-mid\n! Open\n\nFor the most part, consonants are pronounced as in English, while the vowels are like Spanish. Written double consonants may be geminated as in Italian for extra clarity or pronounced as single as in English or French. Interlingua has five falling diphthongs, , and , although and are rare.\n\nThe \"general rule\" is that stress falls on the vowel before the last consonant (e.g., \"lingua\", 'language', \"esser\", 'to be', \"requirimento\", 'requirement') ignoring the final plural \"-(e)s\" (e.g. \"linguas\", the plural of \"lingua\", still has the same stress as the singular), and where that is not possible, on the first vowel (\"via\", 'way', \"io crea\", 'I create'). There are a few exceptions, and the following rules account for most of them:\nBULLET::::- Adjectives and nouns ending in a vowel followed by \"-le, -ne,\" or \"-re\" are stressed on the third-last syllable (\"fragile, margine, altere\" 'other', but \"illa impone\" 'she imposes').\nBULLET::::- Words ending in \"-ica/-ico, -ide/-ido\" and \"-ula/-ulo,\" are stressed on the third-last syllable (\"politica, scientifico, rapide, stupido, capitula, seculo\" 'century').\nBULLET::::- Words ending in \"-ic\" are stressed on the second-last syllable (\"cubic\").\n\nSpeakers may pronounce all words according to the general rule mentioned above. For example, \"kilometro\" is acceptable, although \"kilometro\" is more common.\n\nInterlingua has no explicitly defined phonotactics. However, the prototyping procedure for determining Interlingua words, which strives for internationality, should in general lead naturally to words that are easy for most learners to pronounce. In the process of forming new words, an ending cannot always be added without a modification of some kind in between. A good example is the plural \"-s\", which is always preceded by a vowel to prevent the occurrence of a hard-to-pronounce consonant cluster at the end. If the singular does not end in a vowel, the final \"-s\" becomes \"-es.\"\n\nUnassimilated foreign loanwords, or borrowed words, are spelled as in their language of origin. Their spelling may contain diacritics, or accent marks. If the diacritics do not affect pronunciation, they are removed.\n\nWords in Interlingua may be taken from any language, as long as their internationality is verified by their presence in seven \"control\" languages: Spanish, Portuguese, Italian, French, and English, with German and Russian acting as secondary controls. These are the most widely spoken Romance, Germanic, and Slavic languages, respectively. Because of their close relationship, Spanish and Portuguese are treated as one unit. The largest number of Interlingua words are of Latin origin, with the Greek and Germanic languages providing the second and third largest number. The remainder of the vocabulary originates in Slavic and non-Indo-European languages.\n\nA word, that is a form with meaning, is eligible for the Interlingua vocabulary if it is verified by at least three of the four primary control languages. Either secondary control language can substitute for a primary language. Any word of Indo-European origin found in a control language can contribute to the eligibility of an international word. In some cases, the archaic or \"potential\" presence of a word can contribute to its eligibility.\n\nA word can be potentially present in a language when a derivative is present, but the word itself is not. English \"proximity\", for example, gives support to Interlingua \"proxime\", meaning 'near, close'. This counts as long as one or more control languages actually have this basic root word, which the Romance languages all do. Potentiality also occurs when a concept is represented as a compound or derivative in a control language, the morphemes that make it up are themselves international, and the combination adequately conveys the meaning of the larger word. An example is Italian \"fiammifero\" (lit. flamebearer), meaning \"match, lucifer\", which leads to Interlingua \"flammifero\", or \"match\". This word is thus said to be potentially present in the other languages although they may represent the meaning with a single morpheme.\n\nWords do not enter the Interlingua vocabulary solely because cognates exist in a sufficient number of languages. If their meanings have become different over time, they are considered different words for the purpose of Interlingua eligibility. If they still have one or more meanings in common, however, the word can enter Interlingua with this smaller set of meanings.\n\nIf this procedure did not produce an international word, the word for a concept was originally taken from Latin (see below). This only occurred with a few grammatical particles.\n\nThe form of an Interlingua word is considered an \"international prototype\" with respect to the other words. On the one hand, it should be neutral, free from characteristics peculiar to one language. On the other hand, it should maximally capture the characteristics common to all contributing languages. As a result, it can be transformed into any of the contributing variants using only these language-specific characteristics. If the word has any derivatives that occur in the source languages with appropriate parallel meanings, then their morphological connection must remain intact; for example, the Interlingua word for 'time' is spelled \"tempore\" and not \"*tempus\" or \"*tempo\" in order to match it with its derived adjectives, such as \"temporal\".\n\nThe language-specific characteristics are closely related to the sound laws of the individual languages; the resulting words are often close or even identical to the most recent form common to the contributing words. This sometimes corresponds with that of Vulgar Latin. At other times, it is much more recent or even contemporary. It is never older than the classical period.\n\nThe French \"œil\", Italian \"occhio\", Spanish \"ojo\", and Portuguese \"olho\" appear quite different, but they descend from a historical form \"oculus\". German \"Auge\", Dutch \"oog\" and English \"eye\" (cf. Czech and Polish \"oko\", Ukrainian \"око\" \"(óko)\") are related to this form in that all three descend from Proto-Indo-European \"*okʷ\". In addition, international derivatives like \"ocular\" and \"oculista\" occur in all of Interlingua's control languages. Each of these forms contributes to the eligibility of the Interlingua word. German and English base words do not influence the form of the Interlingua word, because their Indo-European connection is considered too remote. Instead, the remaining base words and especially the derivatives determine the form \"oculo\" found in Interlingua.\n\nInterlingua has been developed to omit any grammatical feature that is absent from any one primary control language. Thus, Interlingua has no noun–adjective agreement by gender, case, or number (cf. Spanish and Portuguese \"gatas negras\" or Italian \"gatte nere\", 'black female cats'), because this is absent from English, and it has no progressive verb tenses (English \"I am reading\"), because they are absent from French. Conversely, Interlingua distinguishes singular nouns from plural nouns because all the control languages do. With respect to the secondary control languages, Interlingua has articles, unlike Russian.\n\nThe definite article \"le\" is invariable, as in English. Nouns have no grammatical gender. Plurals are formed by adding \"-s\", or \"-es\" after a final consonant. Personal pronouns take one form for the subject and one for the direct object and reflexive. In the third person, the reflexive is always \"se\". Most adverbs are derived regularly from adjectives by adding \"-mente\", or \"-amente\" after a \"-c\". An adverb can be formed from any adjective in this way.\n\nVerbs take the same form for all persons (\"io vive, tu vive, illa vive\", 'I live', 'you live', 'she lives'). The indicative (\"pare\", 'appear', 'appears') is the same as the imperative (\"pare!\" 'appear!'), and there is no subjunctive. Three common verbs usually take short forms in the present tense: \"es\" for 'is', 'am', 'are;' \"ha\" for 'has', 'have;' and \"va\" for 'go', 'goes'. A few irregular verb forms are available, but rarely used.\n\nThere are four simple tenses (present, past, future, and conditional), three compound tenses (past, future, and conditional), and the passive voice. The compound structures employ an auxiliary plus the infinitive or the past participle (e.g., \"Ille ha arrivate\", 'He has arrived'). Simple and compound tenses can be combined in various ways to express more complex tenses (e.g., \"Nos haberea morite\", 'We would have died').\n\nWord order is subject–verb–object, except that a direct object pronoun or reflexive pronoun comes before the verb (\"Io les vide\", 'I see them'). Adjectives may precede or follow the nouns they modify, but they most often follow it. The position of adverbs is flexible, though constrained by common sense.\n\nThe grammar of Interlingua has been described as similar to that of the Romance languages, but greatly simplified, primarily under the influence of English. More recently, Interlingua's grammar has been likened to the simple grammars of Japanese and particularly Chinese.\n\nCritics argue that, being based on a few European languages, Interlingua is best suited for speakers of European languages. Others contend that Interlingua has spelling irregularities that, while internationally recognizable in written form, increase the time needed to fully learn the language, especially for those unfamiliar with Indo-European languages. A related point of criticism is that Interlingua's credential as being Standard Average European is too weak outside the Romance languages. Some opponents see the Germanic, Slavic, and Celtic languages, in particular, as having little influence.\n\nProponents argue that Interlingua's source languages include not only Romance languages but English, German, and Russian as well. Moreover, the source languages are widely spoken internationally, and large numbers of their words also appear in other languages – still more when derivative forms and loan translations are included. Tests had shown that if a larger number of source languages were used, the results would be about the same.\n\nFrom an essay by Alexander Gode:\n\n+ The Lord's Prayer\n\nPatre nostre, qui es in le celos,\nque tu nomine sia sanctificate;\nque tu regno veni;\nque tu voluntate sia facite\ncomo in le celo, etiam super le terra.\nNos Padre, ci es en sielo,\nsante es tua nome;\ntua renia va veni;\ntua vole va es fada\nen tera como en sielo.\nPatre nostro, qui es in celos,\nque tuo nomine fi sanctificato;\nque tuo regno adveni;\nque tuo voluntate es facto\nsicut in celo et in terra.\nPatro nia, Kiu estas en la ĉielo,\nsanktigata estu Via nomo.\nVenu Via regno,\nfariĝu Via volo,\nkiel en la ĉielo tiel ankaŭ sur la tero.\nPatro nia, qua esas en la cielo,\ntua nomo santigesez;\ntua regno advenez;\ntua volo facesez quale en la cielo\ntale anke sur la tero.\nPater noster, qui es in caelis,\nsanctificetur nomen tuum.\nAdveniat regnum tuum.\nFiat voluntas tua,\nsicut in caelo, et in terra.\nPadre nuestro, que estás en los cielos,\nsantificado sea tu Nombre;\nvenga a nosotros tu Reino;\nhágase tu Voluntad\nasí en la tierra como en el cielo.\nPadre nostro che sei nei cieli, \nsia santificato il tuo Nome, \nvenga il tuo Regno, \nsia fatta la tua Volontà \ncome in cielo così in terra. \nOur Father, who art in heaven,\nhallowed be thy name;\nthy kingdom come,\nthy will be done.\non earth, as it is in heaven.\n\nDa nos hodie nostre pan quotidian,\ne pardona a nos nostre debitas\ncomo etiam nos los pardona a nostre debitores.\nE non induce nos in tentation,\nsed libera nos del mal.\nAmen.\nDona nosa pan dial a nos,\npardona nosa pecas,\ncomo nos pardona los ci peca a nos.\nNo condui nos a tentia,\nma proteje nos de mal.\nAmen.\nDa hodie ad nos nostro pane quotidiano,\net remitte ad nos nostro debitos,\nsicut et nos remitte ad nostro debitores.\nEt non induce nos in tentatione,\nsed libera nos ab malo.\nAmen.\nNian panon ĉiutagan donu al ni hodiaŭ\nkaj pardonu al ni niajn ŝuldojn,\nkiel ankaŭ ni pardonas al niaj ŝuldantoj.\nKaj ne konduku nin en tenton,\nsed liberigu nin de la malbono.\nAmen\nDonez a ni cadie la omnadiala pano,\ne pardonez a ni nia ofensi,\nquale anke ni pardonas a nia ofensanti,\ne ne duktez ni aden la tento,\nma liberigez ni del malajo.\nAmen\nPanem nostrum quotidianum da nobis hodie,\net dimitte nobis debita nostra,\nsicut et nos dimittimus debitoribus nostris.\nEt ne nos inducas in tentationem,\nsed libera nos a malo.\nAmen.\nDanos hoy nuestro pan de cada día;\nperdona nuestras ofensas,\nasí como nosotros perdonamos a quienes nos ofenden;\ny no nos dejes caer en la tentación,\nmas líbranos del mal.\nAmen.\nDacci oggi il nostro pane quotidiano, \ne rimetti a noi i nostri debiti \ncome noi li rimettiamo ai nostri debitori, \ne non ci indurre in tentazione, \nma liberaci dal male. \nAmen.\nGive us this day our daily bread;\nand forgive us our debts\nas we have forgiven our debtors.\nAnd lead us not into temptation,\nbut deliver us from evil.\nAmen.\n\nAs with Esperanto, there have been proposals for a flag of Interlingua; the proposal by Czech translator Karel Podrazil is recognized by multilingual sites. It consists of a white four-pointed star extending to the edges of the flag and dividing it into an upper blue and lower red half. The star is symbolic of the four cardinal directions, and the two halves symbolize Romance and non-Romance speakers of Interlingua who understand each other.\n\nAnother symbol of Interlingua is the \"Blue Marble\" surrounded by twelve stars on a black or blue background, echoing the twelve stars of the Flag of Europe (because the source languages of Interlingua are purely European).\n\nBULLET::::- Comparison between Esperanto and Interlingua\nBULLET::::- Comparison between Ido and Interlingua\nBULLET::::- Publications\nBULLET::::- \"Grammatica de Interlingua\"\nBULLET::::- \"Interlingua, Instrumento Moderne de Communication International\" (course manual)\nBULLET::::- Interlingua dictionaries\nBULLET::::- Interlingua and eligibility of international words\nBULLET::::- Irregularities and exceptions in Interlingua\nBULLET::::- Internationalism (linguistics)\nBULLET::::- Willem Jacob Visser\n\nBULLET::::- Falk, Julia S. \"Women, Language and Linguistics: Three American stories from the first half of the twentieth century.\" Routledge, London & New York: 1999.\nBULLET::::- Gopsill, F.P. \"Le historia antenatal de Interlingua.\". (In Interlingua.) Accessed 28 May 2005.\nBULLET::::- International Auxiliary Language Association (IALA). \"General Report\". IALA, New York: 1945.\nBULLET::::- Pei, Mario. \"One Language for the World and How To Achieve It.\" Devin-Adair, New York; 1958.\nBULLET::::- Union Mundial pro Interlingua (UMI). \"Interlingua 2001: communication sin frontieras durante 50 annos\" (in Interlingua). Accessed 17 August 2006.\n\nBULLET::::- Collection of links to Interlingua resources\n"}
{"id": "15102", "url": "https://en.wikipedia.org/wiki?curid=15102", "title": "Isle of Wight", "text": "Isle of Wight\n\nThe Isle of Wight () is a county and the largest and second-most populous island in England. It is in the English Channel, between 2 and 5 miles off the coast of Hampshire, separated by the Solent. The island has resorts that have been holiday destinations since Victorian times, and is known for its mild climate, coastal scenery, and verdant landscape of fields, downland and chines. The island is designated a UNESCO Biosphere Reserve.\n\nThe island has been home to the poets Swinburne and Tennyson and to Queen Victoria, who built her much-loved summer residence and final home Osborne House at East Cowes. It has a maritime and industrial tradition including boat-building, sail-making, the manufacture of flying boats, the hovercraft, and Britain's space rockets. The island hosts annual music festivals including the Isle of Wight Festival, which in 1970 was the largest rock music event ever held. It has well-conserved wildlife and some of the richest cliffs and quarries for dinosaur fossils in Europe.\n\nThe isle was owned by a Norman family until 1293 and was earlier a kingdom in its own right. In common with the Crown dependencies, the British Crown was then represented on the island by the Governor of the Isle of Wight until 1995. The island has played an important part in the defence of the ports of Southampton and Portsmouth, and been near the front-line of conflicts through the ages, including the Spanish Armada and the Battle of Britain. Rural for most of its history, its Victorian fashionability and the growing affordability of holidays led to significant urban development during the late 19th and early 20th centuries. Historically part of Hampshire, the island became a separate administrative county in 1890. It continued to share the Lord Lieutenant of Hampshire until 1974, when it was made its own ceremonial county. Apart from a shared police force, and the island's Anglican churches belonging to the Diocese of Portsmouth (originally Winchester), there is now no administrative link with Hampshire; although a combined local authority with Portsmouth and Southampton was considered, this is now unlikely to proceed.\n\nThe quickest public transport link to the mainland is the hovercraft from Ryde to Southsea; three vehicle ferry and two catamaran services cross the Solent to Southampton, Lymington and Portsmouth.\n\nDuring the last Ice Age, sea levels were lower and the Solent was part of a river flowing southeast from current day Poole Harbour towards mid-Channel of Doggerland. The Bouldner Cliff archaeological site is 1 km long, 8000 year old wooden platform at the neolithic river bank, and now submerged 12 m below sea level. As sea levels rose, the river valley became flooded, and the chalk ridgeline west of the Needles breached to form the island. The Isle of Wight is first mentioned in writing in \"Geography\" by Ptolemy.\n\nBronze Age Britain had large reserves of tin in the areas of Cornwall and Devon and tin is necessary to smelt bronze. At that time the sea level was much lower and carts of tin were brought across the Solent at low tide for export, possibly on the Ferriby Boats. Anthony Snodgrass suggests that a shortage of tin, as a part of the Bronze Age Collapse and trade disruptions in the Mediterranean around 1300 BC, forced metalworkers to seek an alternative to bronze. During Iron Age Britain, the Late Iron Age, the Isle of Wight would appear to have been occupied by the Celtic tribe, the Durotriges – as attested by finds of their coins, for example, the South Wight Hoard, and the Shalfleet Hoard. South eastern Britain experienced significant immigration that is reflected in the genetic makeup of the current residents. As the Iron Age began the value of tin likely dropped sharply and this likely greatly changed the economy of the Isle of Wight. Trade however continued as evidenced by the remarkable local abundance of European Iron Age coins.\n\nJulius Caesar reported that the Belgae took the Isle of Wight in about 85 BC, and recognised the culture of this general region as \"Belgic\", but made no reference to Vectis. The Roman historian Suetonius mentions that the island was captured by the commander Vespasian. The Romans built no towns on the island, but the remains of at least seven Roman villas have been found, indicating the prosperity of local agriculture. First-century exports were principally hides, slaves, hunting dogs, grain, cattle, silver, gold, and iron. Ferriby boats and later Blackfriars ships likely were important to the local economy.\n\nStarting in AD 449 (according to the Anglo Saxon Chronicles) the 5th and 6th centuries saw groups of Germanic speaking peoples from Northern Europe crossing the English Channel and setting up home. Bede's (731) \"Historia ecclesiastica gentis Anglorum\" identifies three separate groups of invaders: of these, the Jutes from Denmark settled the Isle of Wight and Kent. From then onwards, there are indications that the island had wide trading links, with a port at Bouldnor, evidence of Bronze Age tin trading, and finds of Late Iron Age coins.\n\nDuring the Dark Ages the island was settled by Jutes as the pagan kingdom of Wihtwara under King Arwald. In 685 it was invaded by Caedwalla, who tried to replace the inhabitants with his own followers. In 686 Arwald was defeated and the island became the last part of English lands to be converted to Christianity, added to Wessex and then becoming part of England under King Alfred the Great, included within the shire of Hampshire.\n\nIt suffered especially from Viking raids, and was often used as a winter base by Viking raiders when they were unable to reach Normandy. Later, both Earl Tostig and his brother Harold Godwinson (who became King Harold II) held manors on the island.\n\nThe Norman Conquest of 1066 created the position of Lord of the Isle of Wight; the island was given by William the Conqueror to his kinsman William FitzOsbern. Carisbrooke Priory and the fort of Carisbrooke Castle were then founded. Allegiance was sworn to FitzOsbern rather than the king; the Lordship was subsequently granted to the de Redvers family by Henry I, after his succession in 1100.\n\nFor nearly 200 years the island was a semi-independent feudal fiefdom, with the de Redvers family ruling from Carisbrooke. The final private owner was the Countess Isabella de Fortibus, who, on her deathbed in 1293, was persuaded to sell it to Edward I. Thereafter the island was under control of the English Crown and its Lordship a royal appointment.\n\nThe island continued to be attacked from the continent: it was raided in 1374 by the fleet of Castile, and in 1377 by French raiders who burned several towns, including Newtown, and laid siege to Carisbrooke Castle before they were defeated.\n\nUnder Henry VIII, who developed the Royal Navy and its Portsmouth base, the island was fortified at Yarmouth, Cowes, East Cowes, and Sandown.\n\nThe French invasion on 21 July 1545 (famous for the sinking of the Mary Rose on the 19th) was repulsed by local militia.\n\nDuring the English Civil War, King Charles fled to the Isle of Wight, believing he would receive sympathy from the governor Robert Hammond, but Hammond imprisoned the king in Carisbrooke Castle.\n\nDuring the Seven Years' War, the island was used as a staging post for British troops departing on expeditions against the French coast, such as the Raid on Rochefort. During 1759, with a planned French invasion imminent, a large force of soldiers was stationed there. The French called off their invasion following the Battle of Quiberon Bay.\n\nIn the 1860s, what remains in real terms the most expensive ever government spending project saw fortifications built on the island and in the Solent, as well as elsewhere along the south coast, including the Palmerston Forts, The Needles Batteries and Fort Victoria, because of fears about possible French invasion.\n\nThe future Queen Victoria spent childhood holidays on the island and became fond of it. When queen she made Osborne House her winter home, and so the island became a fashionable holiday resort, including for Alfred, Lord Tennyson, Julia Margaret Cameron, and Charles Dickens (who wrote much of \"David Copperfield\" there), as well as the French painter Berthe Morisot and members of European royalty. Until then, the island had been rural, with most people employed in farming, fishing or boat-building. The boom in tourism, spurred by growing wealth and leisure time, and by Victoria's example, led to significant urban development of the island's coastal resorts.\n\nThe world's first radio station was set up by Marconi in 1897, during her reign, at the Needles Battery, at the western tip of the island. In 1898 the first paid wireless telegram (called a \"Marconigram\") was sent from this station, and the island was for some time the home of the National Wireless Museum, near Ryde.\n\nQueen Victoria died at Osborne House on 22 January 1901, aged 81.\n\nDuring the Second World War the island was frequently bombed. With its proximity to German-occupied France, the island hosted observation stations and transmitters, as well as the RAF radar station at Ventnor. It was the starting-point for one of the earlier Operation Pluto pipelines to feed fuel to Europe after the Normandy landings.\n\nThe Needles Battery was used to develop and test the Black Arrow and Black Knight space rockets, which were subsequently launched from Woomera, Australia.\nThe Isle of Wight Festival was a very large rock festival that took place near Afton Down, West Wight in 1970, following two smaller concerts in 1968 and 1969. The 1970 show was notable both as one of the last public performances by Jimi Hendrix and for the number of attendees, reaching by some estimates 600,000. The festival was revived in 2002 in a different format, and is now an annual event.\n\nThe oldest records that give a name for the Isle of Wight are from the Roman Empire: it was then called \"Vectis\" or \"Vecta\" in Latin, \"Iktis\" or \"Ouiktis\" in Greek. From the Anglo-Saxon period Latin \"Vecta\", Old English \"Wiht\" and Old Welsh forms \"Gueid\" and \"Guith\" are recorded. In Domesday Book it is \"Wit\"; the modern Welsh name is \"Ynys Wyth\" (\"ynys\" = island). These are all variant forms of the same name, possibly Celtic in origin. It may mean \"place of the division\", because the island divides the two arms of the Solent.\n\nThe Isle of Wight is situated between the Solent and the English Channel, is roughly rhomboid in shape, and covers an area of . Slightly more than half, mainly in the west, is designated as the Isle of Wight Area of Outstanding Natural Beauty. The island has of farmland, of developed areas, and of coastline. Its landscapes are diverse, leading to its oft-quoted description as \"England in miniature\". In June 2019 the whole island was designated a UNESCO Biosphere Reserve, recognising the sustainable relationships between its residents and the local environment.\n\nWest Wight is predominantly rural, with dramatic coastlines dominated by the chalk downland ridge, running across the whole island and ending in the Needles stacks. The southwestern quarter is commonly referred to as the Back of the Wight, and has a unique character. The highest point on the island is St Boniface Down in the south east, which at is a marilyn. The most notable habitats on the rest of the island are probably the soft cliffs and sea ledges, which are scenic features, important for wildlife, and internationally protected.\n\nThe island has three principal rivers. The River Medina flows north into the Solent, the Eastern Yar flows roughly northeast to Bembridge Harbour, and the Western Yar flows the short distance from Freshwater Bay to a relatively large estuary at Yarmouth. Without human intervention the sea might well have split the island into three: at the west end where a bank of pebbles separates Freshwater Bay from the marshy backwaters of the Western Yar east of Freshwater, and at the east end where a thin strip of land separates Sandown Bay from the marshy Eastern Yar basin.\n\nThe Undercliff between St Catherine's Point and Bonchurch is the largest area of landslip morphology in western Europe.\n\nThe north coast is unusual in having four high tides each day, with a double high tide every twelve and a half hours. This arises because the western Solent is narrower than the eastern; the initial tide of water flowing from the west starts to ebb before the stronger flow around the south of the island returns through the eastern Solent to create a second high water.\n\nThe Isle of Wight is made up of a variety of rock types dating from early Cretaceous (around 127 million years ago) to the middle of the Palaeogene (around 30 million years ago). The geological structure is dominated by a large monocline which causes a marked change in age of strata from the northern younger Tertiary beds to the older Cretaceous beds of the south. This gives rise to a dip of almost 90 degrees in the chalk beds, seen best at the Needles.\n\nThe northern half of the island is mainly composed of clays, with the southern half formed of the chalk of the central east–west downs, as well as Upper and Lower Greensands and Wealden strata. These strata continue west from the island across the Solent into Dorset, forming the basin of Poole Harbour (Tertiary) and the Isle of Purbeck (Cretaceous) respectively. The chalky ridges of Wight and Purbeck were a single formation before they were breached by waters from the River Frome during the last ice age, forming the Solent and turning Wight into an island. The Needles, along with Old Harry Rocks on Purbeck, represent the edges of this breach.\n\nAll the rocks found on the island are sedimentary, such as limestones, mudstones and sandstones. They are rich in fossils; many can be seen exposed on beaches as the cliffs erode. Lignitic coal is present in small quantities within seams, and can be seen on the cliffs and shore at Whitecliff Bay. Fossilised molluscs have been found there, and also on the northern coast along with fossilised crocodiles, turtles and mammal bones; the youngest date back to around 30 million years ago.\n\nThe island is one of the most important areas in Europe for dinosaur fossils. The eroding cliffs often reveal previously hidden remains, particularly along the Back of the Wight. Dinosaur bones and fossilised footprints can be seen in and on the rocks exposed around the island's beaches, especially at Yaverland and Compton Bay. As a result, the island has been nicknamed \"Dinosaur Island\" and Dinosaur Isle was established in 2001.\n\nThe area was affected by sea level changes during the repeated Quaternary glaciations. The island probably became separated from the mainland about 125,000 years ago, during the Ipswichian interglacial.\n\nLike the rest of the UK, the island has an oceanic climate, but is somewhat milder and sunnier, which makes it a holiday destination. It also has a longer growing season. Lower Ventnor and the neighbouring Undercliff have a particular microclimate, because of their sheltered position south of the downs. The island enjoys 1,800–2,100 hours of sunshine a year. Some years have almost no snow in winter, and only a few days of hard frost. The island is in Hardiness zone 9.\nThe Isle of Wight is one of the few places in England where the red squirrel is still flourishing; no grey squirrels are to be found. There are occasional sightings of wild deer, and there is a colony of wild goats on Ventnor's downs. Protected species such as the dormouse and rare bats can be found. The Glanville fritillary butterfly's distribution in the United Kingdom is largely restricted to the edges of the island's crumbling cliffs.\n\nA competition in 2002 named the pyramidal orchid as the Isle of Wight's county flower.\n\nIn 1904 bees began to die on the island in large quantities. None could explain the reason, but some related the mystery of the phenomenon to the fact that a few years prior to that Giuglielmo Marconi erected a tall tower to support the antenna for the world’s first permanent radio station. In 1906, when the island had the greatest concentration of radio signals in the world, 90% of honey bees had disappeared for no apparent reason. This followed by “Isle of Wight disease” that spread like a plague, and bees started dying throughout Great Britain and the rest of the world.\n\nThe island has a single Member of Parliament. The Isle of Wight constituency covers the entire island, with 138,300 permanent residents in 2011, being one of the most populated constituencies in the United Kingdom (more than 50% above the English average). In 2011 following passage of the Parliamentary Voting System and Constituencies Act, the Sixth Periodic Review of Westminster constituencies was to have changed this, but this was deferred to no earlier than October 2018 by the Electoral Registration and Administration Act 2013. Thus the single constituency remained for the 2015 and 2017 general elections. However, two separate East and West constituencies are proposed for the island under the 2018 review now under way.\n\nThe Isle of Wight is a ceremonial and non-metropolitan county. Since the abolition of its two borough councils and restructuring of the county council as Isle of Wight Council in 1995, it has been a unitary authority.\n\nElections in the constituency have traditionally been a battle between the Conservatives and the Liberal Democrats. Andrew Turner of the Conservative Party gained the seat from Peter Brand of the Lib Dems at the 2001 general election. Since 2009, Turner was embroiled in controversy over his expenses, health, and relationships with colleagues, with local Conservatives having tried but failed to remove him in the runup to the 2015 general election. He stood down prior to the 2017 snap general election, and the new Conservative Party candidate Bob Seely was elected with a majority of 21,069 votes.\n\nAt the Isle of Wight Council election of 2013, the Conservatives lost the majority which they had held since 2005 to the Island Independents, with Island Independent councillors holding 16 of the 40 seats, and a further five councillors sitting as independents outside the group. The Conservatives regained control, winning 25 seats, at the 2017 local election.\n\nThere have been small regionalist movements: the Vectis National Party and the Isle of Wight Party; but they have attracted little support at elections.\n\nBULLET::::- Newport is the centrally located county town, with a population of about 25,000 and the island's main shopping area. Located next to the River Medina, Newport Quay was a busy port until the mid-19th century.\nBULLET::::- Ryde, the largest town with a population of about 30,000, is in the northeast. It is Victorian with the oldest seaside pier in England and miles of sandy and pebble beaches.\nBULLET::::- Cowes hosts the annual Cowes Week and is an international sailing centre.\nBULLET::::- East Cowes is famous for Osborne House, Norris Castle and as the home from 1929 to 1964 of Saunders-Roe, the historic aircraft, flying boat, rocket and hovercraft company.\nBULLET::::- Sandown is a popular seaside resort. It is home to the Isle of Wight Zoo, the Dinosaur Isle geological museum and one of the island's two 18-hole golf courses.\nBULLET::::- Shanklin, just south of Sandown, attracts tourists with its high summer sunshine levels, sandy beaches, Shanklin Chine and the old village.\nBULLET::::- Ventnor, built on the steep slopes of St Boniface Down on the south coast of the island, leads down to a picturesque bay that attracts many tourists. Ventnor Haven is a small harbour.\nThe local accent is similar to the traditional dialect of Hampshire, featuring the dropping of some consonants and an emphasis on longer vowels. It is similar to the West Country dialects heard in South West England, but less pronounced.\n\nThe island has its own local and regional words. Some, such as \"nipper/nips\" (a young male person), are still commonly used and are shared with neighbouring areas of the mainland. A few are unique to the island, for example \"overner\" and \"caulkhead\" (see below). Others are more obscure and now used mainly for comic emphasis, such as \"mallishag\" (meaning \"caterpillar\"), \"gurt\" meaning \"large\", \"nammit\" (a mid-morning snack) and \"gallybagger\" (\"scarecrow\", and now the name of a local cheese).\n\nThere remains occasional confusion between the Isle of Wight as a county and its former position within Hampshire. The island was regarded and administered as a part of Hampshire until 1890, when its distinct identity was recognised with the formation of Isle of Wight County Council (see also \"Politics of the Isle of Wight\"). However, it remained a part of Hampshire until the local government reforms of 1974 when it became a full ceremonial county with its own Lord Lieutenant.\n\nIn January 2009, the first general flag for the county was accepted by the Flag Institute.\n\nIsland residents are sometimes referred to as \"Vectensians\", \"Vectians\" or, if born on the island, \"caulkheads\". One theory is that this last comes from the once prevalent local industry of caulking or sealing wooden boats; the term became attached to islanders either because they were so employed, or as a derisory term for perceived unintelligent labourers from elsewhere. The term \"overner\" is used for island residents originating from the mainland (an abbreviated form of \"overlander\", which is an archaic term for \"outsider\" still found in parts of Australia).\n\nResidents refer to the island as \"The Island\", as did Jane Austen in Mansfield Park, and sometimes to the UK mainland as \"North Island\".\n\nTo promote the island's identity and culture, the High Sheriff Robin Courage founded an Isle of Wight Day; the first was held on Saturday 24 September 2016.\n\nThe island is said to be the most haunted in the world, sometimes referred to as \"Ghost Island\". Notable claimed hauntings include God's Providence House in Newport (now a tea room), Appuldurcombe House, and the remains of Knighton Gorges.\n\nThe island is well known for its cycling, and it was included within Lonely Planet's \"Best in Travel Guide\" (2010) top ten cycling locations. The island also hosts events such as the Isle of Wight Randonnée and the Isle of Wight Cycling Festival each year. A popular cycling track is the Sunshine Trail which starts in Newport and ends in Sandown.\n\nThere are rowing clubs at Newport, Ryde and Shanklin, all members of the Hants and Dorset rowing association.\n\nThere is a long tradition of rowing around the island dating back to the 1880s.\n\nIn May 1999 a group of local women made history by becoming the first ladies' crew to row around the island, in ten hours and twenty minutes. Rowers from Ryde Rowing Club have rowed around the island several times since 1880. The fours record was set 16 August 1995 at 7 hours 54 minutes.\n\nTwo rowers from Southampton ARC (Chris Bennett and Roger Slaymaker) set the two-man record in July 2003 at 8 hours 34 minutes, and in 2005 Gus McKechnie of Coalporters Rowing Club became the first adaptive rower to row around, completing a clockwise row.\n\nThe route around the island is about and usually rowed anticlockwise. Even in good conditions, it includes a number of significant obstacles such as the Needles and the overfalls at St Catherine's Point. The traditional start and finish were at Ryde Rowing Club; however, other starts have been chosen in recent years to give a tidal advantage.\n\nCowes is a centre for sailing, hosting several racing regattas. Cowes Week is the longest-running regular regatta in the world, with over 1,000 yachts and 8,500 competitors taking part in over 50 classes of racing.\nIn 1851 the first America's Cup race was around the island. Other major sailing events hosted in Cowes include the Fastnet race, the Round the Island Race, the Admiral's Cup, and the Commodore's Cup.\n\nThere are two main trampoline clubs on the island, in Freshwater and Newport, competing at regional, national and international grades.\n\nThe Isle of Wight Marathon is the United Kingdom's oldest continuously held marathon, having been run every year since 1957. Since 2013 the course has started and finished in Cowes, heading out to the west of the island and passing through Gurnard, Rew Street, Porchfield, Shalfleet, Yarmouth, Afton, Willmingham, Thorley, Wellow, Shalfleet, Porchfield, and Northwood. It is an undulating course with a total climb of .\n\nThe island is home to the Wightlink Warriors speedway team, who compete in the sport's third division, the National League.\n\nFollowing an amalgamation of local hockey clubs in 2011, the Isle of Wight Hockey Club now runs two men's senior and two ladies' senior teams. These compete at a range of levels in the Hampshire open leagues.\n\nThe now-disbanded Ryde Sports F.C., founded in 1888, was one of the eight founder members of the Hampshire League in 1896. There are several non-league clubs such as Newport (IW) F.C. There is an Isle of Wight Saturday Football League which feeds into the Hampshire League with two divisions and two reserve team leagues, and a rugby union club.\n\nThe Isle of Wight is the 39th official county in English cricket, and the Isle of Wight Cricket Board organises a league of local clubs. Ventnor Cricket Club competes in the Southern Premier League, and has won the Second Division several times. Newclose County Cricket Ground near Newport opened officially in 2009 but with its first match held on 6 September 2008. The island has produced some notable cricketers, such as Danny Briggs, who plays county cricket for Sussex.\n\nThe Isle of Wight competes in the biennial Island Games, which it hosted in 1993 and again in 2011.\n\nThe annual Isle of Wight International Scooter Rally has since 1980 met on the August Bank Holiday. This is now one of the biggest scooter rallies in the world, attracting between four and seven thousand participants.\n\nThe island is home to the Isle of Wight Festival and until 2016, Bestival before it was relocated to Lulworth Estate in Dorset. In 1970, the festival was headlined by Jimi Hendrix attracting an audience of 600,000, some six times the local population at the time. It is the home of the band The Bees, Trixie's Big Red Motorbike.\n\nThe table below shows the regional gross value (in millions of pounds) added by the Isle of Wight economy, at current prices, compiled by the Office for National Statistics.\n+Regional gross value in millions of pounds sterling\n!scope=\"col\" Year\n!scope=\"col\" Regional gross<br>value added\n!scope=\"col\" Agriculture\n!scope=\"col\" Industry\n!scope=\"col\" Services\n!scope=\"row\" 1995\n!scope=\"row\" 2000\n1,369\n!scope=\"row\" 2003\n1,521\n!scope=\"row\" 2008\n2,023\n\n!scope=\"row\" 2012\n2,175\n\nAccording to the 2011 census, the island's population of 138,625 lives in 61,085 households, giving an average household size of 2.27 people.\n\n41% of households own their home outright and a further 29% own with a mortgage, so in total 70% of households are owned (compared to 68% for South East England).\n\nCompared to South East England, the island has fewer children (19% aged 0–17 against 22% for the South East) and more elderly (24% aged 65+ against 16%), giving an average age of 44 years for an island resident compared to 40 in South East England.\n\nThe largest industry is tourism, but the island also has a strong agricultural heritage, including sheep and dairy farming and arable crops. Traditional agricultural commodities are more difficult to market off the island because of transport costs, but local farmers have succeeded in exploiting some specialist markets, with the higher price of such products absorbing the transport costs. One of the most successful agricultural sectors is now the growing of crops under cover, particularly salad crops including tomatoes and cucumbers. The island has a warmer climate and a longer growing season than much of the United Kingdom. Garlic has been successfully grown in Newchurch for many years, and is even exported to France. This has led to the establishment of an annual Garlic Festival at Newchurch, which is one of the largest events of the local calendar. A favourable climate supports two vineyards, including one of the oldest in the British Isles at Adgestone. Lavender is grown for its oil. The largest agricultural sector has been dairying, but due to low milk prices and strict legislation for UK milk producers, the dairy industry has been in decline: there were nearly 150 producers in the mid-1980s, but now just 24.\n\nMaritime industries, especially the making of sailcloth and boat building, have long been associated with the island, although this has diminished somewhat in recent years. GKN operates what began as the British Hovercraft Corporation, a subsidiary of (and known latterly as) Westland Aircraft, although they have reduced the extent of plant and workforce and sold the main site. Previously it had been the independent company Saunders-Roe, one of the island's most notable historic firms that produced many flying boats and the world's first hovercraft.\n\nAnother manufacturing activity is in composite materials, used by boat-builders and the wind turbine manufacturer Vestas, which has a wind turbine blade factory and testing facilities in West Medina Mills and East Cowes.\n\nBembridge Airfield is the home of Britten-Norman, manufacturers of the Islander and Trislander aircraft. This is shortly to become the site of the European assembly line for Cirrus light aircraft. The Norman Aeroplane Company is a smaller aircraft manufacturing company operating in Sandown. There have been three other firms that built planes on the island.\n\nIn 2005, Northern Petroleum began exploratory drilling for oil at its Sandhills-2 borehole at Porchfield, but ceased operations in October that year after failing to find significant reserves.\n\nThere are three breweries on the island. Goddards Brewery in Ryde opened in 1993. David Yates, who was head brewer of the Island Brewery, started brewing as Yates Brewery at the Inn at St Lawrence in 2000.\n\nVentnor Brewery, which closed in 2009, was the last incarnation of Burt's Brewery, brewing since the 1840s in Ventnor. Until the 1960s most pubs were owned by Mews Brewery, situated in Newport near the old railway station, but it closed and the pubs were taken over by Strong's, and then by Whitbread. By some accounts Mews beer was apt to be rather cloudy and dark. In the 19th century they pioneered the use of screw top cans for export to British India.\n\nThe island's heritage is a major asset that has for many years supported its tourist economy. Holidays focused on natural heritage, including wildlife and geology, are becoming an alternative to the traditional British seaside holiday, which went into decline in the second half of the 20th century due to the increased affordability of foreign holidays. The island is still an important destination for coach tours from other parts of the United Kingdom.\nTourism is still the largest industry, and most island towns and villages offer hotels, hostels and camping sites. In 1999, it hosted 2.7 million visitors, with 1.5 million staying overnight, and 1.2 million day visits; only 150,000 of these were from abroad. Between 1993 and 2000, visits increased at an average rate of 3% per year.\n\nAt the turn of the 19th century the island had ten pleasure piers, including two at Ryde and a \"chain pier\" at Seaview. The Victoria Pier in Cowes succeeded the earlier Royal Pier but was itself removed in 1960. The piers at Ryde, Seaview, Sandown, Shanklin and Ventnor originally served a coastal steamer service that operated from Southsea on the mainland. The piers at Seaview, Shanklin, Ventnor and Alum Bay were all destroyed by various storms during the 20th century; only the railway pier at Ryde and the piers at Sandown, Totland Bay (currently closed to the public) and Yarmouth survive.\n\nBlackgang Chine is the oldest theme park in Britain, opened in 1843. The skeleton of a dead whale that its founder Alexander Dabell found in 1844 is still on display.\n\nAs well as its more traditional attractions, the island is often host to walking or cycling holidays through the attractive scenery. An annual walking festival has attracted considerable interest. The Isle of Wight Coastal Path follows the coastline as far as possible, deviating onto roads where the route along the coast is impassable.\n\nThe tourist board for the island is Visit Isle of Wight, a not for profit company. It is the Destination Management Organisation for the Isle of Wight, a public and private sector partnership led by the private sector, and consists of over 1,200 companies, including the ferry operators, the local bus company, rail operator and tourism providers working together to collectively promote the island. Its income is derived from the Wight BID a business improvement district levy fund.\n\nA major contributor to the local economy is sailing and marine-related tourism.\n\nSummer Camp at Camp Beaumont is an attraction at the old Bembridge School site.\n\nThe Isle of Wight has of roadway. It does not have a motorway, although there is a short stretch of dual carriageway towards the north of Newport near the hospital and prison.\n\nA comprehensive bus network operated by Southern Vectis links most settlements, with Newport as its central hub.\n\nJourneys away from the island involve a ferry journey. Car ferry and passenger catamaran services are run by Wightlink and Red Funnel, and a hovercraft passenger service (the only such remaining in the world) by Hovertravel.\n\nThe island formerly had its own railway network of over , but only one line remains in regular use. The Island Line is part of the United Kingdom's National Rail network, running a little under from to , where there is a connecting ferry service to station on the mainland network. The line was opened by the Isle of Wight Railway in 1864, and from 1996 to 2007 was run by the smallest train operating company on the network, Island Line Trains. It is notable for utilising old ex-London Underground rolling stock, due to the small size of its tunnels and unmodernised signalling. Branching off the Island Line at is the heritage Isle of Wight Steam Railway, which runs for to the outskirts of on the former line to Newport.\n\nThere are two airfields for general aviation, Isle of Wight Airport at Sandown and Bembridge Airport.\n\nThe island has over of cycleways, many of which can be enjoyed off-road. The principal trails are:\nBULLET::::- The Sunshine Trail, which is a circular route linking Sandown, Shanklin, Godshill, and Wroxall of ;\nBULLET::::- The Troll Trail between Cowes and Sandown of , 90% off-road;\nBULLET::::- The Round the Island Cycle Route of .\n\nThe main local newspaper is the \"Isle of Wight County Press\", published most Fridays.\n\nThe island hosts a news website, \"Island Echo\", which was launched in May 2012.\n\nThe island has a local commercial radio station and a community radio station: commercial station Isle of Wight Radio has broadcast in the medium-wave band since 1990 and on 107.0 MHz (with three smaller transmitters on 102.0 MHz) FM since 1998, as well as streaming on the Internet. Community station Vectis Radio has broadcast online since 2010, and in 2017 started broadcasting on FM 104.6. The station operates from the Riverside Centre in Newport.\n\nThe island is also covered by a number of local stations on the mainland, including the BBC station BBC Radio Solent broadcast from Southampton.\n\nThe island's not-for-profit community radio station Angel Radio opened in 2007. Angel Radio began broadcasting on 91.5 MHz from studios in Cowes and a transmitter near Newport.\n\nOther online news sources for the Isle of Wight include \"On the Wight\".\n\nThe island has had community television stations in the past, first TV12 and then Solent TV from 2002 until its closure on 24 May 2007. iWight.tv is a local internet video news channel.\n\nThe Isle of Wight is part of the BBC South region and the ITV Meridian region.\n\nImportant broadcasting infrastructure includes Chillerton Down transmitting station with a mast that is the tallest structure on the island, and Rowridge transmitting station, which broadcasts the main television signal both locally and for most of Hampshire and parts of Dorset and West Sussex.\n\nThe Isle of Wight is near the densely populated south of England, yet separated from the mainland. This position led to it hosting three prisons: Albany, Camp Hill and Parkhurst, all located outside Newport near the main road to Cowes. Albany and Parkhurst were among the few Category A prisons in the UK until they were downgraded in the 1990s. The downgrading of Parkhurst was precipitated by a major escape: three prisoners (two murderers and a blackmailer) escaped from the prison on 3 January 1995 for four days, before being recaptured. Parkhurst enjoyed notoriety as one of the toughest jails in the United Kingdom, and housed many notable inmates including the Yorkshire Ripper Peter Sutcliffe, New Zealand drug lord Terry Clark and the Kray twins.\n\nCamp Hill is located adjacent but to the west of Albany and Parkhurst, on the very edge of Parkhurst Forest, having been converted first to a borstal and later to a Category C prison. It was built on the site of an army camp (both Albany and Parkhurst were barracks); there is a small estate of tree-lined roads with the former officers' quarters (now privately owned) to the south and east. Camp Hill closed as a prison in March 2013.\n\nThe management of all three prisons was merged into a single administration, under HMP Isle of Wight in April 2009.\n\nThere are 69 local education authority-maintained schools on the Isle of Wight, and two independent schools. As a rural community, many of these are small and with fewer pupils than in urban areas. The Isle of Wight College is located on the outskirts of Newport.\n\nFrom September 2010, there was a transition period from the three-tier system of primary, middle and high schools to the two-tier system that is usual in England. Some schools have now closed, such as Chale C.E. Primary. Others have become \"federated\", such as Brading C.E. Primary and St Helen's Primary. Christ the King College started as two \"middle schools,\" Trinity Middle School and Archbishop King Catholic Middle School, but has now been converted into a dual-faith secondary school and sixth form.\n\nSince September 2011 five new secondary schools, with an age range of 11 to 18 years, replaced the island's high schools (as a part of the previous three-tier system).\n\nNotable residents have included:\n\nBULLET::::- King Arwald, last pagan king in England\nBULLET::::- King Charles I of England, who was imprisoned at Carisbrooke Castle\nBULLET::::- Viking Earl Tostig Godwinson\nBULLET::::- Actor, highwayman and conspirator Cardell \"Scum\" Goodman\nBULLET::::- Soldier and regicide of Charles I Thomas Harrison, imprisoned at Carisbrooke with John Rogers & Christopher Feake\nBULLET::::- Soldier Peter de Heyno\nBULLET::::- Philosopher and polymath Robert Hooke\nBULLET::::- Murderer Michal Morey\n\nBULLET::::- Marine painter Thomas Buttersworth\nBULLET::::- Explorer Anthony Henday\nBULLET::::- Radical journalist John Wilkes\n\nBULLET::::- Queen Victoria and Prince Albert (monarch and consort), who built and lived at Osborne House\nBULLET::::- Photographer Julia Margaret Cameron, who lived at Dimbola Lodge\nBULLET::::- Irish Republican Thomas Clarke\nBULLET::::- Naval captain Jeremiah Coghlan CBG, who retired to Ryde\nBULLET::::- Writer Charles Dickens\nBULLET::::- Poet John Keats\nBULLET::::- Inventor and radio pioneer Guglielmo Marconi\nBULLET::::- Poet and hymnwriter Albert Midlane\nBULLET::::- Geologist and engineer John Milne\nBULLET::::- Regency architect John Nash\nBULLET::::- Novelist Miss Harriet Parr\nBULLET::::- Early Hong Kong Government administrator William Pedder\nBULLET::::- New Zealand PM Henry Sewell\nBULLET::::- Poet Algernon Charles Swinburne\nBULLET::::- Poet Alfred Tennyson\nBULLET::::- Philosopher Karl Marx, who stayed at 1, St. Boniface Gardens, Ventnor\nBULLET::::- Surgeon James Mann Williamson, at the Royal National Hospital, Ventnor\n\nBULLET::::- Scriptwriter Raymond Allen\nBULLET::::- Indie rock group The Bees\nBULLET::::- Concert organist E. Power Biggs\nBULLET::::- Darts player Keegan Brown\nBULLET::::- Singer-songwriter Sarah Close\nBULLET::::- Inventor of the hovercraft Sir Christopher Cockerell\nBULLET::::- Presenter and actor Ray Cokes\nBULLET::::- Actress Bella Emberg\nBULLET::::- Yachtsman Uffa Fox\nBULLET::::- Actor Marius Goring\nBULLET::::- Survival expert and Chief Scout Bear Grylls\nBULLET::::- Actress Sheila Hancock\nBULLET::::- Folk-rock musician Robyn Hitchcock\nBULLET::::- Actor Geoffrey Hughes\nBULLET::::- Author and conspiracy theorist David Icke\nBULLET::::- Actor Jeremy Irons\nBULLET::::- Comedian Phill Jupitus\nBULLET::::- Actor Laura Michelle Kelly\nBULLET::::- Composer Albert Ketèlbey\nBULLET::::- Iranian poet Mimi Khalvati\nBULLET::::- Musician Mark King\nBULLET::::- Radio presenter Allan Lake\nBULLET::::- Musician Jack Green\nBULLET::::- Yachtswoman Ellen MacArthur\nBULLET::::- BBC 'Tonight' presenter Cliff Michelmore\nBULLET::::- Film director Anthony Minghella\nBULLET::::- Actor David Niven\nBULLET::::- Cyclist Kieran Page\nBULLET::::- TV personality Anneka Rice\nBULLET::::- Heptathlete Kelly Sotherton\nBULLET::::- Gardener and presenter Alan Titchmarsh\nBULLET::::- Novelist Edward Upward\nBULLET::::- Actor Melvyn Hayes\n\nThe Isle of Wight has given names to many parts of former colonies, most notably Isle of Wight County in Virginia founded by settlers from the island in the 17th century. Its county seat is a town named Isle of Wight.\n\nOther notable examples include:\nBULLET::::- Isle of Wight - an island off Maryland, United States\nBULLET::::- Dunnose Head, West Falkland\nBULLET::::- Ventnor, Cowes on Philip Island, Victoria, Australia\nBULLET::::- Carisbrook, Victoria, Australia\nBULLET::::- Carisbrook, a former stadium in Dunedin, New Zealand\nBULLET::::- Ryde, New South Wales, Australia\nBULLET::::- Shanklin, Sandown, New Hampshire, United States\nBULLET::::- Ventnor City, New Jersey, United States\nBULLET::::- Gardiners Island, New York, United States shown as \"Isle of Wight\" on some of the older maps.\n\nBULLET::::- The film \"Something to Hide\" (1972; US title \" Shattered\"), starring Peter Finch, was filmed near Cowes, including a scene on the Red Funnel ferry;\nBULLET::::- The British film \"That'll Be the Day\" (1973), starring David Essex and Ringo Starr, included scenes shot in Ryde (notably Cross Street), Sandown (school), Shanklin (beach) and Wootton Bridge (fairground);\nBULLET::::- \"Mrs. Brown\" (1997), with Dame Judi Dench and Billy Connolly, was filmed at Osborne and Chale;\nBULLET::::- The film \"Fragile\" (2005), starring Calista Flockhart, is based on the Isle of Wight.\nBULLET::::- Victoria and Abdul (2017) starring Dame Judi Dench and Ali Fazal began shooting principal photography at Osborne House in September 2016.\n\nBULLET::::- John Worsley's Commodore 64 game \"Spirit of the Stones\" was set on the Isle of Wight.\n\nThe Isle of Wight was:\n\nBULLET::::- the setting of Julian Barnes's novel \"England, England\";\nBULLET::::- called \"The Island\" in some editions of Thomas Hardy's novels in his fictional Wessex;\nBULLET::::- selected for the development of a new base by the supercomputer \"Colossus\", in D. F. Jones' novel \"Colossus\" (1966);\nBULLET::::- the setting for D.H. Lawrence's book \"The Trespasser\", filmed for TV on location in 1981;\nBULLET::::- the setting of Graham Masterton's book \"Prey\";\nBULLET::::- mentioned in J.K. Rowling's first Harry Potter book, which refers to Uncle Vernon's sister Marge on holiday on the island, who got sick after eating a whelk;\nBULLET::::- a major element in Daniel O'Malley's series \"The Rook\" (2012) & its sequel \"Stiletto\" (2016). The antagonists try to invade in the 1600s, the effects of which continue to colour perceptions of the Crown's secret supernatural agency, the \"Checquy Group\";\nBULLET::::- the refuge of the British monarchy & government in S.M. Stirling's alternative history novel \"The Protector's War\" (2005), in which high energy technology ceased to function. After an ensuing holocaust, the island was the base for re-population of Europe, whose populations had mostly perished;\nBULLET::::- one of the destinations to which the British government evacuates in Frank Tayell's post-apocalyptic novel \"Surviving the Evacuation Book One: London\" (2013), guided by the mistaken impression that it would be defensible against the zombie hordes;\nBULLET::::- featured in John Wyndham's novel \"The Day of the Triffids\" and Simon Clark's sequel \"The Night of the Triffids\".\n\nBULLET::::- The Beatles' song \"When I'm Sixty-Four\" (1967), credited to Lennon-McCartney and sung by Paul McCartney, refers to renting a cottage on the island;\nBULLET::::- Bob Dylan recorded \"Like a Rolling Stone\" (1965), \"Minstrel Boy\", \"Quinn the Eskimo (The Mighty Quinn)\" (1967), and \"She Belongs to Me\" (1965) for the album \"Self Portrait\" (1970) live on the island;\nBULLET::::- \"Wight Is Wight\" (1969), a song by French artist Michel Delpech, also spawned an Italian cover by Dik Dik, titled \"\" (1970).\n\nBULLET::::- There was a running joke in radio sitcom \"The Navy Lark\" involving Sub-Lieutenant Phillips's inability to navigate and subsequently tail the Isle of Wight ferry.\n\nBULLET::::- ITV's dramatisation of Dennis Potter's work \"Blade on the Feather\" (19 October 1980) was filmed on the island.\nBULLET::::- The 1984 TV miniseries, \"Annika\", was partly filmed in Ryde.\nBULLET::::- A 2002 \"Top Gear\" feature showed an Aston Martin being driven around Cowes, East Cowes, and along the Military Road and seawall at Freshwater Bay.\nBULLET::::- The setting for \"Free Rein\" was based on the Isle of Wight.\n\nBULLET::::- List of civil parishes on the Isle of Wight\nBULLET::::- List of places on the Isle of Wight\nBULLET::::- List of current places of worship on the Isle of Wight\nBULLET::::- List of High Sheriffs of the Isle of Wight\nBULLET::::- List of Lord Lieutenants of the Isle of Wight\nBULLET::::- List of Governors of the Isle of Wight\nBULLET::::- List of hills of the Isle of Wight\nBULLET::::- Isle of Wight gasification facility\nBULLET::::- Isle of Wight NHS Trust\nBULLET::::- Isle of Wight Rifles\nBULLET::::- Yaverland Battery\n\nBULLET::::- Hansard, Wednesday 14 November 2001 column 850\n\nBULLET::::- Visit Isle of Wight Official Website\nBULLET::::- Isle of Wight Council website\nBULLET::::- Isleofwight.com\n\nBULLET::::- Images of the Isle of Wight at the English Heritage Archive\n"}
{"id": "15107", "url": "https://en.wikipedia.org/wiki?curid=15107", "title": "Internet Control Message Protocol", "text": "Internet Control Message Protocol\n\nThe Internet Control Message Protocol (ICMP) is a supporting protocol in the Internet protocol suite. It is used by network devices, including routers, to send error messages and operational information indicating success or failure when communicating with another IP address, for example, an error is indicated when a requested service is not available or that a host or router could not be reached. ICMP differs from transport protocols such as TCP and UDP in that it is not typically used to exchange data between systems, nor is it regularly employed by end-user network applications (with the exception of some diagnostic tools like ping and traceroute).\n\nICMP for IPv4 is defined in RFC 792.\n\nICMP is part of the Internet protocol suite as defined in RFC 792. ICMP messages are typically used for diagnostic or control purposes or generated in response to errors in IP operations (as specified in RFC 1122). ICMP errors are directed to the source IP address of the originating packet. \n\nFor example, every device (such as an intermediate router) forwarding an IP datagram first decrements the time to live (TTL) field in the IP header by one. If the resulting TTL is 0, the packet is discarded and an ICMP time exceeded in transit message is sent to the datagram's source address.\n\nMany commonly used network utilities are based on ICMP messages. The traceroute command can be implemented by transmitting IP datagrams with specially set IP TTL header fields, and looking for ICMP time exceeded in transit and Destination unreachable messages generated in response. The related ping utility is implemented using the ICMP \"echo request\" and \"echo reply\" messages.\n\nICMP uses the basic support of IP as if it were a higher level protocol, however, ICMP is actually an integral part of IP. Although ICMP messages are contained within standard IP packets, ICMP messages are usually processed as a special case, distinguished from normal IP processing. In many cases, it is necessary to inspect the contents of the ICMP message and deliver the appropriate error message to the application responsible for transmission of the IP packet that prompted the sending of the ICMP message.\n\nICMP is a network layer protocol. There is no TCP or UDP port number associated with ICMP packets as these numbers are associated with the transport layer above.\n\nThe ICMP packet is encapsulated in an IPv4 packet. The packet consists of header and data sections.\n\nThe ICMP header starts after the IPv4 header and is identified by IP protocol number '1'. All ICMP packets have an 8-byte header and variable-sized data section. The first 4 bytes of the header have fixed format, while the last 4 bytes depend on the type/code of that ICMP packet.\n\n+ICMP Header Format\n! \"Offsets\"\n! Octet\n! colspan=\"8\"  0\n! colspan=\"8\"  1\n! colspan=\"8\"  2\n! colspan=\"8\"  3\n! style=\"border-top: none\"  Octet\n! Bit\n! style=\"width:2.6%;\" 0\n! style=\"width:2.6%;\" 1\n! style=\"width:2.6%;\" 2\n! style=\"width:2.6%;\" 3\n! style=\"width:2.6%;\" 4\n! style=\"width:2.6%;\" 5\n! style=\"width:2.6%;\" 6\n! style=\"width:2.6%;\" 7\n! style=\"width:2.6%;\" 8\n! style=\"width:2.6%;\" 9\n! style=\"width:2.6%;\" 10\n! style=\"width:2.6%;\" 11\n! style=\"width:2.6%;\" 12\n! style=\"width:2.6%;\" 13\n! style=\"width:2.6%;\" 14\n! style=\"width:2.6%;\" 15\n! style=\"width:2.6%;\" 16\n! style=\"width:2.6%;\" 17\n! style=\"width:2.6%;\" 18\n! style=\"width:2.6%;\" 19\n! style=\"width:2.6%;\" 20\n! style=\"width:2.6%;\" 21\n! style=\"width:2.6%;\" 22\n! style=\"width:2.6%;\" 23\n! style=\"width:2.6%;\" 24\n! style=\"width:2.6%;\" 25\n! style=\"width:2.6%;\" 26\n! style=\"width:2.6%;\" 27\n! style=\"width:2.6%;\" 28\n! style=\"width:2.6%;\" 29\n! style=\"width:2.6%;\" 30\n! style=\"width:2.6%;\" 31\n! 0\n! 0\n! 4\n! 32\n\nBULLET::::- Type : ICMP type, see Control messages.\nBULLET::::- Code : ICMP subtype, see Control messages.\nBULLET::::- Checksum : Error checking data, calculated from the ICMP header and data, with value 0 substituted for this field. The Internet Checksum is used, specified in RFC 1071.\nBULLET::::- Rest of Header : Four-bytes field, contents vary based on the ICMP type and code.\n\nICMP error messages contain a data section that includes a copy of the entire IPv4 header, plus at least the first eight bytes of data from the IPv4 packet that caused the error message. The maximum length of ICMP error messages is 576 bytes. This data is used by the host to match the message to the appropriate process. If a higher level protocol uses port numbers, they are assumed to be in the first eight bytes of the original datagram's data.\n\nThe variable size of the ICMP packet data section has been exploited. In the \"Ping of death\", large or fragmented ICMP packets are used for denial-of-service attacks. ICMP data can also be used to create covert channels for communication. These channels are known as ICMP tunnels.\n\nControl messages are identified by the value in the \"type\" field. The \"code\" field gives additional context information for the message. Some control messages have been deprecated since the protocol was first introduced.\n+Notable control messages\n! Type !! Code !! Status !! Description\n0 – Echo Reply\n1 and 2\nrowspan=163 – Destination Unreachable\nrowspan=4 5 – Redirect Message\nrowspan=2 11 – Time Exceeded\nrowspan=3 12 – Parameter Problem: Bad IP header\n\n\"Source Quench\" requests that the sender decrease the rate of messages sent to a router or host. This message may be generated if a router or host does not have sufficient buffer space to process the request, or may occur if the router or host buffer is approaching its limit.\n\nData is sent at a very high speed from a host or from several hosts at the same time to a particular router on a network. Although a router has buffering capabilities, the buffering is limited to within a specified range. The router cannot queue any more data than the capacity of the limited buffering space. Thus if the queue gets filled up, incoming data is discarded until the queue is no longer full. But as no acknowledgement mechanism is present in the network layer, the client does not know whether the data has reached the destination successfully. Hence some remedial measures should be taken by the network layer to avoid these kind of situations. These measures are referred to as source quench. In a source quench mechanism, the router sees that the incoming data rate is much faster than the outgoing data rate, and sends an ICMP message to the clients, informing them that they should slow down their data transfer speeds or wait for a certain amount of time before attempting to send more data. When a client receives this message, it will automatically slow down the outgoing data rate or wait for a sufficient amount of time, which enables the router to empty the queue. Thus the source quench ICMP message acts as flow control in the network layer.\n\nSince research suggested that \"ICMP Source Quench [was] an ineffective (and unfair) antidote for congestion\", routers' creation of source quench messages was deprecated in 1995 by RFC 1812. Furthermore, forwarding of and any kind of reaction to (flow control actions) source quench messages was deprecated from 2012 by RFC 6633.\n\n+Source quench message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n\n\"Redirect\" requests data packets be sent on an alternative route. ICMP Redirect is a mechanism for routers to convey routing information to hosts. The message informs a host to update its routing information (to send packets on an alternative route). If a host tries to send data through a router (R1) and R1 sends the data on another router (R2) and a direct path from the host to R2 is available (that is, the host and R2 are on the same Ethernet segment), then R1 will send a redirect message to inform the host that the best route for the destination is via R2. The host should then send packets for the destination directly to R2. The router will still send the original datagram to the intended destination. However, if the datagram contains routing information, this message will not be sent even if a better route is available. RFC 1122 states that redirects should only be sent by gateways and should not be sent by Internet hosts.\n\n+Redirect message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n! Code\n! Description\n! 0\n! 1\n! 2\n! 3\n\n\"Time Exceeded\" is generated by a gateway to inform the source of a discarded datagram due to the time to live field reaching zero. A time exceeded message may also be sent by a host if it fails to reassemble a fragmented datagram within its time limit.\n\nTime exceeded messages are used by the traceroute utility to identify gateways on the path between two hosts.\n\n+Time exceeded message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n! Code  Description\n! 0\n! 1\n\n\"Timestamp\" is used for time synchronization. The originating timestamp is set to the time (in milliseconds since midnight) the sender last touched the packet. The receive and transmit timestamps are not used.\n\n+Timestamp message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n\n\"Timestamp Reply\" replies to a \"Timestamp\" message. It consists of the originating timestamp sent by the sender of the \"Timestamp\" as well as a receive timestamp indicating when the \"Timestamp\" was received and a transmit timestamp indicating when the \"Timestamp reply\" was sent.\n\n+Timestamp reply message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n\n\"Address mask request\" is normally sent by a host to a router in order to obtain an appropriate subnet mask.\n\nRecipients should reply to this message with an \"Address mask reply\" message.\n\n+Address mask request\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n\nICMP Address Mask Request may be used as a part of reconnaissance attack to gather information on the target network, therefore ICMP Address Mask Reply is disabled by default on Cisco IOS.\n\n\"Address mask reply\" is used to reply to an address mask request message with an appropriate subnet mask.\n\n+Address mask reply\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n\n\"Destination unreachable\" is generated by the host or its inbound gateway to inform the client that the destination is unreachable for some reason. Reasons for this message may include: the physical connection to the host does not exist (distance is infinite); the indicated protocol or port is not active; the data must be fragmented but the 'don't fragment' flag is on. Unreachable TCP ports notably respond with TCP RST rather than a \"destination unreachable\" type 3 as might be expected. \"Destination unreachable\" is never reported for IP Multicast transmissions. \n\n+Destination unreachable message\n! 00  01  02  03  04  05  06  07\n! 08  09  10  11  12  13  14  15\n! 16  17  18  19  20  21  22  23\n! 24  25  26  27  28  29  30  31\n\nWhere:\n! Code  Description\n! 0\n! 1\n! 2\n! 3\n! 4\n! 5\n! 6\n! 7\n! 8\n! 9\n! 10\n! 11\n! 12\n! 13\n! 14\n! 15\n\nBULLET::::- ICMP tunnel\nBULLET::::- ICMP hole punching\nBULLET::::- ICMP Router Discovery Protocol\nBULLET::::- PMTU blackhole\nBULLET::::- Pathping\nBULLET::::- Path MTU Discovery\nBULLET::::- Smurf attack\nBULLET::::- RFC 792, \"Internet Control Message Protocol\"\nBULLET::::- RFC 950, \"Internet Standard Subnetting Procedure\"\nBULLET::::- RFC 1016, \"Something a Host Could Do with Source Quench: The Source Quench Introduced Delay (SQuID)\"\nBULLET::::- RFC 1122, \"Requirements for Internet Hosts – Communication Layers\"\nBULLET::::- RFC 1716, \"Towards Requirements for IP Routers\"\nBULLET::::- RFC 1812, \"Requirements for IP Version 4 Routers\"\n\nBULLET::::- IANA ICMP parameters\nBULLET::::- IANA protocol numbers\nBULLET::::- Explanation of ICMP Redirect Behavior\n"}
{"id": "15108", "url": "https://en.wikipedia.org/wiki?curid=15108", "title": "ICMP", "text": "ICMP\n\nICMP may refer to:\n\nBULLET::::- International Collection of Microorganisms from Plants, a culture collection in New Zealand\nBULLET::::- International Congress on Mathematical Physics\nBULLET::::- Internet Control Message Protocol, used in computer networking\nBULLET::::- Ischemic cardiomyopathy, a type of heart disease\n\nBULLET::::- The Institute of Contemporary Music Performance, in London, UK\nBULLET::::- International Commission on Missing Persons, an intergovernmental organization\n"}
{"id": "15109", "url": "https://en.wikipedia.org/wiki?curid=15109", "title": "Inverse limit", "text": "Inverse limit\n\nIn mathematics, the inverse limit (also called the projective limit) is a construction that allows one to \"glue together\" several related objects, the precise manner of the gluing process being specified by morphisms between the objects. Inverse limits can be defined in any category, and they are a special case of the concept of a limit in category theory.\n\nWe start with the definition of an inverse system (or projective system) of groups and homomorphisms. Let (\"I\", ≤) be a directed poset (not all authors require \"I\" to be directed). Let (\"A\") be a family of groups and suppose we have a family of homomorphisms \"f\": \"A\" → \"A\" for all \"i\" ≤ \"j\" (note the order), called bonding maps, with the following properties:\nBULLET::::1. \"f\" is the identity on \"A\",\nBULLET::::2. \"f\" = \"f\" ∘ \"f\" for all \"i\" ≤ \"j\" ≤ \"k\".\nThen the pair ((\"A\"), (\"f\")) is called an inverse system of groups and morphisms over \"I\", and the morphisms \"f\" are called the transition morphisms of the system.\n\nWe define the inverse limit of the inverse system ((\"A\"), (\"f\")) as a particular subgroup of the direct product of the \"A\"'s:\n\nThe inverse limit \"A\" comes equipped with \"natural projections\" π: \"A\" → \"A\" which pick out the \"i\"th component of the direct product for each \"i\" in \"I\". The inverse limit and the natural projections satisfy a universal property described in the next section.\n\nThis same construction may be carried out if the \"A\"'s are sets, semigroups, topological spaces, rings, modules (over a fixed ring), algebras (over a fixed ring), etc., and the homomorphisms are morphisms in the corresponding category. The inverse limit will also belong to that category.\n\nThe inverse limit can be defined abstractly in an arbitrary category by means of a universal property. Let (\"X\", \"f\") be an inverse system of objects and morphisms in a category \"C\" (same definition as above). The inverse limit of this system is an object \"X\" in \"C\" together with morphisms π: \"X\" → \"X\" (called \"projections\") satisfying π = \"f\" ∘ π for all \"i\" ≤ \"j\". The pair (\"X\", π) must be universal in the sense that for any other such pair (\"Y\", ψ) (i.e. ψ: \"Y\" → \"X\" with ψ = \"f\" ∘ ψ for all \"i\" ≤ \"j\") there exists a unique morphism \"u\": \"Y\" → \"X\" such that the diagram\n\ncommutes for all \"i\" ≤ \"j\", for which it suffices to show that ψ = π ∘ \"u\" for all \"i\". The inverse limit is often denoted\nwith the inverse system (\"X\", \"f\") being understood.\n\nIn some categories, the inverse limit of certain inverse systems does not exist. If it does, however, it is unique in a strong sense: given any two inverse limits \"X\" and \"X\"' of an inverse system, there exists a \"unique\" isomorphism \"X\"′ → \"X\" commuting with the projection maps.\n\nWe note that an inverse system in a category \"C\" admits an alternative description in terms of functors. Any partially ordered set \"I\" can be considered as a small category where the morphisms consist of arrows \"i\" → \"j\" if and only if \"i\" ≤ \"j\". An inverse system is then just a contravariant functor \"I\" → \"C\", and the inverse limit functor\nformula_3 is a covariant functor.\n\nBULLET::::- The ring of \"p\"-adic integers is the inverse limit of the rings Z/\"p\"Z (see modular arithmetic) with the index set being the natural numbers with the usual order, and the morphisms being \"take remainder\". That is, one considers sequences of integers formula_4 such that each element of the sequence \"projects\" down to the previous ones, namely, that formula_5 whenever formula_6 The natural topology on the \"p\"-adic integers is the one implied here, namely the product topology with cylinder sets as the open sets.\nBULLET::::- The ring formula_7 of formal power series over a commutative ring \"R\" can be thought of as the inverse limit of the rings formula_8, indexed by the natural numbers as usually ordered, with the morphisms from formula_9 to formula_8 given by the natural projection.\nBULLET::::- Pro-finite groups are defined as inverse limits of (discrete) finite groups.\nBULLET::::- Let the index set \"I\" of an inverse system (\"X\", \"f\") have a greatest element \"m\". Then the natural projection π: \"X\" → \"X\" is an isomorphism.\nBULLET::::- In the category of sets, every inverse system has an inverse limit, which can be constructed in an elementary manner as a subset of the product of the sets forming the inverse system. The inverse limit of any inverse system of non-empty finite sets is non-empty. This is a generalization of Kőnig's lemma in graph theory and may be proved with Tychonoff's theorem, viewing the finite sets as compact discrete spaces, and then applying the finite intersection property characterization of compactness.\nBULLET::::- In the category of topological spaces, every inverse system has an inverse limit. It is constructed by placing the initial topology on the underlying set-theoretic inverse limit. This is known as the limit topology.\nBULLET::::- The set of infinite strings is the inverse limit of the set of finite strings, and is thus endowed with the limit topology. As the original spaces are discrete, the limit space is totally disconnected. This is one way of realizing the \"p\"-adic numbers and the Cantor set (as infinite strings).\n\nFor an abelian category \"C\", the inverse limit functor\nis left exact. If \"I\" is ordered (not simply partially ordered) and countable, and \"C\" is the category Ab of abelian groups, the Mittag-Leffler condition is a condition on the transition morphisms \"f\" that ensures the exactness of formula_12. Specifically, Eilenberg constructed a functor\n(pronounced \"lim one\") such that if (\"A\", \"f\"), (\"B\", \"g\"), and (\"C\", \"h\") are three inverse systems of abelian groups, and\nis a short exact sequence of inverse systems, then\nis an exact sequence in Ab.\n\nIf the ranges of the morphisms of an inverse system of abelian groups (\"A\", \"f\") are \"stationary\", that is, for every \"k\" there exists \"j\" ≥ \"k\" such that for all \"i\" ≥ \"j\" :formula_16 one says that the system satisfies the Mittag-Leffler condition.\n\nThe name \"Mittag-Leffler\" for this condition was given by Bourbaki in their chapter on uniform structures for a similar result about inverse limits of complete Hausdorff uniform spaces. Mittag-Leffler used a similar argument in the proof of Mittag-Leffler's theorem.\n\nThe following situations are examples where the Mittag-Leffler condition is satisfied: \nBULLET::::- a system in which the morphisms \"f\" are surjective\nBULLET::::- a system of finite-dimensional vector spaces or finite abelian groups or modules of finite length or Artinian modules.\n\nAn example where formula_17 is non-zero is obtained by taking \"I\" to be the non-negative integers, letting \"A\" = \"p\"Z, \"B\" = Z, and \"C\" = \"B\" / \"A\" = Z/\"p\"Z. Then\nwhere Z denotes the p-adic integers.\n\nMore generally, if \"C\" is an arbitrary abelian category that has enough injectives, then so does \"C\", and the right derived functors of the inverse limit functor can thus be defined. The \"n\"th right derived functor is denoted\nIn the case where \"C\" satisfies Grothendieck's axiom (AB4*), Jan-Erik Roos generalized the functor lim on Ab to series of functors lim such that\nIt was thought for almost 40 years that Roos had proved (in \"Sur les foncteurs dérivés de lim. Applications. \") that lim \"A\" = 0 for (\"A\", \"f\") an inverse system with surjective transition morphisms and \"I\" the set of non-negative integers (such inverse systems are often called \"Mittag-Leffler sequences\"). However, in 2002, Amnon Neeman and Pierre Deligne constructed an example of such a system in a category satisfying (AB4) (in addition to (AB4*)) with lim \"A\" ≠ 0. Roos has since shown (in \"Derived functors of inverse limits revisited\") that his result is correct if \"C\" has a set of generators (in addition to satisfying (AB3) and (AB4*)).\n\nBarry Mitchell has shown (in \"The cohomological dimension of a directed set\") that if \"I\" has cardinality formula_21 (the \"d\"th infinite cardinal), then \"R\"lim is zero for all \"n\" ≥ \"d\" + 2. This applies to the \"I\"-indexed diagrams in the category of \"R\"-modules, with \"R\" a commutative ring; it is not necessarily true in an arbitrary abelian category (see Roos' \"Derived functors of inverse limits revisited\" for examples of abelian categories in which lim, on diagrams indexed by a countable set, is nonzero for \"n\" > 1).\n\nThe categorical dual of an inverse limit is a direct limit (or inductive limit). More general concepts are the limits and colimits of category theory. The terminology is somewhat confusing: inverse limits are a class of limits, while direct limits are a class of colimits.\n\nBULLET::::- Direct, or inductive limit\nBULLET::::- Protorus\n\nBULLET::::- Section 3.5 of\n"}
{"id": "15111", "url": "https://en.wikipedia.org/wiki?curid=15111", "title": "Interplanetary spaceflight", "text": "Interplanetary spaceflight\n\nInterplanetary spaceflight or interplanetary travel is travel between planets, usually within a single planetary system. In practice, spaceflights of this type are confined to travel between the planets of the Solar System.\n\nRemotely guided space probes have flown by all of the planets of the Solar System from Mercury to Neptune, with the \"New Horizons\" probe having flown by the dwarf planet Pluto and the \"Dawn\" spacecraft currently orbiting the dwarf planet Ceres. The most distant spacecrafts, \"Voyager 1\" and \"Voyager 2\" have left the Solar System as of while \"Pioneer 10\", \"Pioneer 11\", and \"New Horizons\" are on course to leave it.\n\nIn general, planetary orbiters and landers return much more detailed and comprehensive information than fly-by missions. Space probes have been placed into orbit around all the five planets known to the ancients: first Mars (Mariner 9, 1971), then Venus (Venera 9, 1975; but landings on Venus and atmospheric probes were performed even earlier), Jupiter (\"Galileo\", 1995), Saturn (\"Cassini/Huygens\", 2004), and most recently Mercury (\"MESSENGER\", March 2011), and have returned data about these bodies and their natural satellites.\n\nThe NEAR Shoemaker mission in 2000 orbited the large near-Earth asteroid 433 Eros, and was even successfully landed there, though it had not been designed with this maneuver in mind. The Japanese ion-drive spacecraft \"Hayabusa\" in 2005 also orbited the small near-Earth asteroid 25143 Itokawa, landing on it briefly and returning grains of its surface material to Earth. Another powerful ion-drive mission, \"Dawn\", has orbited the large asteroid Vesta (July 2011 – September 2012) and later moved on to the dwarf planet Ceres, arriving in March 2015.\n\nRemotely controlled landers such as Viking, Pathfinder and the two Mars Exploration Rovers have landed on the surface of Mars and several Venera and Vega spacecraft have landed on the surface of Venus. The \"Huygens\" probe successfully landed on Saturn's moon, Titan.\n\nNo manned missions have been sent to any planet of the Solar System. NASA's Apollo program, however, landed twelve people on the Moon and returned them to Earth. The American Vision for Space Exploration, originally introduced by U.S. President George W. Bush and put into practice through the Constellation program, had as a long-term goal to eventually send human astronauts to Mars. However, on February 1, 2010, President Barack Obama proposed cancelling the program in Fiscal Year 2011. An earlier project which received some significant planning by NASA included a manned fly-by of Venus in the Manned Venus Flyby mission, but was cancelled when the Apollo Applications Program was terminated due to NASA budget cuts in the late 1960s.\n\nThe costs and risk of interplanetary travel receive a lot of publicity — spectacular examples include the malfunctions or complete failures of unmanned probes such as Mars 96, Deep Space 2, and Beagle 2 (the article List of Solar System probes gives a full list).\n\nMany astronomers, geologists and biologists believe that exploration of the Solar System provides knowledge that could not be gained by observations from Earth's surface or from orbit around Earth. But they disagree about whether manned missions make a useful scientific contribution — some think robotic probes are cheaper and safer, while others argue that either astronauts advised by Earth-based scientists, or spacefaring scientists advised by Earth-based scientists, can respond more flexibly and intelligently to new or unexpected features of the region they are exploring.\n\nThose who pay for such missions (primarily in the public sector) are more likely to be interested in benefits for themselves or for the human race as a whole. So far the only benefits of this type have been \"spin-off\" technologies which were developed for space missions and then were found to be at least as useful in other activities (NASA publicizes spin-offs from its activities).\n\nOther practical motivations for interplanetary travel are more speculative, because our current technologies are not yet advanced enough to support test projects. But science fiction writers have a fairly good track record in predicting future technologies — for example geosynchronous communications satellites (Arthur C. Clarke) and many aspects of computer technology (Mack Reynolds).\n\nMany science fiction stories feature detailed descriptions of how people could extract minerals from asteroids and energy from sources including orbital solar panels (unhampered by clouds) and the very strong magnetic field of Jupiter. Some point out that such techniques may be the only way to provide rising standards of living without being stopped by pollution or by depletion of Earth's resources (for example peak oil).\n\nFinally, colonizing other parts of the Solar System would prevent the whole human species from being exterminated by any one of a number of possible events (see Human extinction). One of these possible events is an asteroid impact like the one which may have resulted in the Cretaceous–Paleogene extinction event. Although various Spaceguard projects monitor the Solar System for objects that might come dangerously close to Earth, current asteroid deflection strategies are crude and untested. To make the task more difficult, carbonaceous chondrites are rather sooty and therefore very hard to detect. Although carbonaceous chondrites are thought to be rare, some are very large and the suspected \"dinosaur-killer\" may have been a carbonaceous chondrite.\n\nSome scientists, including members of the Space Studies Institute, argue that the vast majority of mankind eventually will live in space and will benefit from doing this.\n\nOne of the main challenges in interplanetary travel is producing the very large velocity changes necessary to travel from one body to another in the Solar System.\n\nDue to the Sun's gravitational pull, a spacecraft moving farther from the Sun will slow down, while a spacecraft moving closer will speed up. Also, since any two planets are at different distances from the Sun, the planet from which the spacecraft starts is moving around the Sun at a different speed than the planet to which the spacecraft is travelling (in accordance with Kepler's Third Law). Because of these facts, a spacecraft desiring to transfer to a planet closer to the Sun must decrease its speed with respect to the Sun by a large amount in order to intercept it, while a spacecraft traveling to a planet farther out from the Sun must increase its speed substantially. Then, if additionally the spacecraft wishes to enter into orbit around the destination planet (instead of just flying by it), it must match the planet's orbital speed around the Sun, usually requiring another large velocity change.\n\nSimply doing this by brute force – accelerating in the shortest route to the destination and then matching the planet's speed – would require an extremely large amount of fuel. And the fuel required for producing these velocity changes has to be launched along with the payload, and therefore even more fuel is needed to put both the spacecraft and the fuel required for its interplanetary journey into orbit. Thus, several techniques have been devised to reduce the fuel requirements of interplanetary travel.\n\nAs an example of the velocity changes involved, a spacecraft travelling from low Earth orbit to Mars using a simple trajectory must first undergo a change in speed (also known as a delta-v), in this case an increase, of about 3.8 km/s. Then, after intercepting Mars, it must change its speed by another 2.3 km/s in order to match Mars' orbital speed around the Sun and enter an orbit around it. For comparison, launching a spacecraft into low Earth orbit requires a change in speed of about 9.5 km/s.\n\nFor many years economical interplanetary travel meant using the Hohmann transfer orbit. Hohmann demonstrated that the lowest energy route between any two orbits is an elliptical \"orbit\" which forms a tangent to the starting and destination orbits. Once the spacecraft arrives, a second application of thrust will re-circularize the orbit at the new location. In the case of planetary transfers this means directing the spacecraft, originally in an orbit almost identical to Earth's, so that the aphelion of the transfer orbit is on the far side of the Sun near the orbit of the other planet. A spacecraft traveling from Earth to Mars via this method will arrive near Mars orbit in approximately 8.5 months, but because the orbital velocity is greater when closer to the center of mass (i.e. the Sun) and slower when farther from the center, the spacecraft will be traveling quite slowly and a small application of thrust is all that is needed to put it into a circular orbit around Mars. If the manoeuver is timed properly, Mars will be \"arriving\" under the spacecraft when this happens.\n\nThe Hohmann transfer applies to any two orbits, not just those with planets involved. For instance it is the most common way to transfer satellites into geostationary orbit, after first being \"parked\" in low Earth orbit. However, the Hohmann transfer takes an amount of time similar to ½ of the orbital period of the outer orbit, so in the case of the outer planets this is many years – too long to wait. It is also based on the assumption that the points at both ends are massless, as in the case when transferring between two orbits around Earth for instance. With a planet at the destination end of the transfer, calculations become considerably more difficult.\n\nThe gravitational slingshot technique uses the gravity of planets and moons to change the speed and direction of a spacecraft without using fuel. In typical example, a spacecraft is sent to a distant planet on a path that is much faster than what the Hohmann transfer would call for. This would typically mean that it would arrive at the planet's orbit and continue past it. However, if there is a planet between the departure point and the target, it can be used to bend the path toward the target, and in many cases the overall travel time is greatly reduced. A prime example of this are the two crafts of the Voyager program, which used slingshot effects to change trajectories several times in the outer Solar System. It is difficult to use this method for journeys in the inner part of the Solar System, although it is possible to use other nearby planets such as Venus or even the Moon as slingshots in journeys to the outer planets.\n\nThis maneuver can only change an object's velocity relative to a third, uninvolved object, – possibly the “centre of mass” or the Sun. There is no change in the velocities of the two objects involved in the maneuver relative to each other. The Sun cannot be used in a gravitational slingshot because it is stationary compared to rest of the Solar System, which orbits the Sun. It may be used to send a spaceship or probe into the galaxy because the Sun revolves around the center of the Milky Way.\n\nA powered slingshot is the use of a rocket engine at or around closest approach to a body (periapsis). The use at this point multiplies up the effect of the delta-v, and gives a bigger effect than at other times.\n\nComputers did not exist when Hohmann transfer orbits were first proposed (1925) and were slow, expensive and unreliable when gravitational slingshots were developed (1959). Recent advances in computing have made it possible to exploit many more features of the gravity fields of astronomical bodies and thus calculate even lower-cost trajectories. Paths have been calculated which link the Lagrange points of the various planets into the so-called Interplanetary Transport Network. Such \"fuzzy orbits\" use significantly less energy than Hohmann transfers but are much, much slower. They aren't practical for manned missions because they generally take years or decades, but may be useful for high-volume transport of low-value commodities if humanity develops a space-based economy.\n\nAerobraking uses the atmosphere of the target planet to slow down. It was first used on the Apollo program where the returning spacecraft did not enter Earth orbit but instead used a S-shaped vertical descent profile (starting with an initially steep descent, followed by a leveling out, followed by a slight climb, followed by a return to a positive rate of descent continuing to splash-down in the ocean) through Earth's atmosphere to reduce its speed until the parachute system could be deployed enabling a safe landing. Aerobraking does not require a thick atmosphere – for example most Mars landers use the technique, and Mars' atmosphere is only about 1% as thick as Earth's.\n\nAerobraking converts the spacecraft's kinetic energy into heat, so it requires a heatshield to prevent the craft from burning up. As a result, aerobraking is only helpful in cases where the fuel needed to transport the heatshield to the planet is less than the fuel that would be required to brake an unshielded craft by firing its engines. This can be addressed by creating heatshields from material available near the target\n\nSeveral technologies have been proposed which both save fuel and provide significantly faster travel than the traditional methodology of using Hohmann transfers. Some are still just theoretical, but over time, several of the theoretical approaches have been tested on spaceflight missions. For example, the Deep Space 1 mission was a successful test of an ion drive. These improved technologies typically focus on one or more of:\nBULLET::::- Space propulsion systems with much better fuel economy. Such systems would make it possible to travel much faster while keeping the fuel cost within acceptable limits.\nBULLET::::- Using solar energy and in-situ resource utilization to avoid or minimize the expensive task of shipping components and fuel up from the Earth's surface, against the Earth's gravity (see \"Using non-terrestrial resources\", below).\nBULLET::::- Novel methodologies of using energy at different locations or in different ways that can shorten transport time or reduce cost per unit mass of space transport\n\nBesides making travel faster or cost less, such improvements could also allow greater design \"safety margins\" by reducing the imperative to make spacecraft lighter.\n\nAll rocket concepts are limited by the rocket equation, which sets the characteristic velocity available as a function of exhaust velocity and mass ratio, of initial (\"M\", including fuel) to final (\"M\", fuel depleted) mass. The main consequence is that mission velocities of more than a few times the velocity of the rocket motor exhaust (with respect to the vehicle) rapidly become impractical.\n\nIn a nuclear thermal rocket or solar thermal rocket a working fluid, usually hydrogen, is heated to a high temperature, and then expands through a rocket nozzle to create thrust. The energy replaces the chemical energy of the reactive chemicals in a traditional rocket engine. Due to the low molecular mass and hence high thermal velocity of hydrogen these engines are at least twice as fuel efficient as chemical engines, even after including the weight of the reactor.\n\nThe US Atomic Energy Commission and NASA tested a few designs from 1959 to 1968. The NASA designs were conceived as replacements for the upper stages of the Saturn V launch vehicle, but the tests revealed reliability problems, mainly caused by the vibration and heating involved in running the engines at such high thrust levels. Political and environmental considerations make it unlikely such an engine will be used in the foreseeable future, since nuclear thermal rockets would be most useful at or near the Earth's surface and the consequences of a malfunction could be disastrous. Fission-based thermal rocket concepts produce lower exhaust velocities than the electric and plasma concepts described below, and are therefore less attractive solutions. For applications requiring high thrust-to-weight ratio, such as planetary escape, nuclear thermal is potentially more attractive.\n\nElectric propulsion systems use an external source such as a nuclear reactor or solar cells to generate electricity, which is then used to accelerate a chemically inert propellant to speeds far higher than achieved in a chemical rocket. Such drives produce feeble thrust, and are therefore unsuitable for quick maneuvers or for launching from the surface of a planet. But they are so economical in their use of\nreaction mass that they can keep firing continuously for days or weeks, while chemical rockets use up reaction mass so quickly that they can only fire for seconds or minutes. Even a trip to the Moon is long enough for an electric propulsion system to outrun a chemical rocket – the Apollo missions took 3 days in each direction.\n\nNASA's Deep Space One was a very successful test of a prototype ion drive, which fired for a total of 678 days and enabled the probe to run down Comet Borrelly, a feat which would have been impossible for a chemical rocket. \"Dawn\", the first NASA operational (i.e., non-technology demonstration) mission to use an ion drive for its primary propulsion, is currently on track to explore and orbit the large main-belt asteroids 1 Ceres and 4 Vesta. A more ambitious, nuclear-powered version was intended for an unmanned Jupiter mission, the Jupiter Icy Moons Orbiter (JIMO), originally planned for launch sometime in the next decade. Due to a shift in priorities at NASA that favored manned space missions, the project lost funding in 2005. A similar mission is currently under discussion as the US component of a joint NASA/ESA program for the exploration of Europa and Ganymede.\n\nA NASA multi-center Technology Applications Assessment Team led from the Johnson Spaceflight Center, has as of January 2011 described \"Nautilus-X\", a concept study for a multi-mission space exploration vehicle useful for missions beyond low Earth orbit (LEO), of up to 24 months duration for a crew of up to six. Although Nautilus-X is adaptable to a variety of mission-specific propulsion units of various low-thrust, high specific impulse (I) designs, nuclear ion-electric drive is shown for illustrative purposes. It is intended for integration and checkout at the International Space Station (ISS), and would be suitable for deep-space missions from the ISS to and beyond the Moon, including Earth/Moon L1, Sun/Earth L2, near-Earth asteroidal, and Mars orbital destinations. It incorporates a reduced-g centrifuge providing artificial gravity for crew health to ameliorate the effects of long-term 0g exposure, and the capability to mitigate the space radiation environment.\n\nThe electric propulsion missions already flown, or currently scheduled, have used solar electric power, limiting their capability to operate far from the Sun, and also limiting their peak acceleration due to the mass of the electric power source. Nuclear-electric or plasma engines, operating for long periods at low thrust and powered by fission reactors, can reach speeds much greater than chemically powered vehicles.\n\nFusion rockets, powered by nuclear fusion reactions, would \"burn\" such light element fuels as deuterium, tritium, or He. Because fusion yields about 1% of the mass of the nuclear fuel as released energy, it is energetically more favorable than fission, which releases only about 0.1% of the fuel's mass-energy. However, either fission or fusion technologies can in principle achieve velocities far higher than needed for Solar System exploration, and fusion energy still awaits practical demonstration on Earth.\n\nOne proposal using a fusion rocket was Project Daedalus. Another fairly detailed vehicle system, designed and optimized for crewed Solar System exploration, \"Discovery II\", based on the DHe reaction but using hydrogen as reaction mass, has been described by a team from NASA's Glenn Research Center. It achieves characteristic velocities of >300 km/s with an acceleration of ~1.7•10 \"g\", with a ship initial mass of ~1700 metric tons, and payload fraction above 10%.\n\nSee the spacecraft propulsion article for a discussion of a number of other technologies that could, in the medium to longer term, be the basis of interplanetary missions. Unlike the situation with interstellar travel, the barriers to fast interplanetary travel involve engineering and economics rather than any basic physics.\n\nSolar sails rely on the fact that light reflected from a surface exerts pressure on the surface. The radiation pressure is small and decreases by the square of the distance from the Sun, but unlike rockets, solar sails require no fuel. Although the thrust is small, it continues as long as the Sun shines and the sail is deployed.\n\nThe original concept relied only on radiation from the Sun – for example in Arthur C. Clarke's 1965 story \"Sunjammer\". More recent light sail designs propose to boost the thrust by aiming ground-based lasers or masers at the sail. Ground-based lasers or masers can also help a light-sail spacecraft to \"decelerate\": the sail splits into an outer and inner section, the outer section is pushed forward and its shape is changed mechanically to focus reflected radiation on the inner portion, and the radiation focused on the inner section acts as a brake.\n\nAlthough most articles about light sails focus on interstellar travel, there have been several proposals for their use within the Solar System.\n\nCurrently, the only spacecraft to use a solar sail as the main method of propulsion is IKAROS which was launched by JAXA on May 21, 2010. It has since been successfully deployed, and shown to be producing acceleration as expected. Many ordinary spacecraft and satellites also use solar collectors, temperature-control panels and Sun shades as light sails, to make minor corrections to their attitude and orbit without using fuel. A few have even had small purpose-built solar sails for this use (for example Eurostar E3000 geostationary communications satellites built by EADS Astrium).\n\nIt is possible to put stations or spacecraft on orbits that cycle between different planets, for example a Mars cycler would synchronously cycle between Mars and Earth, with very little propellant usage to maintain the trajectory. Cyclers are conceptually a good idea, because massive radiation shields, life support and other equipment only need to be put onto the cycler trajectory once. A cycler could combine several roles: habitat (for example it could spin to produce an \"artificial gravity\" effect); mothership (providing life support for the crews of smaller spacecraft which hitch a ride on it). Cyclers could also possibly make excellent cargo ships for resupply of a colony.\n\nA space elevator is a theoretical structure that would transport material from a planet's surface into orbit. The idea is that, once the expensive job of building the elevator is complete, an indefinite number of loads can be transported into orbit at minimal cost. Even the simplest designs avoid the vicious circle of rocket launches from the surface, wherein the fuel needed to travel the last 10% of the distance into orbit must be lifted all the way from the surface, requiring even more fuel, and so on. More sophisticated space elevator designs reduce the energy cost per trip by using counterweights, and the most ambitious schemes aim to balance loads going up and down and thus make the energy cost close to zero. Space elevators have also sometimes been referred to as \"beanstalks\", \"space bridges\", \"space lifts\", \"space ladders\" and \"orbital towers\". \n\nA terrestrial space elevator is beyond our current technology, although a lunar space elevator could theoretically be built using existing materials.\n\nA skyhook is a theoretical class of orbiting tether propulsion intended to lift payloads to high altitudes and speeds. Proposals for skyhooks include designs that employ tethers spinning at hypersonic speed for catching high speed payloads or high altitude aircraft and placing them in orbit. In addition, it has been suggested that the rotating skyhook is \"not engineeringly feasible using presently available materials\".\n\nThe SpaceX Starship, with maiden launch slated to be no earlier than 2020, is designed to be fully and rapidly reusable, making use of the SpaceX reusable technology that was developed during 2011–2018 for Falcon 9 and Falcon Heavy launch vehicles.\n\nSpaceX CEO Elon Musk estimates that the reusability capability alone, on both the launch vehicle and the spacecraft associated with the Starship will reduce overall system costs per tonne delivered to Mars by at least two orders of magnitude over what NASA had previously achieved.\n\nWhen launching interplanetary probes from the surface of Earth, carrying all energy needed for the long-duration mission, payload quantities are necessarily extremely limited, due to the basis mass limitations described theoretically by the rocket equation. One alternative to transport more mass on interplanetary trajectories is to use up nearly all of the upper stage propellant on launch, and then refill propellants in Earth orbit before firing the rocket to escape velocity for a heliocentric trajectory. These propellants could be stored on orbit at a propellant depot, or carried to orbit in a propellant tanker to be directly transferred to the interplanetary spacecraft. For returning mass to Earth, a related option is to mine raw materials from a solar system celestial object, refine, process, and store the reaction products (propellant) on the Solar System body until such time as a vehicle needs to be loaded for launch.\n\nAs of 2019, SpaceX is developing a system in which a reusable first stage vehicle would transport a crewed interplanetary spacecraft to Earth orbit, detach, return to its launch pad where a tanker spacecraft would be mounted atop it, then both fueled, then launched again to rendezvous with the waiting manned spacecraft. The tanker would then transfer its fuel to the manned spacecraft for use on its interplanetary voyage. The SpaceX Starship is a stainless steel-structure spacecraft propelled by six Raptor engines operating on densified methane/oxygen propellants. It is -long, -diameter at its widest point, and is capable of transporting up to of cargo and passengers per trip to Mars, with on-orbit propellant refill before the interplanetary part of the journey.\n\nAs an example of a funded project currently under development, a key part of the system SpaceX has designed for Mars in order to radically decrease the cost of spaceflight to interplanetary destinations is the placement and operation of a physical plant on Mars to handle production and storage of the propellant components necessary to launch and fly the Starships back to Earth, or perhaps to increase the mass that can be transported onward to destinations in the outer Solar System.\n\nThe first Starship to Mars will carry a small propellant plant as a part of its cargo load. The plant will be expanded over multiple synods as more equipment arrives, is installed, and placed into mostly-autonomous production.\n\nThe SpaceX propellant plant will take advantage of the large supplies of carbon dioxide and water resources on Mars, mining the water (HO) from subsurface ice and collecting CO from the atmosphere. A chemical plant will process the raw materials by means of electrolysis and the Sabatier process to produce oxygen (O) and methane (CH), and then liquefy it to facilitate long-term storage and ultimate use.\n\nCurrent space vehicles attempt to launch with all their fuel (propellants and energy supplies) on board that they will need for their entire journey, and current space structures are lifted from the Earth's surface. Non-terrestrial sources of energy and materials are mostly a lot further away, but most would not require lifting out of a strong gravity field and therefore should be much cheaper to use in space in the long term.\n\nThe most important non-terrestrial resource is energy, because it can be used to transform non-terrestrial materials into useful forms (some of which may also produce energy). At least two fundamental non-terrestrial energy sources have been proposed: solar-powered energy generation (unhampered by clouds), either directly by solar cells or indirectly by focusing solar radiation on boilers which produce steam to drive generators; and electrodynamic tethers which generate electricity from the powerful magnetic fields of some planets (Jupiter has a very powerful magnetic field).\n\nWater ice would be very useful and is widespread on the moons of Jupiter and Saturn:\nBULLET::::- The low gravity of these moons would make them a cheaper source of water for space stations and planetary bases than lifting it up from Earth's surface.\nBULLET::::- Non-terrestrial power supplies could be used to electrolyse water ice into oxygen and hydrogen for use in bipropellant rocket engines.\nBULLET::::- Nuclear thermal rockets or Solar thermal rockets could use it as reaction mass. Hydrogen has also been proposed for use in these engines and would provide much greater specific impulse (thrust per kilogram of reaction mass), but it has been claimed that water will beat hydrogen in cost/performance terms despite its much lower specific impulse by orders of magnitude.\n\nOxygen is a common constituent of the moon's crust, and is probably abundant in most other bodies in the Solar System. Non-terrestrial oxygen would be valuable as a source of water ice only if an adequate source of hydrogen can be found. Possible uses include:\n\nBULLET::::- In the life support systems of space ships, space stations and planetary bases.\nBULLET::::- In rocket engines. Even if the other propellant has to be lifted from Earth, using non-terrestrial oxygen could reduce propellant launch costs by up to 2/3 for hydrocarbon fuel, or 85% for hydrogen. The savings are so high because oxygen accounts for the majority of the mass in most rocket propellant combinations.\n\nUnfortunately hydrogen, along with other volatiles like carbon and nitrogen, are much less abundant than oxygen in the inner Solar System.\n\nScientists expect to find a vast range of organic compounds in some of the planets, moons and comets of the outer Solar System, and the range of possible uses is even wider. For example, methane can be used as a fuel (burned with non-terrestrial oxygen), or as a feedstock for petrochemical processes such as making plastics. And ammonia could be a valuable feedstock for producing fertilizers to be used in the vegetable gardens of orbital and planetary bases, reducing the need to lift food to them from Earth.\n\nEven unprocessed rock may be useful as rocket propellant if mass drivers are employed.\n\nLife support systems must be capable of supporting human life for weeks, months or even years. A breathable atmosphere of at least must be maintained, with adequate amounts of oxygen, nitrogen, and controlled levels of carbon dioxide, trace gases and water vapor.\n\nIn October 2015, the NASA Office of Inspector General issued a health hazards report related to human spaceflight, including a human mission to Mars.\nOnce a vehicle leaves low Earth orbit and the protection of Earth's magnetosphere, it enters the Van Allen radiation belt, a region of high radiation. Once through there the radiation drops to lower levels, with a constant background of high energy cosmic rays which pose a health threat. These are dangerous over periods of years to decades.\n\nScientists of Russian Academy of Sciences are searching for methods of reducing the risk of radiation-induced cancer in preparation for the mission to Mars. They consider as one of the options a life support system generating drinking water with low content of deuterium (a stable isotope of hydrogen) to be consumed by the crew members. Preliminary investigations have shown that deuterium-depleted water features certain anti-cancer effects. Hence, deuterium-free drinking water is considered to have the potential of lowering the risk of cancer caused by extreme radiation exposure of the Martian crew.\n\nIn addition, coronal mass ejections from the Sun are highly dangerous, and are fatal within a very short timescale to humans unless they are protected by massive shielding.\n\nAny major failure to a spacecraft en route is likely to be fatal, and even a minor one could have dangerous results if not repaired quickly, something difficult to accomplish in open space. The crew of the Apollo 13 mission survived despite an explosion caused by a faulty oxygen tank (1970).\n\nFor astrodynamics reasons, economic spacecraft travel to other planets is only practical within certain time windows. Outside these windows the planets are essentially inaccessible from Earth with current technology. This constrains flights and limits rescue options in the case of an emergency.\n"}
{"id": "15112", "url": "https://en.wikipedia.org/wiki?curid=15112", "title": "Wave interference", "text": "Wave interference\n\nIn physics, interference is a phenomenon in which two waves superpose to form a resultant wave of greater, lower, or the same amplitude. Constructive and destructive interference result from the interaction of waves that are correlated or coherent with each other, either because they come from the same source or because they have the same or nearly the same frequency. Interference effects can be observed with all types of waves, for example, light, radio, acoustic, surface water waves, gravity waves, or matter waves. The resulting images or graphs are called interferograms.\n\nThe principle of superposition of waves states that when two or more propagating waves of same type are incident on the same point, the resultant amplitude at that point is equal to the vector sum of the amplitudes of the individual waves. If a crest of a wave meets a crest of another wave of the same frequency at the same point, then the amplitude is the sum of the individual amplitudes—this is constructive interference. If a crest of one wave meets a trough of another wave, then the amplitude is equal to the difference in the individual amplitudes—this is known as destructive interference.\n\nConstructive interference occurs when the phase difference between the waves is an even multiple of (180°) , whereas destructive interference occurs when the difference is an odd multiple of . If the difference between the phases is intermediate between these two extremes, then the magnitude of the displacement of the summed waves lies between the minimum and maximum values.\n\nConsider, for example, what happens when two identical stones are dropped into a still pool of water at different locations. Each stone generates a circular wave propagating outwards from the point where the stone was dropped. When the two waves overlap, the net displacement at a particular point is the sum of the displacements of the individual waves. At some points, these will be in phase, and will produce a maximum displacement. In other places, the waves will be in anti-phase, and there will be no net displacement at these points. Thus, parts of the surface will be stationary—these are seen in the figure above and to the right as stationary blue-green lines radiating from the centre.\n\nInterference of light is a common phenomenon that can be explained classically by the superposition of waves, however a deeper understanding of light interference requires knowledge of wave-particle duality of light which is due to quantum mechanics. Prime examples of light interference are the famous double-slit experiment, laser speckle, anti-reflective coatings and interferometers. Traditionally the classical wave model is taught as a basis for understanding optical interference, based on the Huygens–Fresnel principle.\n\nThe above can be demonstrated in one dimension by deriving the formula for the sum of two waves. The equation for the amplitude of a sinusoidal wave traveling to the right along the x-axis is\nwhere formula_2 is the peak amplitude, formula_3 is the wavenumber and formula_4 is the angular frequency of the wave. Suppose a second wave of the same frequency and amplitude but with a different phase is also traveling to the right \nwhere formula_6 is the phase difference between the waves in radians. The two waves will superpose and add: the sum of the two waves is\nUsing the trigonometric identity for the sum of two cosines: formula_8 this can be written\nThis represents a wave at the original frequency, traveling to the right like the components, whose amplitude is proportional to the cosine of formula_10. \nBULLET::::- \"Constructive interference\": If the phase difference is an even multiple of : formula_11 then formula_12, so the sum of the two waves is a wave with twice the amplitude\nBULLET::::- \"Destructive interference\": If the phase difference is an odd multiple of : formula_14 then formula_15, so the sum of the two waves is zero\n\nA simple form of interference pattern is obtained if two plane waves of the same frequency intersect at an angle. \nInterference is essentially an energy redistribution process. The energy which is lost at the destructive interference is regained at the constructive interference.\nOne wave is travelling horizontally, and the other is travelling downwards at an angle θ to the first wave. Assuming that the two waves are in phase at the point B, then the relative phase changes along the \"x\"-axis. The phase difference at the point A is given by\n\nIt can be seen that the two waves are in phase when\n\nand are half a cycle out of phase when\n\nConstructive interference occurs when the waves are in phase, and destructive interference when they are half a cycle out of phase. Thus, an interference fringe pattern is produced, where the separation of the maxima is\n\nand is known as the fringe spacing. The fringe spacing increases with increase in wavelength, and with decreasing angle .\n\nThe fringes are observed wherever the two waves overlap and the fringe spacing is uniform throughout.\n\nA point source produces a spherical wave. If the light from two point sources overlaps, the interference pattern maps out the way in which the phase difference between the two waves varies in space. This depends on the wavelength and on the separation of the point sources. The figure to the right shows interference between two spherical waves. The wavelength increases from top to bottom, and the distance between the sources increases from left to right.\n\nWhen the plane of observation is far enough away, the fringe pattern will be a series of almost straight lines, since the waves will then be almost planar.\n\nInterference occurs when several waves are added together provided that the phase differences between them remain constant over the observation time.\n\nIt is sometimes desirable for several waves of the same frequency and amplitude to sum to zero (that is, interfere destructively, cancel). This is the principle behind, for example, 3-phase power and the diffraction grating. In both of these cases, the result is achieved by uniform spacing of the phases.\n\nIt is easy to see that a set of waves will cancel if they have the same amplitude and their phases are spaced equally in angle. Using phasors, each wave can be represented as formula_21 for formula_22 waves from formula_23 to formula_24, where\n\nTo show that\n\none merely assumes the converse, then multiplies both sides by formula_27\n\nThe Fabry–Pérot interferometer uses interference between multiple reflections.\n\nA diffraction grating can be considered to be a multiple-beam interferometer; since the peaks which it produces are generated by interference between the light transmitted by each of the elements in the grating; see interference vs. diffraction for further discussion.\n\nBecause the frequency of light waves (~10 Hz) is too high to be detected by currently available detectors, it is possible to observe only the intensity of an optical interference pattern. The intensity of the light at a given point is proportional to the square of the average amplitude of the wave. This can be expressed mathematically as follows. The displacement of the two waves at a point is:\n\nwhere represents the magnitude of the displacement, represents the phase and represents the angular frequency.\n\nThe displacement of the summed waves is\n\nThe intensity of the light at is given by\n\nThis can be expressed in terms of the intensities of the individual waves as\n\nThus, the interference pattern maps out the difference in phase between the two waves, with maxima occurring when the phase difference is a multiple of 2. If the two beams are of equal intensity, the maxima are four times as bright as the individual beams, and the minima have zero intensity.\n\nThe two waves must have the same polarization to give rise to interference fringes since it is not possible for waves of different polarizations to cancel one another out or add together. Instead, when waves of different polarization are added together, they give rise to a wave of a different polarization state.\n\nThe discussion above assumes that the waves which interfere with one another are monochromatic, i.e. have a single frequency—this requires that they are infinite in time. This is not, however, either practical or necessary. Two identical waves of finite duration whose frequency is fixed over that period will give rise to an interference pattern while they overlap. Two identical waves which consist of a narrow spectrum of frequency waves of finite duration, will give a series of fringe patterns of slightly differing spacings, and provided the spread of spacings is significantly less than the average fringe spacing, a fringe pattern will again be observed during the time when the two waves overlap.\n\nConventional light sources emit waves of differing frequencies and at different times from different points in the source. If the light is split into two waves and then re-combined, each individual light wave may generate an interference pattern with its other half, but the individual fringe patterns generated will have different phases and spacings, and normally no overall fringe pattern will be observable. However, single-element light sources, such as sodium- or mercury-vapor lamps have emission lines with quite narrow frequency spectra. When these are spatially and colour filtered, and then split into two waves, they can be superimposed to generate interference fringes. All interferometry prior to the invention of the laser was done using such sources and had a wide range of successful applications.\n\nA laser beam generally approximates much more closely to a monochromatic source, and it is much more straightforward to generate interference fringes using a laser. The ease with which interference fringes can be observed with a laser beam can sometimes cause problems in that stray reflections may give spurious interference fringes which can result in errors.\n\nNormally, a single laser beam is used in interferometry, though interference has been observed using two independent lasers whose frequencies were sufficiently matched to satisfy the phase requirements.\nThis has also been observed for widefield interference between two incoherent laser sources.\nIt is also possible to observe interference fringes using white light. A white light fringe pattern can be considered to be made up of a 'spectrum' of fringe patterns each of slightly different spacing. If all the fringe patterns are in phase in the centre, then the fringes will increase in size as the wavelength decreases and the summed intensity will show three to four fringes of varying colour. Young describes this very elegantly in his discussion of two slit interference. Since white light fringes are obtained only when the two waves have travelled equal distances from the light source, they can be very useful in interferometry, as they allow the zero path difference fringe to be identified.\n\nTo generate interference fringes, light from the source has to be divided into two waves which have then to be re-combined. Traditionally, interferometers have been classified as either amplitude-division or wavefront-division systems.\n\nIn an amplitude-division system, a beam splitter is used to divide the light into two beams travelling in different directions, which are then superimposed to produce the interference pattern. The Michelson interferometer and the Mach–Zehnder interferometer are examples of amplitude-division systems.\n\nIn wavefront-division systems, the wave is divided in space—examples are Young's double slit interferometer and Lloyd's mirror.\n\nInterference can also be seen in everyday phenomena such as iridescence and structural coloration. For example, the colours seen in a soap bubble arise from interference of light reflecting off the front and back surfaces of the thin soap film. Depending on the thickness of the film, different colours interfere constructively and destructively.\n\nInterferometry has played an important role in the advancement of physics, and also has a wide range of applications in physical and engineering measurement.\n\nThomas Young's double slit interferometer in 1803 demonstrated interference fringes when two small holes were illuminated by light from another small hole which was illuminated by sunlight. Young was able to estimate the wavelength of different colours in the spectrum from the spacing of the fringes. The experiment played a major role in the general acceptance of the wave theory of light. \nIn quantum mechanics, this experiment is considered to demonstrate the inseparability of the wave and particle natures of light and other quantum particles (wave–particle duality). Richard Feynman was fond of saying that all of quantum mechanics can be gleaned from carefully thinking through the implications of this single experiment.\nThe results of the Michelson–Morley experiment are generally considered to be the first strong evidence against the theory of a luminiferous aether and in favor of special relativity.\n\nInterferometry has been used in defining and calibrating length standards. When the metre was defined as the distance between two marks on a platinum-iridium bar, Michelson and Benoît used interferometry to measure the wavelength of the red cadmium line in the new standard, and also showed that it could be used as a length standard. Sixty years later, in 1960, the metre in the new SI system was defined to be equal to 1,650,763.73 wavelengths of the orange-red emission line in the electromagnetic spectrum of the krypton-86 atom in a vacuum. This definition was replaced in 1983 by defining the metre as the distance travelled by light in vacuum during a specific time interval. Interferometry is still fundamental in establishing the calibration chain in length measurement.\n\nInterferometry is used in the calibration of slip gauges (called gauge blocks in the US) and in coordinate-measuring machines. It is also used in the testing of optical components.\n\nIn 1946, a technique called astronomical interferometry was developed. Astronomical radio interferometers usually consist either of arrays of parabolic dishes or two-dimensional arrays of omni-directional antennas. All of the telescopes in the array are widely separated and are usually connected together using coaxial cable, waveguide, optical fiber, or other type of transmission line. Interferometry increases the total signal collected, but its primary purpose is to vastly increase the resolution through a process called Aperture synthesis. This technique works by superposing (interfering) the signal waves from the different telescopes on the principle that waves that coincide with the same phase will add to each other while two waves that have opposite phases will cancel each other out. This creates a combined telescope that is equivalent in resolution (though not in sensitivity) to a single antenna whose diameter is equal to the spacing of the antennas furthest apart in the array.\n\nAn acoustic interferometer is an instrument for measuring the physical characteristics of sound waves in a gas or liquid, such velocity, wavelength, absorption, or impedance. A vibrating crystal creates ultrasonic waves that are radiated into the medium. The waves strike a reflector placed parallel to the crystal, reflected back to the source and measured.\n\nIf a system is in state formula_33, its wavefunction is described in Dirac or bra–ket notation as:\n\nwhere the formula_35s specify the different quantum \"alternatives\" available (technically, they form an eigenvector basis) and the formula_36 are the probability amplitude coefficients, which are complex numbers.\n\nThe probability of observing the system making a transition or quantum leap from state formula_33 to a new state formula_38 is the square of the modulus of the scalar or inner product of the two states:\n\nwhere formula_41 (as defined above) and similarly formula_42 are the coefficients of the final state of the system. * is the complex conjugate so that formula_43, etc.\n\nNow consider the situation classically and imagine that the system transited from formula_44 to formula_45 via an intermediate state formula_46. Then we would \"classically\" expect the probability of the two-step transition to be the sum of all the possible intermediate steps. So we would have\n\nThe classical and quantum derivations for the transition probability differ by the presence, in the quantum case, of the extra terms formula_49; these extra quantum terms represent \"interference\" between the different formula_50 intermediate \"alternatives\". These are consequently known as the \"quantum interference terms\", or \"cross terms\". This is a purely quantum effect and is a consequence of the non-additivity of the probabilities of quantum alternatives.\n\nThe interference terms vanish, via the mechanism of quantum decoherence, if the intermediate state formula_35 is measured or coupled with its environment. \n\nBULLET::::- Active noise control\nBULLET::::- Beat (acoustics)\nBULLET::::- Coherence (physics)\nBULLET::::- Diffraction\nBULLET::::- Haidinger fringes\nBULLET::::- Interference lithography\nBULLET::::- Interference visibility\nBULLET::::- Interferometer\nBULLET::::- Lloyd's Mirror\nBULLET::::- Moiré pattern\nBULLET::::- Newton's rings\nBULLET::::- Optical path length\nBULLET::::- Thin-film interference\nBULLET::::- Upfade\nBULLET::::- Multipath interference\nBULLET::::- Easy JavaScript Simulation Model of One Dimensional Wave Interference\nBULLET::::- Expressions of position and fringe spacing\nBULLET::::- Java simulation of interference of water waves 1\nBULLET::::- Java simulation of interference of water waves 2\nBULLET::::- Flash animations demonstrating interference\n"}
{"id": "15114", "url": "https://en.wikipedia.org/wiki?curid=15114", "title": "Indictable offence", "text": "Indictable offence\n\nIn many common law jurisdictions (e.g., England and Wales, Ireland, Canada, Hong Kong, India, Australia, New Zealand, Malaysia, Singapore), an indictable offence is an offence which can only be tried on an indictment after a preliminary hearing to determine whether there is a \"prima facie\" case to answer or by a grand jury (in contrast to a summary offence). In the United States, a crime of similar severity and rules is called a felony, which also requires an indictment.\n\nIn relation to England and Wales, the expression \"indictable offence\" means an offence which, if committed by an adult, is triable on indictment, whether it is exclusively so triable or triable either way; and the term \"indictable\", in its application to offences, is to be construed accordingly. In this definition, references to the way or ways in which an offence is triable are to be construed without regard to the effect, if any, of section 22 of the Magistrates' Courts Act 1980 on the mode of trial in a particular case.\n\nAn either-way offence allows the defendant to elect between trial by jury on indictment in the Crown Court and summary trial in a magistrates' court. However, the election may be overruled by the magistrates' court if the facts suggest that the sentencing powers of a magistrates' court would be inadequate to reflect the seriousness of the offence. \n\nIn relation to some indictable offences, for example criminal damage, only summary trial is available unless the damage caused exceeds £5,000. \n\nA youth court has jurisdiction to try all indictable offences with the exception of homicide and certain firearms offences, and will normally do so provided that the available sentencing power of two years' detention is adequate to punish the offender if found guilty.\n\nSee section 64 of the Criminal Law Act 1977. \n\nGrand juries were abolished in 1933.\n\nSome offences such as murder and rape are considered so serious that they can only be tried on indictment at the Crown Court where the widest range of sentencing powers is available to the judge.\n\nThe expression \"indictable-only offence\" was defined by section 51 of the Crime and Disorder Act 1998, as originally enacted, as an offence triable only on indictment. Sections 51 and 52 of, and Schedule 3 to, that Act abolished committal proceedings for such offences and made other provisions in relation to them.\n\nWhen the accused is charged with an indictable-only offence, he or she will be tried in the Crown Court. The rules are different in England and Wales in respect of those under 18 years of age.\n\nSee also section 14(a) of the Criminal Law Act 1977.\n\nSimilarly in New Zealand, a rape or murder charge will be tried at the High Court, while less serious offences such as theft, will be tried at the District Court. However, the District Court can hold both jury and summary trials.\n\nFor differences between indictable offences and summary offences see summary offences.\n\nIn United States penal law, other than a felony, court findings of, or an act of gross negligence can be counted as an indictable offence.\n\nBULLET::::- Federal crime\nBULLET::::- Felony\nBULLET::::- Indictment\nBULLET::::- Summary offence\n"}
{"id": "15116", "url": "https://en.wikipedia.org/wiki?curid=15116", "title": "Inter Milan", "text": "Inter Milan\n\nFootball Club Internazionale Milano, commonly referred to as Internazionale () or simply Inter and colloquially known as Inter Milan outside Italy, is an Italian professional football club based in Milan, Lombardy. Inter is the only Italian club to have never been relegated from the top flight.\n\nFounded in 1908 following a schism within the Milan Cricket and Football Club (now A.C. Milan), Inter won its first championship in 1910. Since its formation, the club has won 30 domestic trophies, including 18 league titles, 7 Coppa Italia and 5 Supercoppa Italiana. From 2006 to 2010, the club won five successive league titles, equalling the all-time record at that time. They have won the Champions League three times: two back-to-back in 1964 and 1965 and then another in 2010. Their latest win completed an unprecedented Italian seasonal treble, with Inter winning the Coppa Italia and the \"Scudetto\" the same year. The club has also won three UEFA Cups, two Intercontinental Cups and one FIFA Club World Cup.\n\nInter's home games are played at the San Siro stadium, which they share with local rivals A.C. Milan. The stadium is the largest in Italian football with a capacity of 80,018. Matches between A.C. Milan and Inter, known as the Derby della Madonnina, are one of the most followed derbies in football. , Inter has the highest home game attendance in Italy and the sixth hightes attendance in Europe. The club is one of the most valuable in Italian and world football.\n\n valign=top \n\nThe club was founded on 9 March 1908 as \"Football Club Internazionale\", following the schism with the Milan Cricket and Football Club (now A.C. Milan). The name of the club derives from the wish of its founding members to accept foreign players as well as Italians.\n\nThe club won its very first championship in 1910 and its second in 1920. The captain and coach of the first championship winning team was Virgilio Fossati, who was later killed in battle while serving in the Italian army during World War I.\n\nIn 1922, Inter remained in the top league after winning two play-offs. Six years later, during the Fascist era, the club was forced to merge with the \"Unione Sportiva Milanese\" and was renamed \"Società Sportiva Ambrosiana\". The team wore white jerseys during this time with a red cross emblazoned on it. The jersey's design was inspired by the flag and coat of arms of the city of Milan. In 1929, club chairman Oreste Simonotti changed the club's name to \"Associazione Sportiva Ambrosiana\", however supporters continued to call the team \"Inter\", and in 1931 new chairman Pozzani caved in to shareholder pressure and changed the name to \"Associazione Sportiva Ambrosiana-Inter\".\nTheir first Coppa Italia (Italian Cup) was won in 1938–39, led by the iconic Giuseppe Meazza, after whom the San Siro stadium is officially named. A fifth championship followed in 1940, despite Meazza incurring an injury. After the end of World War II the club regained its original name, winning its sixth championship in 1953 and its seventh in 1954.\n\nIn 1960, manager Helenio Herrera joined Inter from Barcelona, bringing with him his midfield general Luis Suárez, who won the European Footballer of the Year in the same year for his role in Barcelona's La Liga/Fairs Cup double. He would transform Inter into one of the greatest teams in Europe. He modified a 5–3–2 tactic known as the \"\"Verrou\"\" (\"door bolt\") which created greater flexibility for counterattacks. The \"catenaccio\" system was invented by an Austrian coach, Karl Rappan. Rappan's original system was implemented with four fixed defenders, playing a strict man-to-man marking system, plus a playmaker in the middle of the field who plays the ball together with two midfield wings. Herrera would modify it by adding a fifth defender, the sweeper or libero behind the two centre backs. The sweeper or libero who acted as the free man would deal with any attackers who went through the two centre backs. Inter finished third in the Serie A in his first season, second the next year and first in his third season. Then followed a back-to-back European Cup victory in 1964 and 1965, earning him the title \"\"il Mago\"\" (\"the Wizard\"). The core of Herrera's team were the attacking fullbacks Tarcisio Burgnich and Giacinto Facchetti, Armando Picchi the sweeper, Suárez the playmaker, Jair the winger, Mario Corso the left midfielder, and Sandro Mazzola, who played on the inside-right.\nIn 1964, Inter reached the European Cup Final by beating Borussia Dortmund in the semi-final and Partizan in the quarter-final. In the final, they met Real Madrid, a team that had reached seven out of the nine finals to date. Mazzola scored two goals in a 3–1 victory, and then the team won the Intercontinental Cup against Independiente. A year later, Inter repeated the feat by beating two-time winner Benfica in the final held at home, from a Jair goal, and then again beat Independiente in the Intercontinental Cup.\n\nIn 1967, with Jair gone and Suárez injured, Inter lost the European Cup Final 2–1 to Celtic. During that year the club changed its name to \"Football Club Internazionale Milano\".\n\nFollowing the golden era of the 1960s, Inter managed to win their eleventh league title in 1971 and their twelfth in 1980. Inter were defeated for the second time in five years in the final of the European Cup, going down 0–2 to Johan Cruyff's Ajax in 1972. During the 1970s and the 1980s, Inter also added two to its Coppa Italia tally, in 1977–78 and 1981–82.\n\nLed by the German duo of Andreas Brehme and Lothar Matthäus, and Argentine Ramón Díaz, Inter captured the 1989 Serie A championship. Inter were unable to defend their title despite adding fellow German Jürgen Klinsmann to the squad and winning their first Supercoppa Italiana at the start of the season.\n\nThe 1990s was a period of disappointment. While their great rivals Milan and Juventus were achieving success both domestically and in Europe, Inter were left behind, with repeated mediocre results in the domestic league standings, their worst coming in 1993–94 when they finished just one point out of the relegation zone. Nevertheless, they achieved some European success with three UEFA Cup victories in 1991, 1994 and 1998.\n\nWith Massimo Moratti's takeover from Ernesto Pellegrini in 1995, Inter twice broke the world record transfer fee in this period (£19.5 million for Ronaldo from Barcelona in 1997 and £31 million for Christian Vieri from Lazio two years later). However, the 1990s remained the only decade in Inter's history in which they did not win a single Serie A championship. For Inter fans, it was difficult to find who in particular was to blame for the troubled times and this led to some icy relations between them and the chairman, the managers and even some individual players.\nMoratti later became a target of the fans, especially when he sacked the much-loved coach Luigi Simoni after only a few games into the 1998–99 season, having just received the Italian manager of the year award for 1998 the day before being dismissed. That season, Inter failed to qualify for any European competition for the first time in almost ten years, finishing in eighth place.\n\nThe following season, Moratti appointed former Juventus manager Marcello Lippi, and signed players such as Angelo Peruzzi and Laurent Blanc together with other former Juventus players Vieri and Vladimir Jugović. The team came close to their first domestic success since 1989 when they reached the Coppa Italia final only to be defeated by Lazio.\n\nInter's misfortunes continued the following season, losing the 2000 Supercoppa Italiana match against Lazio 4–3 after initially taking the lead through new signing Robbie Keane. They were also eliminated in the preliminary round of the Champions League by Swedish club Helsingborgs IF, with Álvaro Recoba missing a crucial late penalty. Lippi was sacked after only a single game of the new season following Inter's first ever Serie A defeat to Reggina. Marco Tardelli, chosen to replace Lippi, failed to improve results, and is remembered by Inter fans as the manager that lost 6–0 in the city derby against Milan. Other members of the Inter \"family\" during this period that suffered were the likes of Vieri and Fabio Cannavaro, both of whom had their restaurants in Milan vandalised after defeats to the \"Rossoneri\".\n\nIn 2002, not only did Inter manage to make it to the UEFA Cup semi-finals, but were also only 45 minutes away from capturing the \"Scudetto\" when they needed to maintain their one-goal advantage away to Lazio. Inter were 2–1 up after only 24 minutes. Lazio equalised during first half injury time and then scored two more goals in the second half to clinch victory that eventually saw Juventus win the championship. The next season, Inter finished as league runners-up and also managed to make it to the 2002–03 Champions League semi-finals against Milan, losing on the away goals rule.\n\nOn 8 July 2004, Inter appointed former Lazio coach Roberto Mancini as its new head coach. In his first season, the team collected 72 points from 18 wins, 18 draws and only two losses, as well as winning the Coppa Italia and later the Supercoppa Italiana. On 11 May 2006, Inter retained their Coppa Italia title once again after defeating Roma with a 4–1 aggregate victory (a 1–1 scoreline in Rome and a 3–1 win at the San Siro).\n\nInter were awarded the 2005–06 Serie A championship retrospectively after points were stripped from Juventus and Milan due to the match fixing scandal that year. During the following season, Inter went on a record-breaking run of 17 consecutive victories in Serie A, starting on 25 September 2006 with a 4–1 home victory over Livorno, and ending on 28 February 2007, after a 1–1 draw at home to Udinese. On 22 April 2007, Inter won their second consecutive \"Scudetto\"—and first on the field since 1989—when they defeated Siena 2–1 at Stadio Artemio Franchi. Italian World Cup-winning defender Marco Materazzi scored both goals.\n\nInter started the 2007–08 season with the goal of winning both Serie A and Champions League. The team started well in the league, topping the table from the first round of matches, and also managed to qualify for the Champions League knockout stage. However, a late collapse, leading to a 2–0 defeat with ten men away to Liverpool on 19 February in the Champions League, threw into question manager Roberto Mancini's future at Inter while domestic form took a sharp turn of fortune with the team failing to win in the three following Serie A games. After being eliminated by Liverpool in the Champions League, Mancini announced his intention to leave his job immediately only to change his mind the following day. On the final day of the 2007–08 Serie A season, Inter played Parma away, and two goals from Zlatan Ibrahimović sealed their third consecutive championship. Mancini, however, was sacked soon after due to his previous announcement to leave the club.\nOn 2 June 2008, Inter appointed former Porto and Chelsea boss José Mourinho as new head coach. In his first season, the \"Nerazzurri\" won a Suppercoppa Italiana and a fourth consecutive title, though falling in the Champions League in the first knockout round for a third-straight year, losing to eventual finalist Manchester United. In winning the league title Inter became the first club in the last 60 years to win the title for the fourth consecutive time and joined Torino and Juventus as the only clubs to accomplish this feat, as well as being the first club based outside Turin.\n\nInter enjoyed more success in the 2009–10 Champions League, defeating reigning champions Barcelona in the semi-final, and then beating Bayern Munich 2–0 in the final with two goals from Diego Milito. Inter also won the 2009–10 Serie A title by two points over Roma, and the 2010 Coppa Italia by defeating the same side 1–0 in the final. This made Inter the first Italian team to win Treble. At the end of the season, Mourinho left the club to manage Real Madrid; he was replaced by Rafael Benítez.\n\nOn 21 August 2010, Inter defeated Roma 3–1 and won the 2010 Supercoppa Italiana, their fourth trophy of the year. In December 2010, they claimed the FIFA Club World Cup for the first time after a 3–0 win against TP Mazembe in the final. However, after this win, on 23 December 2010, due to their declining performance in Serie A, the team fired Benítez. He was replaced by Leonardo the following day.\n\nLeonardo started with 30 points from 12 games, with an average of 2.5 points per game, better than his predecessors Benítez and Mourinho. On 6 March 2011, Leonardo set a new Italian Serie A record by collecting 33 points in 13 games; the previous record was 32 points in 13 games made by Fabio Capello in the 2004–05 season. Leonardo led the club to the quarter-finals of the Champions League before losing to Schalke 04, and lead them to Coppa Italia title. At the end of the season, however, he resigned and was followed by not-so-successful new managers Gian Piero Gasperini, Claudio Ranieri and Andrea Stramaccioni.\n\nOn 1 August 2012, the club announced that Moratti was to sell a minority interest of the club to a Chinese consortium led by Kenneth Huang. On the same day, Inter announced an agreement was formed with China Railway Construction Corporation Limited for a new stadium project, however, the deal with the Chinese eventually collapsed. The 2012–13 season was the worst in recent club history with Inter finishing ninth in Serie A and failing to qualify for any European competitions. Walter Mazzarri was appointed to replace Stramaccioni on 24 May 2013.\nOn 15 October 2013, an Indonesian consortium (International Sports Capital HK Ltd.) led by Erick Thohir, Handy Soetedjo and Rosan Roeslani, signed an agreement to acquire 70% of Inter shares from Internazionale Holding S.r.l. Immediately after the deal, Moratti's Internazionale Holding S.r.l. still retained 29.5% of the shares of FC Internazionale Milano S.p.A. After the deal, the shares of Inter was owned by a chain of holding companies, namely International Sports Capital S.p.A. of Italy (for 70% stake), International Sports Capital HK Limited and Asian Sports Ventures HK Limited of Hong Kong. Asian Sports Ventures HK Limited, itself another intermediate holding company, was owned by Nusantara Sports Ventures HK Limited (60% stake, a company owned by Thohir), Alke Sports Investment HK Limited (20% stake) and Aksis Sports Capital HK Limited (20% stake).\n\nThohir, whom also co-owned Major League Soccer (MLS) club D.C. United and Indonesia Super League (ISL) club Persib Bandung, announced on 2 December 2013 that Inter and D.C. United had formed strategic partnership. During the Thohir era the club began to modify its financial structure from one reliant on continual owner investment to a more self sustain business model although the club still breached UEFA Financial Fair Play Regulations in 2015. The club was fined and received squad reduction in UEFA competitions, with additional penalties suspended in the probation period. During this time, Roberto Mancini returned as coach on 14 November 2014.\n\nOn 6 June 2016, Suning Holdings Group (via a Luxembourg-based subsidiary Great Horizon S.á r.l.) a company owned by Zhang Jindong, co-founder and chairman of Suning Commerce Group, acquired a majority stake of Inter from Thohir's consortium International Sports Capital S.p.A. and from Moratti family's remaining shares in Internazionale Holding S.r.l. According to various filings, the total investment from Suning was around €270 million. The deal was approved by an extraordinary general meeting on 28 June 2016, from which Suning Holdings Group had acquired a 68.55% stake in the club.\n\nThe first season of new ownership, however, started with poor performance in pre-season friendlies. On 8 August 2016, Inter parted company with head coach Roberto Mancini by mutual consent over disagreements regarding the club's direction. He was replaced by Frank de Boer who was sacked on 1 November 2016 after leading Inter to a 4W–2D–5L record in 11 Serie A games as head coach. The successor, Stefano Pioli, didn't save the team from getting the worst group result in UEFA competitions in the club's history. Despite an eight-game winning streak, he and the club parted away before season's end when it became clear they would finish outside the league's top three for the sixth consecutive season. On 9 June 2017, former Roma coach Luciano Spalletti was appointed as Inter manager, signing a two-year contract and eleven months later Inter clinched a UEFA Champions League group stage spot after going six years without Champions League participation thanks to a 3–2 victory against Lazio in the season finale of 2017–18 Serie A.\n\nOn 26 October 2018, Steven Zhang was appointed as new president of the club. On 25 January 2019, the club officially announced that LionRock Capital from Hong Kong reached an agreement with International Sports Capital HK Limited, in order to acquire its 31.05% shares in Inter and to become the club's new minority shareholder. On 31 May 2019, Inter appointed former Juventus and Italian manager Antonio Conte as their new coach, signing a three-year deal.\n\nOne of the founders of Inter, a painter named Giorgio Muggiani, was responsible for the design of the first Inter logo in 1908. The first design incorporated the letters \"FCIM\" in the centre of a series of circles that formed the badge of the club. The basic elements of the design have remained constant even as finer details have been modified over the years. Starting at the 1999–2000 season, the original club crest was reduced in size, to give place for the addition of the club's name and foundation year at the upper and lower part of the logo respectively.\n\nIn 2007, the logo was returned to the pre-1999–2000 era. It was given a more modern look with a smaller \"Scudetto\" star and lighter color scheme. This version was used until July 2014, when the club decided to undertake a rebranding. The most significant difference between the current and the previous logo is the omission of the star from other media except match kits.\n\nSince its founding in 1908, Inter have worn black and blue stripes. It is rumoured that black was chosen to represent night and blue was chosen to represent the sky. Aside from a short period during World War II, Inter continued to wear the black and blue stripes, earning them the nickname \"Nerazzurri\".\nFor a period of time, however, Inter were forced to abandon their black and blue uniforms. In 1928, Inter's name and philosophy made the ruling Fascist Party uneasy. As a result, during the same year the 20-year-old club was merged with \"Unione Sportiva Milanese\". The new club was named \"Società Sportiva Ambrosiana\" after the patron saint of Milan. The flag of Milan (the red cross on white background) replaced the traditional black and blue. After World War II, when the Fascists had fallen from power, the club reverted to their original name and colours. In 2008, Inter celebrated their centenary with a red cross on their away shirt. The cross is reminiscent of the flag of their city, and they continue to use the pattern on their third kit. In 2014, the club adopted a predominantly black home kit with thin blue pinstripes before returning to a more traditional design the following season.\n\nAnimals are often used to represent football clubs in Italy – the grass snake, called \"Biscione\", represents Inter. The snake is an important symbol for the city of Milan, appearing often in Milanese heraldry as a coiled viper with a man in its jaws. The symbol is present on the coat of arms of the House of Sforza (which ruled over Italy from Milan during the Renaissance period), the city of Milan, the historical Duchy of Milan (a 400-year state of the Holy Roman Empire) and Insubria (a historical region the city of Milan falls within). For the 2010–11 season, Inter's away kit featured the serpent.\n\nThe team's stadium is the 80,018 seat San Siro, officially known as the \"Stadio Giuseppe Meazza\" after the former player who represented both Milan and Inter. The more commonly used name, \"San Siro\", is the name of the district where it is located. San Siro has been the home of Milan since 1926, when it was privately built by funding from Milan's chairman at the time, Piero Pirelli. Construction was performed by 120 workers, and took 13 and a half months to complete. The stadium was owned by the club until it was sold to the city in 1935, and since 1947 it has been shared with Inter, when they were accepted as joint tenant.\n\nThe first game played at the stadium was on 19 September 1926, when Inter beat Milan 6–3 in a friendly match. Milan played its first league game in San Siro on 19 September 1926, losing 1–2 to Sampierdarenese. From an initial capacity of 35,000 spectators, the stadium has undergone several major renovations, most recently in preparation for the 1990 FIFA World Cup when its capacity was set to 85,700, all covered with a polycarbonate roof. In the summer of 2008, its capacity was reduced to 80,018 to meet the new standards set by UEFA.\n\nBased on the English model for stadiums, San Siro is specifically designed for football matches, as opposed to many multi-purpose stadiums used in Serie A. It is therefore renowned in Italy for its fantastic atmosphere during matches owing to the closeness of the stands to the pitch. The frequent use of flares by supporters contributes to the atmosphere, but the practice has occasionally also caused problems.\n\nInter is one of the most supported clubs in Italy, according to an August 2007 research by Italian newspaper \"La Repubblica\". Historically, the largest section of Inter fans from the city of Milan were the middle-class bourgeoisie Milanese, while Milan fans were typically working-class.\n\nThe traditional ultras group of Inter is \"Boys San\"; they hold a significant place in the history of the ultras scene in general due to the fact that they are one of the oldest, being founded in 1969. Politically, the ultras of Inter are usually considered right-wing and they have good relationships with the Lazio ultras. As well as the main group of \"Boys San\", there are four more significant groups: \"Viking\", \"Irriducibili\", \"Ultras\", and \"Brianza Alcoolica\".\n\nInter's most vocal fans are known to gather in the Curva Nord, or north curve of the San Siro. This longstanding tradition has led to the Curva Nord being synonymous with the club's most die-hard supporters, who unfurl banners and wave flags in support of their team.\nInter have several rivalries, two of which are highly significant in Italian football; firstly, they participate in the intra city \"Derby della Madonnina\" with Milan; the rivalry has existed ever since Inter splintered off from Milan in 1908. The name of the derby refers to the Blessed Virgin Mary, whose statue atop the Milan Cathedral is one of the city's main attractions. The match usually creates a lively atmosphere, with numerous (often humorous or offensive) banners unfolded before the match. Flares are commonly present, but they also led to the abandonment of the second leg of the 2004–05 Champions League quarter-final matchup between Milan and Inter on 12 April after a flare thrown from the crowd by an Inter supporter struck Milan keeper Dida on the shoulder.\n\nThe other most significant rivalry is with Juventus; the two participate in the \"Derby d'Italia\". Up until the 2006 Italian football scandal, which saw Juventus relegated, the two were the only Italian clubs to have never played below Serie A. In recent years, post-\"Calciopoli\", Inter have developed a rivalry with Roma, having finished runners-up to Inter in all but one of Inter's five \"Scudetto\"-winning seasons between 2005 and 2010. The two sides have also contested in five Coppa Italia finals and four Supercoppa Italiana finals since 2006. Other clubs, like Atalanta and Napoli, are also considered amongst their rivals.\nTheir supporters collectively go by \"Interisti\", or \"Nerazzurri.\"\n\nInter have won 30 domestic trophies, including the league 18 times, the Coppa Italia seven and the Supercoppa Italiana five. From 2006 to 2010, the club won five successive league titles, equalling the all-time record before 2017, when Juventus won the sixth successive league title. They have won the Champions League three times: two back-to-back in 1964 and 1965 and then another in 2010; the last completed an unprecedented Italian treble with the Coppa Italia and the \"Scudetto\". The club has also won three UEFA Cups, two Intercontinental Cups and one FIFA Club World Cup.\n\nInter has never been relegated from the top flight of Italian football in its entire existence. It is the only club to have competed in Serie A and its predecessors in every season. The \"Nerrazurri\" currently have the longest unbroken run in the top flight of any club on the Continent, and among European clubs, only five British clubs have longer current spells in the top flight.\n\n+Inter honours\n! scope=colType\n!scope=colCompetition\n!scope=colTitles\n!scope=colSeasons\n! scope=colSerie A\nalign=\"center\"18\n! scope=colCoppa Italia\nalign=\"center\"7\n! scope=colSupercoppa Italiana\nalign=\"center\"5\n! scope=colEuropean Cup / UEFA Champions League\nalign=\"center\"3\n! scope=colUEFA Cup\nalign=\"center\"3\n! scope=colIntercontinental Cup\nalign=\"center\"2\n! scope=colFIFA Club World Cup\nalign=\"center\"1\n\nJavier Zanetti holds the records for both total appearances and Serie A appearances for Inter, with 858 official games played in total and 618 in Serie A.\n\nGiuseppe Meazza is Inter's all-time top goalscorer, with 284 goals in 408 games. Behind him, in second place, is Alessandro Altobelli with 209 goals in 466 games, and Roberto Boninsegna in third place, with 171 goals over 281 games.\n\nHelenio Herrera had the longest reign as Inter coach, with nine years (eight consecutive) in charge, and is the most successful coach in Inter history with three \"Scudetti\", two European Cups, and two Intercontinental Cup wins. José Mourinho, who was appointed on 2 June 2008, and completed his first season in Italy by winning the Serie A league title and the Supercoppa Italiana, in the second season he won the first \"treble\" in Italian history, the Serie A league title, Coppa Italia and the UEFA Champions League in the season 2009–2010.\n\n3 – Giacinto Facchetti, left back, 1960–1978 \"(posthumous honour)\". The number was retired on 8 September 2006. The last player to wear the shirt was Argentinian center back Nicolás Burdisso, who took on the number 16 shirt for the rest of the season.\n<br>\n4 – Javier Zanetti, defensive midfielder, played 858 games for Inter between 1995 and his retirement in the summer of 2014. Club chairman Erick Thohir confirmed that Zanetti's number 4 was to be retired out of respect.\n\n! Position\n! Name\n\nBelow is a list of Inter chairmen from 1908 until the present day.\n\nBelow is a list of Inter coaches from 1909 until the present day.\n\nFC Internazionale Milano S.p.A. was described as one of the financial \"black-holes\" among the Italian clubs, which was heavily dependent on the financial contribution from the owner Massimo Moratti. In June 2006, the shirt sponsor and the minority shareholder of the club, Pirelli, sold 15.26% shares of the club to Moratti family, for €13.5 million. The tyre manufacturer retained 4.2%. However, due to several capital increases of Inter, such as a reversed merger with an intermediate holding company, Inter Capital S.r.l. in 2006, which held 89% shares of Inter and €70 million capitals at that time, or issues new shares for €70.8 million in June 2007, €99.9 million in December 2007, €86.6 million in 2008, €70 million in 2009, €40 million in 2010 and 2011, €35 million in 2012 or allowing Thoir subscribed €75 million new shares of Inter in 2013, Pirelli became the third largest shareholders of just 0.5%, . Inter had yet another recapitalization that was reserved for Suning Holdings Group in 2016. In the prospectus of Pirelli's second IPO in 2017, the company also revealed that the value of the remaining shares of Inter that was owned by Pirelli, was write-off to zero in 2016 financial year. Inter also received direct capital contribution from the shareholders to cover loss which was excluded from issuing shares in the past. ()\n\nRight before the takeover of Thohir, the consolidated balance sheets of \"Internazionale Holding S.r.l.\" showed the whole companies group had a bank debt of €157 million, including the bank debt of a subsidiary \"Inter Brand Srl\", as well as the club itself, to Istituto per il Credito Sportivo (ICS), for €15.674 million on the balance sheet at end of 2012–13 financial year. In 2006 Inter sold its brand to the new subsidiary, \"Inter Brand S.r.l.\", a special purpose entity with a shares capital of €40 million, for €158 million (the deal made Internazionale make a net loss of just €31 million in a separate financial statement). At the same time the subsidiary secured a €120 million loan from Banca Antonveneta, which would be repaid in installments until 30 June 2016; \"La Repubblica\" described the deal as \"doping\". In September 2011 Inter secured a loan from ICS by factoring the sponsorship of Pirelli of 2012–13 and 2013–14 season, for €24.8 million, in an interest rate of 3 months Euribor + 1.95% spread. In June 2014 new Inter Group secured €230 million loan from Goldman Sachs and UniCredit at a new interest rate of 3 months Euribor + 5.5% spread, as well as setting up a new subsidiary to be the debt carrier: \"Inter Media and Communication S.r.l.\". €200 million of which would be utilized in debt refinancing of the group. The €230million loan, €1 million (plus interests) would be due on 30 June 2015, €45 million (plus interests) would be repaid in 15 installments from 30 September 2015 to 31 March 2019, as well as €184 million (plus interests) would be due on 30 June 2019. In ownership side, the Hong Kong-based International Sports Capital HK Limited, had pledged the shares of Italy-based International Sports Capital S.p.A. (the direct holding company of Inter) to CPPIB Credit Investments for €170 million in 2015, at an interest rate of 8% p.a (due March 2018) to 15% p.a. (due March 2020). ISC repaid the notes on 1 July 2016 after they sold part of the shares of Inter to Suning Holdings Group. However, in the late 2016 the shares of ISC S.p.A. was pledged again by ISC HK to private equity funds of OCP Asia for US$80 million. In December 2017, the club also refinanced its debt of €300 million, by issuing corporate bond to the market, via Goldman Sachs as the bookkeeper, for an interest rate of 4.875% p.a.\n\nConsidering revenue alone, Inter surpassed city rivals in Deloitte Football Money League for the first time, in the 2008–09 season, to rank in 9th place, one place behind Juventus in 8th place. (Milan in 10th place.) In the 2009–10 season, Inter remained in 9th place, surpassing Juventus (10th) but Milan re-took the leading role as the 7th. Inter became the 8th in 2010–11, but was still one place behind Milan. Since 2011, Inter fell to 11th in 2011–12, 15th in 2012–13, 17th in 2013–14, 19th in 2014–15 and 2015–16 season. In 2016–17 season, Inter was ranked 15th in the \"Money League\".\n\nIn 2010 \"Football Money League\" (2008–09 season), the normalized revenue of €196.5 million were divided up between matchday (14%, €28.2 million), broadcasting (59%, €115.7 million, +7%, +€8 million) and commercial (27%, €52.6 million, +43%). Kit sponsors Nike and Pirelli contributed €18.1 million and €9.3 million respectively to commercial revenues, while broadcasting revenues were boosted €1.6 million (6%) by Champions League distribution. Deloitte expressed the idea that issues in Italian football, particularly matchday revenue issues were holding Inter back compared to other European giants, and developing their own stadia would result in Serie A clubs being more competitive on the world stage.\n\nIn 2009–10 season the revenue of Inter was boosted by the sales of Ibrahimović, the treble and the release clause of coach José Mourinho. According to the normalized figures by Deloitte in their 2011 \"Football Money League\", in 2009–10 season, the revenue had increased €28.3 million (14%) to €224.8 million. The ratio of matchday, broadcasting and commercial in the adjusted figures was 17%:62%:21%.\n\nFor the 2010–11 season, Serie A clubs started negotiating club TV rights collectively rather than individually. This was predicted to result in lower broadcasting revenues for big clubs such as Juventus and Inter, with smaller clubs gaining from the loss. Eventually the result included an extraordinary income of €13 million from RAI. In 2012 \"Football Money League\" (2010–11 season), the normalized revenue was €211.4 million. The ratio of matchday, broadcasting and commercial in the adjusted figures was 16%:58%:26%.\n\nHowever, combining revenue and cost, in the 2006–07 season they had a net loss of €206 million (€112 million extraordinary basis, due to the abolition of non-standard accounting practice of the special amortization fund), followed by a net loss of €148 million in the 2007–08 season, a net loss of €154 million in 2008–09 season, a net loss of €69 million in the 2009–10 season, a net loss of €87 million in the 2010–11 season, a net loss of €77 million in the 2011–12 season, a net loss of €80 million in 2012–13 season and a net profit of €33 million in 2013–14 season, due to special income from the establishment of subsidiary Inter Media and Communication. All aforementioned figures were in separate financial statement. Figures from consolidated financial statement were announced since 2014–15 season, which were net losses of €140.4 million (2014–15), €59.6 million (2015–16 season, before 2017 restatement) and €24.6 million (2016–17).\n\nIn 2015 Inter and Roma were the only two Italian clubs that were sanctioned by the UEFA due to their breaking of UEFA Financial Fair Play Regulations, which was followed by Milan which was once barred from returning to European competition in 2018. As a probation to avoid further sanction, Inter agreed to have a three-year aggregate break-even from 2015 to 2018, with the 2015–16 season being allowed to have a net loss of a maximum of €30 million, followed by break-even in the 2016–17 season and onwards. Inter was also fined €6 million plus an additional €14 million in probation.\n\nInter also made a financial trick in the transfer market in mid-2015, in which Stevan Jovetić and Miranda were signed by Inter on temporary deals plus an obligation to sign outright in 2017, making their cost less in the loan period. Moreover, despite heavily investing in new signings, namely Geoffrey Kondogbia and Ivan Perišić that potentially increased the cost in amortization, Inter also sold Mateo Kovačić for €29 million, making a windfall profit. In November 2018, documents from Football Leaks further revealed that the loan signings such as Xherdan Shaqiri in January 2015, was in fact had inevitable conditions to trigger the outright purchase.\n\nOn 21 April 2017, Inter announced that their net loss (FFP adjusted) of 2015–16 season was within the allowable limit of €30 million. However, on the same day UEFA also announced that the reduction of squad size of Inter in European competitions would not be lifted yet, due to partial fulfilment of the targets in the settlement agreement. Same announcement was made by UEFA in June 2018, based on Inter's 2016–17 season financial result.\n\n!Period\n!Kit manufacturer\n!Shirt sponsor\nrowspan=2Puma\n\n1981/1982\nInno-Hit\n1982–1986\nMecsport\nrowspan=3Misura\n1986–1988\n1988–1991\nrowspan=3 Umbro\n1998–2016\n2016–\n\nBULLET::::- Dynasties in Italian football\nBULLET::::- European Club Association\n\nBULLET::::- FC Internazionale Milano at Serie A\nBULLET::::- FC Internazionale Milano at UEFA\nBULLET::::- FC Internazionale Milano at FIFA\n"}
{"id": "15120", "url": "https://en.wikipedia.org/wiki?curid=15120", "title": "Interferon", "text": "Interferon\n\nInterferons (IFNs, ) are a group of signaling proteins made and released by host cells in response to the presence of several viruses. In a typical scenario, a virus-infected cell will release interferons causing nearby cells to heighten their anti-viral defenses.\n\nIFNs belong to the large class of proteins known as cytokines, molecules used for communication between cells to trigger the protective defenses of the immune system that help eradicate pathogens. Interferons are named for their ability to \"interfere\" with viral replication by protecting cells from virus infections. IFNs also have various other functions: they activate immune cells, such as natural killer cells and macrophages; they increase host defenses by up-regulating antigen presentation by virtue of increasing the expression of major histocompatibility complex (MHC) antigens. Certain symptoms of infections, such as fever, muscle pain and \"flu-like symptoms\", are also caused by the production of IFNs and other cytokines.\n\nMore than twenty distinct IFN genes and proteins have been identified in animals, including humans. They are typically divided among three classes: Type I IFN, Type II IFN, and Type III IFN. IFNs belonging to all three classes are important for fighting viral infections and for the regulation of the immune system.\n\nBased on the type of receptor through which they signal, human interferons have been classified into three major types.\n\nBULLET::::- Interferon type I: All type I IFNs bind to a specific cell surface receptor complex known as the IFN-α/β receptor (IFNAR) that consists of IFNAR1 and IFNAR2 chains. The type I interferons present in humans are IFN-α, IFN-β, IFN-ε, IFN-κ and IFN-ω. In general, type I interferons are produced when the body recognizes a virus that has invaded it. They are produced by fibroblasts and monocytes. However, the production of type I IFN-α is prohibited by another cytokine known as Interleukin-10. Once released, type I interferons bind to specific receptors on target cells, which leads to expression of proteins that will prevent the virus from producing and replicating its RNA and DNA. Overall, IFN-α can be used to treat hepatitis B and C infections, while IFN-β can be used to treat multiple sclerosis.\nBULLET::::- Interferon type II (IFN-γ in humans): This is also known as immune interferon and is activated by Interleukin-12. Furthermore, type II interferons are released by Cytotoxic T cells and T helper cells, type 1 specifically. However, they block the proliferation of T helper cells type two. The previous results in an inhibition of T2 immune response and a further induction of T1 immune response, which leads to the development of debilitating diseases such as multiple sclerosis. IFN type II binds to IFNGR, which consists of IFNGR1 and IFNGR2 chains.\nBULLET::::- Interferon type III: Signal through a receptor complex consisting of IL10R2 (also called CRF2-4) and IFNLR1 (also called CRF2-12). Although discovered more recently than type I and type II IFNs, recent information demonstrates the importance of Type III IFNs in some types of virus or fungal infections.\n\nIn general, type I and II interferons are responsible for regulating and activating the immune response. Expression of type I and III IFNs can be induced in virtually all cell types upon recognition of viral components, especially nucleic acids, by cytoplasmic and endosomal receptors, whereas type II interferon is induced by cytokines such as IL-12, and its expression is restricted to immune cells such as T cells and NK cells.\n\nAll interferons share several common effects: they are antiviral agents and they modulate functions of the immune system. Administration of Type I IFN has been shown experimentally to inhibit tumor growth in animals, but the beneficial action in human tumors has not been widely documented. \nA virus-infected cell releases viral particles that can infect nearby cells. However, the infected cell can protect neighboring cells against a potential infection of the virus by releasing interferons. In response to interferon, cells produce large amounts of an enzyme known as protein kinase R (PKR). This enzyme phosphorylates a protein known as eIF-2 in response to new viral infections; the phosphorylated eIF-2 forms an inactive complex with another protein, called eIF2B, to reduce protein synthesis within the cell. Another cellular enzyme, RNAse L—also induced by interferon action—destroys RNA within the cells to further reduce protein synthesis of both viral and host genes. Inhibited protein synthesis impairs both virus replication and infected host cells. In addition, interferons induce production of hundreds of other proteins—known collectively as interferon-stimulated genes (ISGs)—that have roles in combating viruses and other actions produced by interferon.\nThey also limit viral spread by increasing p53 activity, which kills virus-infected cells by promoting apoptosis. The effect of IFN on p53 is also linked to its protective role against certain cancers.\n\nAnother function of interferons is to up-regulate major histocompatibility complex molecules, MHC I and MHC II, and increase immunoproteasome activity. All interferons significantly enhance the presentation of MHC I dependent antigens. Interferon gamma (IFN-gamma) also significantly stimulates the MHC II-dependent presentation of antigens. Higher MHC I expression increases presentation of viral and abnormal peptides from cancer cells to cytotoxic T cells, while the immunoproteasome processes these peptides for loading onto the MHC I molecule, thereby increasing the recognition and killing of infected or malignant cells. Higher MHC II expression increases presentation of these peptides to helper T cells; these cells release cytokines (such as more interferons and interleukins, among others) that signal to and co-ordinate the activity of other immune cells.\n\nInterferons can also suppress angiogenesis by down regulation of angiogenic stimuli deriving from tumor cells. They also suppress the proliferation of endothelial cells. Such suppression causes a decrease in tumor angiogenesis, a decrease in its vascularization and subsequent growth inhibition. Interferons, such as interferon gamma, directly activate other immune cells, such as macrophages and natural killer cells.\n\nProduction of interferons occurs mainly in response to microbes, such as viruses and bacteria, and their products. Binding of molecules uniquely found in microbes—viral glycoproteins, viral RNA, bacterial endotoxin (lipopolysaccharide), bacterial flagella, CpG motifs—by pattern recognition receptors, such as membrane bound Toll like receptors or the cytoplasmic receptors RIG-I or MDA5, can trigger release of IFNs.\nToll Like Receptor 3 (TLR3) is important for inducing interferons in response to the presence of double-stranded RNA viruses; the ligand for this receptor is double-stranded RNA (dsRNA). After binding dsRNA, this receptor activates the transcription factors IRF3 and NF-κB, which are important for initiating synthesis of many inflammatory proteins. RNA interference technology tools such as siRNA or vector-based reagents can either silence or stimulate interferon pathways. Release of IFN from cells (specifically IFN-γ in lymphoid cells) is also induced by mitogens. Other cytokines, such as interleukin 1, interleukin 2, interleukin-12, tumor necrosis factor and colony-stimulating factor, can also enhance interferon production.\n\nBy interacting with their specific receptors, IFNs activate \"signal transducer and activator of transcription\" (STAT) complexes; STATs are a family of transcription factors that regulate the expression of certain immune system genes. Some STATs are activated by both type I and type II IFNs. However each IFN type can also activate unique STATs.\n\nSTAT activation initiates the most well-defined cell signaling pathway for all IFNs, the classical Janus kinase-STAT (JAK-STAT) signaling pathway. In this pathway, JAKs associate with IFN receptors and, following receptor engagement with IFN, phosphorylate both STAT1 and STAT2. As a result, an IFN-stimulated gene factor 3 (ISGF3) complex forms—this contains STAT1, STAT2 and a third transcription factor called IRF9—and moves into the cell nucleus. Inside the nucleus, the ISGF3 complex binds to specific nucleotide sequences called \"IFN-stimulated response elements\" (ISREs) in the promoters of certain genes, known as IFN stimulated genes ISGs. Binding of ISGF3 and other transcriptional complexes activated by IFN signaling to these specific regulatory elements induces transcription of those genes. A collection of known ISGs is available on Interferome, a curated online database of ISGs (www.interferome.org); Additionally, STAT homodimers or heterodimers form from different combinations of STAT-1, -3, -4, -5, or -6 during IFN signaling; these dimers initiate gene transcription by binding to IFN-activated site (GAS) elements in gene promoters. Type I IFNs can induce expression of genes with either ISRE or GAS elements, but gene induction by type II IFN can occur only in the presence of a GAS element.\n\nIn addition to the JAK-STAT pathway, IFNs can activate several other signaling cascades. For instance, both type I and type II IFNs activate a member of the CRK family of adaptor proteins called CRKL, a nuclear adaptor for STAT5 that also regulates signaling through the C3G/Rap1 pathway. Type I IFNs further activate \"p38 mitogen-activated protein kinase\" (MAP kinase) to induce gene transcription. Antiviral and antiproliferative effects specific to type I IFNs result from p38 MAP kinase signaling. The \"phosphatidylinositol 3-kinase\" (PI3K) signaling pathway is also regulated by both type I and type II IFNs. PI3K activates P70-S6 Kinase 1, an enzyme that increases protein synthesis and cell proliferation; phosphorylates of ribosomal protein s6, which is involved in protein synthesis; and phosphorylates a translational repressor protein called \"eukaryotic translation-initiation factor 4E-binding protein 1\" (EIF4EBP1) in order to deactivate it.\n\nInterferons can disrupt signaling by other stimuli. For example, Interferon alpha induces RIG-G, which disrupts the CSN5-containing COP9 signalosome (CSN), a highly conserved multiprotein complex implicated in protein deneddylation, deubiquitination, and phosphorylation. RIG-G has shown the capacity to inhibit NF-κB and STAT3 signaling in lung cancer cells, which demonstrates the potential of type I IFNs.\n\nMany viruses have evolved mechanisms to resist interferon activity. They circumvent the IFN response by blocking downstream signaling events that occur after the cytokine binds to its receptor, by preventing further IFN production, and by inhibiting the functions of proteins that are induced by IFN. Viruses that inhibit IFN signaling include Japanese Encephalitis Virus (JEV), dengue type 2 virus (DEN-2) and viruses of the herpesvirus family, such as human cytomegalovirus (HCMV) and Kaposi's sarcoma-associated herpesvirus (KSHV or HHV8). Viral proteins proven to affect IFN signaling include EBV nuclear antigen 1 (EBNA1) and EBV nuclear antigen 2 (EBNA-2) from Epstein-Barr virus, the large T antigen of Polyomavirus, the E7 protein of Human papillomavirus (HPV), and the B18R protein of vaccinia virus. Reducing IFN-α activity may prevent signaling via STAT1, STAT2, or IRF9 (as with JEV infection) or through the JAK-STAT pathway (as with DEN-2 infection). Several poxviruses encode soluble IFN receptor homologs—like the B18R protein of the vaccinia virus—that bind to and prevent IFN interacting with its cellular receptor, impeding communication between this cytokine and its target cells. Some viruses can encode proteins that bind to double-stranded RNA (dsRNA) to prevent the activity of RNA-dependent protein kinases; this is the mechanism reovirus adopts using its sigma 3 (σ3) protein, and vaccinia virus employs using the gene product of its E3L gene, p25. The ability of interferon to induce protein production from interferon stimulated genes (ISGs) can also be affected. Production of protein kinase R, for example, can be disrupted in cells infected with JEV. Some viruses escape the anti-viral activities of interferons by gene (and thus protein) mutation. The H5N1 influenza virus, also known as bird flu, has resistance to interferon and other anti-viral cytokines that is attributed to a single amino acid change in its Non-Structural Protein 1 (NS1), although the precise mechanism of how this confers immunity is unclear.\n\nInterferon beta-1a and interferon beta-1b are used to treat and control multiple sclerosis, an autoimmune disorder. This treatment is effective for reducing attacks in relapsing-remitting multiple sclerosis and slowing disease progression and activity in secondary progressive multiple sclerosis.\n\nInterferon therapy is used (in combination with chemotherapy and radiation) as a treatment for some cancers. This treatment can be used in hematological malignancy; leukemia and lymphomas including hairy cell leukemia, chronic myeloid leukemia, nodular lymphoma, and cutaneous T-cell lymphoma. Patients with recurrent melanomas receive recombinant IFN-α2b. \nBoth hepatitis B and hepatitis C are treated with IFN-α, often in combination with other antiviral drugs. Some of those treated with interferon have a sustained virological response and can eliminate hepatitis virus. The most harmful strain—hepatitis C genotype I virus—can be treated with a 60-80% success rate with the current standard-of-care treatment of interferon-α, ribavirin and recently approved protease inhibitors such as Telaprevir (Incivek) May 2011, Boceprevir (Victrelis) May 2011 or the nucleotide analog polymerase inhibitor Sofosbuvir (Sovaldi) December 2013. Biopsies of patients given the treatment show reductions in liver damage and cirrhosis. Some evidence shows giving interferon immediately following infection can prevent chronic hepatitis C, although diagnosis early in infection is difficult since physical symptoms are sparse in early hepatitis C infection. Control of chronic hepatitis C by IFN is associated with reduced hepatocellular carcinoma.\n\nUnconfirmed results suggested that interferon eye drops may be an effective treatment for people who have herpes simplex virus epithelial keratitis, a type of eye infection. There is no clear evidence to suggest that removing the infected tissue (debridement) followed by interferon drops is an effective treatment approach for these types of eye infections. Unconfirmed results suggested that the combination of interferon and an antiviral agent may speed the healing process compared to antiviral therapy alone.\n\nWhen used in systemic therapy, IFNs are mostly administered by an intramuscular injection. The injection of IFNs in the muscle or under the skin is generally well tolerated. The most frequent adverse effects are flu-like symptoms: increased body temperature, feeling ill, fatigue, headache, muscle pain, convulsion, dizziness, hair thinning, and depression. Erythema, pain, and hardness at the site of injection are also frequently observed. IFN therapy causes immunosuppression, in particular through neutropenia and can result in some infections manifesting in unusual ways.\n\n+Pharmaceutical forms of interferons\n! Generic name !! Trade name\n\nSeveral different types of interferons are approved for use in humans. One was first approved for medical use in 1986. For example, in January 2001, the Food and Drug Administration (FDA) approved the use of PEGylated interferon-alpha in the USA; in this formulation, PEGylated interferon-alpha-2b (\"Pegintron\"), polyethylene glycol is linked to the interferon molecule to make the interferon last longer in the body. Approval for PEGylated interferon-alpha-2a (\"Pegasys\") followed in October 2002. These PEGylated drugs are injected once weekly, rather than administering two or three times per week, as is necessary for conventional interferon-alpha. When used with the antiviral drug ribavirin, PEGylated interferon is effective in treatment of hepatitis C; at least 75% of people with hepatitis C genotypes 2 or 3 benefit from interferon treatment, although this is effective in less than 50% of people infected with genotype 1 (the more common form of hepatitis C virus in both the U.S. and Western Europe). Interferon-containing regimens may also include protease inhibitors such as boceprevir and telaprevir.\n\nInterferons were first described in 1957 by Alick Isaacs and Jean Lindenmann at the National Institute for Medical Research in London; the discovery was a result of their studies of viral interference. Viral interference refers to the inhibition of virus growth caused by previous exposure of cells to an active or a heat-inactivated virus. Isaacs and Lindenmann were working with a system that involved the inhibition of the growth of live influenza virus in chicken embryo chorioallantoic membranes by heat-inactivated influenza virus. Their experiments revealed that this interference was mediated by a protein released by cells in the heat-inactivated influenza virus-treated membranes. They published their results in 1957 naming the antiviral factor they had discovered \"interferon\". The findings of Isaacs and Lindenmann have been widely confirmed and corroborated in the literature.\n\nFurthermore, others may have made observations on interferons before the 1957 publication of Isaacs and Lindenmann. For example, during research to produce a more efficient vaccine for smallpox, Yasu-ichi Nagano and Yasuhiko Kojima—two Japanese virologists working at the Institute for Infectious Diseases at the University of Tokyo—noticed inhibition of viral growth in an area of rabbit-skin or testis previously inoculated with UV-inactivated virus. They hypothesised that some \"viral inhibitory factor\" was present in the tissues infected with virus and attempted to isolate and characterize this factor from tissue homogenates. Independently, Monto Ho, in John Enders's lab, observed in 1957 that attenuated poliovirus conferred a species specific anti-viral effect in human amniotic cell cultures. They described these observations in a 1959 publication, naming the responsible factor \"viral inhibitory factor\" (VIF). It took another fifteen to twenty years, using somatic cell genetics, to show that the interferon action gene and interferon gene reside in different human chromosomes. The purification of human beta interferon did not occur until 1977. Y.H. Tan and his co-workers purified and produced biologically active, radio-labeled human beta interferon by superinducing the interferon gene in fibroblast cells, and they showed its active site contains tyrosine residues. Tan's laboratory isolated sufficient amounts of human beta interferon to perform the first amino acid, sugar composition and N-terminal analyses. They showed that human beta interferon was an unusually hydrophobic glycoprotein. This explained the large loss of interferon activity when preparations were transferred from test tube to test tube or from vessel to vessel during purification. The analyses showed the reality of interferon activity by chemical verification. The purification of human alpha interferon was not reported until 1978. A series of publications from the laboratories of Sidney Pestka and Alan Waldman between 1978 and 1981, describe the purification of the type I interferons IFN-α and IFN-β. By the early 1980s, genes for these interferons had been cloned, adding further definitive proof that interferons were responsible for interfering with viral replication. Gene cloning also confirmed that IFN-α was encoded by a family of many related genes. The type II IFN (IFN-γ) gene was also isolated around this time.\n\nInterferon was scarce and expensive until 1980, when the interferon gene was inserted into bacteria using recombinant DNA technology, allowing mass cultivation and purification from bacterial cultures or derived from yeasts. Interferon can also be produced by recombinant mammalian cells.\nBefore the early 1970s, large scale production of human interferon had been pioneered by Kari Cantell. He produced large amounts of human alpha interferon from large quantities of human white blood cells collected by the Finnish Blood Bank. Large amounts of human beta interferon were made by superinducing the beta interferon gene in human fibroblast cells.\n\nCantell's and Tan's methods of making large amounts of natural interferon were critical for chemical characterisation, clinical trials and the preparation of small amounts of interferon messenger RNA to clone the human alpha and beta interferon genes. The superinduced human beta interferon messenger RNA was prepared by Tan's lab for Cetus corp. to clone the human beta interferon gene in bacteria and the recombinant interferon was developed as 'betaseron' and approved for the treatment of MS. Superinduction of the human beta interferon gene was also used by Israeli scientists to manufacture human beta interferon.\n\nBULLET::::- ATC code L03#L03AB Interferons\nBULLET::::- Immunosuppression\nBULLET::::- Immunosuppressive drug\nBULLET::::- Immunotherapy\nBULLET::::- Interferon Consensus Sequence-binding protein\n"}
{"id": "15123", "url": "https://en.wikipedia.org/wiki?curid=15123", "title": "Israeli settlement", "text": "Israeli settlement\n\nIsraeli settlements are civilian communities inhabited by Israeli citizens, almost exclusively of Jewish ethnicity, built on lands occupied by Israel in the 1967 Six-Day War. Israeli settlements currently exist in the Palestinian territory of the West Bank, including East Jerusalem, and in the Syrian territory of the Golan Heights, and had previously existed within the Egyptian territory of the Sinai Peninsula, and within the Palestinian territory of the Gaza Strip; however, Israel evacuated and dismantled the 18 Sinai settlements following the 1979 Egypt–Israel peace agreement and all of the 21 settlements in the Gaza Strip, along with four in the West Bank, in 2005 as part of its unilateral disengagement from Gaza. The international community considers the settlements to be illegal under international law, and the United Nations has repeatedly upheld the view that Israel's construction of settlements constitutes a violation of the Fourth Geneva Convention.\n\nIsrael has established Jewish neighborhoods in East Jerusalem and in the Israeli-occupied portion of the Golan Heights, both of which Israel has effectively annexed, and as such Israel does not consider the developments there to be settlements. The international community regards both territories as held under Israeli occupation and the localities established there to be illegal settlements. The International Court of Justice also said that these settlements are illegal in its 2004 advisory opinion on the West Bank barrier. In the West Bank, Israel continues to expand its remaining settlements as well as settling new areas, despite pressure from the international community to desist.\n\nThe presence and ongoing expansion of existing settlements by Israel and the construction of settlement outposts is frequently criticized as an obstacle to the Israeli–Palestinian peace process by the Palestinians, and third parties such as the OIC, the United Nations, Russia, the United Kingdom, France, and the European Union have echoed those criticisms. The United States for decades considered the settlements to be \"illegitimate\" until the Trump Administration in November 2019 shifted its position declaring \"the establishment of Israeli civilian settlements in the West Bank is not \"per se\" inconsistent with international law.\"\n\nThe population of the 121 officially recognized settlements in the West Bank, excluding East Jerusalem, is 400,000 almost exclusively Jewish citizens of Israel; East Jerusalem settlements are inhabited by over 300,000 Israeli citizens (both Jewish citizens of Israel and Arab citizens of Israel); and over 20,000 Israeli citizens live in settlements in the Golan Heights. East Jerusalem and the Golan Heights have been annexed by Israel, so residents are treated equivalently to the rest of Israel under Israeli law. Although the West Bank settlements are on land administered under Israeli military law rather than civil law, Israeli civil law is \"pipelined\" into the settlements such that Israeli citizens living there are treated similarly to those living in Israel.\n\nSettlement has an economic dimension, much of it driven by the significantly lower costs of housing for Israeli citizens living in Israeli settlements compared to the cost of housing and living in Israel proper. Government spending per citizen in the settlements is double that spent per Israeli citizen in Tel Aviv and Jerusalem, while government spending for settlers in isolated Israeli settlements is three times the Israeli national average. Most of the spending goes to the security of the Israeli citizens living there.\n\nOn 30 June 2014, according to the Yesha Council, 382,031 Israeli citizens lived in the 121 officially recognised Israeli settlements in the West Bank. A number of Palestinian non-Israeli citizens (as opposed to Arab citizens of Israel) also reside in Israeli settlements in East Jerusalem, however, over 300,000 Israeli citizens (both Jewish citizens of Israel and Arab citizens of Israel) lived in settlements in East Jerusalem, and over 20,000 Israeli citizens lived in settlements in the Golan Heights. In January 2015 the Israeli Interior Ministry gave figures of 389,250 Israeli citizens living in the West Bank and a further 375,000 Israeli citizens living in East Jerusalem.\n\nSettlements range in character from farming communities and frontier villages to urban suburbs and neighborhoods. The four largest settlements, Modi'in Illit, Ma'ale Adumim, Beitar Illit and Ariel, have achieved city status. Ariel has 18,000 residents, while the rest have around 37,000 to 55,500 each.\n\nFollowing the 1967 Six-Day War, Israel occupied a number of territories. It took over the remainder of the Palestinian Mandate territories of the West Bank including East Jerusalem, from Jordan which had controlled the territories since the 1948 Arab-Israeli war, and the Gaza Strip from Egypt, which had held Gaza under occupation since 1949. From Egypt it also captured the Sinai Peninsula and from Syria it captured most of the Golan Heights, which since 1981 has been administered under the Golan Heights Law.\n\nAs early as September 1967, Israeli settlement policy was progressively encouraged by the Labor government of Levi Eshkol. The basis for Israeli settlement in the West Bank became the Allon Plan, named after its inventor Yigal Allon. It implied Israeli annexation of major parts of the Israeli-occupied territories, especially East Jerusalem, Gush Etzion and the Jordan Valley. The settlement policy of the government of Yitzhak Rabin was also derived from the Allon Plan.\n\nThe first settlement was Kfar Etzion, in the southern West Bank, although that location was outside the Allon Plan. Many settlements began as Nahal settlements. They were established as military outposts and later expanded and populated with civilian inhabitants. According to a secret document dating to 1970, obtained by Haaretz, the settlement of Kiryat Arba was established by confiscating land by military order and falsely representing the project as being strictly for military use while in reality, Kiryat Arba was planned for settler use. The method of confiscating land by military order for establishing civilian settlements was an open secret in Israel throughout the 1970s, but publication of the information was suppressed by the military censor.\n\nThe Likud government of Menahem Begin, from 1977, was more supportive to settlement in other parts of the West Bank, by organizations like Gush Emunim and the Jewish Agency/World Zionist Organization, and intensified the settlement activities. In a government statement, Likud declared that the entire historic Land of Israel is the inalienable heritage of the Jewish people, and that no part of the West Bank should be handed over to foreign rule. Ariel Sharon declared in the same year (1977) that there was a plan to settle 2 million Jews in the West Bank by 2000. The government abrogated the prohibition from purchasing occupied land by Israelis; the \"Drobles Plan\", a plan for large-scale settlement in the West Bank meant to prevent a Palestinian state under the pretext of security became the framework for its policy. The \"Drobles Plan\" from the World Zionist Organization, dated October 1978 and named \"Master Plan for the Development of Settlements in Judea and Samaria, 1979–1983\", was written by the Jewish Agency director and former Knesset member Matityahu Drobles. In January 1981, the government adopted a follow up-plan from Drobles, dated September 1980 and named \"The current state of the settlements in Judea and Samaria\", with more details about settlement strategy and policy.\nSince 1967, government-funded settlement projects in the West Bank are implemented by the \"Settlement Division\" of the World Zionist Organization. Though formally a non-governmental organization, it is funded by the Israeli government and leases lands from the Civil Administration to settle in the West Bank. It is authorized to create settlements in the West Bank on lands licensed to it by the Civil Administration. Traditionally, the Settlement Division has been under the responsibility of the Agriculture Ministry. Since the Olso Accords, it was always housed within the Prime Minister's Office (PMO). In 2007, it was moved back to the Agriculture Ministry. In 2009, the Netanyahu Government decided to subject all settlement activities to additional approval of the Prime Minister and the Defense Minister. In 2011, Netanyahu sought to move the Settlement Division again under the direct control of (his own) PMO, and to curtail Defense Minister Ehud Barak's authority.\n\nAt the presentation of the Oslo II Accord on 5 October 1995 in the Knesset, PM Yitzhak Rabin expounded the Israeli settlement policy in connection with the permanent solution to the conflict. Israel wanted \"\"a Palestinian entity, less than a state, which will be a home to most of the Palestinian residents living in the Gaza Strip and the West Bank\"\". It wanted to keep settlements beyond the Green Line including Ma'ale Adumim and Givat Ze'ev in East Jerusalem. Blocs of settlements should be established in the West Bank. Rabin promised not to return to the 4 June 1967 lines.\n\nIn June 1997, the Likud government of Benjamin Netanyahu presented its \"Allon Plus Plan\". This plan holds the retention of some 60% of the West Bank, including the \"Greater Jerusalem\" area with the settlements Gush Etzion and Ma'aleh Adumim, other large concentrations of settlements in the West Bank, the entire Jordan Valley, a \"security area\", and a network of Israeli-only bypass roads.\n\nIn the Road map for peace of 2002, which was never implemented, the establishment of a Palestinian state was acknowledged. Outposts would be dismantled. However, many new outposts appeared instead, few were removed. Israel's settlement policy remained unchanged. Settlements in East Jerusalem and remaining West Bank were expanded.\n\nWhile according to official Israeli policy no new settlements were built, at least some hundred unauthorized outposts were established since 2002 with state funding in the 60% of the West Bank that was not under Palestinian administrative control and the population growth of settlers did not diminish.\n\nIn 2005, all 21 settlements in the Gaza Strip and four in the northern West Bank were forcibly evacuated as part of Israeli disengagement from the Gaza Strip, known to some in Israel as \"the Expulsion\". However, the disengagement was more than compensated by transfers to the West Bank.\n\nAfter the failure of the Roadmap, several new plans emerged to settle in major parts of the West Bank. In 2011, \"Haaretz\" revealed the Civil Administration's \"\"Blue Line\"\"-plan, written in January 2011, which aims to increase Israeli \"state-ownership\" of West Bank lands (\"state lands\") and settlement in strategic areas like the Jordan Valley and the Palestinian northern Dead Sea area. In March 2012, it was revealed that the Civil Administration over the years covertly allotted 10% of the West Bank for further settlement. Provisional names for future new settlements or settlement expansions were already assigned. The plan includes many Palestinian built-up sites in the Areas A and B.\n\nBULLET::::- Jews who had been living in the West Bank before they were expelled in 1948 wanted to return home.\nBULLET::::- After the Six-Day War, some Israelis believed that war might break out again. They built settlements on hilltops to act as observation posts for an early warning system.\nBULLET::::- Israelis were afraid that if strategically important lands were returned, Israelis would be in danger. For years, Syria had been firing from the Golan Heights into the kibbutzim of the valley. If Syria got back the Golan Heights, they would resume firing on the Israelis below. Israelis remembered that after conquering the Sinai, Israel withdrew from the Sinai. If Israel constructed a military base, the soldiers could be ordered to leave, but if they created a \"settlement on the Syrian heights – a civilian presence, then no one could just order a withdrawal. There'd have to be a debate in the Knesset.\"\nBULLET::::- There were Israelis who remembered that Israel had conquered the Sinai in 1956, but gave it back. \"The promises made by Eisenhower had proved hollow at the first test and had failed to prevent war …\" They were willing to return land, but only if Israel got a peace treaty in return. They were hoping that building settlements would make it more difficult for Israel to withdraw from land without getting a peace treaty in return.\nBULLET::::- There were \"Religious radicals, convinced that they were fulfilling God's plan for history …\" For Avraham Kook, \"the Jews' role was to be the vessel that brings the \"divine idea\" into the world. The world's redemption depended on the Jews living in the Land of Israel\" Rabbi Tzvi Kook said...It's \"the Lord's land. Is it in our hands to give up even a millimeter?\" The State of Israel represented the \"beginning of redemption\" and was \"the state that the prophets foresaw\" when they spoke of the End of Days. \"…the Bible was the Jewish deed to the Land of Israel…\" \"…the conquest as introducing the end of days, when 'nation shall not lift up sword against nation.'\"\nBULLET::::- There were secular Israelis who saw \"the West Bank as the historic patrimony of the Jewish people and control of this region as a matter of momentous historic importance.\"\nBULLET::::- Settlement building as punishment. \"According to reports on Israel Radio, the development is a response to the 2014 kidnapping and murder of Israeli teenagers.\"\nBULLET::::- Settlements as bargaining chips for negotiations.\n\nSome settlements are self-contained cities with a stable population in the tens of thousands, infrastructure, and all other features of permanence. Examples are Beitar Illit (a city of close to 45,000 residents), Ma'ale Adumim, Modi'in Illit, and Ariel (almost 20,000 residents). Some are towns with a local council status with populations of 2,000–20,0000, such as Alfei Menashe, Eli, Elkana, Efrat and Kiryat Arba. There are also clusters of villages governed by a local elected committee and regional councils that are responsible for municipal services. Examples are Kfar Adumim, Neve Daniel, Kfar Tapuach and Ateret. Kibbutzim and moshavim in the territories include Argaman, Gilgal, Niran and Yitav. Jewish neighborhoods have been built on the outskirts of Arab neighborhoods, for example in Hebron. In Jerusalem, there are urban neighborhoods where Jews and Arabs live together: the Muslim Quarter, Silwan, Abu Tor, Sheikh Jarrah and Shimon HaTzadik.\n\nUnder the Oslo Accords, the West Bank was divided into three separate parts designated as Area A, Area B and Area C. Leaving aside the position of East Jerusalem, all of the settlements are in Area C which comprises about 60% of the West Bank.\n\nBULLET::::- Cities/towns: Ariel, Betar Illit, Modi'in Illit and Ma'ale Adumim.\nBULLET::::- Urban suburbs, such as Har Gilo.\nBULLET::::- Block settlements, such as Gush Etzion and settlements in the Nablus area.\nBULLET::::- Frontier villages, such as those along the Jordan River.\nBULLET::::- Outposts, small settlements, some authorized and some unauthorized, often on hilltops. The Sasson Report, commissioned by Ariel Sharon's administration, found that several government ministries had cooperated to establish illegal outposts, spending millions of dollars on infrastructure.\n\nSome settlements were established on sites where Jewish communities had existed during the British Mandate of Palestine.\nBULLET::::- Jerusalem – Jewish presence alongside other peoples since biblical times, various surrounding communities and neighborhoods, including Kfar Shiloah, also known as Silwan—settled by Yemenite Jews in 1884, Jewish residents evacuated in 1938, a few Jewish families move into reclaimed homes in 2004.\nOther communities: Shimon HaTzadik, Neve Yaakov and Atarot which in post-1967 was rebuilt as an industrial zone.\nBULLET::::- Gush Etzion – four communities, established between 1927 and 1947, destroyed 1948, reestablished beginning 1967.\nBULLET::::- Hebron – Jewish presence since biblical times, forced out in the wake of the 1929 Hebron massacre, some families returned in 1931 but were evacuated by the British, a few buildings resettled in 1967.\nBULLET::::- Kfar Darom – established in 1946, evacuated in 1948, resettled in 1970, evacuated in 2005 as part of the withdrawal from the Gaza Strip.\nBULLET::::- Kalia and Beit HaArava – the former was built in 1934 as a kibbutz for potash mining. The latter was built in 1943 as an agricultural community. Both were abandoned in 1948, and subsequently destroyed by Jordanian forces, and resettled after the Six-Day War.\nBULLET::::- Gaza City had a Jewish community for many centuries that was evacuated following riots in 1929. After the Six-Day War, Jewish communities were built elsewhere in the Gaza Strip, but not in Gaza City proper.\n\nAt the end of 2010, 534,224 Jewish Israeli lived in the West Bank, including East Jerusalem. 314,132 of them lived in the 121 authorised settlements and 102 unauthorised settlement outposts on the West Bank, 198,629 were living in East Jerusalem, and almost 20,000 lived in settlements in the Golan Heights.\n\nIn 2011, 328,423 Israeli Jews were living on the West Bank, excluding Jerusalem, and the Jewish population in the Golan Heights exceeded 20,000.\n\nFor the year 2012, the Jewish population in the West Bank settlements excluding East Jerusalem was expected to rise to 350,000.\nIn May 2014, the Israeli Housing Minister Uri Ariel, who himself lives in the West Bank settlement of Kfar Adumim, put the settler population at up to 750,000: 400,000 in the West Bank and up to 350,000 in East Jerusalem. He stated: \"I think that in five years there will be 550,000 or 600,000 Jews in Judea and Samaria, rather than 400,000 (now)\".\n\nAs of 30 June 2014, according to the Yesha Council, 382,031 Israeli citizens lived in the 121 officially recognised Israeli settlements in the West Bank, almost exclusively Jewish citizens of Israel. A number of Palestinian non-Israeli citizens (as opposed to Arab citizens of Israel) also reside in Israeli settlements in East Jerusalem, however, over 300,000 Israeli citizens (both Jewish citizens of Israel and Arab citizens of Israel) lived in settlements in East Jerusalem, and over 20,000 Israeli citizens lived in settlements in the Golan Heights. In January 2015 the Israeli Interior Ministry gave figures of 389,250 Israeli citizens living in the West Bank and a further 375,000 Israeli citizens living in East Jerusalem.\n\nBy the end of 2016, the West Bank Jewish population rose to 420,899, excluding East Jerusalem, where there were more than 200,000 Jews.\n\nNote: due to change of definition, the number of settlements in the West Bank decreased in 1997 from 138 to 121 (outposts not included).\n\nBased on various sources, population dispersal can be estimated as follows:\n\n! Settler population\n! 1948\n! 1972\n! 1977\n! 1980\n! 1983\n! 1993\n! 2004\n! 2007\n! 2010\n! 2014\n\n! 2018\nWest Bank (excluding Jerusalem)\n480 (see Gush Etzion)1,1823,200\n-4,400\n17,40022,800111,600234,500276,500314,100400,000427,800\nGaza Strip \n30 (see Kfar Darom)700 9004,8007,8260000\nGolan Heights\n0776,80012,60017,26518,69219,79721,000\nEast Jerusalem\n2,300 (see Jewish Quarter, Atarot, Neve Yaakov)8,64976,095152,800181,587189,708198,629300,000-350,000218,000\n\n! Total\n! 2,810\n! 10,608 \n!\n! 106,595\n! 281,800\n! 441,178\n! 485,170\n! 532,526\n! 721,000-771,000\n\nIn addition to internal migration, in large though declining numbers, the settlements absorb annually about 1000 new immigrants from outside Israel. In the 1990s, the annual settler population growth was more than three times the annual population growth in Israel. Population growth has continued in the 2000s. According to the BBC, the settlements in the West Bank have been growing at a rate of 5–6% since 2001. In 2016, there were sixty thousand American Israelis living in settlements in the West Bank.\n\nThe establishment of settlements in the Palestinian territories is linked to the displacement of the Palestinian populations as evidenced by a 1979 Security Council Commission which established a link between Israeli settlements and the displacement of the local population. The commission also found that those who remained were under consistent pressure to leave to make room for further settlers who were being encouraged into the area. In conclusion the commission stated that settlement in the Palestinian territories was causing \"profound and irreversible changes of a geographic and demographic nature\".\n\nThe Israeli settlements in the West Bank fall under the administrative district of \"Judea and Samaria Area\". Since December 2007, approval by both the Israeli Prime Minister and Israeli Defense Minister of all settlement activities (including planning) in the West Bank is required. Authority for planning and construction is held by the Israel Defense Forces Civil Administration.\n\nThe area consists of four cities, thirteen local councils and six regional councils.\nBULLET::::- Cities: Ariel, Betar Illit, Maale Adumim, Modi'in Illit;\nBULLET::::- Local councils: Alfei Menashe, Beit Aryeh-Ofarim, Beit El, Efrat, Elkana, Giv'at Ze'ev, Har Adar, Immanuel, Karnei Shomron, Kedumim, Kiryat Arba, Ma'ale Efraim, Oranit;\nBULLET::::- Regional councils: Gush Etzion (\"Ezion Bloc\"), Har Hebron (\"Mount Hebron\"), Matte Binyamin (\"Staff of Benjamin\", named after the ancient Israelite tribe that dwelled in the area), Megilot (\"Scrolls\", named after the Dead Sea scrolls, which were discovered in the area), Shomron Regional Council (\"Samaria\"), Biq'at HaYarden (\"Jordan valley\").\nThe Yesha Council (, \"Moatzat Yesha\", a Hebrew acronym for Judea, Samaria and Gaza) is the umbrella organization of municipal councils in the West Bank.\n\nThe actual buildings of the Israeli settlements cover only 1 percent of the West Bank, but their jurisdiction and their regional councils extend to about 42 percent of the West Bank, according to the Israeli NGO B'Tselem. Yesha Council chairman Dani Dayan disputes the figures and claims that the settlements only control 9.2 percent of the West Bank.\n\nBetween 2001 and 2007 more than 10,000 Israeli settlement units were built, while 91 permits were issued for Palestinian construction, and 1,663 Palestinian structures were demolished in Area C.\n\nWest Bank Palestinians have their cases tried in Israel's military courts while Jewish Israeli settlers living in the same occupied territory are tried in civil courts. The arrangement has been described as \"de facto segregation\" by the UN Committee on the Elimination of Racial Discrimination.\nA bill to formally extend Israeli law to the Israeli settlements in the West Bank was rejected in 2012. The basic military laws governing the West Bank are influenced by what is called the \"pipelining\" of Israeli legislation.As a result of \"Enclave law\", large portions of Israeli civil law are applied to Israeli settlements and Israeli residents in the occupied territories.\n\nOn 31 August 2014, Israel announced it was appropriating 400 hectares of land in the West Bank to eventually house 1,000 Israel families. The appropriation was described as the largest in more than 30 years. According to reports on Israel Radio, the development is a response to the 2014 kidnapping and murder of Israeli teenagers.\n\nEast Jerusalem is defined in the Jerusalem Law as part of Israel and its capital, Jerusalem. As such it is administered as part of the city and its district, the Jerusalem District. Pre-1967 residents of East Jerusalem and their descendants have residency status in the city but many have refused Israeli citizenship. Thus, the Israeli government maintains an administrative distinction between Israeli citizens and non-citizens in East Jerusalem, but the Jerusalem municipality does not.\n\nThe Golan Heights is administered under Israeli civil law as the Golan sub-district, a part of the Northern District. Israel makes no legal or administrative distinction between pre-1967 communities in the Golan Heights (mainly Druze) and the post-1967 settlements.\n\nAfter the capture of the Sinai Peninsula from Egypt in the 1967 Six-Day War, settlements were established along the Gulf of Aqaba and in northeast Sinai, just below the Gaza Strip. Israel had plans to expand the settlement of Yamit into a city with a population of 200,000, though the actual population of Yamit did not exceed 3,000. The Sinai Peninsula was returned to Egypt in stages beginning in 1979 as part of the Egypt–Israel Peace Treaty. As required by the treaty, in 1982 Israel evacuated the Israeli civilian population from the 18 Sinai settlements in Sinai. In some instances evacuations were done forcefully, such as the evacuation of Yamit. All the settlements were then dismantled.\n\nBefore Israel's unilateral disengagement plan in which the Israeli settlements were evacuated, there were in the Gaza Strip under the administration of the Hof Aza Regional Council. The land was allocated in such a way that each Israeli settler disposed of 400 times the land available to the Palestinian refugees, and 20 times the volume of water allowed to the peasant farmers of the Strip.\n\nThe consensus view in the international community is that the existence of Israeli settlements in the West Bank including East Jerusalem and the Golan Heights is in violation of international law. The Fourth Geneva Convention includes statements such as \"the Occupying Power shall not deport or transfer parts of its own civilian population into the territory it occupies\".\n\nAt present, the view of the international community, as reflected in numerous UN resolutions, regards the building and existence of Israeli settlements in the West Bank, East Jerusalem and the Golan Heights as a violation of international law. UN Security Council Resolution 446 refers to the Fourth Geneva Convention as the applicable international legal instrument, and calls upon Israel to desist from transferring its own population into the territories or changing their demographic makeup. The reconvened Conference of the High Contracting Parties to the Geneva Conventions has declared the settlements illegal as has the primary judicial organ of the UN, the International Court of Justice.\n\nThe position of successive Israeli governments is that all authorized settlements are entirely legal and consistent with international law. In practice, Israel does not accept that the Fourth Geneva Convention applies \"de jure\", but has stated that on humanitarian issues it will govern itself \"de facto\" by its provisions, without specifying which these are. The scholar and jurist Eugene Rostow has disputed the illegality of authorized settlements.\n\nUnder Israeli law, West Bank settlements must meet specific criteria to be legal. In 2009, there were approximately 100 small communities that did not meet these criteria and are referred to as illegal outposts.\n\nIn 2014 twelve EU countries warned businesses against involving themselves in the settlements. According to the warnings, economic activities relating to the settlements involve legal and economic risks stemming from the fact that the settlements are built on occupied land not recognized as Israel's.\n\nAfter the Six-Day War, in 1967, Theodor Meron, legal counsel to the Israeli Foreign Ministry stated in a legal opinion to the Prime Minister,\n\n\"My conclusion is that civilian settlement in the administered territories contravenes the explicit provisions of the Fourth Geneva Convention.\"\n\nThis legal opinion was sent to Prime Minister Levi Eshkol. However, it was not made public at the time. The Labor cabinet allowed settlements despite the warning. This paved the way for future settlement growth. In 2007, Meron stated that \"I believe that I would have given the same opinion today.\"\n\nIn 1978, the Legal Adviser of the Department of State of the United States reached the same conclusion.\n\nThe International Court of Justice, in its advisory opinion, has since ruled that Israel is in breach of international law by establishing settlements in Occupied Palestinian Territory, including East Jerusalem. The Court maintains that Israel cannot rely on its right of self-defense or necessity to impose a regime that violates international law. The Court also ruled that Israel violates basic human rights by impeding liberty of movement and the inhabitants' right to work, health, education and an adequate standard of living.\n\nInternational intergovernmental organizations such as the Conference of the High Contracting Parties to the Fourth Geneva Convention, major organs of the United Nations, the European Union, and Canada, also regard the settlements as a violation of international law. The Committee on the Elimination of Racial Discrimination wrote that \"The status of the settlements was clearly inconsistent with Article 3 of the Convention, which, as noted in the Committee's General Recommendation XIX, prohibited all forms of racial segregation in all countries. There is a consensus among publicists that the prohibition of racial discrimination, irrespective of territories, is an imperative norm of international law.\" Amnesty International, and Human Rights Watch have also characterized the settlements as a violation of international law.\n\nIn late January 2013 a report drafted by three justices, presided over by Christine Chanet, and issued by the United Nations Human Rights Council declared that Jewish settlements constituted a creeping annexation based on multiple violations of the Geneva Conventions and international law, and stated that if Palestine ratified the Rome Accord, Israel could be tried for \"gross violations of human rights law and serious violations of international humanitarian law.' A spokesman for Israel's Foreign Ministry declared the report ‘unfortunate' and accused the UN's Human Rights Council of a \"systematically one-sided and biased approach towards Israel.\" \n\nAccording to Talia Sasson, the High Court of Justice in Israel, with a variety of different justices sitting, has repeatedly stated for more than 4 decades that Israel's presence in the West Bank is in violation of international law.\n\nFour prominent jurists cited the concept of the \"sovereignty vacuum\" in the immediate aftermath of the Six-Day War to describe the legal status of the West Bank and Gaza: Yehuda Zvi Blum in 1968, Elihu Lauterpacht in 1968, Julius Stone in 1969 and 1981, and Stephen M. Schwebel in 1970. Eugene V. Rostow also argued in 1979 that the occupied territories' legal status was undetermined.\nBULLET::::- Stephen M. Schwebel made three distinctions specific to the Israeli situation to claim that the territories were seized in self-defense and that Israel has more title to them than the previous holders.\nBULLET::::- Professor Julius Stone also wrote that \"Israel's presence in all these areas pending negotiation of new borders is entirely lawful, since Israel entered them lawfully in self-defense.\" He argued that it would be an \"irony bordering on the absurd\" to read Article 49(6) as meaning that the State of Israel was obliged to ensure (by force if necessary) that areas with a millennial association with Jewish life, shall be forever \"\"judenrein\"\".\nProfessor Ben Saul took exception to this view, arguing that Article 49(6) can be read to include voluntary or assisted transfers, as indeed it was in the advisory opinion of the International Court of Justice which had expressed this interpretation in the Israeli Wall Advisory Opinion (2003).\n\nIsrael maintains that a temporary use of land and buildings for various purposes is permissible under a plea of military necessity and that the settlements fulfilled security needs. Israel argues that its settlement policy is consistent with international law, including the Fourth Geneva Convention, while recognising that some settlements have been constructed illegally on private land. The Israeli Supreme Court has ruled that the power of the Civil Administration and the Military Commander in the occupied territories is limited by the entrenched customary rules of public international law as codified in the Hague Regulations and Geneva Convention IV. In 1998 the Israeli Minister of Foreign Affairs produced \"The International Criminal Court Background Paper\". It concludesInternational law has long recognised that there are crimes of such severity they should be considered \"international crimes.\" Such crimes have been established in treaties such as the Genocide Convention and the Geneva Conventions... The following are Israel's primary issues of concern [ie with the rules of the ICC]: The inclusion of settlement activity as a \"war crime\" is a cynical attempt to abuse the Court for political ends. The implication that the transfer of civilian population to occupied territories can be classified as a crime equal in gravity to attacks on civilian population centres or mass murder is preposterous and has no basis in international law.\n\nA UN conference was held in Rome in 1998, where Israel was one of seven countries to vote against the Rome Statute to establish the International Criminal Court. Israel was opposed to a provision that included as a war crime the transfer of civilian populations into territory the government occupies. Israel has signed the statute, but not ratified the treaty.\n\nBy Israeli law, privately owned land can not be part of a settlement, unless the land in question has been confiscated for military purposes. In 2006 Peace Now acquired a report, which it claims was leaked from the Israeli Government's Civil Administration, indicating that up to 40 percent of the land Israel plans to retain in the West Bank is privately owned by Palestinians. Peace Now called this a violation of Israeli law. Peace Now published a comprehensive report about settlements on private lands. In the wake of a legal battle, Peace Now lowered the figure to 32 percent, which the Civil Administration also denied. \"The Washington Post\" reported that \"The 38-page report offers what appears to be a comprehensive argument against the Israeli government's contention that it avoids building on private land, drawing on the state's own data to make the case.\"\n\nIn February 2008, the Civil Administration stated that the land on which more than a third of West Bank settlements was built had been expropriated by the IDF for \"security purposes.\" The unauthorized seizure of private Palestinian land was defined by the Civil Administration itself as 'theft.' According to B'Tselem, more than 42 percent of the West Bank are under control of the Israeli settlements, 21 percent of which was seized from private Palestinian owners, much of it in violation of the 1979 Israeli Supreme Court decision.\n\nIn 1979, the government decided to extend settlements or build new ones only on \"state lands\".\n\nA secret database, drafted by a retired senior officer, Baruch Spiegel, on orders from former defense minister Shaul Mofaz, found that some settlements deemed legal by Israel were illegal outposts, and that large portions of Ofra, Elon Moreh and Beit El were built on private Palestinian land. The \"Spiegel report\" was revealed by Haaretz in 2009. Many settlements are largely built on private lands, without approval of the Israeli Government. According to Israel, the bulk of the land was vacant, was leased from the state, or bought fairly from Palestinian landowners.\n\nInvoking the Absentee Property Law to transfer, sell or lease property in East Jerusalem owned by Palestinians who live elsewhere without compensation has been criticized both inside and outside of Israel. Opponents of the settlements claim that \"vacant\" land belonged to Arabs who fled or collectively to an entire village, a practice that developed under Ottoman rule. B'Tselem charged that Israel is using the absence of modern legal documents for the communal land as a legal basis for expropriating it. These \"abandoned lands\" are sometimes laundered through a series of fraudulent sales.\n\nAccording to Amira Hass, one of the techniques used by Israel to expropriate Palestinian land is to place desired areas under a 'military firing zone' classification, and then issue orders for the evacuation of Palestinians from the villages in that range, while allowing contiguous Jewish settlements to remain unaffected.\n\nAmnesty International argues that Israel's settlement policy is discriminatory and a violation of Palestinian human rights. B'Tselem claims that Israeli travel restrictions impact on Palestinian freedom of movement and Palestinian human rights have been violated in Hebron due to the presence of the settlers within the city. According to B'Tselem, over fifty percent of West Bank land expropriated from Palestinians has been used to establish settlements and create reserves of land for their future expansion. The seized lands mainly benefit the settlements and Palestinians cannot use them. The roads built by Israel in the West Bank to serve the settlements are closed to Palestinian vehicles' and act as a barrier often between villages and the lands on which they subsist.\n\nHuman Rights Watch and other human rights observer volunteer regularly file reports on \"settler violence,\" referring to stoning and shooting incidents involving Israeli settlers. Israel's withdrawal from Gaza and Hebron have led to violent settler protests and disputes over land and resources. Meron Benvenisti described the settlement enterprise as a \"commercial real estate project that conscripts Zionist rhetoric for profit.\"\n\nThe construction of the Israeli West Bank barrier has been criticized as an infringement on Palestinian human and land rights. The United Nations Office for the Coordination of Humanitarian Affairs estimated that 10% of the West Bank would fall on the Israeli side of the barrier.\n\nIn July 2012, the UN Human Rights Council decided to set up a probe into Jewish settlements. The report of the independent international fact-finding mission which investigated the \"implications of the Israeli settlements on the civil, political, economic, social and cultural rights of the Palestinian people throughout the Occupied Palestinian Territory\" was published in February 2013.\n\nGoods produced in Israeli settlements are able to stay competitive on the global market, in part because of massive state subsidies they receive from the Israeli government. Farmers and producers are given state assistance, while companies that set up in the territories receive tax breaks and direct government subsidies. An Israeli government fund has also been established to help companies pay customs penalties. Palestinian officials estimate that settlers sell goods worth some $500 million to the Palestinian market. Israel has built 16 industrial zones, containing roughly 1000 industrial plants, in the West Bank and East Jerusalem on acreage that consumes large parts of the territory planned for a future Palestinian state. According to Jodi Rudoren these installations both entrench the occupation and provide work for Palestinians, even those opposed to it. The 16 parks are located at Shaked, Beka'ot, Baran, Karnei Shomron, Emmanuel, Barkan, Ariel, Shilo, Halamish, Ma'ale Efraim, Sha'ar Binyamin, Atarot, Mishor Adumim, Gush Etzion, Kiryat Arba and Metarim (2001).\n\nIn spite of this, the West Bank settlements have failed to develop a self-sustaining local economy. About 60% of the settler workforce commutes to Israel for work. The settlements rely primarily on the labor of their residents in Israel proper rather than local manufacturing, agriculture, or research and development. Of the industrial parks in the settlements, there are only two significant ones, at Ma'ale Adumim and Barkan, with most of the workers there being Palestinian. Only a few hundred settler households cultivate agricultural land, and rely primarily on Palestinian labor in doing so.\n\nSettlement has an economic dimension, much of it driven by the significantly lower costs of housing for Israeli citizens living in Israeli settlements compared to the cost of housing and living in Israel proper. Government spending per citizen in the settlements is double that spent per Israeli citizen in Tel Aviv and Jerusalem, while government spending for settlers in isolated Israeli settlements is three times the Israeli national average. Most of the spending goes to the security of the Israeli citizens living there.\n\nAccording to Israeli government estimates, $230 million worth of settler goods including fruit, vegetables, cosmetics, textiles and toys are exported to the EU each year, accounting for approximately 2% of all Israeli exports to Europe. A 2013 report of Profundo revealed that at least 38 Dutch companies imported settlement products.\n\nEuropean Union law requires a distinction to be made between goods originating in Israel and those from the occupied territories. The former benefit from preferential custom treatment according to the EU-Israel Association Agreement (2000); the latter don't, having been explicitly excluded from the agreement. In practice, however, settler goods often avoid mandatory customs through being labelled as originating in Israel, while European customs authorities commonly fail to complete obligatory postal code checks of products to ensure they have not originated in the occupied territories.\n\nIn 2009, the United Kingdom's Department for the Environment, Food and Rural Affairs issued new guidelines concerning labelling of goods imported from the West Bank. The new guidelines require labelling to clarify whether West Bank products originate from settlements or from the Palestinian economy. Israel's foreign ministry said that the UK was \"catering to the demands of those whose ultimate goal is the boycott of Israeli products\"; but this was denied by the UK government, who said that the aim of the new regulations was to allow consumers to choose for themselves what produce they buy. Denmark has similar legislation requiring food products from settlements in the occupied territories to be accurately labelled.\n\nOn November 12, 2019 the Court of Justice of the European Union in a ruling covering all territory Israel captured in the 1967 war decided that labels on foodstuffs must not imply that goods produced in occupied territory came from Israel itself and must \"prevent consumers from being misled as to the fact that the State of Israel is present in the territories concerned as an occupying power and not as a sovereign entity\". In its ruling, the court said that failing to inform EU consumers they were potentially buying goods produced in settlements denies them access to “ethical considerations and considerations relating to the observance of international law”.\n\nIn January 2019 the Dail (Ireland's lower house) voted in favour, by 78 to 45, of the Control of Economic Activity (Occupied Territories) bill. This piece of legislation prohibits the purchasing of any good and/or service from the Golan Heights, East Jerusalem or West Bank settlements. As of February 2019 the bill has some stages to be completed,once codified, either a five-year jail sentence or fines of up to €250,000 ($284,000) will affect anyone who breaks this law.\n\nA Palestinian report argued in 2011 that settlements have a detrimental effect on the Palestinian economy, equivalent to about 85% of the nominal gross domestic product of Palestine, and that the \"occupation enterprise\" allows the state of Israel and commercial firms to profit from Palestinian natural resources and tourist potential. A 2013 report published by the World Bank analysed the impact that the limited access to Area C lands and resources had on the Palestinian economy. While settlements represent a single axis of control, it is the largest with 68% of the Area C lands reserved for the settlements. The report goes on to calculate that access to the lands and resources of Area C, including the territory in and around settlements, would increase the Palestinian GDP by some $3.5 billion (or 35%) per year.\n\nThe Israeli Supreme Court has ruled that Israeli companies are entitled to exploit the West Bank's natural resources for economic gain, and that international law must be \"adapted\" to the \"reality on the ground\" of long-term occupation.\n\nDue to the availability of jobs offering twice the prevailing salary of the West Bank (), as well as high unemployment, tens of thousands of Palestinians work in Israeli settlements. According to the Manufacturers Association of Israel, some 22,000 Palestinians were employed in construction, agriculture, manufacturing and service industries. An Al-Quds University study in 2011 found that 82% of Palestinian workers said they would prefer to not work in Israeli settlements if they had alternative employment in the West Bank.\n\nPalestinians have been highly involved in the construction of settlements in the West Bank. In 2013, the Palestinian Central Bureau of Statistics released their survey showing that the number of Palestinian workers who are employed by the Jewish settlements increased from 16,000 to 20,000 in the first quarter. The survey also found that Palestinians who work in Israel and the settlements are paid more than twice their salary compared to what they receive from Palestinian employers.\n\nIn 2008, Kav LaOved charged that Palestinians who work in Israeli settlements are not granted basic protections of Israeli labor law. Instead, they are employed under Jordanian labor law, which does not require minimum wage, payment for overtime and other social rights. In 2007, the Supreme Court of Israel ruled that Israeli labor law does apply to Palestinians working in West Bank settlements and applying different rules in the same work place constituted discrimination. The ruling allowed Palestinian workers to file lawsuits in Israeli courts. In 2008, the average sum claimed by such lawsuits stood at 100,000 shekels.\n\nAccording to Palestinian Center for Policy and Survey Research, 63% of Palestinians opposed PA plans to prosecute Palestinians who work in the settlements. However, 72% of Palestinians support a boycott of the products they sell. Although the Palestinian Authority has criminalized working in the settlements, the director-general at the Palestinian Ministry of Labor, Samer Salameh, described the situation in February 2014 as being \"caught between two fires\". He said \"We strongly discourage work in the settlements, since the entire enterprise is illegal and illegitimate...but given the high unemployment rate and the lack of alternatives, we do not enforce the law that criminalizes work in the settlements.\"\n\nGush Emunim Underground was a militant organization that operated in 1979–1984. The organization planned attacks on Palestinian officials and the Dome of the Rock. In 1994, Baruch Goldstein of Hebron, a member of Kach carried out the Cave of the Patriarchs massacre, killing 29 Muslim worshipers and injuring 125. The attack was widely condemned by the Israeli government and Jewish community. The Palestinian leadership has accused Israel of \"encouraging and enabling\" settler violence in a bid to provoke Palestinian riots and violence in retaliation. Violence perpetrated by Israeli settlers against Palestinians constitutes terrorism according to the U.S. Department of State, and former IDF Head of Central Command Avi Mizrahi stated that such violence constitutes \"terror.\"\n\nIn mid-2008, a UN report recorded 222 acts of Israeli settler violence against Palestinians and IDF troops compared with 291 in 2007. This trend reportedly increased in 2009. Maj-Gen Shamni said that the number had risen from a few dozen individuals to hundreds, and called it \"a very grave phenomenon.\" In 2008–2009, the defense establishment adopted a harder line against the extremists. This group responded with a tactic dubbed \"price tagging,\" vandalizing Palestinian property whenever police or soldiers were sent in to dismantle outposts. From January through to September 2013, 276 attacks by settlers against Palestinians were recorded.\n\nLeading religious figures in the West Bank have harshly criticized these tactics. Rabbi Menachem Froman of Tekoa said that \"Targeting Palestinians and their property is a shocking thing, (...) It's an act of hurting humanity. (...) This builds a wall of fire between Jews and Arabs.\" The Yesha Council and Hanan Porat also condemned such actions. Other rabbis have been accused of inciting violence against non-Jews. In response to settler violence, the Israeli government said that it would increase law enforcement and cut off aid to illegal outposts. Some settlers are thought to lash out at Palestinians because they are \"easy victims.\" The United Nations accused Israel of failing to intervene and arrest settlers suspected of violence. In 2008, Haaretz wrote that \"Israeli society has become accustomed to seeing lawbreaking settlers receive special treatment and no other group could similarly attack Israeli law enforcement agencies without being severely punished.\"\n\nIn September 2011, settlers vandalized a mosque and an army base. They slashed tires and cut cables of 12 army vehicles and sprayed graffiti. In November 2011, the United Nations Office for Coordination of Human Affairs (OCHA) in the Palestinian territories published a report on settler violence that showed a significant rise compared to 2009 and 2010. The report covered physical violence and property damage such as uprooted olive trees, damaged tractors and slaughtered sheep. The report states that 90% of complaints filed by Palestinians have been closed without charge.\n\nAccording to EU reports, Israel has created an \"atmosphere of impunity\" for Jewish attackers, which is seen as tantamount to tacit approval by the state. In the West Bank, Jews and Palestinians live under two different legal regimes and it is difficult for Palestinians to lodge complaints, which must be filed in Hebrew in Israeli settlements.\n\nThe 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and denouncing \"continuous settler violence and deliberate provocations against Palestinian civilians.\" The report by all EU ministers called \"on the government of Israel to bring the perpetrators to justice and to comply with its obligations under international law.\"\n\nIn July 2014, a day after the burial of three murdered Israeli teens, Khdeir, a 16-year-old Palestinian, was forced into a car by 3 Israeli settlers on an East Jerusalem street. His family immediately reported the fact to Israeli Police who located his charred body a few hours later at Givat Shaul in the Jerusalem Forest. Preliminary results from the autopsy suggested that he was beaten and burnt while still alive. The murder suspects explained the attack as a response to the June abduction and murder of three Israeli teens. The murders contributed to a breakout of hostilities in the 2014 Israel–Gaza conflict.\nIn July 2015, a similar incident occurred where Israeli settlers made an arson attack on two Palestinian houses, one of which was empty; however, the other was occupied, resulting in the burning to death of a Palestinian infant; the four other members of his family were evacuated to the hospital suffering serious injuries. These two incidents received condemnation from the United States, European Union and the IDF. The European Union criticized Israel for \"failing to protect the Palestinian population\".\n\nWhile the Economy of the Palestinian territories has shown signs of growth, the International Committee of the Red Cross reported that Palestinian olive farming has suffered. According to the ICRC, 10,000 olive trees were cut down or burned by settlers in 2007–2010. Foreign ministry spokesman Yigal Palmor said the report ignored official PA data showing that the economic situation of Palestinians had improved substantially, citing Mahmoud Abbas's comment to \"The Washington Post\" in May 2009, where he said \"in the West Bank, we have a good reality, the people are living a normal life.\"\n\n\"Haaretz\" blamed the violence during the olive harvest on a handful of extremists. In 2010, trees belonging to both Jews and Arabs were cut down, poisoned or torched. In the first two weeks of the harvest, 500 trees owned by Palestinians and 100 trees owned by Jews had been vandalized. In October 2013, 100 trees were cut down.\n\nViolent attacks on olive trees seem to be facilitated by the apparently systematic refusal of the Israeli authorities to allow Palestinians to visit their own groves, some times for years, especially in cases where the groves are deemed to be too close to settlements.\n\nPro-Palestinian activists who hold regular protests near the settlements have been accused of stone-throwing, physical assault and provocation. In 2008, Avshalom Peled, head of the Israel Police's Hebron district, called \"left-wing\" activity in the city dangerous and provocative, and accused activists of antagonizing the settlers in the hope of getting a reaction.\n\nSettlers are targeted by Palestinian armed groups who, according to Human Rights Watch, say that settlers are a legitimate target because they have forfeited their civilian status by residing in settlements that are illegal under international humanitarian law. Both Human Rights Watch and B'tselem rejected this argument on the basis that the legal status of the settlements has no effect on the civilian status of their residents. Human Rights Watch said the \"prohibition against intentional attacks against civilians is absolute\". B'tselem said \"The settlers constitute a distinctly civilian population, which is entitled to all the protections granted civilians by international law. The Israeli security forces' use of land in the settlements or the membership of some settlers in the Israeli security forces does not affect the status of the other residents living among them, and certainly does not make them proper targets of attack.\"\n\nFatal attacks on settlers have included firing of rockets and mortars and drive-by shootings, also targeting infants and children. Violent incidents include the murder of Shalhevet Pass, a ten-month-old baby shot by a Palestinian sniper in Hebron, and the murder of two teenagers by unknown perpetrators on 8 May 2001, whose bodies were hidden in a cave near Tekoa, a crime that Israeli authorities suggest may have been committed by Palestinian terrorists. In the Bat Ayin axe attack, children in Bat Ayin were attacked by a Palestinian wielding an axe and a knife. A 13-year-old boy was killed and another was seriously wounded. Rabbi Meir Hai, a father of seven, was killed in a drive-by shooting. In August 2011, five members of one family were killed in their beds. The victims were the father Ehud (Udi) Fogel, the mother Ruth Fogel, and three of their six children—Yoav, 11, Elad, 4, and Hadas, the youngest, a three-month-old infant. According to David Ha'ivri, and as reported by multiple sources, the infant was decapitated.\n\nMunicipal Environmental Associations of Judea and Samaria, an environmental awareness group, was established by the settlers to address sewage treatment problems and cooperate with the Palestinian Authority on environmental issues. According to a 2004 report by Friends of the Earth Middle East, settlers account for 10% of the population in the West Bank but produce 25% of the sewage output. Beit Duqqu and Qalqilyah have accused settlers of polluting their farmland and villagers claim children have become ill after swimming in a local stream. Legal action was taken against 14 settlements by the Israeli Ministry of the Environment. The Palestinian Authority has also been criticized by environmentalists for not doing more to prevent water pollution. Settlers and Palestinians share the mountain aquifer as a water source, and both generate sewage and industrial effluents that endanger the aquifer. Friends of the Earth Middle East claimed that sewage treatment was inadequate in both sectors. Sewage from Palestinian sources was estimated at 46 million cubic meters a year, and sources from settler sources at 15 million cubic meters a year. A 2004 study found that sewage was not sufficiently treated in many settlements, while sewage from Palestinian villages and cities flowed into unlined cesspits, streams and the open environment with no treatment at all.\n\nIn a 2007 study, the Israel Nature and Parks Authority and Israeli Ministry of Environmental Protection, found that Palestinian towns and cities produced 56 million cubic meters of sewage per year, 94 percent discharged without adequate treatment, while Israeli sources produced 17.5 million cubic meters per year, 31.5 percent without adequate treatment.\n\nAccording to Palestinian environmentalists, the settlers operate industrial and manufacturing plants that can create pollution as many do not conform to Israeli standards. In 2005, an old quarry between Kedumim and Nablus was slated for conversion into an industrial waste dump. Pollution experts warned that the dump would threaten Palestinian water sources.\n\nThe Consortium for Applied Research on International Migration (CARIM) has reported in their 2011 migration profile for Palestine that the reasons for individuals to leave the country are similar to those of other countries in the region and they attribute less importance to the specific political situation of the occupied Palestinian territory. Human Rights Watch in 2010 reported that Israeli settlement policies have had the effect of \"forcing residents to leave their communities\".\n\nIn 2008, Condoleezza Rice suggested sending Palestinian refugees to South America, which might reduce pressure on Israel to withdraw from the settlements. Sushil P. Seth speculates that Israelis seem to feel that increasing settlements will force many Palestinians to flee to other countries and that the remainder will be forced to live under Israeli terms. Speaking anonymously with regard to Israeli policies in the South Hebron Hills, a UN expert said that the Israeli crackdown on alternative energy infrastructures like solar panels is part of a deliberate strategy in Area C.\n\"From December 2010 to April 2011, we saw a systematic targeting of the water infrastructure in Hebron, Bethlehem and the Jordan valley. Now, in the last couple of months, they are targeting electricity. Two villages in the area have had their electrical poles demolished. There is this systematic effort by the civil administration targeting all Palestinian infrastructure in Hebron. They are hoping that by making it miserable enough, they [the Palestinians] will pick up and leave.\"\nApproximately 1,500 people in 16 communities, living in the area since the 19th century, and dependent on energy produced by these installations duct business are threatened with work stoppage orders from the Israeli administration on their installation of alternative power infrastructure, and demolition orders expected to follow will darken the homes of 500 people.\n\nAriel University, formerly the College of Judea and Samaria, is the major Israeli institution of higher education in the West Bank. With close to 13,000 students, it is Israel's largest public college. The college was accredited in 1994 and awards bachelor's degrees in arts, sciences, technology, architecture and physical therapy. On 17 July 2012, the Council for Higher Education in Judea and Samaria voted to grant the institution full university status.\n\nTeacher training colleges include Herzog College in Alon Shvut and Orot Israel College in Elkana. Ohalo College is located in Katzrin, in the Golan Heights. Curricula at these institutions are overseen by the Council for Higher Education in Judea and Samaria (CHE-JS).\n\nIn March 2012, The Shomron Regional Council was awarded the Israeli Ministry of Education's first prize National Education Award in recognizing its excellence in investing substantial resources in the educational system. The Shomron Regional Council achieved the highest marks in all parameters (9.28 / 10). Gershon Mesika, the head of the regional council, declared that the award was a certificate of honour of its educators and the settlement youth who proved their quality and excellence.\n\nIn 1983 an Israeli government plan entitled \"Master Plan and Development Plan for Settlement in Samaria and Judea\" envisaged placing a \"maximally large Jewish population\" in priority areas to accomplish incorporation of the West Bank in the Israeli \"national system\". According to Ariel Sharon, strategic settlement locations would work to preclude the formation of a Palestinian state.\n\nPalestinians argue that the policy of settlements constitutes an effort to preempt or sabotage a peace treaty that includes Palestinian sovereignty, and claim that the presence of settlements harm the ability to have a viable and contiguous state. This was also the view of the Israeli Vice Prime Minister Haim Ramon in 2008, saying \"the pressure to enlarge Ofra and other settlements does not stem from a housing shortage, but rather is an attempt to undermine any chance of reaching an agreement with the Palestinians ...\"\n\nThe Israel Foreign Ministry asserts that some settlements are legitimate, as they took shape when there was no operative diplomatic arrangement, and thus they did not violate any agreement. Based on this, they assert that:\n\nBULLET::::- Prior to the signing of the Egypt–Israel Peace Treaty, the eruption of the First Intifada, down to the signing of the Israel–Jordan peace treaty in 1994, Israeli governments on the left and right argued that the settlements were of strategic and tactical importance. The location of the settlements was primarily chosen based on the threat of an attack by the bordering hostile countries of Jordan, Syria, and Egypt and possible routes of advance into Israeli population areas. These settlements were seen as contributing to the security of Israel at a time when peace treaties had not been signed.\n\nAn early evacuation took place in 1982 as part of the Egypt–Israel Peace Treaty, when Israel was required to evacuate its settlers from the 18 Sinai settlements. Arab parties to the conflict had demanded the dismantlement of the settlements as a condition for peace with Israel. The evacuation was carried out with force in some instances, for example in Yamit. The settlements were demolished, as it was feared that settlers might try to return to their homes after the evacuation.\n\nIsrael's unilateral disengagement plan took place in 2005. It involved the evacuation of settlements in the Gaza Strip and part of the West Bank, including all 21 settlements in Gaza and four in the West Bank, while retaining control over Gaza's borders, coastline, and airspace. Most of these settlements had existed since the early 1980s, some were over 30 years old; the total population involved was more than 10,000. There was significant opposition to the plan among parts of the Israeli public, and especially those living in the territories. George W. Bush said that a permanent peace deal would have to reflect \"demographic realities\" in the West Bank regarding Israel's settlements.\n\nWithin the former settlements, almost all buildings were demolished by Israel, with the exception of certain government and religious structures, which were completely emptied. Under an international arrangement, productive greenhouses were left to assist the Palestinian economy but about 30% of these were destroyed within hours by Palestinian looters. Following the withdrawal, many of the former synagogues were torched and destroyed by Palestinians. The Palestinian leadership \"maintained\" that the synagogues were \"symbols of Israeli occupation.\" Kofi Annan, the Secretary-General of the United Nations at the time, said the Palestinian Authority had a \"moral responsibility to protect the synagogues as places with religious significance.\"\n\nSome believe that settlements need not necessarily be dismantled and evacuated, even if Israel withdraws from the territory where they stand, as they can remain under Palestinian rule. These ideas have been expressed both by left-wing Israelis, and by Palestinians who advocate the two-state solution, and by extreme Israeli right-wingers and settlers who object to any dismantling and claim links to the land that are stronger than the political boundaries of the state of Israel.\n\nThe Israeli government has often threatened to dismantle outposts. Some have actually been dismantled, occasionally with use of force; this led to settler violence.\n\nAmerican refusal to declare the settlements illegal was said to be the determining factor in the 2011 attempt to declare Palestinian statehood at the United Nations, the so-called Palestine 194 initiative.\n\nIsrael announced additional settlements in response to the Palestinian diplomatic initiative and Germany responded by moving to stop deliveries to Israel of submarines capable of carrying nuclear weapons.\n\nFinally in 2012, several European states switched to either abstain or vote for statehold in response to continued settlement construction. Israel approved further settlements in response to the vote, which brought further worldwide condemnation.\n\nThe settlements have been a source of tension between Israel and the U.S. Jimmy Carter regarded the settlements as illegal and tactically unwise. Ronald Reagan stated that they were legal but an obstacle to negotiations. In 1991, the U.S. delayed a subsidized loan to pressure Israel on the subject of settlement-building in the Jerusalem-Bethlehem corridor. In 2005, U.S. declared support for \"the retention by Israel of major Israeli population centers as an outcome of negotiations,\" reflecting the statement by George W. Bush that a permanent peace treaty would have to reflect \"demographic realities\" in the West Bank. In June 2009, Barack Obama said that the United States \"does not accept the legitimacy of continued Israeli settlements.\"\n\nPalestinians claim that Israel has undermined the Oslo accords and peace process by continuing to expand the settlements. Settlements in the Sinai Peninsula were evacuated and razed in the wake of the peace agreement with Egypt. The 27 ministers of foreign affairs of the European Union published a report in May 2012 strongly denouncing policies of the State of Israel in the West Bank and finding that Israeli settlements in the West Bank are illegal and \"threaten to make a two-state solution impossible.\" In the framework of the Oslo I Accord of 1993 between the Israeli government and the Palestine Liberation Organization (PLO), a modus vivendi was reached whereby both parties agreed to postpone a final solution on the destination of the settlements to the permanent status negotiations (Article V.3). Israel claims that settlements thereby were not prohibited, since there is no explicit interim provision prohibiting continued settlement construction, the agreement does register an undertaking by both sides, namely that \"Neither side shall initiate or take any step that will change the status of the West Bank and the Gaza Strip pending the outcome of the permanent status negotiations\" (Article XXX1 (7)), which has been interpreted as, not forbidding settlements, but imposing severe restrictions on new settlement building after that date. Melanie Jacques argued in this context that even 'agreements between Israel and the Palestinians which would allow settlements in the OPT, or simply tolerate them pending a settlement of the conflict, violate the Fourth Geneva Convention.'\n\nFinal status proposals have called for retaining long-established communities along the Green Line and transferring the same amount of land in Israel to the Palestinian state. The Clinton administration proposed that Israel keep some settlements in the West Bank, especially those in large blocs near the pre-1967 borders of Israel, with the Palestinians receiving concessions of land in other parts of the country. Both Clinton and Tony Blair pointed out the need for territorial and diplomatic compromise based on the validity of some of the claims of both sides.\n\nFayed Mustafa, Palestinian ambassador to Russia, called for the return of Palestinian territories to Egypt and Jordan if talks failed.\n\nAs Minister of Defense, Ehud Barak approved a plan requiring security commitments in exchange for withdrawal from the West Bank. Barak also expressed readiness to cede parts of East Jerusalem and put the holy sites in the city under a \"special regime.\"\n\nOn 14 June 2009, Israeli Prime Minister Benjamin Netanyahu, as an answer to U.S. President Barack Obama's speech in Cairo, delivered a speech setting out his principles for a Palestinian-Israeli peace, among others, he alleged \"... we have no intention of building new settlements or of expropriating additional land for existing settlements.\" In March 2010, the Netanyahu government announced plans for building 1,600 housing units in Ramat Shlomo across the Green Line in East Jerusalem during U.S. Vice President Joe Biden's visit to Israel causing a diplomatic row.\n\nOn 6 September 2010, Jordanian King Abdullah II and Syrian President Bashar al-Assad said that Israel would need to withdraw from all of the lands occupied in 1967 in order to achieve peace with the Palestinians.\n\nBradley Burston has said that a negotiated or unilateral withdraw from most of the settlements in the West Bank is gaining traction in Israel.\n\nIn November 2010, the United States offered to \"fight against efforts to delegitimize Israel\" and provide extra arms to Israel in exchange for a continuation of the settlement freeze and a final peace agreement, but failed to come to an agreement with the Israelis on the exact terms.\n\nIn December 2010, the United States criticised efforts by the Palestinian Authority to impose borders for the two states through the United Nations rather than through direct negotiations between the two sides. In February 2011, it vetoed a draft resolution to condemn all Jewish settlements established in the occupied Palestinian territory since 1967 as illegal. The resolution, which was supported by all other Security Council members and co-sponsored by nearly 120 nations, would have demanded that \"Israel, as the occupying power, immediately and completely ceases all settlement activities in the occupied Palestinian territory, including East Jerusalem and that it fully respect its legal obligations in this regard.\" The U.S. representative said that while it agreed that the settlements were illegal, the resolution would harm chances for negotiations. Israel's deputy Foreign Minister, Daniel Ayalon, said that the \"UN serves as a rubber stamp for the Arab countries and, as such, the General Assembly has an automatic majority,\" and that the vote \"proved that the United States is the only country capable of advancing the peace process and the only righteous one speaking the truth: that direct talks between Israel and the Palestinians are required.\" Palestinian negotiators, however, have refused to resume direct talks until Israel ceases all settlement activity.\n\nIn November 2009, Israeli Prime Minister Netanyahu issued a 10-month settlement freeze in the West Bank in an attempt to restart negotiations with the Palestinians. The freeze did not apply to building in Jerusalem in areas across the green line, housing already under construction and existing construction described as \"essential for normal life in the settlements\" such as synagogues, schools, kindergartens and public buildings. The Palestinians refused to negotiate without a complete halt to construction. In the face of pressure from the United States and most world powers supporting the demand by the Palestinian Authority that Israel desist from settlement project in 2010, Israel's ambassador to the UN Meron Reuben said Israel would only stop settlement construction after a peace agreement is concluded, and expressed concern were Arab countries to press for UN recognition of a Palestinian state before such an accord. He cited Israel's dismantlement of settlements in both the Sinai which took place after a peace agreement, and its unilateral dismantlement of settlements in the Gaza Strip. He presumed that settlements would stop being built were Palestinians to establish a state in a given area.\n\nThe Clinton Parameters, a 2000 peace proposal by then U.S. President Bill Clinton, included a plan on which the Palestinian State was to include 94–96% of the West Bank, and around 80% of the settlers were to be under Israeli sovereignty, and in exchange for that, Israel will concede some territory (so called 'Territory Exchange' or 'Land Swap') within the Green Line (1967 borders). The swap would consist of 1–3% of Israeli territory, such that the final borders of the West Bank part of the Palestinian state would include 97% of the land of the original borders.\n\nIn 2010, Palestinian Authority President Mahmoud Abbas said that the Palestinians and Israel have agreed on the principle of a land swap. The issue of the ratio of land Israel would give to the Palestinians in exchange for keeping settlement blocs is an issue of dispute, with the Palestinians demanding that the ratio be 1:1, and Israel insisting that other factors be considered as well.\n\nUnder any peace deal with the Palestinians, Israel intends to keep the major settlement blocs close to its borders, which contain over 80% of the settlers. Prime Ministers Yitzhak Rabin, Ariel Sharon, and Benjamin Netanyahu have all stated Israel's intent to keep such blocs under any peace agreement. U.S. President George W. Bush acknowledged that such areas should be annexed to Israel in a 2004 letter to Prime Minister Sharon.\n\nThe European Union position is that any annexation of settlements should be done as part of mutually agreed land swaps, which would see the Palestinians controlling territory equivalent to the territory captured in 1967. The EU says that it will not recognise any changes to the 1967 borders without an agreement between the parties.\n\nIsraeli Foreign Minister Avigdor Lieberman has proposed a plan which would see settlement blocs annexed to Israel in exchange for heavily Arab areas inside Israel as part of a population exchange.\n\nAccording to Mitchell G. Bard: \"Ultimately, Israel may decide to unilaterally disengage from the West Bank and determine which settlements it will incorporate within the borders it delineates. Israel would prefer, however, to negotiate a peace treaty with the Palestinians that would specify which Jewish communities will remain intact within the mutually agreed border of Israel, and which will need to be evacuated. Israel will undoubtedly insist that some or all of the \"consensus\" blocs become part of Israel\".\n\nA number of proposals for the granting of Palestinian citizenship or residential permits to Jewish settlers in return for the removal of Israeli military installations from the West Bank have been fielded by such individuals as Arafat, Ibrahim Sarsur and Ahmed Qurei. In contrast, Mahmoud Abbas said in July 2013 that \"In a final resolution, we would not see the presence of a single Israeli—civilian or soldier—on our lands.\"\n\nIsraeli Minister Moshe Ya'alon said in April 2010 that \"\"just as Arabs live in Israel, so, too, should Jews be able to live in Palestine.\" ... \"If we are talking about coexistence and peace, why the [Palestinian] insistence that the territory they receive be ethnically cleansed of Jews?\"\".\n\nThe idea has been expressed by both advocates of the two-state solution and supporters of the settlers and conservative or fundamentalist currents in Israeli Judaism that, while objecting to any withdrawal, claim stronger links to the land than to the state of Israel.\n\nOn 19 June 2011, \"Haaretz\" reported that the Israeli cabinet voted to revoke Defense Minister Ehud Barak's authority to veto new settlement construction in the West Bank, by transferring this authority from the Agriculture Ministry, headed by Barak ally Orit Noked, to the Prime Minister's office.\n\nIn 2009, newly elected Prime Minister Benjamin Netanyahu said: \"I have no intention of building new settlements in the West Bank... But like all the governments there have been until now, I will have to meet the needs of natural growth in the population. I will not be able to choke the settlements.\" On 15 October 2009, he said the settlement row with the United States had been resolved.\n\nIn April 2012, four illegal outposts were retroactively legalized by the Israeli government. In June 2012, the Netanyahu government announced a plan to build 851 homes in five settlements: 300 units in Beit El and 551 units in other settlements.\n\nAmid peace negotiations that showed little signs of progress, Israel issued on 3 November 2013, tenders for 1,700 new homes for Jewish settlers. The plots were offered in nine settlements in areas Israel says it intends to keep in any peace deal with the Palestinians. On 12 November, Peace Now revealed that the Construction and Housing Ministry had issued tenders for 24,000 more settler homes in the West Bank, including 4,000 in East Jerusalem. 2,500 units were planned in Ma'aleh Adumim, some 9,000 in the Gush Etzion Region, and circa 12,000 in the Binyamin Region, including 1,200 homes in the E1 area in addition to 3,000 homes in previously frozen E1 projects. Circa 15,000 homes of the 24,000 plan would be east of the West Bank Barrier and create the first new settlement blocs for two decades, and the first blocs ever outside the Barrier, far inside the West Bank.\n\nAs stated before, the Israeli government (as of 2015) has a program of residential subsidies in which Israeli settlers receive about double that given to Israelis in Tel Aviv and Jerusalem. As well, settlers in isolated areas receive three times the Israeli national average. From the beginning of 2009 to the end of 2013, the Israeli settlement population as a whole increased by a rate of over 4% per year. A \"New York Times\" article in 2015 stated that said building had been \"at the heart of mounting European criticism of Israel.\"\n\nUnited Nations Security Council Resolution 2334 \"Requests the Secretary-General to report to the Council every three months on the implementation of the provisions of the present resolution;\"\nIn the first of these reports, delivered verbally at a security council meeting on 24 March 2017, United Nations Special Coordinator for the Middle East Peace Process, Nickolay Mladenov, noted that Resolution 2334 called on Israel to take steps to cease all settlement activity in the Occupied Palestinian Territory, that \"no such steps have been taken during the reporting period\" and that instead, there had been a marked increase in statements, announcements and decisions related to construction and expansion.\n\nThe 2017 Settlement Regularization in “Judea and Samaria” Law permits backdated legalization of outposts constructed on private Palestinian land. Its status is awaiting the result of a petition to the Israeli High Court challenging its legality. The Israeli Attorney General has stated that existing laws already allow legalization of Israeli constructions on private Palestinian land in the West Bank. The Israeli Attorney General, Avichai Mandelblit, has updated the High Court on his official approval of the use of a legal tactic permitting the de facto legalization of roughly 2,000 illegally built Israeli homes throughout the West Bank. The legal mechanism is known as \"market regulation\" and relies on the notion that wildcat Israeli homes built on private Palestinian land were done so in good faith.\n\nIn a report of 22 July 2019, PeaceNow notes that after a gap of 6 years when there were no new outposts, establishment of new outposts recommenced in 2012, with 32 of the current 126 outposts set up to date. 2 outposts were subject to eviction, 15 were legalized and at least 35 are in process of legalization.\n\nThe Israeli government announced in 2019 that it has made monetary grants available for the construction of hotels in Area C of the West Bank.\n\nAccording to Peace Now approvals for building in Israeli settlements in East Jerusalem has expanded by 60% since Trump became US president in 2017.\n\nBULLET::::- Israeli settlement timeline\nBULLET::::- Jewish land purchase in Palestine\nBULLET::::- List of Israeli settlements with city status in the West Bank\nBULLET::::- Moroccan settlers\nBULLET::::- Neo-Zionism\nBULLET::::- Palestinian Land Law\nBULLET::::- Population statistics for Israeli West Bank settlements\nBULLET::::- State of Judea\nBULLET::::- Unrecognized Bedouin villages in Israel\n\nstyle=\"text-align:right; vertical-align:top;\"i.  \nStatistics for the West Bank (\"Judea and Samaria\") from the Statistical Abstract of Israel 2013 No. 64.\nBULLET::::- 2.16 Localities and Population, by District, Sub-District, Religion and Population Group\nBULLET::::- Total population = 341,400 in 123 \"Jewish localities\"\nBULLET::::- Jews = 334,200 in 123 \"Jewish localities\"\nBULLET::::- Arabs = 0 in 0 \"Non-Jewish localities\"\n\nBULLET::::- Israeli Settlements interactive map and Israeli land use from \"The Guardian\"\nBULLET::::- Israeli Settlements. Bloomberg News\nBULLET::::- Israeli settlements: Where, when, and why they're built, Ilene R. Prusher, \"Christian Science Monitor\", 15 September 2009\nBULLET::::- Text of the Fourth 1949 Geneva Convention from icrc.org\nBULLET::::- The legal status of Israeli settlements under IHL (International Humanitarian Law), Reuters \"ReliefWeb\", 31 January 2004\nBULLET::::- The Humanitarian Impact on Palestinians of Israeli Settlements and Other Infrastructure in the West Bank from UN OCHA, Palestinian territories\nBULLET::::- Israeli Communities in Yesha & Jordan Valley\nBULLET::::- The Illegal Settlements—slideshow by \"The First Post\"\nBULLET::::- Bearing Witness, Metete Publications\n\nBULLET::::- Viewpoints and commentary\nBULLET::::- Monitoring Israeli Colonization Activities in the Palestinian Territory, The Applied Research Institute Jerusalem\nBULLET::::- Land Expropriation and Settlements from B'tselem\nBULLET::::- Israel and The Palestinian Territories, The Carter Center\nBULLET::::- Israeli Confiscation and Settlement on Palestinian Land from If Americans Knew\nBULLET::::- Myths about the settlements and A compilation of facts on the settlements, Jewish Virtual Library\nBULLET::::- Settlements and Settlements and U.S. Policy, Americans for Peace Now\nBULLET::::- Bregman, Ahron, \"Elusive Peace: How the Holy Land Defeated America\"\nBULLET::::- 'The Wye River Memorandum and Israeli Settlements\", Geoffrey Aronson, The Jerusalem Fund, 4 August 1999\nBULLET::::- For Israel, Land or Peace Jimmy Carter, The Carter Center, 26 November 2000\nBULLET::::- Backgrounder: Jewish settlements and the Media from the Committee for Accuracy in Middle East Reporting in America, 5 October 2001\nBULLET::::- From \"occupied territories\" to \"disputed territories\", Dore Gold, Jerusalem Center for Public Affairs, 16 January 2002\nBULLET::::- Ottoman Land Registration Law as a Contributing Factor in the Israeli-Arab Conflict by Rabbi Jon-Jay Tilsen, 2003\nBULLET::::- Diplomatic and Legal Aspects of the Settlement Issue from the Jerusalem Center for Public Affairs, 19 January 2003\nBULLET::::- Jewish Settlements in \"the Territories\" Aren't the Problem, Chaim Herzog, FrontPageMag.com, 9 April 2003\nBULLET::::- Occupation and Settlement: The Myth and Reality, David Meir-Levi, Think-Israel.org, 24 June 2005\nBULLET::::- \"At Israeli Outpost, Showdown Looms for Settlers, Government Gershom Gorenberg, \"Jewish Daily Forward\", 27 January 2006\nBULLET::::- Settlements 'violate Israeli law', BBC News, 21 November 2006\nBULLET::::- Backgrounder: The debate about settlements from the Committee for Accuracy in Middle East Reporting in America, 13 June 2007\nBULLET::::- \"Israel's Settlers Are Here to Stay\" op-ed by Dani Dayan in \"The New York Times\" 25 July 2012\n\nBULLET::::- 2019 amnesty 2019 Think Twice: Can companies do business with Israeli settlements in the Occupied Palestinian Territories while respecting human rights?\nBULLET::::- UNSC 2334 quarterly reports\n"}
{"id": "15125", "url": "https://en.wikipedia.org/wiki?curid=15125", "title": "Irrealism (the arts)", "text": "Irrealism (the arts)\n\nIrrealism is a term that has been used by various writers in the fields of philosophy, literature, and art to denote specific modes of unreality and/or the problems in concretely defining reality. While in philosophy the term specifically refers to a position put forward by the American philosopher Nelson Goodman, in literature and art it refers to a variety of writers and movements. If the term has nonetheless retained a certain consistency in its use across these fields and would-be movements, it perhaps reflects the word’s position in general English usage: though the standard dictionary definition of \"irreal\" gives it the same meaning as \"unreal\", \"irreal\" is very rarely used in comparison with \"unreal\". Thus, it has generally been used to describe something which, while unreal, is so in a very specific or unusual fashion, usually one emphasizing not just the \"not real,\" but some form of estrangement from our generally accepted sense of reality.\n\nIn literature, the term irrealism was first used extensively in the United States in the 1970s to describe the post-realist \"new fiction\" of writers such as Donald Barthelme or John Barth. More generally, it described the notion that all forms of writing could only \"offer particular versions of reality rather than actual descriptions of it,\" and that a story need not offer a clear resolution at its end. John Gardner, in \"The Art of Fiction\", cites in this context the work of Barthelme and its \"seemingly limitless ability to manipulate [literary] techniques as modes of apprehension [which] apprehend nothing.\" Though Barth, in a 1974 interview, stated, \"irrealism—not antirealism or unrealism, but irrealism—is all that I would confidently predict is likely to characterize the prose fiction of the 1970s,\" this did not prove to be the case. Instead writing in the United States quickly returned to its realist orthodoxy and the term irrealism fell into disuse.\n\nIn recent years, however, the term has been revived in an attempt to describe and categorize, in literary and philosophical terms, how it is that the work of an irrealist writer differs from the work of writers in other, non-realistic genres (e.g., the fantasy of J.R.R. Tolkien, the magical realism of Gabriel García Márquez) and what the significance of this difference is. This can be seen in Dean Swinford's essay \"Defining irrealism: scientific development and allegorical possibility\". Approaching the issue from a structuralist and narratological point of view, he has defined irrealism as a \"peculiar mode of postmodern allegory\" that has resulted from modernity’s fragmentation and dismantling of the well-ordered and coherent medieval system of symbol and allegory. Thus a lion, when presented in a given context in medieval literature, could only be interpreted in a single, approved way. Contemporary literary theory, however, denies the attribution of such fixed meanings. According to Swinford, this change can be attributed in part to the fact that \"science and technical culture have changed perceptions of the natural world, have significantly changed the natural world itself, thereby altering the vocabulary of symbols applicable to epistemological and allegorical attempts to understand it.\" Thus irreal works such as Italo Calvino's \"Cosmicomics\" and Jorge Luis Borges' \"Ficciones\" can be seen as an attempt to find a new allegorical language to explain our changed perceptions of the world that have been brought about by our scientific and technical culture, especially concepts such as quantum physics or the theory of relativity. \"The Irrealist work, then, operates within a given system,\" writes Swinford, \"and attests to its plausibility, despite the fact that this system, and the world it represents, is often a mutation, an aberration.\"\n\nThe online journal \"The Cafe Irreal\" , on the other hand, has defined irrealism as being a type of existentialist literature in which the means are continually and absurdly rebelling against the ends that we have determined for them. An example of this would be Franz Kafka's story \"The Metamorphosis\", in which the salesman Gregor Samsa's plans for supporting his family and rising up in rank by hard work and determination are suddenly thrown topsy-turvy by his sudden and inexplicable transformation into a man-sized insect. Such fiction is said to emphasize the fact that human consciousness, being finite in nature, can never make complete sense of, or successfully order, a universe that is infinite in its aspects and possibilities. Which is to say: as much as we might try to order our world with a certain set of norms and goals (which we consider our real world), the paradox of a finite consciousness in an infinite universe creates a zone of irreality (\"that which is beyond the real\") that offsets, opposes, or threatens the real world of the human subject. Irrealist writing often highlights this irreality, and our strange fascination with it, by combining the unease we feel because the real world doesn't conform to our desires with the narrative quality of the dream state (where reality is constantly and inexplicably being undermined); it is thus said to communicate directly, \"by feeling rather than articulation, the uncertainties inherent in human existence or, to put it another way... the irreconcilability between human aspiration and human reality.\" If the irreal story can be considered an allegory, then, it would be an allegory that is \"so many pointers to an unknown meaning,\" in which the meaning is felt more than it is articulated or systematically analyzed.\n\nVarious writers have addressed the question of Irrealism in Art. Many salient observations on Irrealism in Art are found in Nelson Goodman's \"Languages of Art\". Goodman himself produced some multimedia shows, one of which inspired by hockey and is entitled \"Hockey Seen: A Nightmare in Three Periods and Sudden Death\".\n\nGarret Rowlan, writing in \"The Cafe Irreal\", writes that the malaise present in the work of the Italian artist Giorgio de Chirico, \"which recalls Kafka, has to do with the sense of another world lurking, hovering like the long shadows that dominate de Chirico's paintings, which frequently depict a landscape at twilight's uncertain hour. Malaise and mystery are all by-products of the interaction of the real and the unreal, the rub and contact of two worlds caught on irrealism's shimmering surface.\" \n\nThe writer Dean Swinford, whose concept of irrealism was described at length in the section \"Irrealism in Literature\", wrote that the artist Remedios Varos, in her painting \"The Juggler\", \"creates a personal allegorical system which relies on the predetermined symbols of Christian and classical iconography. But these are quickly refigured into a personal system informed by the scientific and organized like a machine...in the Irreal work, allegory operates according to an altered, but constant and orderly iconographic system.\"\n\nArtist Tristan Tondino claims \"There is no specific style to Irrealist Art. It is the result of awareness that every human act is the result of the limitations of the world of the actor.\" \n\nIn Australia, the art journal \"the art life\" has recently detected the presence of a \"New Irrealism\" among the painters of that country, which is described as being an \"approach to painting that is decidedly low key, deploying its effects without histrionic showmanship, while creating an eerie other world of ghostly images and abstract washes.\" What exactly constituted the \"old\" irrealism, they do not say.\n\nIrrealist Art Edition is a publishing company created in the 90s by contemporary plastic artist Frédéric Iriarte. Together with the Estonian poet, writer and art critic Ilmar Laaban, they developed their concept of Irrealism through several essays, exhibitions, projects, manifest and a book, \"Irréalisation\". Irrealist Art Edition \n\nSome hardcore bands in Italy have claimed to be irrealist.\n\nBULLET::::- Franz Kafka\nBULLET::::- Nikolai Gogol\nBULLET::::- René Magritte\nBULLET::::- Kōbō Abe\nBULLET::::- Giorgio de Chirico\nBULLET::::- Magnus Mills\nBULLET::::- Jorge Luis Borges\nBULLET::::- Donald Barthelme\nBULLET::::- John Barth\nBULLET::::- Remedios Varo\nBULLET::::- Frédéric Iriarte\nBULLET::::- D. Harlan Wilson\nBULLET::::- Max Blecher\n\nBULLET::::- Swinford, Dean, “Defining Irrealism: Scientific Development and Allegorical Possibility,” \"Journal of the Fantastic in the Arts\", 12.1 (2001): 77-89.\nBULLET::::- Evans, G.S. and Alice Whittenburg, \"After Kafka: Kafka Criticism and Scholarship as a Resource in an Attempt to Promulgate a New Literary Genre,\" \"Journal of the Kafka Society of America\", 31/32(1+2): 18-26.\n"}
{"id": "15129", "url": "https://en.wikipedia.org/wiki?curid=15129", "title": "You have two cows", "text": "You have two cows\n\n\"You have two cows\" is a form of political satire on various political, economic, etc. systems. The setup of a typical joke of this kind \nis the assumption that you live within a given system and you have two cows. The punch line is what happens to you and the cows in this system.\n\nJokes of this type attracted the attention of a scholar in the USA as early as 1944. An article in \"The Modern Language Journal\" lists the following classical ones:\nBULLET::::- \"Socialism\": You have two cows. The government takes one and gives it to your neighbour.\nBULLET::::- \"Communism\": You have two cows. You give them to the government, and the government then gives you some milk.\nBULLET::::- \"Fascism\": You have two cows. You give them to the government, and the government then sells you some milk.\nBULLET::::- \"Capitalism\": You have two cows. You sell one and buy a bull.\nBULLET::::- \"Nazism\": You have two cows. The government takes both and shoots you.\n\nBill Sherk mentions that such lists circulated throughout the United States since around 1936 under the title \"Parable of the Isms\". A column in \"The Chicago Daily Tribune\" in 1938 attributes a version involving socialism, communism, fascism and New Dealism to an address by Silas Strawn to the Economic Club of Chicago on 29 November 1935.\n\nJokes of this genre formed the base of a monologue by comedian Pat Paulsen on \"The Smothers Brothers Comedy Hour\" in the late 1960s. Satirising the satire, he appended this comment to capitalism: \"...Then put both of them in your wife's name and declare bankruptcy.\" This material was later used as an element of his satirical US presidential campaign in 1968, and was included on his 1968 comedy album \"Pat Paulsen for President\".\n\nRichard M Steers and Luciara Nardon in their book about global economy use the \"two cows\" metaphor to illustrate the concept of cultural differences. They write that jokes of the kind:\nBULLET::::- Russian company: You have two cows. You drink some vodka and count them again. You have five cows. The Russian Mafia shows up and takes however many cows you have.\n\n– are considered funny because they are realistic caricatures of various cultures, and the pervasiveness of such jokes stems from the significant cultural differences. Steers and Nardon also state that others believe such jokes present cultural stereotypes and must be viewed with caution.\n\nBULLET::::- Spherical cow\n"}
{"id": "15134", "url": "https://en.wikipedia.org/wiki?curid=15134", "title": "Lightbulb joke", "text": "Lightbulb joke\n\nA lightbulb joke is a joke that asks how many people of a certain group are needed to change, replace, or screw in a light bulb. Generally, the punch line answer highlights a stereotype of the target group. There are numerous versions of the lightbulb joke satirizing a wide range of cultures, beliefs and occupations.\n\nEarly versions of the joke, popular in the late 1960s and the 1970s, were used to insult the intelligence of people, especially Poles (\"Polish jokes\"). For instance:\n\nAlthough lightbulb jokes tend to be derogatory in tone (\"e.g.\", \"How many drummers...\" / \"Four: one to hold the light bulb and three to drink until the room spins\"), the people targeted by them may take pride in the stereotypes expressed and are often themselves the jokes' originators, as in \"How many Germans does it take to change a lightbulb? One.\" where the joke itself becomes a statement of ethnic pride. Lightbulb jokes applied to subgroups can be used to ease tensions between them.\n\nSome versions of the joke are puns on the words \"change\" or \"screw\", or \"light\":\n\nLightbulb jokes may be responses to current events, particularly those related to energy and political power.\nFor example, the lightbulb may not need to be changed at all due to ongoing power outages.\n\"The Village Voice\" held a $200 lightbulb joke contest around the time of the Iran hostage crisis, with the winning joke being:\n\nBULLET::::- Alan Dundes (1981). \"Many Hands Make Light Work or Caught in the Act of Screwing in Light Bulbs\". In\n"}
{"id": "15144", "url": "https://en.wikipedia.org/wiki?curid=15144", "title": "International Electrotechnical Commission", "text": "International Electrotechnical Commission\n\nThe International Electrotechnical Commission (IEC; in French: \"Commission électrotechnique internationale\") is an international standards organization that prepares and publishes international standards for all electrical, electronic and related technologies – collectively known as \"electrotechnology\". IEC standards cover a vast range of technologies from power generation, transmission and distribution to home appliances and office equipment, semiconductors, fibre optics, batteries, solar energy, nanotechnology and marine energy as well as many others. The IEC also manages four global conformity assessment systems that certify whether equipment, system or components conform to its international standards.\n\nAll electrotechnologies are covered by IEC Standards, including energy production and distribution, electronics, magnetics and electromagnetics, electroacoustics, multimedia, telecommunication and medical technology, as well as associated general disciplines such as terminology and symbols, electromagnetic compatibility, measurement and performance, dependability, design and development, safety and the environment.\n\nThe first International Electrical Congress took place in 1881 at the International Exposition of Electricity, held in Paris. At that time the International System of Electrical and Magnetic Units was agreed to. \n\nThe International Electrotechnical Commission held its inaugural meeting on 26 June 1906, following discussions among the British Institution of Electrical Engineers, the American Institute of Electrical Engineers, and others, which began at the 1900 Paris International Electrical Congress, and continued with Colonel R. E. B. Crompton playing a key role. In 1906, Lord Kelvin was elected as the first President of the International Electrotechnical Commission . \n\nThe IEC was instrumental in developing and distributing standards for units of measurement, particularly the gauss, hertz, and weber. It also first proposed a system of standards, the Giorgi System, which ultimately became the SI, or Système International d’unités (in English, the International System of Units).\n\nIn 1938, it published a multilingual international vocabulary to unify terminology relating to electrical, electronic and related technologies. This effort continues, and the International Electrotechnical Vocabulary (the on-line version of which is known as the \"Electropedia\") remains an important work in the electrical and electronic industries.\n\nThe CISPR (\"Comité International Spécial des Perturbations Radioélectriques\") – in English, the International Special Committee on Radio Interference – is one of the groups founded by the IEC.\n\nCurrently, 86 countries are IEC members while another 87 participate in the Affiliate Country Programme, which is not a form of membership but is designed to help industrializing countries get involved with the IEC. Originally located in London, the Commission moved to its current headquarters in Geneva in 1948.\n\nIt has regional centres in Africa [(Nairobi, Kenya)], Asia-Pacific (Singapore), Latin America (São Paulo, Brazil) and North America (Boston, United States).\n\nToday, the IEC is the world's leading international organization in its field, and its standards are adopted as national standards by its members. The work is done by some 10,000 electrical and electronics experts from industry, government, academia, test labs and others with an interest in the subject.\n\nIEC standards have numbers in the range 60000–79999 and their titles take a form such as \"IEC 60417: Graphical symbols for use on equipment\". Following the Dresden Agreement with CENELEC the numbers of older IEC standards were converted in 1997 by adding 60000, for example IEC 27 became IEC 60027. Standards of the 60000 series are also found preceded by EN to indicate that the IEC standard is also adopted by CENELEC as a European standard; for example IEC 60034 is also available as EN 60034.\n\nThe IEC cooperates closely with the International Organization for Standardization (ISO) and the International Telecommunication Union (ITU). In addition, it works with several major standards development organizations, including the IEEE with which it signed a cooperation agreement in 2002, which was amended in 2008 to include joint development work.\n\nStandards developed jointly with ISO such as ISO/IEC 26300 (\"Open Document Format for Office Applications (OpenDocument) v1.0\"), ISO/IEC 27001 (\"Information technology, Security techniques, Information security management systems, Requirements\"), and CASCO ISO/IEC 17000 series, carry the acronym of both organizations. The use of the ISO/IEC prefix covers publications from ISO/IEC Joint Technical Committee 1 - Information Technology, as well as conformity assessment standards developed by ISO CASCO and IEC CAB (Conformity Assessment Board). Other standards developed in cooperation between IEC and ISO are assigned numbers in the 80000 series, such as IEC 82045-1.\n\nIEC standards are also being adopted by other certifying bodies such as BSI (United Kingdom), CSA (Canada), UL & ANSI/INCITS (United States), SABS (South Africa), SAI (Australia), SPC/GB (China) and DIN (Germany). IEC standards adopted by other certifying bodies may have some noted differences from the original IEC standard.\n\nThe IEC is made up of members, called national committees, and each NC represents its nation's electrotechnical interests in the IEC. This includes manufacturers, providers, distributors and vendors, consumers and users, all levels of governmental agencies, professional societies and trade associations as well as standards developers from national standards bodies. National committees are constituted in different ways. Some NCs are public sector only, some are a combination of public and private sector, and some are private sector only. About 90% of those who prepare IEC standards work in industry.\n\nIEC Member countries include:\n\nBULLET::::- Algeria\nBULLET::::- Argentina – Instituto Argentino de Normalización y Certificación (IRAM)\nBULLET::::- Australia – Standards Australia\nBULLET::::- Austria – Österreichischer Verband für Elektrotechnik (ÖVE)\nBULLET::::- Belarus\nBULLET::::- Belgium\nBULLET::::- Brazil – Comitê Brasileiro de Eletricidade, Eletrônica, Iluminação e Telecomunicações (Cobei)\nBULLET::::- Bulgaria\nBULLET::::- Canada – Standards Council of Canada\nBULLET::::- Colombia - Colombian Institute of Technical Standards and Certification\nBULLET::::- Chile\nBULLET::::- China – Standardization Administration of China (SAC)\nBULLET::::- Croatia – Hrvatski Zavod za Norme (HZN)\nBULLET::::- Czech Republic\nBULLET::::- Denmark\nBULLET::::- Egypt\nBULLET::::- Finland – SESKO\nBULLET::::- France – AFNOR\nBULLET::::- Germany – Deutsche Kommission Elektrotechnik Elektronik Informationstechnik im DIN und VDE (DKE)\nBULLET::::- Greece\nBULLET::::- Hungary\n\nBULLET::::- India – Bureau of Indian Standards (BIS)\nBULLET::::- Indonesia\nBULLET::::- Iran\nBULLET::::- Iraq\nBULLET::::- Ireland\nBULLET::::- Israel\nBULLET::::- Italy – Comitato Elettrotecnico Italiano (CEI)\nBULLET::::- Japan – Japanese Industrial Standards Committee\nBULLET::::- Libya\nBULLET::::- Luxembourg\nBULLET::::- Malaysia\nBULLET::::- Mexico\nBULLET::::- Netherlands\nBULLET::::- New Zealand\nBULLET::::- Norway\nBULLET::::- Oman\nBULLET::::- Pakistan\nBULLET::::- Perú\nBULLET::::- Philippines\nBULLET::::- Poland\nBULLET::::- Portugal\nBULLET::::- Qatar\nBULLET::::- Romania\nBULLET::::- Russia – Federal Agency for Technical Regulation and Metrology (Rostekhregulirovaniye)\n\nBULLET::::- Saudi Arabia\nBULLET::::- Serbia\nBULLET::::- Singapore\nBULLET::::- Slovakia\nBULLET::::- Slovenia\nBULLET::::- South Korea – Korean Agency for Technology and Standards (KATS)\nBULLET::::- South Africa – South African Bureau of Standards (SABS)\nBULLET::::- Spain – Asociación Española de Normalización y Certificación (AENOR)\nBULLET::::- Sweden – Swedish Electrical Standard (SEK)\nBULLET::::- Switzerland – Swiss Electrotechnical Committee (CES)\nBULLET::::- Thailand\nBULLET::::- Turkey\nBULLET::::- Ukraine\nBULLET::::- United Arab Emirates\nBULLET::::- United Kingdom – British Electrotechnical Committee (BEC), part of the British Standards Institution (BSI)\nBULLET::::- United States – American National Standards Institute (ANSI) (USNC/IEC); The National Electrical Manufacturers Association (NEMA) also helps to develop and promote IEC standards\nSource:\nBULLET::::- Albania\nBULLET::::- Bahrain\nBULLET::::- Bosnia & Herzegovina\nBULLET::::- Cuba\nBULLET::::- Cyprus\nBULLET::::- Estonia\nBULLET::::- Georgia\nBULLET::::- Iceland – Icelandic Standards (IST)\n\nBULLET::::- Jordan\nBULLET::::- Kazakhstan\nBULLET::::- Kenya\nBULLET::::- Latvia\nBULLET::::- Lithuania\nBULLET::::- North Macedonia\nBULLET::::- Malta\n\nBULLET::::- Moldova\nBULLET::::- Montenegro\nBULLET::::- Morocco – COMELEC\nBULLET::::- Nigeria\nBULLET::::- Sri Lanka\nBULLET::::- Tunisia\nBULLET::::- Vietnam – Vietnamese National Committee Directorate for Standards and Quality (STAMEQ)\nIn 2001 and in response to calls from the WTO to open itself to more developing nations, the IEC launched the Affiliate Country Programme to encourage developing nations to become involved in the Commission's work or to use its International Standards. Countries signing a pledge to participate in the work and to encourage the use of IEC Standards in national standards and regulations are granted access to a limited number of technical committee documents for the purposes of commenting. In addition, they can select a limited number of IEC Standards for their national standards' library. Countries as of 2011 participating in the Affiliate Country Programme are:\nBULLET::::- Afghanistan\nBULLET::::- Angola\nBULLET::::- Antigua and Barbuda\nBULLET::::- Armenia\nBULLET::::- Azerbaijan\nBULLET::::- Bangladesh\nBULLET::::- Barbados\nBULLET::::- Belize\nBULLET::::- Benin\nBULLET::::- Bhutan\nBULLET::::- Bolivia\nBULLET::::- Botswana\nBULLET::::- Brunei Darussalam\nBULLET::::- Burkina Faso\nBULLET::::- Burundi\nBULLET::::- Cambodia\nBULLET::::- Cameroon\nBULLET::::- Central African Republic\nBULLET::::- Chad\nBULLET::::- Comoros\nBULLET::::- Congo\nBULLET::::- Congo (Democratic Rep. of)\nBULLET::::- Costa Rica\nBULLET::::- Côte d'Ivoire\nBULLET::::- Dominica\nBULLET::::- Dominican Republic\nBULLET::::- Ecuador\nBULLET::::- El Salvador\n\nBULLET::::- Eritrea\nBULLET::::- Ethiopia\nBULLET::::- Fiji\nBULLET::::- Gabon\nBULLET::::- Gambia\nBULLET::::- Ghana\nBULLET::::- Grenada\nBULLET::::- Guatemala\nBULLET::::- Guinea\nBULLET::::- Guinea Bissau\nBULLET::::- Guyana\nBULLET::::- Haiti\nBULLET::::- Honduras\nBULLET::::- Jamaica\nBULLET::::- Kyrgyzstan\nBULLET::::- Lao Pdr\nBULLET::::- Lebanon\nBULLET::::- Lesotho\nBULLET::::- Madagascar\nBULLET::::- Malawi\nBULLET::::- Mali\nBULLET::::- Mauritania\nBULLET::::- Mauritius\nBULLET::::- Mongolia\nBULLET::::- Mozambique\n\nBULLET::::- Myanmar\nBULLET::::- Namibia\nBULLET::::- Nepal\nBULLET::::- Niger\nBULLET::::- Palestinian Authority\nBULLET::::- Panama\nBULLET::::- Papua New Guinea\nBULLET::::- Paraguay\nBULLET::::- Rwanda\nBULLET::::- Saint Lucia\nBULLET::::- Saint Vincent and the Grenadines\nBULLET::::- Senegal\nBULLET::::- Seychelles\nBULLET::::- Sierra Leone\nBULLET::::- Sudan\nBULLET::::- Suriname\nBULLET::::- Swaziland\nBULLET::::- Tanzania\nBULLET::::- Togo\nBULLET::::- Trinidad and Tobago\nBULLET::::- Turkmenistan\nBULLET::::- Uganda\nBULLET::::- Uruguay\nBULLET::::- Venezuela\nBULLET::::- Yemen\nBULLET::::- Zambia\nBULLET::::- Zimbabwe\n\nBULLET::::- International Organisation for Standardisation\nBULLET::::- List of IEC standards\nBULLET::::- List of IEC Technical Committees\n\nBULLET::::- IEC Webstore\nBULLET::::- Free online multilingual dictionary of 20 000 electrical and electronic terms\nBULLET::::- IEC System of Conformity Assessment for Electrotechnical Equipment and Components\nBULLET::::- IEC System for quality assessment of electronic components and associated materials and processes\nBULLET::::- IEC Scheme for certification to standards for electrical equipment for explosive atmospheres\nBULLET::::- IEC System for Certification to Standards Relating to Equipment for Use in Renewable Energy Applications\nBULLET::::- List of IEC Technical Committees on IEC Official Website\nBULLET::::- All IEC standards available in English and Russian (translation) languages, Standards of International Electrotechnical\n\nBULLET::::- Graphical Symbols\nBULLET::::- Hydraulic Turbines\nBULLET::::- Switchgear\nBULLET::::- Dependability\nBULLET::::- Power Systems Management\nBULLET::::- Fibre Optics\nBULLET::::- Multimedia\n\nBULLET::::- International Electrotechnical Vocabulary\nBULLET::::- IEC Glossary\nBULLET::::- IEC 60061: Lamp caps, lampholders and gauges\nBULLET::::- IEC 60417 - ISO 7000: Graphical Symbols for Use on Equipment\nBULLET::::- IEC 60617: Graphical Symbols for Diagrams\n"}
{"id": "15145", "url": "https://en.wikipedia.org/wiki?curid=15145", "title": "ISO 9660", "text": "ISO 9660\n\nISO 9660 is a file system for optical disc media. Being published by the International Organization for Standardization (ISO) the file system is considered an international technical standard. Since the specification is available for anybody to purchase, implementations have been written for many operating systems.\n\nISO 9660 traces its roots to the High Sierra Format file system. High Sierra arranged file information in a dense, sequential layout to minimize nonsequential access by using a hierarchical (eight levels of directories deep) tree file system arrangement, similar to UNIX and FAT. To facilitate cross platform compatibility, it defined a minimal set of common file attributes (directory or ordinary file and time of recording) and name attributes (name, extension, and version), and used a separate system use area where future optional extensions for each file may be specified.\n\nHigh Sierra was adopted in December 1986 (with changes) as an international standard by Ecma International as ECMA-119 and submitted for fast tracking to the ISO, where it was eventually accepted as ISO 9660:1988.\n\nIn 2013, ISO published Amendment 1 to the ISO 9660 standard, introducing new data structures and relaxed file name rules intended to \"bring harmonization between ISO 9660 and widely used 'Joliet Specification'.\" In December 2017, a 3rd Edition of ECMA-119 was published that is technically identical with ISO 9660, Amendment 1.\n\nThe following is the rough overall structure of the ISO 9660 file system:\n\n! colspan=2  ISO 9660 File System\n\nThe System Area, the first 32,768 data bytes of the disc (16 sectors of 2,048 bytes each), is unused by ISO 9660 and therefore available for other uses. For example, a CD-ROM may contain an alternative file system descriptor in this area, as it is often used by hybrid CDs to offer classic Mac OS-specific and macOS-specific content.\n\nAll multi-byte values are stored twice, in little-endian and big-endian format, either one-after-another in what the specification calls \"both-byte orders\", or in duplicated data structures such as the path table. As the structures have been designed with unaligned members, this \"both endian\" encoding does however not help implementors as the data structures need to be read byte-wise to convert them to properly aligned data.\n\nThe data area begins with a set of one or more \"volume descriptors\", terminated with a \"volume descriptor set terminator\". Collectively the \"volume descriptor set\" acts as a header for the data area, describing its content (similar to the BIOS parameter block used by FAT, HPFS and NTFS formatted disks).\n! Volume Descriptor Set\n\nThe \"volume descriptor set terminator\" is simply a particular type of \"volume descriptor\" with the purpose of marking the end of this set of structures.\n\nEach volume descriptor is 2048 bytes in size, fitting perfectly into a single Mode 1 or Mode 2 Form 1 sector. They have the following structure:\n\n! \n! colspan=4  ← 2,048 bytes →\n! Parts\n! Sizes\n\nThe data field of a volume descriptor may be subdivided into several fields, with the exact content depending on the type.\n\nStandard volume descriptor types are the following:\n\n! colspan=2  Basic Volume Descriptor Types\n! Type field value\n! Type\nEnhanced Volume Descriptor\n\nAn ISO 9660 compliant disc contains at least one \"Primary Volume Descriptor\" describing the file system and a \"Volume Descriptor Set Terminator\" for indicating the end of the descriptor sequence.\n\nThe Primary Volume Descriptor provides information about the volume, characteristics and metadata, including a root directory record that indicates in which sector the root directory is located. Other fields contain the description or name of the volume, and information about who created it and with which application. The size of the logical blocks which the file system uses to segment the volume is also stored in a field inside the primary volume descriptor, as well as the amount of space occupied by the volume (measured in number of logical blocks).\n\nIn addition to the Primary Volume Descriptor(s), \"Supplementary Volume Descriptors\" or \"Enhanced Volume Descriptors\" may be present.\n\nSupplementary Volume Descriptors describe the same volume as the Primary Volume Descriptor does, and are normally used for providing additional code page support when the standard code tables are insufficient. The standard specifies that ISO 2022 is used for managing code sets that are wider than 8 bytes, and that ISO 2375 escape sequences are used to identify each particular code page used. Consequently, ISO 9660 supports international single-byte and multi-byte character sets, provided they fit into the framework of the referenced standards. However, ISO 9660 does not specify any code pages that are guaranteed to be supported: all use of code tables other than those defined in the standard itself are subject to agreement between the originator and the recipient of the volume.\n\nEnhanced Volume Descriptors were introduced in ISO 9660, Amendment 1. They relax some of the requirements of the other volume descriptors and the directory records referenced by them: for example, the directory depth can exceed eight, file identifiers need not contain '.' or file version number, the length of a file and directory identifier is maximized to 207.\n\nRedundant copies of each volume descriptor can also be included in case the first copy of the descriptor becomes corrupt.\n\nDirectory entries are stored following the location of the root directory entry, where evaluation of filenames is begun. Both directories and files are stored as extents, which are sequential series of sectors.\n\nFiles and directories are differentiated only by a file attribute that indicates its nature (similar to Unix). The attributes of a file are stored in the directory entry that describes the file, and optionally in the extended attribute record.\n\nTo locate a file, the directory names in the file's path can be checked sequentially, going to the location of each directory to obtain the location of the subsequent subdirectory. However, a file can also be located through the path table provided by the file system. This path table stores information about each directory, its parent, and its location on disc. Since the path table is stored in a contiguous region, it can be searched much faster than jumping to the particular locations of each directory in the file's path, thus reducing seek time.\n\nThe standard specifies three nested levels of interchange (paraphrased from section 10):\nBULLET::::- Level 1: File names are limited to eight characters with a three-character extension. Directory names are limited to eight characters. Files may contain one single file section.\nBULLET::::- Level 2: Files may contain one single file section.\nBULLET::::- Level 3: No additional restrictions than those stipulated in the main body of the standard. That is, directory identifiers may not exceed 31 characters in length, and file name + '.' + file name extension may not exceed 30 characters in length (sections 7.5 and 7.6). Files are also allowed to consist of multiple non-contiguous sections (with some restrictions as to order).\n\nAdditional restrictions in the body of the standard: The depth of the directory hierarchy must not exceed 8 (root directory being at level 1), and the path length of any file must not exceed 255. (section 6.8.2.1).\n\nThe standard also specifies the following name restrictions (sections 7.5 and 7.6):\nBULLET::::- All levels restrict file names in the mandatory file hierarchy to upper case letters, digits, underscores (\"_\"), and a dot. (see also section 7.4.4 and Annex A),\nBULLET::::- If no characters are specified for the File Name then the File Name Extension shall consist of at least one character.\nBULLET::::- If no characters are specified for the File Name Extension then the File Name shall consist of at least one character.\nBULLET::::- File names shall not have more than one dot.\nBULLET::::- Directory names shall not use dots at all.\n\nPath tables summarize the directory structure of the relevant directory hierarchy, providing only the directory identifier, the location of the extent in which the directory is recorded, the length of any extended attributes associated with the directory, and the index of its parent directory path table entry.\n\nThe restrictions on filename length (8 characters plus 3 character extension for interchange level 1) and directory depth (8 levels, including the root directory) are a more serious limitation of the ISO 9660 file system.\n\nThe Rock Ridge extension works around the eight-directory depth limit by folding paths. In practice, however, few drivers and OSes care about the directory depth, so this rule is often ignored.\n\nIn addition to the restrictions mentioned above, a CD-ROM producer may choose one of the lower Levels of Interchange specified in chapter 10 of the standard, and further restrict file name length from 30 characters to only 8+3 in file identifiers, and 8 in directory identifiers in order to promote interchangeability with implementations that do not implement the full standard. (This is sometimes mistakenly interpreted as a restriction in the ISO 9660 standard itself.)\n\nAll numbers in ISO 9660 file systems except the single byte value used for the GMT offset are unsigned numbers. As the length of a file's extent on disc is stored in a 32 bit value, it allows for a maximum length of just over 4.2 GB (more precisely, one byte less than 4 GiB). (Note: Some older operating systems may handle such values incorrectly (i.e. signed instead of unsigned), which would make it impossible to access files larger than 2 GB in size. The latter holds true also for operating systems without large file support.)\n\nBased on this, it is often assumed that a file on an ISO 9660 formatted disc cannot be larger than 2-1 in size, as the file's size is stored in an unsigned 32 bit value, for which 2-1 is the maximum.\n\nIt is, however, possible to circumvent this limitation by using the multi-extent (fragmentation) feature of ISO 9660 Level 3 to create ISO 9660 file systems and single files up to 8 TiB. With this, files larger than 4 GiB can be split up into multiple extents (sequential series of sectors), each not exceeding the 4 GiB limit. For example, the free software such as InfraRecorder, ImgBurn and mkisofs as well as Roxio Toast are able to create ISO 9660 file systems that use multi-extent files to store files larger than 4 GiB on appropriate media such as recordable DVDs.\n\nEmpirical tests with a 4.2 GB fragmented file on a DVD media have shown that Microsoft Windows XP supports this, while Mac OS X (as of 10.4.8) does not handle this case properly. In the case of Mac OS X, the driver appears not to support file fragmentation at all (i.e. it only supports ISO 9660 Level 2 but not Level 3). Linux supports multiple extents.\n\nAnother limitation is the number of directories. The ISO image has a structure called \"path table\". For each directory in the image, the path table provides the number of its parent directory entry. The problem is that the parent directory number is a 16-bit number, limiting its range from 1 to 65,535. The content of each directory is written also in a different place, making the path table redundant, and suitable only for fast searching.\n\nSome operating systems (e.g. Windows) use the path table, while others (e.g. Linux) do not. If an ISO image or disc consists of more than 65,535 directories, it will be readable in Linux, while in early Windows versions all files from the additional directories will be visible, but show up as empty (zero length).\n\nSome software tools can have problems managing the path table if the directory limit is exceeded. A popular application using ISO format, \"mkisofs\", aborts if there is a path table overflow. Nero Burning ROM (for Windows) and Pinnacle Instant CD/DVD do not check whether the problem occurs, and will produce an invalid ISO file or disc without warning.\n\nThere are several extensions to ISO 9660 that relax some of its limitations. \nBULLET::::- Rock Ridge supports the preservation of POSIX (Unix-style) permissions and longer names.\nBULLET::::- Joliet supports Unicode names stored in UCS-2, thus allowing almost any character to be used, even from non-Latin scripts.\nBULLET::::- El Torito enables CDs to be bootable on PCs.\nBULLET::::- Apple ISO 9660 Extensions adds support for classic Mac OS-specific and macOS-specific file characteristics such as resource forks, file backup date and more.\n\nFor operating systems which do not support any extensions, a name translation file TRANS.TBL must be used. It should be located in every directory, including the root directory. This is now obsolete, since few such operating systems are in use today.\n\nThe ISO 13490 standard is an extension to the ISO 9660 format that adds support for multiple sessions on a disc. Since ISO 9660 is by design a read-only, pre-mastered file system, all the data has to be written in one go or \"session\" to the medium. Once written, there is no provision for altering the stored content. ISO 13490 was created to allow adding more files to a writeable disc such as CD-R in multiple sessions.\n\nThe ISO 13346/ECMA-167 standard was designed in conjunction to the ISO 13490 standard to address most of the shortcomings of ISO 9660, and a subset of it evolved into the UDF format, which was adopted for DVDs.\n\nJIS X 0606:1998, also known as ISO 9660:1999, is a Japanese Industrial Standard draft created by the Japanese National Body (JTC1 N4222) in order to make some improvements and remove some limitations from the original ISO 9660 standard. This draft was submitted in 1998, but it has not been ratified as an ISO standard yet. Some of its changes includes the removal of some restrictions imposed by the original standard by extending the maximum file name length to 207 characters, removing the eight-level maximum directory nesting limit, and removing the special meaning of the dot character in filenames. Some operating systems allow these relaxations as well when reading optical discs. Several disc authoring tools (such as Nero Burning ROM, mkisofs and ImgBurn) support a so-called \"ISO 9660:1999\" mode (sometimes called \"ISO 9660 v2\" or \"ISO 9660 Level 4\" mode) that removes restrictions following the guidelines in the ISO 9660:1999 draft.\n\nISO 9660 file system images (ISO images) are a common way to electronically transfer the contents of CD-ROMs. They often have the filename extension codice_1 (codice_2 is less common, but also in use) and are commonly referred to as \"ISOs\".\n\nMost operating systems support reading of ISO 9660 formatted discs, and most new versions support the extensions such as Rock Ridge and Joliet. Operating systems that do not support the extensions usually show the basic (non-extended) features of a plain ISO 9660 disc.\n\nOperating systems that support ISO 9660 and its extensions include the following:\nBULLET::::- DOS: access with extensions, such as MSCDEX.EXE (Microsoft CDROM Extension), NWCDEX.EXE or CORELCDX.EXE\nBULLET::::- Microsoft Windows 95, Windows 98, Windows ME: can read ISO 9660 Level 1, 2, 3, and Joliet\nBULLET::::- Microsoft Windows NT 4.0, Windows 2000, Windows XP, and newer Windows versions, can read ISO 9660 Level 1, 2, 3, Joliet, and ISO 9660:1999. Windows 7 may also mistake UDF format for CDFS. for more information see UDF.\nBULLET::::- Linux and BSD: ISO 9660 Level 1, 2, 3, Joliet, Rock Ridge, and ISO 9660:1999\nBULLET::::- Apple GS/OS: ISO Level 1 and 2 support via the HS.FST File System Translator.\nBULLET::::- Classic Mac OS 7 to 9: ISO Level 1, 2. Optional free software supports Rock Ridge and Joliet (including ISO Level 3): Joke Ridge and Joliet Volume Access.\nBULLET::::- macOS (all versions): ISO Level 1, 2, Joliet and Rock Ridge Extensions. Level 3 is not currently supported, although users have been able to mount these discs\nBULLET::::- AmigaOS supports the \"AS\" extensions (which preserve the Amiga protection bits and file comments)\nBULLET::::- QNX\nBULLET::::- ULTRIX\nBULLET::::- OS/2 and eComStation\nBULLET::::- BeOS, Zeta and Haiku\nBULLET::::- OpenVMS supports only ISO 9660 Interchange levels 1-3, with \"no\" extensions\nBULLET::::- RISC OS support for optical media written on a PC is patchy. Most CD-Rs/RWs work perfectly, however DVD+-Rs/RWs/RAMs are entirely hit and miss running RISC OS 4.02, RISC OS 4.39 and RISC OS 6.20\n\nBULLET::::- Comparison of disc image software\nBULLET::::- Disk image emulator\nBULLET::::- List of International Organization for Standardization standards\nBULLET::::- Hybrid CD\n\nBULLET::::- ISO 9660\nBULLET::::- ECMA-119 This is the ECMA release of the ISO 9660:1988 standard, available as a free download.\nBULLET::::- Summary of the ISO 9660 Specifications\nBULLET::::- Description of data structures in ISO-9660\n"}
{"id": "15146", "url": "https://en.wikipedia.org/wiki?curid=15146", "title": "Ice skating", "text": "Ice skating\n\nIce skating is the self-propulsion of a person across a sheet of ice, using metal-bladed ice skates to glide on the ice surface. This activity can be carried out for various reasons, including recreation, sport, exercise, and travel. Ice skating may be performed on specially prepared ice surfaces (arenas, tracks, parks), both indoors and outdoors, as well as on naturally occurring bodies of frozen water, such as ponds, lakes and rivers.\n\nResearch suggests that the earliest ice skating happened in southern Finland more than 4,000 years ago. This was done to save energy during winter journeys. True skating emerged when a steel blade with sharpened edges was used. Skates now cut into the ice instead of gliding on top of it. Adding edges to ice skates was invented by the Dutch in the 13th or 14th century. These ice skates were made of steel, with sharpened edges on the bottom to aid movement.\nThe fundamental construction of modern ice skates has stayed largely the same since then, although differing greatly in the details, particularly in the method of binding and the shape and construction of the steel blades. In the Netherlands, ice skating was considered proper for all classes of people, as shown in many pictures by the Old Masters.\n\nIce skating was also practiced in China during the Song dynasty, and became popular among the ruling family of the Qing dynasty.\n\nIce skating was brought to Britain from the Netherlands, where James II was briefly exiled in the 17th century. When he returned to England, this 'new' sport was introduced to the British aristocracy, and was soon enjoyed by people from all walks of life.\n\nThe first organised skating club was the Edinburgh Skating Club, formed in the 1740s, (some claim the club was established as early as 1642).\n\nAn early contemporary reference to the club appeared in the second edition (1783) of the Encyclopædia Britannica:\n\nFrom this description and others, it is apparent that the form of skating practiced by club members was indeed an early form of figure skating rather than speed skating. For admission to the club, candidates had to pass a skating test where they performed a complete circle on either foot (e.g., a figure eight), and then jumped over first one hat, then two and three, placed over each other on the ice.\nOn the Continent, participation in ice skating was limited to members of the upper classes. Emperor Rudolf II of the Holy Roman Empire enjoyed ice skating so much, he had a large ice carnival constructed in his court in order to popularise the sport. King Louis XVI of France brought ice skating to Paris during his reign. Madame de Pompadour, Napoleon I, Napoleon III and the House of Stuart were, among others, royal and upper class fans of ice skating.\nThe next skating club to be established was in London and was not founded until 1830. By the mid-19th century, ice skating was a popular pastime among the British upper and middle classes—Queen Victoria became acquainted with her future husband, Prince Albert, through a series of ice skating trips—and early attempts at the construction of artificial ice rinks were made during the \"rink mania\" of 1841–44. As the technology for the maintenance of natural ice did not exist, these early rinks used a substitute consisting of a mixture of hog's lard and various salts. An item in the 8 May 1844 issue of Littell's 'Living Age' headed the 'Glaciarium' reported that \"This establishment, which has been removed to Grafton street East' Tottenham Court Road, was opened on Monday afternoon. The area of artificial ice is extremely convenient for such as may be desirous of engaging in the graceful and manly pastime of skating\".\n\nSkating became popular as a recreation, a means of transport and spectator sport in The Fens in England for people from all walks of life. Racing was the preserve of workers, most of them agricultural labourers. It is not known when the first skating matches were held, but by the early nineteenth century racing was well established and the results of matches were reported in the press. Skating as a sport developed on the lakes of Scotland and the canals of the Netherlands. In the 13th and 14th centuries wood was substituted for bone in skate blades, and in 1572 the first iron skates were manufactured. When the waters froze, skating matches were held in towns and villages all over the Fens. In these local matches men (or sometimes women or children) would compete for prizes of money, clothing or food.\n\nThe winners of local matches were invited to take part in the grand or championship matches, in which skaters from across the Fens would compete for cash prizes in front of crowds of thousands. The championship matches took the form of a Welsh main or \"last man standing\" contest. The competitors, 16 or sometimes 32, were paired off in heats and the winner of each heat went through to the next round. A course of 660 yards was measured out on the ice, and a barrel with a flag on it placed at either end. For a one-and-a-half mile race the skaters completed two rounds of the course, with three barrel turns.\nIn the Fens skates were called pattens, fen runners, or Whittlesey runners. The footstock was made of beechwood. A screw at the back was screwed into the heel of the boot, and three small spikes at the front kept the skate steady. There were holes in the footstock for leather straps to fasten it to the foot. The metal blades were slightly higher at the back than the front. In the 1890s, fen skaters started to race in Norwegian style skates.\n\nOn Saturday 1 February 1879, a number of professional ice skaters from Cambridgeshire and Huntingdonshire met in the Guildhall, Cambridge, to set up the National Skating Association, the first national ice skating body in the world. The founding committee consisted of several landowners, a vicar, a fellow of Trinity College, a magistrate, two Members of Parliament, the mayor of Cambridge, the Lord Lieutenant of Cambridge, journalist James Drake Digby, the president of Cambridge University Skating Club, and Neville Goodman, a graduate of Peterhouse, Cambridge (and son of Potto Brown's milling partner, Joseph Goodman). The newly formed Association held their first one-and-a-half-mile British professional championship at Thorney in December 1879.\n\nThe first instructional book concerning ice skating was published in London in 1772. The book, written by a British artillery lieutenant, Robert Jones, describes basic figure skating forms such as circles and figure eights. The book was written solely for men, as women did not normally ice skate in the late 18th century. It was with the publication of this manual that ice skating split into its two main disciplines, speed skating and figure skating.\n\nThe founder of modern figure skating as it is known today was Jackson Haines, an American. He was the first skater to incorporate ballet and dance movements into his skating, as opposed to focusing on tracing patterns on the ice. Haines also invented the sit spin and developed a shorter, curved blade for figure skating that allowed for easier turns. He was also the first to wear blades that were permanently attached to the boot.\n\nThe International Skating Union was founded in 1892 as the first international ice skating organisation in Scheveningen, in the Netherlands. The Union created the first codified set of figure skating rules and governed international competition in speed and figure skating. The first Championship, known as the Championship of the Internationale Eislauf-Vereingung, was held in Saint Petersburg in 1896. The event had four competitors and was won by Gilbert Fuchs.\n\nA skate can glide over ice because there is a layer of ice molecules at the surface that are not as tightly bound as the molecules of the mass of ice beneath. These molecules are in a semiliquid state, providing lubrication. The molecules in this \"quasi-fluid\" or \"water-like\" layer are less mobile than liquid water, but are much more mobile than the molecules deeper in the ice. At about the slippery layer is one molecule thick; as the temperature increases the slippery layer becomes thicker.\n\nIt had long been believed that ice is slippery because the pressure of an object in contact with it causes a thin layer to melt. The hypothesis was that the blade of an ice skate, exerting pressure on the ice, melts a thin layer, providing lubrication between the ice and the blade. This explanation, called \"pressure melting\", originated in the 19th century. This, however, did not account for skating on ice temperatures lower than −3.5 °C, whereas skaters often skate on lower-temperature ice.\n\nIn the 20th century, an alternative explanation, called \"friction melting\", was proposed, whereby the frictional heat generated between skate and ice melts a layer of ice. This is a self-stabilizing mechanism of skating. If by a fluctuation the friction gets high the layers grows in thickness and lowers the friction and if it gets low the layer decreases in thickness and increases the friction. The friction generated in the sheared layer of water between skate and ice grows as \"√V\" with \"V\" the velocity of the skater, such that for low velocities the friction is also low.\n\nWhatever the origin of the water layer, skating is more destructive than simply gliding. A skater leaves a visible trail behind on virgin ice and skating rinks have to be regularly mopped up to improve the skating conditions. It means that the deformation caused by the skate is plastic rather than elastic. The skate ploughs through the ice in particular due to the sharp edges. Thus another component has to be added to the friction: the “ploughing friction”. The calculated frictions are of the same order as the measured frictions in real skating in a rink. The ploughing friction decreases with the velocity \"V\" , since the pressure in the water layer increases with V and lifts the skate (aquaplaning). As a result the sum of the water-layer friction and the ploughing friction only increases slightly with \"V\", making skating at high speeds (>90 km/h) possible.\n\nA person's ability to ice skate depends on the roughness of the ice, the design of the ice skate, and the skill and experience of the skater. While serious injury is rare, a number of short track speed skaters have been paralysed after a heavy fall when they collided with the boarding. A fall can be fatal if a helmet is not worn to protect against severe head trauma. Accidents are rare but there is a risk of injury from collisions, particularly during hockey games or in pair skating.\n\nA significant danger when skating outdoors on a frozen body of water, is falling through the ice into the freezing water underneath. Death can result from shock, hypothermia or drowning. It is often difficult or impossible for the skater to climb out of the water, due to the weight of their ice skates and thick winter clothing, and the ice repeatedly breaking as they struggle to get back onto the surface. Also, if the skater becomes disoriented under the water, they might not be able to find the hole in the ice through which they have fallen. Although this can prove fatal, it is also possible for the rapid cooling to produce a condition in which a person can be revived up to hours after falling into the water.\n\nA number of recreational and sporting activities take place on ice.\n\nBULLET::::- Ice hockey – fast-paced contact team sport, using a vulcanized rubber puck, usually played on a special ice hockey rink\nBULLET::::- Speed skating – competitive form of ice skating where contenders race over fixed distances, short track and long track versions\nBULLET::::- Figure skating – winter sport with four disciplines: men's singles, ladies' singles, pair skating and ice dance\nBULLET::::- Bandy – contact team sport similar to ice hockey, but using a ball instead of a puck, and played on a large ice field\nBULLET::::- Rink bandy – a form of bandy that can be played on a standard ice hockey rink\nBULLET::::- Ringette – non-contact team sport using a small rubber ring instead of a ball or puck\nBULLET::::- Tour skating – recreational long-distance skating outdoors on open areas of natural ice\nBULLET::::- Ice cross downhill – competitive extreme sport featuring downhill skating on a walled track\nBULLET::::- Barrel jumping – speed skating discipline in which skaters jump over a length of multiple barrels\nBULLET::::- Ice yachting is the sport of sailing and racing iceboats, also called ice yachts.\nBroomball and curling are also played on ice but the players are not required to wear ice skates.\n\nBULLET::::- Fen skating\nBULLET::::- Kite ice skating\nBULLET::::- Yuri on Ice\nBULLET::::- Speed skating\n\nBULLET::::- Scientific Papers\n"}
{"id": "15147", "url": "https://en.wikipedia.org/wiki?curid=15147", "title": "International Olympic Committee", "text": "International Olympic Committee\n\nThe International Olympic Committee (IOC; , CIO) is a non-governmental sports organisation based in Lausanne, Switzerland. Founded by Pierre de Coubertin and Demetrios Vikelas in 1894, it is the authority responsible for organising the modern Summer and Winter Olympic Games.\n\nThe IOC is the governing body of the National Olympic Committees (NOCs), which are the national constituents of the worldwide Olympic Movement. As of 2016, there are 206 NOCs officially recognised by the IOC. The current president of the IOC is Thomas Bach of Germany, who succeeded Jacques Rogge of Belgium in September 2013.\n\nThe IOC was created by Pierre de Coubertin, on 23 June 1894 with Demetrios Vikelas as its first president. As of April 2019, its membership consists of 95 active members, 44 honorary members, an honorary president (Jacques Rogge) and two honour members (Henry Kissinger and Youssoupha Ndiaye). The IOC is the supreme authority of the worldwide modern Olympic Movement.\n\nThe IOC organises the modern Olympic Games and Youth Olympic Games (YOG), held in summer and winter, every four years. The first Summer Olympics was held in Athens, Greece, in 1896; the first Winter Olympics was in Chamonix, France, in 1924. The first Summer YOG were in Singapore in 2010 and the first Winter YOG in Innsbruck were in 2012.\n\nUntil 1992, both Summer and Winter Olympics were held in the same year. After that year, however, the IOC shifted the Winter Olympics to the even years between Summer Games, to help space the planning of the two events from one another, and improve the financial balance of the IOC, which receives a proportionally greater income in Olympic years.\n\nIn 2009, the UN General Assembly granted the IOC Permanent Observer status. The decision enables the IOC to be directly involved in the UN Agenda and to attend UN General Assembly meetings where it can take the floor. In 1993, the General Assembly approved a Resolution to further solidify IOC–UN cooperation by reviving the Olympic Truce.\n\nDuring each proclamation at the Olympics, announcers speak in different languages: French is always spoken first, followed by an English translation, and then the dominant language of the host nation (when this is not English or French).\n\nThe IOC received approval in November 2015 to construct a new headquarters in Vidy, Lausanne. The cost of the project was estimated to stand at $156m. The IOC announced on 11 February 2019 that \"Olympic House\" would be inaugurated on 23 June 2019 to coincide with its 125th anniversary. The Olympic Museum remains in Ouchy, Lausanne.\n\nThe stated mission of the IOC is to promote the Olympics throughout the world and to lead the Olympic Movement:\n\nBULLET::::- To encourage and support the organisation, development and coordination of sport and sports competitions;\nBULLET::::- To ensure the regular celebration of the Olympic Games;\nBULLET::::- To cooperate with the competent public or private organisations and authorities in the endeavour to place sport at the service of humanity and thereby to promote peace;\nBULLET::::- To act against any form of discrimination affecting the Olympic Movement;\nBULLET::::- To encourage and support the promotion of women in sport at all levels and in all structures with a view to implementing the principle of equality of men and women;\n\n! Designation !! Name !! Country\nHonorary President Jacques Rogge  \nPresident Thomas Bach  \nrowspan=4 Vice Presidents  Juan Antonio Samaranch, Jr.  \nrowspan=10  Executive Members  Sergey Bubka  \nDirector General  Christophe De Kepper  \n\n bgcolor=\"#efefef\" align=\"center\" \n! Commission !! Chairperson !! Country\n\nThe IOC Session is the general meeting of the members of the IOC, held once a year in which each member has one vote. It is the IOC's supreme organ and its decisions are final.\n\nExtraordinary Sessions may be convened by the President or upon the written request of at least one third of the members.\n\nAmong others, the powers of the Session are:\nBULLET::::- To adopt or amend the Olympic Charter.\nBULLET::::- To elect the members of the IOC, the Honorary President and the honorary members.\nBULLET::::- To elect the President, the Vice-Presidents and all other members of the IOC Executive Board.\nBULLET::::- To elect the host city of the Olympic Games.\n\nIn addition to the Olympic medals for competitors, the IOC awards a number of other honours.\nBULLET::::- The IOC President's Trophy is the highest sports award given to athletes who have excelled in their sport and had an extraordinary career, creating a lasting impact on their sport\nBULLET::::- The Pierre de Coubertin medal is awarded to athletes who demonstrate a special spirit of sportsmanship in Olympic events\nBULLET::::- The Olympic Cup is awarded to institutions or associations with a record of merit and integrity in actively developing the Olympic Movement\nBULLET::::- The Olympic Order is awarded to individuals for exceptionally distinguished contributions to the Olympic Movement; superseded the Olympic Certificate\nBULLET::::- The Olympic Laurel is awarded to individuals for promoting education, culture, development, and peace through sport\nBULLET::::- The Olympic town status has been given to some towns that have been particularly important for the Olympic Movement\n\nFor most of its existence, the IOC was controlled by members who were selected by other members. Countries that had hosted the Games were allowed two members. When named, they did not become the representatives of their respective countries to the IOC, but rather the opposite, IOC members in their respective countries.\n\n\"\"Granted the honour of becoming a member of the International Olympic Committee and declaring myself aware of my responsibilities in such a capacity, I undertake to serve the Olympic Movement to the very best of my ability; to respect and ensure the respect of all the provisions of the Olympic Charter and the decisions of the International Olympic Committee which I consider as not the subject to appeal on my part; to comply with the code of ethics to keep myself free from any political or commercial influence and from any racial or religious consideration; to fight against all other forms of discrimination; and to promote in all circumstances the interests of the International Olympic Committee and those of the Olympic Movement.\"\"\n\nThe membership of IOC members ceases in the following circumstances:\n\nBULLET::::1. Resignation: any IOC member may cease their membership at any time by delivering a written resignation to the President.\nBULLET::::2. Non re-election: any IOC member ceases to be a member without further formality if they are not re-elected.\nBULLET::::3. Age limit: any IOC member ceases to be a member at the end of the calendar year during which they reach the age of 70 or 80. Any member who was elected before 1999 ceases to be a member at age 80 and any member who was elected after 1999 ceases to be a member at age 70.\nBULLET::::4. Failure to attend Sessions or take active part in IOC work for two consecutive years.\nBULLET::::5. Transfer of domicile or of main center of interests to a country other than the country which was theirs at the time of their election.\nBULLET::::6. Members elected as active athletes cease to be a member upon ceasing to be a member of the IOC Athletes' Commission.\nBULLET::::7. Presidents and individuals holding an executive or senior leadership position within NOCs, world or continental associations of NOCs, IFs or associations of IFs, or other organisations recognised by the IOC cease to be a member upon ceasing to exercise the function they were exercising at the time of their election.\nBULLET::::8. Expulsion: an IOC member may be expelled by decision of the Session if such member has betrayed their oath or if the Session considers that such member has neglected or knowingly jeopardised the interests of the IOC or acted in a way which is unworthy of the IOC.\n\nThere are currently 73 international sports federations (IFs) recognised by the IOC. These are:\nBULLET::::- The 29 members of Association of Summer Olympic International Federations (ASOIF)\nBULLET::::- The 7 members of Association of International Olympic Winter Sports Federations (AIOWF)\nBULLET::::- The 37 members of Association of IOC Recognised International Sports Federations (ARISF)\n\nDuring the first half of the 20th century the IOC ran on a small budget. As president of the IOC from 1952 to 1972, Avery Brundage rejected all attempts to link the Olympics with commercial interest. Brundage believed the lobby of corporate interests would unduly impact the IOC's decision-making. Brundage's resistance to this revenue stream meant the IOC left organising committees to negotiate their own sponsorship contracts and use the Olympic symbols. When Brundage retired the IOC had US$2 million in assets; eight years later the IOC coffers had swelled to US$45 million. This was primarily due to a shift in ideology toward expansion of the Games through corporate sponsorship and the sale of television rights. When Juan Antonio Samaranch was elected IOC president in 1980 his desire was to make the IOC financially independent. Samaranch appointed Canadian IOC member Richard Pound to lead the initiative as Chairman of the \"New Sources of Finance Commission\".\n\nIn 1982 the IOC drafted ISL Marketing, a Swiss sports marketing company, to develop a global marketing programme for the Olympic Movement. ISL successfully developed the programme but was replaced by Meridian Management, a company partly owned by the IOC in the early 1990s.\n\nIn 1989, one of the staff members at ISL Marketing, Michael Payne, moved to the IOC and became the organisation's first marketing director. However ISL and subsequently Meridian, continued in the established role as the IOC's sales and marketing agents until 2002. In 2002 the IOC terminated the relationship with Meridian and took its marketing programme in-house under the Direction of Timo Lumme, the IOC's managing director of IOC Television and Marketing Services. During his 17 years with the IOC, in collaboration with ISL Marketing and subsequently Meridian Management, Payne made major contributions to the creation of a multibillion-dollar sponsorship marketing programme for the organisation which, along with improvements in TV marketing and improved financial management, helped to restore the IOC's financial viability.\n\nThe Olympic Movement generates revenue through five major programmes.\n\nBULLET::::1. Broadcast partnerships, managed by the IOC.\nBULLET::::2. Commercial sponsorship, organised through the IOC's worldwide TOP programme.\nBULLET::::3. Domestic sponsorship, managed by the OCOGs.\nBULLET::::4. Ticketing.\nBULLET::::5. Licensing programmes within the host country.\n\nThe OCOGs have responsibility for the domestic sponsorship, ticketing and licensing programmes, under the direction of the IOC.\n\nThe Olympic Movement generated a total of more than US$4 billion (€2.5 billion) in revenue during the Olympic quadrennium from 2001 to 2004.\n\nBULLET::::- Revenue distribution\nThe IOC distributes some of the Olympic marketing revenue to organisations throughout the Olympic Movement to support the staging of the Olympic Games and to promote the worldwide development of sport. The IOC retains approximately 10% of the Olympic marketing revenue for the operational and administrative costs of governing the Olympic Movement.\nThe IOC provides TOP programme contributions and Olympic broadcast revenue to the OCOGs to support the staging of the Summer Olympic Games and the Winter Olympic Games:\nBULLET::::- TOP programme revenue to OCOGs: the two OCOGs of each Olympic quadrennium generally share approximately 50% of TOP programme revenue and value-in-kind contributions, with approximately 30% provided to the summer OCOG and 20% provided to the winter OCOG.\nBULLET::::- Broadcast revenue to OCOGs: the IOC contributes 49% of the Olympic broadcast revenue for each Games to the OCOG. During the 2001–2004 Olympic quadrennium, the Salt Lake 2002 Organizing Committee received US$443 million, €395 million in broadcast revenue from the IOC, and the Athens 2004 Organizing Committee received US$732 million, €690 million.\nBULLET::::- Domestic programme revenue to OCOGs: the OCOGs generate substantial revenue from the domestic marketing programmes that they manage within the host country, including domestic sponsorship, ticketing and licensing.\n\nThe NOCs receive financial support for the training and development of Olympic teams, Olympic athletes and Olympic hopefuls. The IOC distributes TOP programme revenue to each of the NOCs throughout the world. The IOC also contributes Olympic broadcast revenue to Olympic Solidarity, an IOC organisation that provides financial support to NOCs with the greatest need.\n\nThe continued success of the TOP programme and Olympic broadcast agreements has enabled the IOC to provide increased support for the NOCs with each Olympic quadrennium. The IOC provided approximately US$318.5 million to NOCs for the 2001–2004 quadrennium.\n\nThe IOC is now the largest single revenue source for the majority of IFs, with its contributions of Olympic broadcast revenue that assist the IFs in the development of their respective sports worldwide. The IOC provides financial support from Olympic broadcast revenue to the 28 IFs of Olympic summer sports and the seven IFs of Olympic winter sports after the completion of the Summer Olympics and the Winter Olympics, respectively.\n\nThe continually increasing value of Olympic broadcast partnership has enabled the IOC to deliver substantially increased financial support to the IFs with each successive Games. The seven winter sports IFs shared US$85.8 million, €75 million in Salt Lake 2002 broadcast revenue. The contribution to the 28 summer sports IFs from Athens 2004 broadcast revenue has not yet been determined, but the contribution is expected to mark a significant increase over the US$190 million, €150 million that the IOC provided to the summer IFs following Sydney 2000.\n\nThe IOC contributes Olympic marketing revenue to the programmes of various recognised international sports organisations, including the International Paralympic Committee (IPC), and the World Anti-Doping Agency (WADA).\n\nThe Olympic Partner (TOP) sponsorship programme includes the following commercial sponsors of the Olympic Games. \nBULLET::::- Airbnb\nBULLET::::- Allianz\nBULLET::::- Alibaba Group\nBULLET::::- Atos\nBULLET::::- Bridgestone\nBULLET::::- Coca-Cola\nBULLET::::- Dow Chemical Company\nBULLET::::- General Electric\nBULLET::::- Intel\nBULLET::::- Mengniu Dairy (joint partnership with Coca-Cola)\nBULLET::::- Omega SA (previously The Swatch Group, its parent company)\nBULLET::::- Panasonic\nBULLET::::- Procter & Gamble\nBULLET::::- Samsung\nBULLET::::- Toyota\nBULLET::::- Visa Inc.\n\nThe IOC recognizes that the Olympic Games demand substantial environmental resources, activities, and construction projects that could be detrimental to a host city's environment.<ref name=Jin2008</ref> In 1995, IOC President Juan Antonio Samaranch stated, \"the International Olympic Committee is resolved to ensure that the environment becomes the third dimension of the organization of the Olympic Games, the first and second being sport and culture.\" Acting on this statement, in 1996 the IOC added the \"environment\" as a third pillar to its vision for the Olympic Games. The IOC requires cities bidding to host the Olympics to provide a comprehensive strategy to protect the environment in preparation for hosting, and following the conclusion of the Games. This initiative was most notably acted upon in 2000, when the \"Green Olympics\" effort was developed by the Beijing Organizing Committee for the Beijing Olympic Games. The Beijing 2008 Summer Olympics effort to host environmentally friendly games resulted in over 160 projects meeting the goal of \"green\" games through improved air quality and water quality, implementation of sustainable energy sources, improved waste management, and environmental education. These projects included industrial plant relocation or closure, furnace replacement, introduction of new emission standards, and more strict traffic control. Most of these measures were adopted on a temporary basis, and although real improvements were realized (particularly in air quality), most of these improvements had disappeared one year following the Games. Although these improvements were short lived, IOC's inclusion of environmental policies in evaluating and selecting host cities demonstrates a corporate responsibility that may be built upon in years to come. Detailed frameworks for environmental sustainability have been released for the 2018 Winter Olympics, and 2020 Summer Olympics in PyeongChang, South Korea, and Tokyo, Japan, respectively.\n\nThe IOC has four major approaches to addressing environmental health concerns during the construction and competitions of the Olympic Games. First, the IOC Sustainability and Legacy Commission focuses on how the IOC can improve the strategies and policies associated with environmental health throughout the process of cities hosting the Olympic Games. Secondly, every candidate city must provide information to the IOC on environmental health issues like air quality and environmental impact assessments. Thirdly, every host city is given the option to declare \"pledges\" to address specific or general environmental health concerns of hosting the Olympic Game. Fourthly, the IOC has every host city collaborate with the United Nations to work towards addressing environmental health objectives. Ultimately, the IOC uses these four major approaches in an attempt to minimize the negative environmental health concerns of a host city.\n\nCities hosting the Olympic Games have two primary concerns: traffic congestion and air pollution, both of which can result in compromised air quality during and after Olympic venue construction. Research at the Beijing Olympic Games identified particulate matter – measured in terms of PM10 (the amount of aerodynamic diameter of particle≤10 μm in a given amount of air) – as a top priority that should be taken into consideration. The particulate matter in the air, along with other airborne pollutants, cause both serious health problems, such as asthma, and contribute to the deterioration of urban ecosystems. Black Carbon is released into the air from incomplete combustion of carbonaceous fluids contributing to global climate change and human health effects. The black carbon concentrations are highly impacted by the truck traffic due to the traffic congestion during the massive construction. Additionally, secondary pollutants like CO, NOx, SO2, benzene, toluene, ethylbenzene, and xylenes (BTEX) are also released during the venue construction, resulting in harmful effects to the environment.\n\nEnvironmental magnetic methods have been established as a successful way of measuring the degree of pollution in air, water and soil. Environmental magnetism is sensitive to particle size, and has proven effective even at low detection levels. For these reasons, it is becoming more widely used.\n\nVarious air quality measures are undertaken before and after the Olympic Games. Research studies demonstrate that the primary method to reduce concentrations of air pollutants is traffic control, including barring heavy vehicles from the roads. For the Beijing Olympics, vehicles not meeting the Euro 1 emission standards were also banned from the roads, and the odd-even rule was implemented in the Beijing administrative area. Additional air quality improvement measures include replacing coal with natural gas, suspending construction and/or imposing strict dust control on construction sites, closing or relocating the polluting industrial plants, building long subway lines, using cleaner fluid in power plants, and reducing the activity by some of the polluting factories. These were several air quality improvement measures implemented by the Beijing government. There, levels of primary and secondary pollutants were reduced, and good air quality was recorded during the Beijing Olympics on most of the days.\n\nSoil contamination can occur during the process of constructing the Olympic venues. In the case of the 2006 Winter Olympic Games in Torino, Italy, negative environmental impacts were observed, including impacts on soil. Before the Games, researchers studied four areas which the Games would likely affect: a floodplain, a highway, the motorway connecting the city to Lyon, France, and a landfill. They performed an extensive analysis in the types of chemicals found in the soils in these areas both before and after the Games. Their findings revealed an increase in the number of metals in the topsoils post-Games, and indicated that soil was capable, as part of an ecosystem, of negating, or \"buffering,\" the effects of many heavy metals. However, their findings also revealed that this was not the case for all metals, and that mercury, lead, and arsenic may have been transferred into the food chain on a massive scale.\nOne of the promises made to Londoners when they won the right to host the 2012 Olympic Games was that the Olympic Park would be a \"blueprint for sustainable living.\" However, residents of the allotments of Manor Road were relocated, due to the building of the Olympic stadium, and would later disagree that the Olympics had had any positive effect on their lives. Allotments, originally, were intended to provide low-income residents with a plot of land on which to grow their own food, thus receiving the dual health benefits of a supply of fresh food and outdoor work. Many of these sites were lost as a result of the Olympic venue construction, most notably the Manor Road site. Residents were promised that the allotments would be returned, and they eventually were. However, the soil quality would never be the same. Crops tended by allotment residents were the result of years of careful cultivation, and thus, those years of care and attention were destroyed by a bulldozer. Further, allotment residents were exposed to radioactive waste for five months prior to moving, during the excavation of the site for the Games. Other local residents, construction workers, and onsite archeologists faced similar exposures and risks.\nIn contrast, the Sydney Olympic Games of 2000 provided an opportunity to improve a highly contaminated area known as the Homebush Bay site. A study commissioned by the New South Wales Government Olympic Coordination Authority, which was responsible for the Games' site preparation, looked at soil contamination prior to the Games. The work assessed soils that had been previously impacted by waste and identified areas that could pose a risk to the environment. Soil metal concentrations were found to be high enough to potentially contaminate groundwater. After risk areas were identified, a remediation strategy was developed. Contaminated soil was consolidated into four containment areas within the site, which left the remaining areas available for recreational use. Also, the contained waste materials no longer posed a threat to surrounding aquifers. Sydney's winning Olympic bid provided a catalyst to undertake the \"greenest\" single urban remediation ever attempted in Australia.\n\nThe Olympic Games can affect water quality in the surrounding region in several ways, including water runoff and the transfer of polluting substances from the air to water sources through rainfall. Harmful particulates come from both natural substances (such as plant matter crushed by higher volumes of pedestrian and vehicle traffic) and man-made substances (such as exhaust from vehicles or industry). Contaminants from these two categories lead to elevated amounts of toxins in street dust. Street dust then reaches water sources through runoff, facilitating the transfer of toxins to environments and communities that rely on these water sources. For example, one method of measuring the runoff contamination of water sources involves magnetism. Magnetism measurement systems allow specialists to measure the differences in mineral magnetic parameters in samples of water, air, and vegetation. Unlike traditional methods of measuring pollutants, magnetism is relatively inexpensive, and can identify smaller particle sizes.\nAnother method used to assess the amount and effects of water pollutants is to measure the amount of PM2.5 in rainfall. Measuring PM2.5 (the amount of aerodynamic diameter of particle≤2.5 μm in a given amount of air) is a common metric for assessing air quality. Comparing PM2.5 levels between air and rainfall samples allows scientists to determine the amount of air pollution being transferred to water sources. Pollutants in rainfall quickly and directly affect pollution in groundwater sources. In 2013, researchers in Beijing found a significant relationship between the amount of PM2.5 concentrations in the air and in rainfall. Studies showed that rainfall had a significant \"washing\" effect on PM2.5 in the air, transferring a large portion of these pollutants from the air to water sources. In this way, Beijing's notorious air pollution has a direct and significant impact on rainfall, and therefore, on water resources throughout the region.\n\nPierre de Coubertin, founder of the IOC, was influenced by the ethos of the aristocracy as exemplified in the English public schools. The public schools subscribed to the belief that sport formed an important part of education and there was a prevailing concept of fairness in which practicing or training was considered cheating. As class structure evolved through the 20th century, the definition of the amateur athlete as an aristocratic gentleman became outdated. The advent of the state-sponsored \"full-time amateur athlete\" of the Eastern Bloc countries further eroded the ideology of the pure amateur, as it put the self-financed amateurs of the Western countries at a disadvantage. The Soviet Union entered teams of athletes who were all nominally students, soldiers, or working in a profession, but many of whom were in reality paid by the state to train on a full-time basis. Nevertheless, the IOC held to the traditional rules regarding amateurism.\n\nNear the end of the 1960s, the Canadian Amateur Hockey Association (CAHA) felt their amateur players could no longer be competitive against the Soviet team's full-time athletes and the other constantly improving European teams. They pushed for the ability to use players from professional leagues but met opposition from the IIHF and IOC. At the IIHF Congress in 1969, the IIHF decided to allow Canada to use nine non-NHL professional hockey players at the 1970 World Championships in Montreal and Winnipeg, Manitoba, Canada. The decision was reversed in January 1970 after Brundage said that ice hockey's status as an Olympic sport would be in jeopardy if the change was made. In response, Canada withdrew from international ice hockey competition and officials stated that they would not return until \"open competition\" was instituted.\n\nBeginning in the 1970s, amateurism requirements were gradually phased out of the Olympic Charter. After the 1988 Games, the IOC decided to make all professional athletes eligible for the Olympics, subject to the approval of the IFs.\n\nThe cities of Denver, Colorado, United States; Sion, Switzerland; Tampere, Finland; and Vancouver (with the Garibaldi mountains), Canada, made bids for the 1976 Winter Olympics.\n\nThe Games were originally awarded to Denver on 12 May 1970, but a rise in costs led to Colorado voters' rejection on 7 November 1972, by a 3 to 2 margin, of a $5 million bond issue to finance the Games with public funds.\n\nDenver officially withdrew on 15 November, and the IOC then offered the Games to Whistler, British Columbia, Canada, but they too declined, owing to a change of government following elections. Whistler would go on to be associated with neighbouring Vancouver's successful bid for the 2010 Games.\n\nSalt Lake City, Utah, a 1972 Winter Olympics final candidate who would eventually host the 2002 Winter Olympics, offered itself as a potential host after the withdrawal of Denver. The IOC, still reeling from the Denver rejection, declined the offer from Salt Lake City and, on 5 February 1973, selected Innsbruck to host the 1976 Winter Olympics, the same city that had hosted the Games twelve years earlier.\n\nA scandal broke on 10 December 1998, when Swiss IOC member Marc Hodler, head of the coordination committee overseeing the organisation of the 2002 Games, announced that several members of the IOC had taken gifts. Although nothing strictly illegal had been done, it was felt that the acceptance of the gifts was morally dubious. Soon four independent investigations were underway: by the IOC, the United States Olympic Committee (USOC), the SLOC, and the United States Department of Justice.\n\nBefore any of the investigations could even get under way, both Welch and Johnson resigned their posts as the head of the SLOC. Many others soon followed. The Department of Justice filed charges against the two: fifteen charges of bribery and fraud.\n\nAs a result of the investigation, ten members of the IOC were expelled and another ten were sanctioned. Stricter rules were adopted for future bids, and caps were put into place as to how much IOC members could accept from bid cities. Additionally, new term and age limits were put into place for IOC membership, and fifteen former Olympic athletes were added to the committee.\n\nFrom sporting and business standpoints, however, Salt Lake 2002 was one of the most successful Winter Olympiads in history; records were set in both the broadcasting and marketing programs. Over 2 billion viewers watched more than 13 billion viewer-hours. The Games were also financially successful raising more money with fewer sponsors than any prior Olympic Games, which left SLOC with a surplus of $40 million. The surplus was used to create the Utah Athletic Foundation, which maintains and operates many of the remaining Olympic venues.\n\nIn 2006, a report ordered by the Nagano region's governor said the Japanese city provided millions of dollars in an \"illegitimate and excessive level of hospitality\" to IOC members, including $4.4 million spent on entertainment alone. Earlier reports put the figure at approximately $14 million. The precise figures are unknown since Nagano, after the IOC asked that the entertainment expenditures not be made public, destroyed the financial records.\n\nInternational groups attempted to pressure the IOC to reject Beijing's bid in protest of the state of human rights in the People's Republic of China. One Chinese dissident who expressed similar sentiments was arrested and sentenced to two years in prison for calling on the IOC to do just that at the same time that IOC inspectors were touring the city. Amnesty International expressed concern in 2006 regarding the Olympic Games to be held in China in 2008, likewise expressing concerns over the human rights situation. The second principle in the Fundamental Principles of Olympism, Olympic Charter states that \"The goal of Olympism is to place sport at the service of the harmonious development of man, with a view to promoting a peaceful society concerned with the preservation of human dignity.\" Amnesty International considers the policies and practices of the People's Republic as failing to meet that principle, and urged the IOC to press China to immediately enact human rights reform.\n\nIn August 2008, the IOC issued DMCA take down notices on Tibetan Protest videos of the Beijing Olympics hosted on YouTube. YouTube and the Electronic Frontier Foundation (EFF) both pushed back against the IOC, which then withdrew their complaint.\n\nIn 2010, the IOC was nominated for the Public Eye Awards. This award seeks to present \"shame-on-you-awards to the nastiest corporate players of the year\".\n\nBefore the start of the 2012 Olympic Games, the IOC decided not to hold a minute of silence to honor the 11 Israeli Olympians who were killed 40 years prior in the Munich Massacre. Jacques Rogge, the then-IOC President, said it would be \"inappropriate\" to do so. Speaking of the decision, Israeli Olympian Shaul Ladany, who had survived the Munich Massacre, commented: \"I do not understand. I do not understand, and I do not accept it\".\n\nIn February 2013, the IOC did not include wrestling as one of its core Olympic sports for the Summer Olympic programme for the 2020 Olympics. This decision was poorly received by the sporting and wrestling community. Wrestling was still part of the programme at the 2016 Summer Olympics in Rio de Janeiro. This decision was later overturned, and wrestling will be a part of the 2020 Olympic Games in Tokyo.\n\nAs planned, the alpine ski run and luge racing area of the 2022 Beijing Winter Olympics will be built in the core area of Beijing Songshan National Reserves. A great number of valuable species such as Lonicera oblata and Cypripedium shanxiense S. C. Chen are found here and many of them can not be conserved through ex situ conservation. Many Chinese professionals of biology and environmentalists deemed that if the Olympic venues are developed in such area, the rare species and integrated ecological environment will be catastrophically collapsed. Chinese government intended to remove such area out from the range of the natural reserves and chose some other area with few rare species as the reserves. Besides, the comments regarding the strict compliance with laws and protection of Songshan National Reserves are widely deleted or restricted in China. All these actions have been criticized by some media and the professionals of biology in China.\n\nMedia attention began growing in December 2014 when German broadcaster ARD reported on state-sponsored doping in Russia, comparing it to doping in East Germany. In November 2015, the World Anti-Doping Agency (WADA) published a report and the International Association of Athletics Federations (IAAF) suspended Russia indefinitely from world track and field events. The United Kingdom Anti-Doping agency later assisted WADA with testing in Russia. In June 2016, they reported that they were unable to fully carry out their work and noted intimidation by armed Federal Security Service (FSB) agents.\nAfter a Russian former lab director made allegations about the 2014 Winter Olympics in Sochi, WADA commissioned an independent investigation led by Richard McLaren. McLaren's investigation found corroborating evidence, concluding in a report published in July 2016 that the Ministry of Sport and the FSB had operated a \"state-directed failsafe system\" using a \"disappearing positive [test] methodology\" (DPM) from \"at least late 2011 to August 2015\".\n\nIn response to these findings, WADA announced that RUSADA should be regarded as non-compliant with respect to the World Anti-Doping Code and recommended that Russia be banned from competing at the 2016 Summer Olympics. The IOC rejected the recommendation, stating that a separate decision would be made for each athlete by the relevant IF and the IOC, based on the athlete's individual circumstances. One day prior to the opening ceremony, 270 athletes were cleared to compete under the Russian flag, while 167 were removed because of doping. In contrast, the entire Kuwaiti team was banned from competing under their own flag (for a non-doping related matter).\n\nThe IOC's decision on 24 July 2016 was criticised by athletes and writers.<ref name=\"https://nationalpost.com\"></ref> It received support from the European Olympic Committees, which said that Russia was \"a valued member\". Cam Cole of Canada's \"National Post\" said that the IOC had \"caved, as it always does, defaulting to whatever compromise it could safely adopt without offending a superpower.\" Expressing disappointment, a member of the IOC Athletes' Commission, Hayley Wickenheiser, wrote, \"I ask myself if we were not dealing with Russia would this decision to ban a nation [have] been an easier one? I fear the answer is yes.\" Writing for \"Deutsche Welle\" in Germany, Olivia Gerstenberger said that Bach had \"flunked\" his first serious test, adding, \"With this decision, the credibility of the organization is shattered once more, while that of state-sponsored doping actually receives a minor boost.\" \"Bild\" (Germany) described Bach as \"Putin's poodle\". Paul Hayward, chief sports writer of \"The Daily Telegraph\" (UK), remarked, \"The white flag of capitulation flies over the International Olympic Committee. Russia's deep political reach should have told us this would happen.\n\nLeaders of thirteen national anti-doping organisations wrote that the IOC had \"violated the athletes' fundamental rights to participate in Games that meet the stringent requirements of the World Anti-Doping Code\" and \"[demonstrated that] it lacks the independence required to keep commercial and political interests from influencing the tough decisions necessary to protect clean sport.\" WADA's former chief investigation, Jack Robertson, said \"The anti-doping code is now just suggestions to follow or not\" and that \"WADA handed the IOC that excuse [not enough time before the Olympics] by sitting on the allegations for close to a year.\" McLaren was dissatisfied with the IOC's handling of his report, saying \"It was about state-sponsored doping and the mis-recording of doping results and they turned the focus into individual athletes and whether they should compete. [...] it was a complete turning upside down of what was in the report and passing over responsibility to all the different international federations.\"\n\nIn contrast to the IOC, the IPC voted unanimously to ban the entire Russian team from the 2016 Summer Paralympics, having found evidence that the DPM was also in operation at the 2014 Winter Paralympics.\n\nOn 5 December 2017, the IOC announced that the Russian Olympic Committee had been suspended effective immediately from the 2018 Winter Olympics. Athletes who had no previous drug violations and a consistent history of drug testing were to be allowed to compete under the Olympic Flag as an \"Olympic Athlete from Russia\" (OAR). Under the terms of the decree, Russian government officials were barred from the Games, and neither the country's flag nor anthem would be present. The Olympic Flag and Olympic Anthem will be used instead, and on 20 December 2017 the IOC proposed an alternate logo for the uniforms. IOC President Thomas Bach said that \"after following due process [the IOC] has issued proportional sanctions for this systematic manipulation while protecting the clean athletes.\" \"The New York Times\"' Rebecca Ruiz and Tariq Panja reported the decision was \"without precedent in Olympics history\", while Sean Ingle at \"The Guardian\" noted the IOC's view that Russian doping was an \"unprecedented attack on the integrity of the Olympic Games and sport\". Hugo Lowell at the \"i\" \"newspaper\", meanwhile, reported that the IOC nonetheless stopped short of a total ban against Russia from the Games.\n\nOn 1 February 2018, the Court of Arbitration for Sport (CAS) found that the IOC provided insufficient evidence for 28 athletes, and overturned their IOC sanctions. For 11 other athletes, the CAS decided that there was sufficient evidence to uphold their Sochi sanctions, but reduced their lifetime bans to only the 2018 Winter Olympics. The IOC said in a statement that \"the result of the CAS decision does not mean that athletes from the group of 28 will be invited to the Games. Not being sanctioned does not automatically confer the privilege of an invitation\" and that \"this [case] may have a serious impact on the future fight against doping\". The IOC found it important to note that the CAS Secretary General \"insisted that the CAS decision does not mean that these 28 athletes are innocent\" and that they would consider an appeal against the court's decision. Later that month, the Russian Olympic Committee was reinstated by the IOC, despite numerous failed drug tests by Russian athletes in the 2018 Olympics, and the Russian Anti-Doping Agency was re-certified in September, despite the Russian officials not accepting the McLaren Report.\n\nThe IOC was harshly criticized for their handling of the Russian doping scandal. After reinstating the Russian Olympic committee following the 2018 Winter Olympics, Jim Walden, attorney for Dr. Grigory Rodchenkov, who masterminded Russia's programme, called the move \"weakness in the face of evil.\" \n\nOn 1 March 2016, Owen Gibson of \"The Guardian\" reported that French financial prosecutors investigating corruption in world athletics had expanded their remit to include the bidding and voting processes for the Rio 2016 and Tokyo 2020 Olympics. The story followed an earlier report in January by Gibson, who revealed that Papa Massata Diack, the son of the then-IAAF president Lamine Diack, appeared to arrange for \"parcels\" to be delivered to six IOC members in 2008 when Qatar was bidding for the 2016 Olympic Games, though it failed to make it beyond the shortlisting stage. Qatar denied the allegations. Gibson then reported on 11 May 2016 that a €1.3m (£1m) payment from the Tokyo Olympic bid team to an account linked to Papa Diack was made during Japan's successful race to host the 2020 Games. The following day, French financial prosecutors confirmed they were investigating allegations of \"corruption and money laundering\" of more than $2m in suspicious payments made by the Tokyo 2020 Olympic bid to a secret bank account linked to Papa Diack. The string of exclusives by \"The Guardian\" prompted a response from Tsunekazu Takeda of the Tokyo 2020 bid committee on 17 May 2016, though he denied any allegations of wrongdoing, and refused to reveal details of the transfers. The controversy was reignited on 11 January 2019 after it emerged Takeda had been indicted on corruption charges in France over his role in the bid process.\n\nBULLET::::- Association of International Olympic Winter Sports Federations (AIOWF)\nBULLET::::- Association of IOC Recognised International Sports Federations (ARISF)\nBULLET::::- Association of Summer Olympic International Federations (ASOIF)\nBULLET::::- Deaflympics\nBULLET::::- International Academy of Sport Science and Technology (AISTS)\nBULLET::::- International Committee of Sports for the Deaf (ICSD)\nBULLET::::- International Paralympic Committee\nBULLET::::- SportAccord\nBULLET::::- FICTS (Fédération Internationale Cinéma Télévision Sportifs) (Organisation recognised by the IOC)\n\n\nBULLET::::- Olympics on Twitter\nBULLET::::- Overview of IOC-elections of hosting cities\n"}
{"id": "15150", "url": "https://en.wikipedia.org/wiki?curid=15150", "title": "Integrated circuit", "text": "Integrated circuit\n\nAn integrated circuit or monolithic integrated circuit (also referred to as an IC, a chip, or a microchip) is a set of electronic circuits on one small flat piece (or \"chip\") of semiconductor material that is normally silicon. The integration of large numbers of tiny MOS transistors into a small chip results in circuits that are orders of magnitude smaller, faster, and less expensive than those constructed of discrete electronic components. The IC's mass production capability, reliability, and building-block approach to circuit design has ensured the rapid adoption of standardized ICs in place of designs using discrete transistors. ICs are now used in virtually all electronic equipment and have revolutionized the world of electronics. Computers, mobile phones, and other digital home appliances are now inextricable parts of the structure of modern societies, made possible by the small size and low cost of ICs.\n\nIntegrated circuits were made practical by technological advancements in metal–oxide–silicon (MOS) semiconductor device fabrication. Since their origins in the 1960s, the size, speed, and capacity of chips have progressed enormously, driven by technical advances that fit more and more MOS transistors on chips of the same size – a modern chip may have many billions of MOS transistors in an area the size of a human fingernail. These advances, roughly following Moore's law, make computer chips of today possess millions of times the capacity and thousands of times the speed of the computer chips of the early 1970s.\n\nICs have two main advantages over discrete circuits: cost and performance. Cost is low because the chips, with all their components, are printed as a unit by photolithography rather than being constructed one transistor at a time. Furthermore, packaged ICs use much less material than discrete circuits. Performance is high because the IC's components switch quickly and consume comparatively little power because of their small size and proximity. The main disadvantage of ICs is the high cost to design them and fabricate the required photomasks. This high initial cost means ICs are only practical when high production volumes are anticipated.\n\nAn \"integrated circuit\" is defined as: A circuit in which all or some of the circuit elements are inseparably associated and electrically interconnected so that it is considered to be indivisible for the purposes of construction and commerce. Circuits meeting this definition can be constructed using many different technologies, including thin-film transistors, thick-film technologies, or hybrid integrated circuits. However, in general usage \"integrated circuit\" has come to refer to the single-piece circuit construction originally known as a \"monolithic integrated circuit\".\n\nEarly concepts of an integrated circuit go back to 1949, when German engineer Werner Jacobi (Siemens AG) filed a patent for an integrated-circuit-like semiconductor amplifying device showing five transistors on a common substrate in a 3-stage amplifier arrangement. Jacobi disclosed small and cheap hearing aids as typical industrial applications of his patent. An immediate commercial use of his patent has not been reported.\n\nThe idea of an integrated circuit was conceived by Geoffrey Dummer (1909–2002), a radar scientist working for the Royal Radar Establishment of the British Ministry of Defence. Dummer presented the idea to the public at the Symposium on Progress in Quality Electronic Components in Washington, D.C. on 7 May 1952. He gave many symposia publicly to propagate his ideas and unsuccessfully attempted to build such a circuit in 1956. Between 1953 and 1957, Sidney Darlington and Yasuro Tarui (Electrotechnical Laboratory) proposed similar chip designs where several transistors could share a common active area, but there was no electrical isolation to separate them from each other.\n\nThe monolithic integrated circuit chip was enabled by the surface passivation process, which electrically stabilized silicon surfaces via thermal oxidation, making it possible to fabricate monolithic integrated circuit chips using silicon. The surface passivation process was developed by Mohamed M. Atalla at Bell Labs in 1957. This was the basis for the planar process, developed by Jean Hoerni at Fairchild Semiconductor in early 1959, which was critical to the invention of the monolithic integrated circuit chip. A key concept behind the monolithic IC is the principle of p–n junction isolation, which allows each transistor to operate independently despite being part of the same piece of silicon. Atalla's surface passivation process isolated individual diodes and transistors, which was extended to independent transistors on a single piece of silicon by Kurt Lehovec at Sprague Electric in 1959, and then independently by Robert Noyce at Fairchild later the same year.\n\nA precursor idea to the IC was to create small ceramic substrates (so-called \"micromodules\"), each containing a single miniaturized component. Components could then be integrated and wired into a bidimensional or tridimensional compact grid. This idea, which seemed very promising in 1957, was proposed to the US Army by Jack Kilby and led to the short-lived Micromodule Program (similar to 1951's Project Tinkertoy). However, as the project was gaining momentum, Kilby came up with a new, revolutionary design: the IC.\n\nNewly employed by Texas Instruments, Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working example of an integrated circuit on 12 September 1958. In his patent application of 6 February 1959, Kilby described his new device as \"a body of semiconductor material … wherein all the components of the electronic circuit are completely integrated.\" The first customer for the new invention was the US Air Force. Kilby won the 2000 Nobel Prize in physics for his part in the invention of the integrated circuit. However, Kilby's invention was a hybrid integrated circuit (hybrid IC), rather than a monolithic integrated circuit (monolithic IC) chip. Kilby's IC had external wire connections, which made it difficult to mass-produce.\n\nHalf a year after Kilby, Robert Noyce at Fairchild Semiconductor invented the first true monolithic IC chip. It was a new variety of integrated circuit, more practical than Kilby's implementation. Noyce's design was made of silicon, whereas Kilby's chip was made of germanium. Noyce's monolithic IC put all components on a chip of silicon and connected them with copper lines. Noyce's monolithic IC was fabricated using the planar process, developed in early 1959 by his colleague Jean Hoerni. In turn, Hoerni's planar process was based on Mohamed Atalla's surface passivation process. Modern IC chips are based on Noyce's monolithic IC, rather than Kilby's hybrid IC.\n\nNearly all modern IC chips are metal–oxide–semiconductor (MOS) integrated circuits, built from MOSFETs (metal–oxide–silicon field-effect transistors). The MOSFET (also known as the MOS transistor), which was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959, made it possible to build high-density integrated circuits. Atalla first proposed the concept of the MOS integrated circuit (MOS IC) chip in 1960, noting that the MOSFET's ease of fabrication made it useful for integrated circuits. In contrast to bipolar transistors which required a number of steps for the p–n junction isolation of transistors on a chip, MOSFETs required no such steps but could be easily isolated from each other. Its advantage for integrated circuits was re-iterated by Dawon Kahng in 1961. The list of IEEE milestones includes the first integrated circuit by Kilby in 1958, Hoerni's planar process and Noyce's planar IC in 1959, and the MOSFET by Atalla and Kahng in 1959.\n\nThe earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. General Microelectronics later introduced the first commercial MOS integrated circuit in 1964, a 120-transistor shift register developed by Robert Norman. By 1964, MOS chips had reached higher transistor density and lower manufacturing costs than bipolar chips. MOS chips further increased in complexity at a rate predicted by Moore's law, leading to large-scale integration (LSI) with hundreds of transistors on a single MOS chip by the late 1960s.\n\nFollowing the development of the self-aligned gate (silicon-gate) MOSFET by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC technology with self-aligned gates, the basis of all modern CMOS integrated circuits, was developed at Fairchild Semiconductor by Federico Faggin in 1968. The application of MOS LSI chips to computing was the basis for the first microprocessors, as engineers began recognizing that a complete computer processor could be contained on a single MOS LSI chip. This led to the inventions of the microprocessor and the microcontroller by the early 1970s. During the early 1970s, MOS integrated circuit technology enabled the very large-scale integration (VLSI) of more than 10,000 transistors on a single chip.\n\nAdvances in IC technology, primarily smaller features and larger chips, have allowed the number of MOS transistors in an integrated circuit to double every two years, a trend known as Moore's law. Moore originally stated it would double every year, but he went on to change the claim to every two years in 1975. This increased capacity has been used to decrease cost and increase functionality. In general, as the feature size shrinks, almost every aspect of an IC's operation improves. The cost per transistor and the switching power consumption per transistor goes down, while the memory capacity and speed go up, through the relationships defined by Dennard scaling (MOSFET scaling). Because speed, capacity, and power consumption gains are apparent to the end user, there is fierce competition among the manufacturers to use finer geometries. Over the years, transistor sizes have decreased from 10s of microns in the early 1970s to 10 nanometers in 2017 with a corresponding million-fold increase in transistors per unit area. As of 2016, typical chip areas range from a few square millimeters to around 600 mm, with up to 25 million transistors per mm.\n\nThe expected shrinking of feature sizes and the needed progress in related areas was forecast for many years by the International Technology Roadmap for Semiconductors (ITRS). The final ITRS was issued in 2016, and it is being replaced by the International Roadmap for Devices and Systems.\n\nInitially, ICs were strictly electronic devices. The success of ICs has led to the integration of other technologies, in an attempt to obtain the same advantages of small size and low cost. These technologies include mechanical devices, optics, and sensors.\nBULLET::::- Charge-coupled devices, and the closely related active-pixel sensors, are chips that are sensitive to light. They have largely replaced photographic film in scientific, medical, and consumer applications. Billions of these devices are now produced each year for applications such as cellphones, tablets, and digital cameras. This sub-field of ICs won the Nobel Prize in 2009.\nBULLET::::- Very small mechanical devices driven by electricity can be integrated onto chips, a technology known as microelectromechanical systems. These devices were developed in the late 1980s and are used in a variety of commercial and military applications. Examples include DLP projectors, inkjet printers, and accelerometers and MEMS gyroscopes used to deploy automobile airbags.\nBULLET::::- Since the early 2000s, the integration of optical functionality (optical computing) into silicon chips has been actively pursued in both academic research and in industry resulting in the successful commercialization of silicon based integrated optical transceivers combining optical devices (modulators, detectors, routing) with CMOS based electronics. Integrated optical circuits are also being developed, using the emerging field of physics known as photonics.\nBULLET::::- Integrated circuits are also being developed for sensor applications in medical implants or other bioelectronic devices. Special sealing techniques have to be applied in such biogenic environments to avoid corrosion or biodegradation of the exposed semiconductor materials.\n, the vast majority of all transistors are MOSFETs fabricated in a single layer on one side of a chip of silicon in a flat two-dimensional planar process. Researchers have produced prototypes of several promising alternatives, such as:\nBULLET::::- various approaches to stacking several layers of transistors to make a three-dimensional integrated circuit (3DIC), such as through-silicon via, \"monolithic 3D\", stacked wire bonding, and other methodologies.\nBULLET::::- transistors built from other materials: graphene transistors, molybdenite transistors, carbon nanotube field-effect transistor, gallium nitride transistor, transistor-like nanowire electronic devices, organic field-effect transistor, etc.\nBULLET::::- fabricating transistors over the entire surface of a small sphere of silicon.\nBULLET::::- modifications to the substrate, typically to make \"flexible transistors\" for a flexible display or other flexible electronics, possibly leading to a roll-away computer.\n\nAs it becomes more difficult to manufacture ever smaller transistors, companies are using multi-chip modules, three-dimensional integrated circuits, 3D NAND, package on package, and through-silicon vias to increase performance and reducing size, without having to reduce the size of the transistors.\n\nThe cost of designing and developing a complex integrated circuit is quite high, normally in the multiple tens of millions of dollars. Therefore, it only makes economic sense to produce integrated circuit products with high production volume, so the non-recurring engineering (NRE) costs are spread across typically millions of production units.\n\nModern semiconductor chips have billions of components, and are too complex to be designed by hand. Software tools to help the designer are essential. Electronic Design Automation (EDA), also referred to as Electronic Computer-Aided Design (ECAD), is a category of software tools for designing electronic systems, including integrated circuits. The tools work together in a design flow that engineers use to design and analyze entire semiconductor chips.\n\nIntegrated circuits can be classified into analog, digital and mixed signal, consisting of both analog and digital signaling on the same IC.\n\nDigital integrated circuits can contain anywhere from one to billions of logic gates, flip-flops, multiplexers, and other circuits in a few square millimeters. The small size of these circuits allows high speed, low power dissipation, and reduced manufacturing cost compared with board-level integration. These digital ICs, typically microprocessors, DSPs, and microcontrollers, work using boolean algebra to process \"one\" and \"zero\" signals.\nAmong the most advanced integrated circuits are the microprocessors or \"cores\", which control everything from personal computers and cellular phones to digital microwave ovens. Digital memory chips and application-specific integrated circuits (ASICs) are examples of other families of integrated circuits that are important to the modern information society.\n\nIn the 1980s, programmable logic devices were developed. These devices contain circuits whose logical function and connectivity can be programmed by the user, rather than being fixed by the integrated circuit manufacturer. This allows a single chip to be programmed to implement different LSI-type functions such as logic gates, adders and registers. Programmability comes in at least four forms - devices that can be programmed only once, devices that can be erased and then re-programmed using UV light, devices that can be (re)programmed using flash memory, and field-programmable gate arrays (FPGAs) which can be programmed at any time, including during operation. Current FPGAs can (as of 2016) implement the equivalent of millions of gates and operate at frequencies up to 1 GHz.\n\nAnalog ICs, such as sensors, power management circuits, and operational amplifiers (op-amps), work by processing continuous signals. They perform analog functions such as amplification, active filtering, demodulation, and mixing. Analog ICs ease the burden on circuit designers by having expertly designed analog circuits available instead of designing and/or constructing a difficult analog circuit from scratch.\n\nICs can also combine analog and digital circuits on a single chip to create functions such as analog-to-digital converters and digital-to-analog converters. Such mixed-signal circuits offer smaller size and lower cost, but must carefully account for signal interference. Prior to the late 1990s, radios could not be fabricated in the same low-cost CMOS processes as microprocessors. But since 1998, a large number of radio chips have been developed using RF CMOS processes. Examples include Intel's DECT cordless phone, or 802.11 (Wi-Fi) chips created by Atheros and other companies.\n\nModern often further sub-categorize the huge variety of integrated circuits now available:\nBULLET::::- Digital ICs are further sub-categorized as logic ICs (such as microprocessors and microcontrollers), memory chips (such as MOS memory and floating-gate memory), interface ICs (level shifters, serializer/deserializer, etc.), power management ICs, and programmable devices.\nBULLET::::- Analog ICs are further sub-categorized as linear integrated circuits and RF circuits (radio frequency circuits).\nBULLET::::- Mixed-signal integrated circuits are further sub-categorized as data acquisition ICs (including A/D converters, D/A converters, digital potentiometers), clock/timing ICs, switched capacitor (SC) circuits, and RF CMOS circuits.\nBULLET::::- Three-dimensional integrated circuits (3D ICs) are further sub-categorized into through-silicon via (TSV) ICs and Cu-Cu connection ICs.\n\nThe semiconductors of the periodic table of the chemical elements were identified as the most likely materials for a \"solid-state vacuum tube\". Starting with copper oxide, proceeding to germanium, then silicon, the materials were systematically studied in the 1940s and 1950s. Today, monocrystalline silicon is the main substrate used for ICs although some III-V compounds of the periodic table such as gallium arsenide are used for specialized applications like LEDs, lasers, solar cells and the highest-speed integrated circuits. It took decades to perfect methods of creating crystals with minimal defects in semiconducting materials' crystal structure.\n\nSemiconductor ICs are fabricated in a planar process which includes three key process steps photolithography, deposition (such as chemical vapor deposition), and etching. The main process steps are supplemented by doping and cleaning.\n\nMono-crystal silicon wafers are used in most applications (or for special applications, other semiconductors such as gallium arsenide are used). The wafer need not be entirely silicon. Photolithography is used to mark different areas of the substrate to be doped or to have polysilicon, insulators or metal (typically aluminium or copper) tracks deposited on them. Dopants are impurities intentionally introduced to a semiconductor to modulate its electronic properties. Doping is the process of adding dopants to a semiconductor material.\nBULLET::::- Integrated circuits are composed of many overlapping layers, each defined by photolithography, and normally shown in different colors. Some layers mark where various dopants are diffused into the substrate (called diffusion layers), some define where additional ions are implanted (implant layers), some define the conductors (doped polysilicon or metal layers), and some define the connections between the conducting layers (via or contact layers). All components are constructed from a specific combination of these layers.\nBULLET::::- In a self-aligned CMOS process, a transistor is formed wherever the gate layer (polysilicon or metal) crosses a diffusion layer.\nBULLET::::- Capacitive structures, in form very much like the parallel conducting plates of a traditional electrical capacitor, are formed according to the area of the \"plates\", with insulating material between the plates. Capacitors of a wide range of sizes are common on ICs.\nBULLET::::- Meandering stripes of varying lengths are sometimes used to form on-chip resistors, though most logic circuits do not need any resistors. The ratio of the length of the resistive structure to its width, combined with its sheet resistivity, determines the resistance.\nBULLET::::- More rarely, inductive structures can be built as tiny on-chip coils, or simulated by gyrators.\n\nSince a CMOS device only draws current on the \"transition\" between logic states, CMOS devices consume much less current than bipolar junction transistor devices.\n\nA random-access memory is the most regular type of integrated circuit; the highest density devices are thus memories; but even a microprocessor will have memory on the chip. (See the regular array structure at the bottom of the first image.) Although the structures are intricate – with widths which have been shrinking for decades – the layers remain much thinner than the device widths. The layers of material are fabricated much like a photographic process, although light waves in the visible spectrum cannot be used to \"expose\" a layer of material, as they would be too large for the features. Thus photons of higher frequencies (typically ultraviolet) are used to create the patterns for each layer. Because each feature is so small, electron microscopes are essential tools for a process engineer who might be debugging a fabrication process.\n\nEach device is tested before packaging using automated test equipment (ATE), in a process known as wafer testing, or wafer probing. The wafer is then cut into rectangular blocks, each of which is called a \"die\". Each good die (plural \"dice\", \"dies\", or \"die\") is then connected into a package using aluminium (or gold) bond wires which are thermosonically bonded to \"pads\", usually found around the edge of the die. Thermosonic bonding was first introduced by A. Coucoulas which provided a reliable means of forming these vital electrical connections to the outside world. After packaging, the devices go through final testing on the same or similar ATE used during wafer probing. Industrial CT scanning can also be used. Test cost can account for over 25% of the cost of fabrication on lower-cost products, but can be negligible on low-yielding, larger, or higher-cost devices.\n\n, a fabrication facility (commonly known as a \"semiconductor fab\") can cost over US$8 billion to construct. The cost of a fabrication facility rises over time because of increased complexity of new products. This is known as Rock's law. Today, the most advanced processes employ the following techniques:\nBULLET::::- The wafers are up to 300 mm in diameter (wider than a common dinner plate).\nBULLET::::- Copper interconnects where copper wiring replaces aluminum for interconnects.\nBULLET::::- Low-κ dielectric insulators.\nBULLET::::- Silicon on insulator (SOI).\nBULLET::::- Strained silicon in a process used by IBM known as strained silicon directly on insulator (SSDOI).\nBULLET::::- Multigate devices such as tri-gate transistors being manufactured by Intel from 2011 in their 22 nm process.\n\nThe earliest integrated circuits were packaged in ceramic flat packs, which continued to be used by the military for their reliability and small size for many years. Commercial circuit packaging quickly moved to the dual in-line package (DIP), first in ceramic and later in plastic. In the 1980s pin counts of VLSI circuits exceeded the practical limit for DIP packaging, leading to pin grid array (PGA) and leadless chip carrier (LCC) packages. Surface mount packaging appeared in the early 1980s and became popular in the late 1980s, using finer lead pitch with leads formed as either gull-wing or J-lead, as exemplified by the small-outline integrated circuit (SOIC) package – a carrier which occupies an area about 30–50% less than an equivalent DIP and is typically 70% thinner. This package has \"gull wing\" leads protruding from the two long sides and a lead spacing of 0.050 inches.\n\nIn the late 1990s, plastic quad flat pack (PQFP) and thin small-outline package (TSOP) packages became the most common for high pin count devices, though PGA packages are still used for high-end microprocessors.\n\nBall grid array (BGA) packages have existed since the 1970s. Flip-chip Ball Grid Array packages, which allow for much higher pin count than other package types, were developed in the 1990s. In an FCBGA package the die is mounted upside-down (flipped) and connects to the package balls via a package substrate that is similar to a printed-circuit board rather than by wires. FCBGA packages allow an array of input-output signals (called Area-I/O) to be distributed over the entire die rather than being confined to the die periphery. BGA devices have the advantage of not needing a dedicated socket, but are much harder to replace in case of device failure.\n\nIntel transitioned away from PGA to land grid array (LGA) and BGA beginning in 2004, with the last PGA socket released in 2014 for mobile platforms. , AMD uses PGA packages on mainstream desktop processors, BGA packages on mobile processors, and high-end desktop and server microprocessors use LGA packages.\n\nElectrical signals leaving the die must pass through the material electrically connecting the die to the package, through the conductive traces (paths) in the package, through the leads connecting the package to the conductive traces on the printed circuit board. The materials and structures used in the path these electrical signals must travel have very different electrical properties, compared to those that travel to different parts of the same die. As a result, they require special design techniques to ensure the signals are not corrupted, and much more electric power than signals confined to the die itself.\n\nWhen multiple dies are put in one package, the result is a system in package, abbreviated . A multi-chip module (), is created by combining multiple dies on a small substrate often made of ceramic. The distinction between a large MCM and a small printed circuit board is sometimes fuzzy.\n\nPackaged integrated circuits are usually large enough to include identifying information. Four common sections are the manufacturer's name or logo, the part number, a part production batch number and serial number, and a four-digit date-code to identify when the chip was manufactured. Extremely small surface-mount technology parts often bear only a number used in a manufacturer's lookup table to find the integrated circuit's characteristics.\n\nThe manufacturing date is commonly represented as a two-digit year followed by a two-digit week code, such that a part bearing the code 8341 was manufactured in week 41 of 1983, or approximately in October 1983.\n\nThe possibility of copying by photographing each layer of an integrated circuit and preparing photomasks for its production on the basis of the photographs obtained is a reason for the introduction of legislation for the protection of layout-designs. The Semiconductor Chip Protection Act of 1984 established intellectual property protection for photomasks used to produce integrated circuits.\n\nA diplomatic conference was held at Washington, D.C., in 1989, which adopted a Treaty on Intellectual Property in Respect of Integrated Circuits (IPIC Treaty).\n\nThe Treaty on Intellectual Property in respect of Integrated Circuits, also called Washington Treaty or IPIC Treaty (signed at Washington on 26 May 1989) is currently not in force, but was partially integrated into the TRIPS agreement.\n\nNational laws protecting IC layout designs have been adopted in a number of countries, including Japan, the EC, the UK, Australia, and Korea. The UK enacted the Copyright, Designs and Patents Act, 1988, c. 48, § 213, after it initially took the position that its copyright law fully protected chip topographies. See British Leyland Motor Corp. v. Armstrong Patents Co.\n\nCriticisms of inadequacy of the UK copyright approach as perceived by the US chip industry are summarized in Further chip rights developments.\n\nAustralia passed the Circuit Layouts Act of 1989 as a \"sui generis\" form of chip protection. Korea passed the \"Act Concerning the Layout-Design of Semiconductor Integrated Circuits\"</ref>\n\nFuture developments seem to follow the multi-core multi-microprocessor paradigm, already used by Intel and AMD multi-core processors. Rapport Inc. and IBM started shipping the KC256 in 2006, a 256-core microprocessor. Intel, as recently as February–August 2011, unveiled a prototype, \"not for commercial sale\" chip that bears 80 cores. Each core is capable of handling its own task independently of the others. This is in response to heat-versus-speed limit, that is about to be reached using existing transistor technology (see: thermal design power). This design provides a new challenge to chip programming. Parallel programming languages such as the open-source X10 programming language are designed to assist with this task.\n\nIn the early days of simple integrated circuits, the technology's large scale limited each chip to only a few transistors, and the low degree of integration meant the design process was relatively simple. Manufacturing yields were also quite low by today's standards. As the technology progressed, millions, then billions of transistors could be placed on one chip, and good designs required thorough planning, giving rise to the field of electronic design automation, or EDA.\n\n! Name !! Signification !! Year !! Transistors number !! Logic gates number\n\nThe first integrated circuits contained only a few transistors. Early digital circuits containing tens of transistors provided a few logic gates, and early linear ICs such as the Plessey SL201 or the Philips TAA320 had as few as two transistors. The number of transistors in an integrated circuit has increased dramatically since then. The term \"large scale integration\" (LSI) was first used by IBM scientist Rolf Landauer when describing the theoretical concept; that term gave rise to the terms \"small-scale integration\" (SSI), \"medium-scale integration\" (MSI), \"very-large-scale integration\" (VLSI), and \"ultra-large-scale integration\" (ULSI). The early integrated circuits were SSI.\n\nSSI circuits were crucial to early aerospace projects, and aerospace projects helped inspire development of the technology. Both the Minuteman missile and Apollo program needed lightweight digital computers for their inertial guidance systems. Although the Apollo guidance computer led and motivated integrated-circuit technology, it was the Minuteman missile that forced it into mass-production. The Minuteman missile program and various other United States Navy programs accounted for the total $4 million integrated circuit market in 1962, and by 1968, U.S. Government spending on space and defense still accounted for 37% of the $312 million total production.\n\nThe demand by the U.S. Government supported the nascent integrated circuit market until costs fell enough to allow IC firms to penetrate the industrial market and eventually the consumer market. The average price per integrated circuit dropped from $50.00 in 1962 to $2.33 in 1968. Integrated circuits began to appear in consumer products by the turn of the 1970s decade. A typical application was FM inter-carrier sound processing in television receivers.\n\nThe first application MOS chips were small-scale integration (SSI) chips. Following Mohamed M. Atalla's proposal of the MOS integrated circuit chip in 1960, the earliest experimental MOS chip to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. The first practical application of MOS SSI chips was for NASA satellites.\n\nThe next step in the development of integrated circuits introduced devices which contained hundreds of transistors on each chip, called \"medium-scale integration\" (MSI).\n\nMOSFET scaling technology made it possible to build high-density chips. By 1964, MOS chips had reached higher transistor density and lower manufacturing costs than bipolar chips.\n\nIn 1964, Frank Wanlass demonstrated a single-chip 16-bit shift register he designed, with a then-incredible 120 MOS transistors on a single chip. The same year, General Microelectronics introduced the first commercial MOS integrated circuit chip, consisting of 120 p-channel MOS transistors. It was a 20-bit shift register, developed by Robert Norman and Frank Wanlass. MOS chips further increased in complexity at a rate predicted by Moore's law, leading to chips with hundreds of MOSFETs on a chip by the late 1960s.\n\nFurther development, driven by the same MOSFET scaling technology and economic factors, led to \"large-scale integration\" (LSI) by the mid-1970s, with tens of thousands of transistors per chip.\n\nThe masks used to process and manufacture SSI, MSI and early LSI and VLSI devices (such as the microprocessors of the early 1970s) were mostly created by hand, often using Rubylith-tape or similar. For large or complex ICs (such as memories or processors), this was often done by specially hired professionals in charge of circuit layout, placed under the supervision of a team of engineers, who would also, along with the circuit designers, inspect and verify the correctness and completeness of each mask.\n\nIntegrated circuits such as 1K-bit RAMs, calculator chips, and the first microprocessors, that began to be manufactured in moderate quantities in the early 1970s, had under 4,000 transistors. True LSI circuits, approaching 10,000 transistors, began to be produced around 1974, for computer main memories and second-generation microprocessors.\n\nSome SSI and MSI chips, like discrete transistors, are still mass-produced, both to maintain old equipment and build new devices that require only a few gates. The 7400 series of TTL chips, for example, has become a de facto standard and remains in production.\n\nThe final step in the development process, starting in the 1980s and continuing through the present, is \"very-large-scale integration\" (VLSI). The development started with hundreds of thousands of transistors in the early 1980s, , transistor counts continue to grow beyond ten billion transistors per chip.\n\nMultiple developments were required to achieve this increased density. Manufacturers moved to smaller MOSFET design rules and cleaner fabrication facilities so that they could make chips with more transistors and maintain adequate yield. The path of process improvements was summarized by the International Technology Roadmap for Semiconductors (ITRS), which has since been succeeded by the International Roadmap for Devices and Systems (IRDS). Electronic design tools improved enough to make it practical to finish these designs in a reasonable time. The more energy-efficient CMOS replaced NMOS and PMOS, avoiding a prohibitive increase in power consumption. Modern VLSI devices contain so many transistors, layers, interconnections, and other features that it is no longer feasible to check the masks or do the original design by hand. Instead, engineers use tools to perform most functional verification work.\n\nIn 1986 the first one-megabit random-access memory (RAM) chips were introduced, containing more than one million transistors. Microprocessor chips passed the million-transistor mark in 1989 and the billion-transistor mark in 2005. The trend continues largely unabated, with chips introduced in 2007 containing tens of billions of memory transistors.\n\nTo reflect further growth of the complexity, the term \"ULSI\" that stands for \"ultra-large-scale integration\" was proposed for chips of more than 1 million transistors.\n\nWafer-scale integration (WSI) is a means of building very large integrated circuits that uses an entire silicon wafer to produce a single \"super-chip\". Through a combination of large size and reduced packaging, WSI could lead to dramatically reduced costs for some systems, notably massively parallel supercomputers. The name is taken from the term Very-Large-Scale Integration, the current state of the art when WSI was being developed.\n\nA system-on-a-chip (SoC or SOC) is an integrated circuit in which all the components needed for a computer or other system are included on a single chip. The design of such a device can be complex and costly, and whilst performance benefits can be had from integrating all needed components on one die, the cost of licensing and developing a one-die machine still outweigh having separate devices. With appropriate licensing, these drawbacks are offset by lower manufacturing and assembly costs and by a greatly reduced power budget: because signals among the components are kept on-die, much less power is required (see Packaging). Further, signal sources and destinations are physically closer on die, reducing the length of wiring and therefore latency, transmission power costs and waste heat from communication between modules on the same chip. This has led to an exploration of so-called Network-on-Chip (NoC) devices, which apply system-on-chip design methodologies to digital communication networks as opposed to traditional bus architectures.\n\nA three-dimensional integrated circuit (3D-IC) has two or more layers of active electronic components that are integrated both vertically and horizontally into a single circuit. Communication between layers uses on-die signaling, so power consumption is much lower than in equivalent separate circuits. Judicious use of short vertical wires can substantially reduce overall wire length for faster operation.\n\nTo allow identification during production most silicon chips will have a serial number in one corner. It is also common to add the manufacturer's logo. Ever since ICs were created, some chip designers have used the silicon surface area for surreptitious, non-functional images or words. These are sometimes referred to as chip art, silicon art, silicon graffiti or silicon doodling.\n\nBULLET::::- The 555 timer IC\nBULLET::::- The 741 operational amplifier\nBULLET::::- 7400 series TTL logic building blocks\nBULLET::::- 4000 series, the CMOS counterpart to the 7400 series (see also: 74HC00 series)\nBULLET::::- Intel 4004, generally regarded as the first commercially available microprocessor, which led to the famous 8080 CPU and then the IBM PC's 8088, 80286, 486 etc.\nBULLET::::- The MOS Technology 6502 and Zilog Z80 microprocessors, used in many home computers of the early 1980s\nBULLET::::- The Motorola 6800 series of computer-related chips, leading to the 68000 and 88000 series (used in some Apple computers and in the 1980s Commodore Amiga series)\nBULLET::::- The LM-series of analog integrated circuits\n\nBULLET::::- Integrated injection logic\nBULLET::::- Ion implantation\nBULLET::::- Monolithic microwave integrated circuit\nBULLET::::- Multi-threshold CMOS\nBULLET::::- Silicon-germanium\nBULLET::::- Sound chip\nBULLET::::- SPICE\nBULLET::::- Chip carrier\n\n\nGeneral\nBULLET::::- The first monolithic integrated circuits\nBULLET::::- A large chart listing ICs by generic number including access to most of the datasheets for the parts.\nBULLET::::- The History of the Integrated Circuit at \"Nobelprize.org\"\n\nPatents\nBULLET::::- – Miniaturized electronic circuit – J.S. Kilby\nBULLET::::- – Integrated semiconductor circuit device – R.F. Stewart\nBULLET::::- – Method of making miniaturized electronic circuits – J.S. Kilby\nBULLET::::- – Capacitor for miniaturized electronic circuits or the like – J. . Kilby\n\nIntegrated circuit die manufacturing\nBULLET::::- IC Die Photography – A gallery of IC die photographs\nBULLET::::- Zeptobars – Yet another gallery of IC die photographs\n"}
{"id": "15154", "url": "https://en.wikipedia.org/wiki?curid=15154", "title": "IBM 3270", "text": "IBM 3270\n\nThe IBM 3270 is a class of block oriented computer terminals (sometimes called \"display devices\") introduced by IBM in 1971 normally used to communicate with IBM mainframes. The 3270 was the successor to the IBM 2260 display terminal. Due to the text colour on the original models, these terminals are informally known as \"green screen\" terminals. Unlike a character-oriented terminal, the 3270 minimizes the number of I/O interrupts required by transferring large blocks of data known as data streams, and uses a high speed proprietary communications interface, using coaxial cable.\n\nIBM no longer manufactures 3270 terminals, but the IBM 3270 protocol is still commonly used via 3270 terminal emulation or web interfaces to access mainframe-based applications, which are sometimes referred to as \"green screen applications\". \n\nThe 3270 series was designed to connect with mainframe computers, often at a remote location, using the technology then available in the early 1970s. The main goal of the system was to maximize the number of terminals that could be used on a single mainframe. To do this, the 3270 was designed to minimize the amount of data transmitted, and minimize the frequency of interrupts to the mainframe. By ensuring the CPU is not interrupted at every keystroke, a 1970s-era IBM 3033 mainframe fitted with only 16 MB of main memory was able to support up to 17,500 3270 terminals under CICS.\n3270 devices are \"clustered\", with one or more displays or printers connected to a \"control unit\" (the 3275 and 3276 included an integrated control unit). Originally devices were connected to the control unit over coaxial cable; later token ring, twisted pair, or Ethernet connections were available. A \"local\" control unit attaches directly to the channel of a nearby mainframe. A \"remote\" control unit is connected to a communications line by a modem. Remote 3270 controllers are frequently \"multi-dropped\", with multiple control units on a line.\n\nIn a data stream, both text and control (or formatting functions) are interspersed allowing an entire screen to be \"painted\" as a single output operation. The concept of formatting in these devices allows the screen to be divided into fields (clusters of contiguous character cells) for which numerous field attributes (colour, highlighting, character set, protection from modification) can be set. A field attribute occupies a physical location on the screen that also determines the beginning and end of a field.\n\nUsing a technique known as \"read modified\", a single transmission back to the mainframe can contain the changes from any number of formatted fields that have been modified, but without sending any unmodified fields or static data. This technique enhances the terminal throughput of the CPU, and minimizes the data transmitted. Some users familiar with character interrupt-driven terminal interfaces find this technique unusual. There is also a \"read buffer\" capability that transfers the entire content of the 3270-screen buffer including field attributes. This is mainly used for debugging purposes to preserve the application program screen contents while replacing it, temporarily, with debugging information.\n\nEarly 3270s offered three types of keyboards. The \"typewriter keyboard\" came in both a 66 key version, with no programmed function (PF) keys, and a 78 key version with twelve. Both versions had two \"program attention\" (PA) keys. The \"data entry keyboard\" had five PF keys and two PA keys. The \"operator console keyboard\" had twelve PF keys and two PA keys. Later 3270s had twenty-four PF keys and three PA keys. When one of these keys is pressed, it will cause its control unit to generate an I/O interrupt to the host computer and present a special code identifying which key was pressed. Application program functions such as termination, page-up, page-down, or help can be invoked by a single key press, thereby reducing the load on very busy processors.\n\nA downside to this approach was that vi-like behaviour, responding to individual keystrokes, was not possible. For the same reason, a porting of Lotus 1-2-3 to mainframes with 3279 screens did not meet with success because its programmers were not able to properly adapt the spreadsheet's user interface to a \"screen at a time\" rather than \"character at a time\" device. But end-user responsiveness was arguably more predictable with 3270, something users appreciated.\n\nFollowing its introduction the 3270 and compatibles were by far the most commonly used terminals on IBM System/370 and successor systems. IBM and third-party software that included an interactive component took for granted the presence of 3270 terminals and provided a set of ISPF panels and supporting programs.\n\nConversational Monitor System (CMS) in VM/SP has support for the 3270.\n\nTime Sharing Option (TSO) in OS/360 and successors has line mode command line support and also has facilities for full screen applications, e.g., ISPF.\n\nDevice independent Display Operator Console Support (DIDOCS) in Multiple Console Support (MCS) for OS/360 and successors.\n\nThe SPF and \"Program Development Facility\" (ISPF/PDF) editors for MVS and VM/SP (ISPF/PDF was available for VM, but little used) and XEDIT editors for VM/SP respectively make extensive use of 3270 features. \n\nCustomer Information Control System (CICS) has support for 3270 panels.\n\nVarious versions of Wylbur have support for 3270, including support for full-screen applications.\nThe modified data tag is well suited to converting formatted, structured punched card input onto the 3270 display device. With the appropriate programming, any batch program that uses formatted, structured card input can be layered onto a 3270 terminal.\n\nIBM's OfficeVision office productivity software enjoyed great success with 3270 interaction because of its design understanding. And for many years the PROFS calendar was the most commonly displayed screen on office terminals around the world.\n\nA version of the WordPerfect word processor ported to System/370 was designed for the 3270 architecture.\n\n3270 and The Web (and HTTP) are similar in that both follow a thin client client-server architecture whereby they, the clients, are given primary responsibility for managing presentation and user input. This minimizes host interactions while still facilitating server-based information retrieval and processing.\n\nWith the arrival of the web, application development has in many ways returned to the 3270 approach. In the 3270 era, all application functionality was provided centrally. With the advent of the PC, the idea was to invoke central systems only when absolutely unavoidable, and to do all application processing with local software on the personal computer. Now in the web era (and with wikis in particular), the application again is strongly centrally controlled, with only technical functionality distributed to the PC.\n\nIn the early 1990s a popular solution to link PCs with the mainframes was the Irma board, an expansion card that plugged into a PC and connected to the controller through a coaxial cable. IRMA also allows file transfers between the PC and the mainframe.\n\nOne of the first groups to write and provide operating system support for the 3270 and its early predecessors was the University of Michigan, who created the Michigan Terminal System in order for the hardware to be useful outside of the manufacturer. MTS was the default OS at Michigan for many years, and was still used at Michigan well into the 1990s.\nMany manufacturers, such as GTE, Hewlett Packard, Honeywell/Incoterm Div, Memorex, ITT Courier and Teletype/AT&T created 3270 compatible terminals, or adapted ASCII terminals such as the HP 2640 series to have a similar block-mode capability that would transmit a screen at a time, with some form validation capability. Modern applications are sometimes built upon legacy 3270 applications, using software utilities to capture (screen scraping) screens and transfer the data to web pages or GUI interfaces.\n\nThe IBM 3270 display terminal subsystem consists of displays, printers and controllers.\nOptional features for the 3275 and 3277 are the \"selector-pen\" or light pen, ASCII rather than EBCDIC character set, an audible alarm, and a keylock for the keyboard. A \"keyboard numeric lock\" was available and will lock the keyboard if the operator attempts to enter non-numeric data into a field defined as numeric. Later an \"Operator Identification Card Reader\" was added which could read information encoded on a magnetic stripe card.\n\nGenerally, 3277 models allow only upper-case input, except for the mixed EBCDIC/APL or \"text\" keyboards, which have lower case. Lower-case capability and possibility of dead keys, at first a simple RPQ (\"Request Price Quotation\", tailored on request at extra cost) were only added in 3278 & 3279 models.\n\nA version of the IBM PC called the 3270 PC, released in October 1983, includes 3270 terminal emulation. Later, the 3270 PC/G (graphics) and 3270 PC/GX (extended graphics) followed.\n\nBULLET::::- 3277 model 1: 40×12 terminal\nBULLET::::- 3277 model 2: 80×24 terminal, the biggest success of all\nBULLET::::- 3277 GA: a 3277 with an RS232C I/O, often used to drive a Tektronix 4013 or 4015 graphic screen (monochrome)\n\nBULLET::::- 3278 models 1–5: next-generation, with accented characters and dead keys in countries that needed them\nBULLET::::- model 1: 80x12\nBULLET::::- model 2: 80×24\nBULLET::::- model 3: 80×32 or 80x24 (switchable)\nBULLET::::- model 4: 80×43 or 80x24 (switchable)\nBULLET::::- model 5: 132×27 or 80×24 (switchable)\nBULLET::::- 3278 PS: programmable characters; able to display monochrome graphics\n\nThe IBM 3279 was IBM's first colour terminal. Two versions existed:\nBULLET::::- 4-colour (text) and\nBULLET::::- 7-colour (graphics).\n\nThe 3279 was introduced in 1979. The 3279 was widely used as an IBM mainframe terminal before PCs became commonly used for the purpose. It was part of the 3270 series, using the 3270 data stream. from IBM. Terminals could be connected to a 3274 controller, either channel connected to an IBM mainframe or linked via an SDLC (Synchronous Data Link Control) link. In the Systems Network Architecture (SNA) protocol these terminals were logical unit type 2 (LU2). The basic model 2 used red, green for input fields, and blue and white for output fields. However, there were other models with seven colours and different screen sizes, and one kind had a loadable character set that could be used to show graphics.\n\nThe IBM 3279 with its software support, Graphical Data Display Manager (GDDM), was designed at IBM's Hursley Development Laboratory, near Winchester, England.\n\nBULLET::::- 3290: a large, amber monochrome plasma display unit, capable of displaying in various modes, including four independent 3278 model 2 terminals, or a single 160×62 terminal; it also supported partitioning.\n\nBULLET::::- 3178: lower cost terminal (1983)\nBULLET::::- 3179: low cost colour terminal (1984)\n\nThe 3180 was a monochrome display, introduced on March 20, 1984, that the user could configure for several different basic and extended display modes; all of the basic modes have a primary screen size of 24x80. Modes 2 and 2+ have a secondary size of 24x80, 3 and 3+ have a secondary size of 32x80, 4 and 4+ have a secondary size of 43x80 and 5 and 5+ have a secondary size of 27x132. An application can override the primary and alternate screen sizes for the extended mode. The 3180 also supported a single explicit partition that could be reconfigured under application control.\n\nThe original 3192 was a monochrome display with the same characteristics as the 3180. \n\nBULLET::::- 3104: low-cost R-loop connected terminal for the IBM 8100 system\nBULLET::::- 3472 Infowindow\n\nBULLET::::- 3275 remote display with controller function (no additional displays up to one printer)\nBULLET::::- 3276 remote display with controller function (up to a limited number of displays or printers)\n\nBULLET::::- 3284 matrix printer\nBULLET::::- 3286 matrix printer\nBULLET::::- 3287 printer, including a colour model\nBULLET::::- 3288 line printer\nBULLET::::- 3268-1 : R-loop connected stand-alone printer for the IBM 8100 system\n\nBULLET::::- 3271 remote controller\nBULLET::::- 3272 local controller\nBULLET::::- 3274 cluster controller (different models could be channel-attached or remote via BSC or SDLC communication lines, and had between eight and 32 co-ax ports)\nBULLET::::- 3174 cluster controller\n\nBy 1994 the \"3174 Establishment Controller\" supported features such as attachment to multiple hosts via token ring, Ethernet, or X.25 in addition to the standard channel attach or SDLC, and terminal attachment via twisted pair, token ring or Ethernet in addition to co-ax. They also support attachment of asynchronous ASCII terminals, printers, and plotters alongside 3270 devices.\n\nThese were specialized models: As with the 3179 (\"No 3179 terminals, other than the 3179-G, can show graphics\"), the 3279 and 3472 had \"G\" models.\n\nThe IBM 3179G released in March 1984 is an IBM mainframe computer terminal providing 80×24 or 80×32 characters plus graphics.\n\n3179-G terminals combine text and graphics as separate layers on the screen. Although the text and graphics appear combined on the screen, the text layer actually sits over the graphics layer. The text layer contains the usual 3270-style cells which display characters (letters, numbers, symbols, or invisible control characters). The graphics layer is an area of 720×384 pixels. 'All Points Addressable' or 'vector graphics' is used to paint each pixel in one of sixteen colors. As well as being separate layers on the screen, the text and graphics layers are sent to the display in separate data streams, making them completely independent.\n\nThe G10 model is a standard 122-key typewriter keyboard, while the G20 model offers APL on the same layout. Compatible with IBM System/370, IBM 4300 series, 303x, 308x, IBM 3090, and IBM 9370.\n\nThe 3279g has a capability called \"Extended Data Stream\" (EDS). Documentation for the SAS software package says \n\"The ability to do graphics on a 3270 terminal implies that it is an EDS device.\"\nThe IBM 3472G has Native Vector Graphics capability.\n\nThe IBM 3270 display terminal subsystem was designed and developed by IBM's Kingston, New York, laboratory (which later closed during in the mid-1990s). The printers were developed by the Endicott, New York, laboratory. As the subsystem expanded, the 3276 display-controller was developed by the Fujisawa laboratory, Japan, and later the Yamato laboratory; and the 3279 colour display and 3287 colour printer by the Hursley, UK, laboratory. The subsystem products were manufactured in Kingston (displays and controllers), Endicott (printers), and Greenock, Scotland, UK, (most products) and shipped to users in U.S. and worldwide. 3278 terminals continued to be manufactured in Hortolândia, near Campinas, Brazil as far as late 1980s, having its internals redesigned by a local engineering team using modern CMOS technology, while retaining its external look and feel.\n\nTelnet 3270, or tn3270 describes both the process of sending and receiving 3270 data streams using the telnet protocol and the software that emulates a 3270 class terminal that communicates using that process. tn3270 allows a 3270 terminal emulator to communicate over a TCP/IP network instead of an SNA network. Telnet 3270 can be used for either terminal or print connections. Standard telnet clients cannot be used as a substitute for tn3270 clients, as they use fundamentally different techniques for exchanging data.\n\nThe following table shows the 3275/3277/3284/3286 character set for US English EBCDIC (optional characters were available for US ASCII, and UK, French, German, and Italian EBCDIC). The numbers are the equivalent Unicode code points.\n\nOn the 3275 and 3277 terminals without the a text feature, lower case characters display as uppercase. NL, EM, DUP, and FM control characters display and print as 5, 9, *, and ; characters, respectively, except by the printer when WCC or CCC bits 2 and 3 = '00'b, in which case NL and EM serve their control function and do not print.\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\n!\n\nData sent to the 3270 consists of \"commands\" and \"orders\". Commands instruct the 3270 control unit to perform some action on a specified device, such a read or write. Orders are sent as part of the data stream to control the format of the device buffer.\n\nThe following description applies to the 3271, 3272, and 3275 control units. Later models of 3270 have additional capabilities.\n\n! Command !! hexadecimal<br>Code (local) !! Function\n\nThe data sent by Write or Erase/Write consists of the command code itself followed by a \"Write Control Character\" (WCC) optionally followed by a buffer containing orders or data (or both). The WCC controls the operation of the device. Bits may start printer operation and specify a print format. Other bit settings will sound the audible alarm if installed, unlock the keyboard to allow operator entry, or reset all the Modified Data Tags in the device buffer.\n\nOrders consist of the order code byte followed by zero to three bytes of variable information.\n\n+ Orders for 3277\n! rowspan=2 Order \n! colspan=4 Hexadecimal code (EBCDIC)\n! rowspan=2 Description\n!Byte 1 !! Byte 2 !! Byte 3 !! Byte 4 \n\nThe original 3277 and 3275 displays used an 8-bit field attribute byte of which five bits were used.\nBULLET::::- Bits 0 and 1 are set so that the attribute will always be a valid EBCDIC (or ASCII) character.\nBULLET::::- Bit 2 is zero to indicate that the associated field is \"unprotected\" (operator could enter data) or one for \"protected\".\nBULLET::::- Bit 3 is zero to indicate that this field, if unprotected, could accept alphanumeric input. One indicates that only numeric input is accepted, and automatically shifts to numeric for some keyboards.\nBULLET::::- Bit 4 and 5 operate in tandem:\nBULLET::::- '00'B indicate that the field is displayed on the screen and is not \"selector-pen detectable\".\nBULLET::::- '01'B indicates that the field is displayable and selector-pen detectable.\nBULLET::::- '10'B indicates that the field is \"intensified\" (bright), displayable, and selector-pen detectable.\nBULLET::::- '11'B indicates that the field is non-display, non-printable, and not pen detectable. This last can be used in conjunction with the modified data tag to imbed static data on the screen that will be read each time data was read from the device.\nBULLET::::- Bit 7 is the \"Modified Data Tag\", where '0' indicates that the associated field has not been modified by the operator and '1' indicates that it has been modified. As noted above, this bit can be set programmatically to cause the field to be treated as modified.\n\nLater models include \"base colour\" \"In base color mode, the protection and intensity bits are used in combination to select among four colors: normally white, red, blue, and green; the protection bits retain their protection functions as well as determining color.\" Still later models used \"extended attributes\" to add support for seven colours, blinking, reverse video, underscoring, field outlining, field validation, and programmed symbols. In addition, later models added character attributes, which could establish, e.g., color for individual characters without starting a new field or taking up a screen position.\n\n3270 displays and printers have a buffer containing one byte for every screen position. For example, a 3277 model 2 featured a screen size of 24 rows of 80 columns for a buffer size of 1920 bytes. Bytes are addressed from zero to the screen size minus one, in this example 1919. \"There is a fixed relationship between each ... buffer storage location and its position on the display screen.\" Most orders start operation at the \"current\" buffer address, and executing an order or writing data will update this address. The buffer address can be set directly using the \"Set Buffer Address (SBA)\" order, often followed by \"Start Field\". For a device with a 1920 character display a twelve bit address is sufficient. Later 3270s with larger screen sizes use fourteen or sixteen bits.\n\nAddresses are encoded in orders in two bytes. For twelve bit addresses the high order two bits of each byte are normally set to form valid EBCDIC (or ASCII) characters. For example, address 0 is coded as X'4040', or space-space, address 1919 is coded as X'5D7F', or \". Programmers hand coding panels usually keep the table of addresses from the 3270 Component Description or the 3270 Reference Card handy. For fourteen and sixteen bit address, the address uses contiguous bits in two bytes.\n\nThe following data stream writes an attribute in row 24, column 1, writes the (protected) characters '> ' in row 24, columns 2 and 3, and creates an unprotected field on row 24 from columns 5-79. Because the buffer wraps around an attribute is placed on row 24, column 80 to terminate the input field. This data stream would normally be written using an Erase/Write command which would set undefined positions on the screen to '00'x. Values are given in hexadecimal.\nBULLET::::- 3270 emulator\nBULLET::::- List of IBM products\nBULLET::::- IBM 5250 display terminal subsystem for IBM AS/400\n\nBULLET::::- Partial IBM history noting the unveiling of the 3270 display system in 1971\nBULLET::::- 3270 Information Display System - 3270 Data Stream Programmer's Reference from IBM\nBULLET::::- Introduction to Telnet 3270 from Cisco\nBULLET::::- RFC 1041 - Telnet 3270 Regime Option\nBULLET::::- RFC 1576 - TN3270 Current Practices\nBULLET::::- RFC 2355 - TN3270 Enhancements\nBULLET::::- 3270 Data Stream Programming\nBULLET::::- rbanffy/3270font: A TTF remake of the font from the 3270\n"}
{"id": "15155", "url": "https://en.wikipedia.org/wiki?curid=15155", "title": "I. M. Pei", "text": "I. M. Pei\n\nIeoh Ming Pei (), FAIA, RIBA ( 26 April 1917 – 16 May 2019) was a Chinese-American architect. Born in Guangzhou but raised in Hong Kong and Shanghai, Pei drew inspiration at an early age from the garden villas at Suzhou, the traditional retreat of the scholar-gentry to which his family belonged. In 1935, he moved to the United States and enrolled in the University of Pennsylvania's architecture school, but he quickly transferred to the Massachusetts Institute of Technology. He was unhappy with the focus at both schools on Beaux-Arts architecture, and spent his free time researching emerging architects, especially Le Corbusier. After graduating, he joined the Harvard Graduate School of Design (GSD) and became a friend of the Bauhaus architects Walter Gropius and Marcel Breuer. In 1948, Pei was recruited by New York City real estate magnate William Zeckendorf, for whom he worked for seven years before establishing his own independent design firm, I. M. Pei & Associates, in 1955, which became I. M. Pei & Partners in 1966 and later in 1989 became Pei Cobb Freed & Partners. Pei retired from full-time practice in 1990. In his retirement, he worked as an architectural consultant primarily from his sons' architectural firm Pei Partnership Architects.\n\nPei's first major recognition came with the Mesa Laboratory at the National Center for Atmospheric Research in Colorado (designed in 1961, and completed in 1967). His new stature led to his selection as chief architect for the John F. Kennedy Library in Massachusetts. He went on to design Dallas City Hall and the East Building of the National Gallery of Art. He returned to China for the first time in 1975 to design a hotel at Fragrant Hills, and designed Bank of China Tower, Hong Kong, a skyscraper in Hong Kong for the Bank of China fifteen years later. In the early 1980s, Pei was the focus of controversy when he designed a glass-and-steel pyramid for the Musée du Louvre in Paris. He later returned to the world of the arts by designing the Morton H. Meyerson Symphony Center in Dallas, the Miho Museum in Japan, Shigaraki, near Kyoto, and the chapel of the junior and high school: MIHO Institute of Aesthetics, the Suzhou Museum in Suzhou, Museum of Islamic Art in Qatar, and the Grand Duke Jean Museum of Modern Art, abbreviated to Mudam, in Luxembourg.\n\nPei won a wide variety of prizes and awards in the field of architecture, including the AIA Gold Medal in 1979, the first Praemium Imperiale for Architecture in 1989, and the Lifetime Achievement Award from the Cooper-Hewitt, National Design Museum in 2003. In 1983, he won the Pritzker Prize, which is sometimes referred to as the Nobel Prize of architecture.\n\nPei's ancestry traces back to the Ming dynasty, when his family moved from Anhui province to Suzhou. The family made their wealth in medicinal herbs, then proceeded to join the ranks of the scholar-gentry, a class which stressed the importance of helping the less fortunate. Ieoh Ming Pei was born on 26 April 1917 to Tsuyee and Lien Kwun, and the family moved to Hong Kong one year later. The family eventually included five children. As a boy, Pei was very close to his mother, a devout Buddhist who was recognized for her skills as a flautist. She invited him (and not his brothers or sisters) to join her on meditation retreats. His relationship with his father was less intimate. Their interactions were respectful but distant.\n\nPei's ancestors' success meant that the family lived in the upper echelons of society, but Pei said his father was \"not cultivated in the ways of the arts\". The younger Pei, drawn more to music and other cultural forms than to his father's domain of banking, explored art on his own. \"I have cultivated myself,\" he said later.\n\nWhen Pei was 10, his father was promoted and he moved with his family to Shanghai. Pei attended St. John's Middle School, run by Anglican missionaries. Academic discipline was rigorous; students were allowed only one half-day each month for leisure. Pei enjoyed playing billiards and watching Hollywood movies, especially those of Buster Keaton and Charlie Chaplin. He also learned rudimentary English skills by reading the Bible and novels by Charles Dickens.\n\nShanghai's many international elements gave it the name \"Paris of the East\". The city's global architectural flavors had a profound influence on Pei, from The Bund waterfront area to the Park Hotel, built in 1934. He was also impressed by the many gardens of Suzhou, where he spent the summers with extended family and regularly visited a nearby ancestral shrine. The Shizilin Garden, built in the 14th century by a Buddhist monk and owned by Pei's uncle Bei Runsheng, was especially influential. Its unusual rock formations, stone bridges, and waterfalls remained etched in Pei's memory for decades. He spoke later of his fondness for the garden's blending of natural and human-built structures.\n\nSoon after the move to Shanghai, Pei's mother developed cancer. As a pain reliever, she was prescribed opium, and assigned the task of preparing her pipe to Pei. She died shortly after his thirteenth birthday, and he was profoundly upset. The children were sent to live with extended family; their father became more consumed by his work and more physically distant. Pei said: \"My father began living his own separate life pretty soon after that.\" His father later married a woman named Aileen, who moved to New York later in her life.\n\nAs Pei neared the end of his secondary education, he decided to study at a university. He was accepted in a number of schools, but decided to enroll at the University of Pennsylvania. Pei's choice had two roots. While studying in Shanghai, he had closely examined the catalogs for various institutions of higher learning around the world. The architectural program at the University of Pennsylvania stood out to him. The other major factor was Hollywood. Pei was fascinated by the representations of college life in the films of Bing Crosby, which differed tremendously from the academic atmosphere in China. \"College life in the U.S. seemed to me to be mostly fun and games\", he said in 2000. \"Since I was too young to be serious, I wanted to be part of it ... You could get a feeling for it in Bing Crosby's movies. College life in America seemed very exciting to me. It's not real, we know that. Nevertheless, at that time it was very attractive to me. I decided that was the country for me.\" Pei added that \"Crosby's films in particular had a tremendous influence on my choosing the United States instead of England to pursue my education.\"\n\nIn 1935 Pei boarded a boat and sailed to San Francisco, then traveled by train to Philadelphia. What he found once he arrived, however, differed vastly from his expectations. Professors at the University of Pennsylvania based their teaching in the Beaux-Arts style, rooted in the classical traditions of ancient Greece and Rome. Pei was more intrigued by modern architecture, and also felt intimidated by the high level of drafting proficiency shown by other students. He decided to abandon architecture and transferred to the engineering program at Massachusetts Institute of Technology (MIT). Once he arrived, however, the dean of the architecture school commented on his eye for design and convinced Pei to return to his original major.\n\nMIT's architecture faculty was also focused on the Beaux-Arts school, and Pei found himself uninspired by the work. In the library he found three books by the Swiss-French architect Le Corbusier. Pei was inspired by the innovative designs of the new International style, characterized by simplified form and the use of glass and steel materials. Le Corbusier visited MIT in , an occasion which powerfully affected Pei: \"The two days with Le Corbusier, or 'Corbu' as we used to call him, were probably the most important days in my architectural education.\" Pei was also influenced by the work of U.S. architect Frank Lloyd Wright. In 1938 he drove to Spring Green, Wisconsin, to visit Wright's famous Taliesin building. After waiting for two hours, however, he left without meeting Wright.\n\nAlthough he disliked the Beaux-Arts emphasis at MIT, Pei excelled in his studies. \"I certainly don't regret the time at MIT\", he said later. \"There I learned the science and technique of building, which is just as essential to architecture.\" Pei received his B.Arch. degree in 1940; his thesis was titled “Standardized Propaganda Units for War Time and Peace Time China\".\n\nWhile visiting New York City in the late 1930s, Pei met a Wellesley College student named Eileen Loo. They began dating and they married in the spring of 1942. She enrolled in the landscape architecture program at Harvard University, and Pei was thus introduced to members of the faculty at Harvard's Graduate School of Design (GSD). He was excited by the lively atmosphere, and joined the GSD in .\n\nLess than a month later, Pei suspended his work at Harvard to join the National Defense Research Committee, which coordinated scientific research into U.S. weapons technology during World War II. Pei's background in architecture was seen as a considerable asset; one member of the committee told him: \"If you know how to build you should also know how to destroy.\" The fight against Germany was ending, so he focused on the Pacific War. The U.S. realized that its bombs used against the stone buildings of Europe would be ineffective against Japanese cities, mostly constructed from wood and paper; Pei was assigned to work on incendiary bombs. Pei spent two and a half years with the NDRC, but revealed few details of his work.\n\nIn 1945 Eileen gave birth to a son, T'ing Chung; she withdrew from the landscape architecture program in order to care for him. Pei returned to Harvard in the autumn of 1945, and received a position as assistant professor of design. The GSD was developing into a hub of resistance to the Beaux-Arts orthodoxy. At the center were members of the Bauhaus, a European architectural movement that had advanced the cause of modernist design. The Nazi regime had condemned the Bauhaus school, and its leaders left Germany. Two of these, Walter Gropius and Marcel Breuer, took positions at the Harvard GSD. Their iconoclastic focus on modern architecture appealed to Pei, and he worked closely with both men.\n\nOne of Pei's design projects at the GSD was a plan for an art museum in Shanghai. He wanted to create a mood of Chinese authenticity in the architecture without using traditional materials or styles. The design was based on straight modernist structures, organized around a central courtyard garden, with other similar natural settings arranged nearby. It was very well received; Gropius, in fact, called it \"the best thing done in [my] master class\". Pei received his M.Arch. degree in 1946, and taught at Harvard for another two years.\n\nIn the spring of 1948 Pei was recruited by New York real estate magnate William Zeckendorf to join a staff of architects for his firm of Webb and Knapp to design buildings around the country. Pei found Zeckendorf's personality the opposite of his own; his new boss was known for his loud speech and gruff demeanor. Nevertheless, they became good friends and Pei found the experience personally enriching. Zeckendorf was well connected politically, and Pei enjoyed learning about the social world of New York's city planners.\n\nHis first project for Webb and Knapp was an apartment building with funding from the Housing Act of 1949. Pei's design was based on a circular tower with concentric rings. The areas closest to the supporting pillar handled utilities and circulation; the apartments themselves were located toward the outer edge. Zeckendorf loved the design and even showed it off to Le Corbusier when they met. The cost of such an unusual design was too high, however, and the building never moved beyond the model stage.\n\nPei finally saw his architecture come to life in 1949, when he designed a two-story corporate building for Gulf Oil in Atlanta, Georgia. The building was demolished in February 2013 although the front facade will be retained as part of an apartment development. His use of marble for the exterior curtain wall brought praise from the journal \"Architectural Forum\". Pei's designs echoed the work of Mies van der Rohe in the beginning of his career as also shown in his own weekend-house in Katonah, New York in 1952. Soon Pei was so inundated with projects that he asked Zeckendorf for assistants, which he chose from his associates at the GSD, including Henry N. Cobb and Ulrich Franzen. They set to work on a variety of proposals, including the Roosevelt Field Shopping Mall. The team also redesigned the Webb and Knapp office building, transforming Zeckendorf's office into a circular space with teak walls and a glass clerestory. They also installed a control panel into the desk that allowed their boss to control the lighting in his office. The project took one year and exceeded its budget, but Zeckendorf was delighted with the results.\n\nIn 1952 Pei and his team began work on a series of projects in Denver, Colorado. The first of these was the Mile High Center, which compressed the core building into less than 25 percent of the total site; the rest is adorned with an exhibition hall and fountain-dotted plazas. One block away, Pei's team also redesigned Denver's Courthouse Square, which combined office spaces, commercial venues, and hotels. These projects helped Pei conceptualize architecture as part of the larger urban geography. \"I learned the process of development,\" he said later, \"and about the city as a living organism.\" These lessons, he said, became essential for later projects.\n\nPei and his team also designed a united urban area for Washington, D.C., called L'Enfant Plaza (named for French-American architect Pierre Charles L'Enfant). Pei's associate Araldo Cossutta was the lead architect for the plaza's North Building (955 L'Enfant Plaza SW) and South Building (490 L'Enfant Plaza SW). Vlastimil Koubek was the architect for the East Building (L'Enfant Plaza Hotel, located at 480 L'Enfant Plaza SW), and for the Center Building (475 L'Enfant Plaza SW; now the United States Postal Service headquarters). The team set out with a broad vision that was praised by both \"The Washington Post\" and \"Washington Star\" (which rarely agreed on anything), but funding problems forced revisions and a significant reduction in scale.\n\nIn 1955 Pei's group took a step toward institutional independence from Webb and Knapp by establishing a new firm called I. M. Pei & Associates. (The name changed later to I. M. Pei & Partners.) They gained the freedom to work with other companies, but continued working primarily with Zeckendorf. The new firm distinguished itself through the use of detailed architectural models. They took on the Kips Bay residential area on the east side of Manhattan, where Pei set up Kips Bay Towers, two large long towers of apartments with recessed windows (to provide shade and privacy) in a neat grid, adorned with rows of trees. Pei involved himself in the construction process at Kips Bay, even inspecting the bags of concrete to check for consistency of color.\n\nThe company continued its urban focus with the Society Hill project in central Philadelphia. Pei designed the Society Hill Towers, a three-building residential block injecting cubist design into the 18th-century milieu of the neighborhood. As with previous projects, abundant green spaces were central to Pei's vision, which also added traditional townhouses to aid the transition from classical to modern design.\n\nFrom 1958 to 1963 Pei and Ray Affleck developed a key downtown block of Montreal in a phased process that involved one of Pei's most admired structures in the Commonwealth, the cruciform tower known as the Royal Bank Plaza (Place Ville Marie). According to \"The Canadian Encyclopedia\" \"its grand plaza and lower office buildings, designed by internationally famous US architect I. M. Pei, helped to set new standards for architecture in Canada in the 1960s ... The tower's smooth aluminum and glass surface and crisp unadorned geometric form demonstrate Pei's adherence to the mainstream of 20th-century modern design.\"\n\nAlthough these projects were satisfying, Pei wanted to establish an independent name for himself. In 1959 he was approached by MIT to design a building for its Earth science program. The Green Building continued the grid design of Kips Bay and Society Hill. The pedestrian walkway at the ground floor, however, was prone to sudden gusts of wind, which embarrassed Pei. \"Here I was from MIT,\" he said, \"and I didn't know about wind-tunnel effects.\" At the same time, he designed the Luce Memorial Chapel in at Tunghai University in Taichung, Taiwan. The soaring structure, commissioned by the same organisation that had run his middle school in Shanghai, broke severely from the cubist grid patterns of his urban projects.\n\nThe challenge of coordinating these projects took an artistic toll on Pei. He found himself responsible for acquiring new building contracts and supervising the plans for them. As a result, he felt disconnected from the actual creative work. \"Design is something you have to put your hand to,\" he said. \"While my people had the luxury of doing one job at a time, I had to keep track of the whole enterprise.\" Pei's dissatisfaction reached its peak at a time when financial problems began plaguing Zeckendorf's firm. I. M. Pei and Associates officially broke from Webb and Knapp in 1960, which benefited Pei creatively but pained him personally. He had developed a close friendship with Zeckendorf, and both men were sad to part ways.\n\nPei was able to return to hands-on design when he was approached in 1961 by Walter Orr Roberts to design the new Mesa Laboratory for the National Center for Atmospheric Research outside Boulder, Colorado. The project differed from Pei's earlier urban work; it would rest in an open area in the foothills of the Rocky Mountains. He drove with his wife around the region, visiting assorted buildings and surveying the natural environs. He was impressed by the United States Air Force Academy in Colorado Springs, but felt it was \"detached from nature\".\n\nThe conceptualization stages were important for Pei, presenting a need and an opportunity to break from the Bauhaus tradition. He later recalled the long periods of time he spent in the area: \"I recalled the places I had seen with my mother when I was a little boy—the mountaintop Buddhist retreats. There in the Colorado mountains, I tried to listen to the silence again—just as my mother had taught me. The investigation of the place became a kind of religious experience for me.\" Pei also drew inspiration from the Mesa Verde cliff dwellings of the Ancestral Puebloans; he wanted the buildings to exist in harmony with their natural surroundings. To this end, he called for a rock-treatment process that could color the buildings to match the nearby mountains. He also set the complex back on the mesa overlooking the city, and designed the approaching road to be long, winding, and indirect.\n\nRoberts disliked Pei's initial designs, referring to them as \"just a bunch of towers\". Roberts intended his comments as typical of scientific experimentation, rather than artistic critique; still, Pei was frustrated. His second attempt, however, fit Roberts' vision perfectly: a spaced-out series of clustered buildings, joined by lower structures and complemented by two underground levels. The complex uses many elements of cubist design, and the walkways are arranged to increase the probability of casual encounters among colleagues.\n\nOnce the laboratory was built, several problems with its construction became apparent. Leaks in the roof caused difficulties for researchers, and the shifting of clay soil beneath caused cracks in the buildings which were expensive to repair. Still, both architect and project manager were pleased with the final result. Pei referred to the NCAR complex as his \"breakout building\", and he remained a friend of Roberts until the scientist died in .\n\nThe success of NCAR brought renewed attention to Pei's design acumen. He was recruited to work on a variety of projects, including the S. I. Newhouse School of Public Communications at Syracuse University, the Everson Museum of Art in Syracuse, New York, the Sundrome terminal at John F. Kennedy International Airport in New York City, and dormitories at New College of Florida.\n\nAfter President John F. Kennedy was assassinated in , his family and friends discussed how to construct a library that would serve as a fitting memorial. A committee was formed to advise Kennedy's widow Jacqueline, who would make the final decision. The group deliberated for months and considered many famous architects. Eventually, Kennedy chose Pei to design the library, based on two considerations. First, she appreciated the variety of ideas he had used for earlier projects. \"He didn't seem to have just one way to solve a problem,\" she said. \"He seemed to approach each commission thinking only of it and then develop a way to make something beautiful.\" Ultimately, however, Kennedy made her choice based on her personal connection with Pei. Calling it \"really an emotional decision\", she explained: \"He was so full of promise, like Jack; they were born in the same year. I decided it would be fun to take a great leap with him.\"\n\nThe project was plagued with problems from the outset. The first was scope. President Kennedy had begun considering the structure of his library soon after taking office, and he wanted to include archives from his administration, a museum of personal items, and a political science institute. After the assassination, the list expanded to include a fitting memorial tribute to the slain president. The variety of necessary inclusions complicated the design process and caused significant delays.\n\nPei's first proposed design included a large glass pyramid that would fill the interior with sunlight, meant to represent the optimism and hope that Kennedy's administration had symbolized for so many in the United States. Mrs. Kennedy liked the design, but resistance began in Cambridge, the first proposed site for the building, as soon as the project was announced. Many community members worried that the library would become a tourist attraction, causing particular problems with traffic congestion. Others worried that the design would clash with the architectural feel of nearby Harvard Square. By the mid-70s, Pei tried proposing a new design, but the library's opponents resisted every effort. These events pained Pei, who had sent all three of his sons to Harvard, and although he rarely discussed his frustration, it was evident to his wife. \"I could tell how tired he was by the way he opened the door at the end of the day,\" she said. \"His footsteps were dragging. It was very hard for I. M. to see that so many people didn't want the building.\"\n\nFinally the project moved to Columbia Point, near the University of Massachusetts Boston. The new site was less than ideal; it was located on an old landfill, and just over a large sewage pipe. Pei's architectural team added more fill to cover the pipe and developed an elaborate ventilation system to conquer the odor. A new design was unveiled, combining a large square glass-enclosed atrium with a triangular tower and a circular walkway.\n\nThe John F. Kennedy Presidential Library and Museum was dedicated on 20 October 1979. Critics generally liked the finished building, but the architect himself was unsatisfied. The years of conflict and compromise had changed the nature of the design, and Pei felt that the final result lacked its original passion. \"I wanted to give something very special to the memory of President Kennedy,\" he said in 2000. \"It could and should have been a great project.\" Pei's work on the Kennedy project boosted his reputation as an architect of note.\n\nThe Pei Plan was a failed urban redevelopment initiative designed for downtown Oklahoma City, Oklahoma, in the 1960s and 1970s. It is the informal name for two related commissions by Pei—namely the Central Business District General Neighborhood Renewal Plan (design completed 1964) and the Central Business District Project I-A Development Plan (design completed 1966). It was formally adopted in 1965, and implemented in various public and private phases throughout the 1960s and 1970s.\n\nThe plan called for the demolition of hundreds of old downtown structures in favor of renewed parking, office building, and retail developments, in addition to public projects such as the Myriad Convention Center and the Myriad Botanical Gardens. It was the dominant template for downtown development in Oklahoma City from its inception through the 1970s. The plan generated mixed results and opinion, largely succeeding in re-developing office building and parking infrastructure but failing to attract its anticipated retail and residential development. Significant public resentment also developed as a result of the destruction of multiple historic structures. As a result, Oklahoma City's leadership avoided large-scale urban planning for downtown throughout the 1980s and early 1990s, until the passage of the Metropolitan Area Projects (MAPS) initiative in 1993.\n\nAnother city which turned to Pei for urban renewal during this time was Providence, Rhode Island. In the late 1960s, Providence hired Pei to redesign Cathedral Square, a once-bustling civic center which had become neglected and empty, as part of an ambitious larger plan to redesign downtown. Pei's new plaza, modeled after the Greek Agora marketplace, opened in 1972. Unfortunately, the city ran out of money before Pei's vision could be fully realized. Also, recent construction of a low-income housing complex and Interstate 95 had changed the neighborhood's character permanently. In 1974, The Providence Evening Bulletin called Pei's new plaza a \"conspicuous failure\". By 2016, media reports characterized the plaza as a neglected, little-visited \"hidden gem\".\n\nIn 1974, the city of Augusta, Georgia turned to Pei and his firm for downtown revitalization. The Chamber of Commerce building and Bicentennial Park were completed from his plan. In 1976, Pei designed a distinctive modern penthouse that was added to the roof of architect William Lee Stoddart's historic Lamar Building, designed in 1916. The penthouse is a modern take on a pyramid, predating Pei's more famous Louvre Pyramid. It has been criticized by architectural critic James Howard Kunstler as an \"Eyesore of the Month,\" with him comparing it to Darth Vader's helmet. In 1980, Pei and his company designed the Augusta Civic Center, now known as the James Brown Arena.\n\nKennedy's assassination also led indirectly to another commission for Pei's firm. In 1964 the acting mayor of Dallas, Erik Jonsson, began working to change the community's image. Dallas was known and disliked as the city where the president had been killed, but Jonsson began a program designed to initiate a community renewal. One of the goals was a new city hall, which could be a \"symbol of the people\". Jonsson, a co-founder of Texas Instruments, learned about Pei from his associate Cecil Howard Green, who had recruited the architect for MIT's Earth Sciences building.\n\nPei's approach to the new Dallas City Hall mirrored those of other projects; he surveyed the surrounding area and worked to make the building fit. In the case of Dallas, he spent days meeting with residents of the city and was impressed by their civic pride. He also found that the skyscrapers of the downtown business district dominated the skyline, and sought to create a building which could face the tall buildings and represent the importance of the public sector. He spoke of creating \"a public-private dialogue with the commercial high-rises\".\n\nWorking with his associate Theodore Musho, Pei developed a design centered on a building with a top much wider than the bottom; the facade leans at an angle of 34 degrees, which shades the building from the Texas sun. A plaza stretches out before the building, and a series of support columns holds it up. It was influenced by Le Corbusier's High Court building in Chandigarh, India; Pei sought to use the significant overhang to unify the building and plaza. The project cost much more than initially expected, and took 11 years to complete. Revenue was secured in part by including a subterranean parking garage. The interior of the city hall is large and spacious; windows in the ceiling above the eighth floor fill the main space with light.\n\nThe city of Dallas received the building well, and a local television news crew found unanimous approval of the new city hall when it officially opened to the public in 1978. Pei himself considered the project a success, even as he worried about the arrangement of its elements. He said: \"It's perhaps stronger than I would have liked; it's got more strength than finesse.\" He felt that his relative lack of experience left him without the necessary design tools to refine his vision, but the community liked the city hall enough to invite him back. Over the years he went on to design five additional buildings in the Dallas area.\n\nWhile Pei and Musho were coordinating the Dallas project, their associate Henry Cobb had taken the helm for a commission in Boston. John Hancock Insurance chairman Robert Slater hired I. M. Pei & Partners to design a building that could overshadow the Prudential Tower, erected by their rival.\n\nAfter the firm's first plan was discarded due to a need for more office space, Cobb developed a new plan around a towering parallelogram, slanted away from the Trinity Church and accented by a wedge cut into each narrow side. To minimize the visual impact, the building was covered in large reflective glass panels; Cobb said this would make the building a \"background and foil\" to the older structures around it. When the Hancock Tower was finished in 1976, it was the tallest building in New England.\n\nSerious issues of execution became evident in the tower almost immediately. Many glass panels fractured in a windstorm during construction in 1973. Some detached and fell to the ground, causing no injuries but sparking concern among Boston residents. In response, the entire tower was reglazed with smaller panels. This significantly increased the cost of the project. Hancock sued the glass manufacturers, Libbey-Owens-Ford, as well as I. M. Pei & Partners, for submitting plans that were \"not good and workmanlike\". LOF countersued Hancock for defamation, accusing Pei's firm of poor use of their materials; I. M. Pei & Partners sued LOF in return. All three companies settled out of court in 1981.\n\nThe project became an albatross for Pei's firm. Pei himself refused to discuss it for many years. The pace of new commissions slowed and the firm's architects began looking overseas for opportunities. Cobb worked in Australia and Pei took on jobs in Singapore, Iran, and Kuwait. Although it was a difficult time for everyone involved, Pei later reflected with patience on the experience. \"Going through this trial toughened us,\" he said. \"It helped to cement us as partners; we did not give up on each other.\"\n\nIn the mid-1960s, directors of the National Gallery of Art in Washington, D.C., declared the need for a new building. Paul Mellon, a primary benefactor of the gallery and a member of its building committee, set to work with his assistant J. Carter Brown (who became gallery director in 1969) to find an architect. The new structure would be located to the east of the original building, and tasked with two functions: offer a large space for public appreciation of various popular collections; and house office space as well as archives for scholarship and research. They likened the scope of the new facility to the Library of Alexandria. After inspecting Pei's work at the Des Moines Art Center in Iowa and the Johnson Museum at Cornell University, they offered him the commission.\n\nPei took to the project with vigor, and set to work with two young architects he had recently recruited to the firm, William Pedersen and Yann Weymouth. Their first obstacle was the unusual shape of the building site, a trapezoid of land at the intersection of Constitution and Pennsylvania Avenues. Inspiration struck Pei in 1968, when he scrawled a rough diagram of two triangles on a scrap of paper. The larger building would be the public gallery; the smaller would house offices and archives. This triangular shape became a singular vision for the architect. As the date for groundbreaking approached, Pedersen suggested to his boss that a slightly different approach would make construction easier. Pei simply smiled and said: \"No compromises.\"\n\nThe growing popularity of art museums presented unique challenges to the architecture. Mellon and Pei both expected large crowds of people to visit the new building, and they planned accordingly. To this end, Pei designed a large lobby roofed with enormous skylights. Individual galleries are located along the periphery, allowing visitors to return after viewing each exhibit to the spacious main room. A large mobile sculpture by American artist Alexander Calder was later added to the lobby. Pei hoped the lobby would be exciting to the public in the same way as the central room of the Guggenheim Museum is in New York City. The modern museum, he said later, \"must pay greater attention to its educational responsibility, especially to the young\".\n\nMaterials for the building's exterior were chosen with careful precision. To match the look and texture of the original gallery's marble walls, builders re-opened the quarry in Knoxville, Tennessee, from which the first batch of stone had been harvested. The project even found and hired Malcolm Rice, a quarry supervisor who had overseen the original 1941 gallery project. The marble was cut into three-inch-thick blocks and arranged over the concrete foundation, with darker blocks at the bottom and lighter blocks on top.\n\nThe East Building was honored on 30 May 1978, two days before its public unveiling, with a black-tie party attended by celebrities, politicians, benefactors, and artists. When the building opened, popular opinion was enthusiastic. Large crowds visited the new museum, and critics generally voiced their approval. Ada Louise Huxtable wrote in \"The New York Times\" that Pei's building was \"a palatial statement of the creative accommodation of contemporary art and architecture\". The sharp angle of the smaller building has been a particular note of praise for the public; over the years it has become stained and worn from the hands of visitors.\n\nSome critics disliked the unusual design, however, and criticized the reliance on triangles throughout the building. Others took issue with the large main lobby, particularly its attempt to lure casual visitors. In his review for \"Artforum\", critic Richard Hennessy described a \"shocking fun-house atmosphere\" and \"aura of ancient Roman patronage\". One of the earliest and most vocal critics, however, came to appreciate the new gallery once he saw it in person. Allan Greenberg had scorned the design when it was first unveiled, but wrote later to J. Carter Brown: \"I am forced to admit that you are right and I was wrong! The building is a masterpiece.\"\nAfter U.S. President Richard Nixon made his famous 1972 visit to China, a wave of exchanges took place between the two countries. One of these was a delegation of the American Institute of Architects in 1974, which Pei joined. It was his first trip back to China since leaving in 1935. He was favorably received, returned the welcome with positive comments, and a series of lectures ensued. Pei noted in one lecture that since the 1950s Chinese architects had been content to imitate Western styles; he urged his audience in one lecture to search China's native traditions for inspiration.\n\nIn 1978, Pei was asked to initiate a project for his home country. After surveying a number of different locations, Pei fell in love with a valley that had once served as an imperial garden and hunting preserve known as Fragrant Hills. The site housed a decrepit hotel; Pei was invited to tear it down and build a new one. As usual, he approached the project by carefully considering the context and purpose. Likewise, he considered modernist styles inappropriate for the setting. Thus, he said, it was necessary to find \"a third way\".\n\nAfter visiting his ancestral home in Suzhou, Pei created a design based on some simple but nuanced techniques he admired in traditional residential Chinese buildings. Among these were abundant gardens, integration with nature, and consideration of the relationship between enclosure and opening. Pei's design included a large central atrium covered by glass panels that functioned much like the large central space in his East Building of the National Gallery. Openings of various shapes in walls invited guests to view the natural scenery beyond. Younger Chinese who had hoped the building would exhibit some of Cubist flavor for which Pei had become known were disappointed, but the new hotel found more favour with government officials and architects.\n\nThe hotel, with 325 guest rooms and a four-story central atrium, was designed to fit perfectly into its natural habitat. The trees in the area were of special concern, and particular care was taken to cut down as few as possible. He worked with an expert from Suzhou to preserve and renovate a water maze from the original hotel, one of only five in the country. Pei was also meticulous about the arrangement of items in the garden behind the hotel; he even insisted on transporting of rocks from a location in southwest China to suit the natural aesthetic. An associate of Pei's said later that he never saw the architect so involved in a project.\n\nDuring construction, a series of mistakes collided with the nation's lack of technology to strain relations between architects and builders. Whereas 200 or so workers might have been used for a similar building in the US, the Fragrant Hill project employed over 3,000 workers. This was mostly because the construction company lacked the sophisticated machines used in other parts of the world. The problems continued for months, until Pei had an uncharacteristically emotional moment during a meeting with Chinese officials. He later explained that his actions included \"shouting and pounding the table\" in frustration. The design staff noticed a difference in the manner of work among the crew after the meeting. As the opening neared, however, Pei found the hotel still needed work. He began scrubbing floors with his wife and ordered his children to make beds and vacuum floors. The project's difficulties took an emotional and physical strain on the Pei family.\n\nThe Fragrant Hill Hotel opened on 17 October 1982 but quickly fell into disrepair. A member of Pei's staff returned for a visit several years later and confirmed the dilapidated condition of the hotel. He and Pei attributed this to the country's general unfamiliarity with deluxe buildings. The Chinese architectural community at the time gave the structure little attention, as their interest at the time centered on the work of American postmodernists such as Michael Graves.\n\nAs the Fragrant Hill project neared completion, Pei began work on the Jacob K. Javits Convention Center in New York City, for which his associate James Freed served as lead designer. Hoping to create a vibrant community institution in what was then a run-down neighborhood on Manhattan's west side, Freed developed a glass-coated structure with an intricate space frame of interconnected metal rods and spheres.\n\nThe convention center was plagued from the start by budget problems and construction blunders. City regulations forbid a general contractor having final authority over the project, so architects and program manager Richard Kahan had to coordinate the wide array of builders, plumbers, electricians, and other workers. The forged steel globes to be used in the space frame came to the site with hairline cracks and other defects: 12,000 were rejected. These and other problems led to media comparisons with the disastrous Hancock Tower. One New York City official blamed Kahan for the difficulties, indicating that the building's architectural flourishes were responsible for delays and financial crises. The Javits Center opened on 3 April 1986, to a generally positive reception. During the inauguration ceremonies, however, neither Freed nor Pei was recognized for their role in the project.\n\nWhen François Mitterrand was elected President of France in 1981, he laid out an ambitious plan for a variety of construction projects. One of these was the renovation of the Louvre Museum. Mitterrand appointed a civil servant named Émile Biasini to oversee it. After visiting museums in Europe and the United States, including the U.S. National Gallery, he asked Pei to join the team. The architect made three secretive trips to Paris, to determine the feasibility of the project; only one museum employee knew why he was there. Pei finally agreed that a reconstruction project was not only possible, but necessary for the future of the museum. He thus became the first foreign architect to work on the Louvre.\n\nThe heart of the new design included not only a renovation of the \"Cour Napoléon\" in the midst of the buildings, but also a transformation of the interiors. Pei proposed a central entrance, not unlike the lobby of the National Gallery East Building, which would link the three major buildings. Below would be a complex of additional floors for research, storage, and maintenance purposes. At the center of the courtyard he designed a glass and steel pyramid, first proposed with the Kennedy Library, to serve as entrance and anteroom skylight. It was mirrored by another inverted pyramid underneath, to reflect sunlight into the room. These designs were partly an homage to the fastidious geometry of the famous French landscape architect André Le Nôtre (1613–1700). Pei also found the pyramid shape best suited for stable transparency, and considered it \"most compatible with the architecture of the Louvre, especially with the faceted planes of its roofs\".\n\nBiasini and Mitterrand liked the plans, but the scope of the renovation displeased Louvre director André Chabaud. He resigned from his post, complaining that the project was \"unfeasible\" and posed \"architectural risks\". The public also reacted harshly to the design, mostly because of the proposed pyramid. One critic called it a \"gigantic, ruinous gadget\"; another charged Mitterrand with \"despotism\" for inflicting Paris with the \"atrocity\". Pei estimated that 90 percent of Parisians opposed his design. \"I received many angry glances in the streets of Paris,\" he said. Some condemnations carried nationalistic overtones. One opponent wrote: \"I am surprised that one would go looking for a Chinese architect in America to deal with the historic heart of the capital of France.\"\nSoon, however, Pei and his team won the support of several key cultural icons, including the conductor Pierre Boulez and Claude Pompidou, widow of former French President Georges Pompidou, after whom another controversial museum was named. In an attempt to soothe public ire, Pei took a suggestion from then-mayor of Paris Jacques Chirac and placed a full-sized cable model of the pyramid in the courtyard. During the four days of its exhibition, an estimated 60,000 people visited the site. Some critics eased their opposition after witnessing the proposed scale of the pyramid.\n\nTo minimize the impact of the structure, Pei demanded a method of glass production that resulted in clear panes. The pyramid was constructed at the same time as the subterranean levels below, which caused difficulties during the building stages. As they worked, construction teams came upon an abandoned set of rooms containing 25,000 historical items; these were incorporated into the rest of the structure to add a new exhibition zone.\n\nThe new Louvre courtyard was opened to the public on 14 October 1988, and the Pyramid entrance was opened the following March. By this time, public opinion had softened on the new installation; a poll found a 56 percent approval rating for the pyramid, with 23 percent still opposed. The newspaper \"Le Figaro\" had vehemently criticized Pei's design, but later celebrated the tenth anniversary of its magazine supplement at the pyramid. Prince Charles of Britain surveyed the new site with curiosity, and declared it \"marvelous, very exciting\". A writer in \"Le Quotidien de Paris\" wrote: \"The much-feared pyramid has become adorable.\"\n\nThe experience was exhausting for Pei, but also rewarding. \"After the Louvre,\" he said later, \"I thought no project would be too difficult.\" The pyramid achieved further widepread international recognition for its central role in the plot at the denouement of \"The Da Vinci Code\" by Dan Brown and its appearance in the final scene of the subsequent screen adaptation. The \"Louvre Pyramid\" has become Pei's most famous structure.\n\nThe opening of the Louvre Pyramid coincided with four other projects on which Pei had been working, prompting architecture critic Paul Goldberger to declare 1989 \"the year of Pei\" in \"The New York Times\". It was also the year in which Pei's firm changed its name to Pei Cobb Freed & Partners, to reflect the increasing stature and prominence of his associates. At the age of 72, Pei had begun thinking about retirement, but continued working long hours to see his designs come to light.\nOne of the projects took Pei back to Dallas, Texas, to design the Morton H. Meyerson Symphony Center. The success of city's performing artists, particularly the Dallas Symphony Orchestra then led by conductor Eduardo Mata, led to interest by city leaders in creating a modern center for musical arts that could rival the best halls in Europe. The organizing committee contacted 45 architects, but at first Pei did not respond, thinking that his work on the Dallas City Hall had left a negative impression. One of his colleagues from that project, however, insisted that he meet with the committee. He did and, although it would be his first concert hall, the committee voted unanimously to offer him the commission. As one member put it: \"We were convinced that we would get the world's greatest architect putting his best foot forward.\"\n\nThe project presented a variety of specific challenges. Because its main purpose was the presentation of live music, the hall needed a design focused on acoustics first, then public access and exterior aesthetics. To this end, a professional sound technician was hired to design the interior. He proposed a shoebox auditorium, used in the acclaimed designs of top European symphony halls such as the Amsterdam Concertgebouw and Vienna Musikverein. Pei drew inspiration for his adjustments from the designs of the German architect Johann Balthasar Neumann, especially the Basilica of the Fourteen Holy Helpers. He also sought to incorporate some of the panache of the Paris Opéra designed by Charles Garnier.\n\nPei's design placed the rigid shoebox at an angle to the surrounding street grid, connected at the north end to a long rectangular office building, and cut through the middle with an assortment of circles and cones. The design attempted to reproduce with modern features the acoustic and visual functions of traditional elements like filigree. The project was risky: its goals were ambitious and any unforeseen acoustic flaws would be virtually impossible to remedy after the hall's completion. Pei admitted that he did not completely know how everything would come together. \"I can imagine only 60 percent of the space in this building,\" he said during the early stages. \"The rest will be as surprising to me as to everyone else.\" As the project developed, costs rose steadily and some sponsors considered withdrawing their support. Billionaire tycoon Ross Perot made a donation of US$10 million, on the condition that it be named in honor of Morton H. Meyerson, the longtime patron of the arts in Dallas.\n\nThe building opened and immediately garnered widespread praise, especially for its acoustics. After attending a week of performances in the hall, a music critic for \"The New York Times\" wrote an enthusiastic account of the experience and congratulated the architects. One of Pei's associates told him during a party before the opening that the symphony hall was \"a very mature building\"; he smiled and replied: \"Ah, but did I have to wait this long?\"\n\nA new offer had arrived for Pei from the Chinese government in 1982. With an eye toward the transfer of sovereignty of Hong Kong from the British in 1997, authorities in China sought Pei's aid on a new tower for the local branch of the Bank of China. The Chinese government was preparing for a new wave of engagement with the outside world and sought a tower to represent modernity and economic strength. Given the elder Pei's history with the bank before the Communist takeover, government officials visited the 89-year-old man in New York to gain approval for his son's involvement. Pei then spoke with his father at length about the proposal. Although the architect remained pained by his experience with Fragrant Hills, he agreed to accept the commission.\n\nThe proposed site in Hong Kong's Central District was less than ideal; a tangle of highways lined it on three sides. The area had also been home to a headquarters for Japanese military police during World War II, and was notorious for prisoner torture. The small parcel of land made a tall tower necessary, and Pei had usually shied away from such projects; in Hong Kong especially, the skyscrapers lacked any real architectural character. Lacking inspiration and unsure of how to approach the building, Pei took a weekend vacation to the family home in Katonah, New York. There he found himself experimenting with a bundle of sticks until he happened upon a cascading sequence.\n\nPei felt that his design for the Bank of China Tower needed to reflect \"the aspirations of the Chinese people\". The design that he developed for the skyscraper was not only unique in appearance, but also sound enough to pass the city's rigorous standards for wind-resistance. The building is composed of four triangular shafts rising up from a square base, supported by a visible truss structure that distributes stress to the four corners of the base. Using the reflective glass that had become something of a trademark for him, Pei organized the facade around diagonal bracing in a union of structure and form that reiterates the triangle motif established in the plan. At the top, he designed the roofs at sloping angles to match the rising aesthetic of the building. Some influential advocates of \"feng shui\" in Hong Kong and China criticized the design, and Pei and government officials responded with token adjustments.\n\nAs the tower neared completion, Pei was shocked to witness the government's massacre of unarmed civilians at the Tiananmen Square protests of 1989. He wrote an opinion piece for \"The New York Times\" titled \"China Won't Ever Be the Same,\" in which he said that the killings \"tore the heart out of a generation that carries the hope for the future of the country\". The massacre deeply disturbed his entire family, and he wrote that \"China is besmirched.\"\n\nAs the 1990s began, Pei transitioned into a role of decreased involvement with his firm. The staff had begun to shrink, and Pei wanted to dedicate himself to smaller projects allowing for more creativity. Before he made this change, however, he set to work on his last major project as active partner: the Rock and Roll Hall of Fame in Cleveland, Ohio. Considering his work on such bastions of high culture as the Louvre and U.S. National Gallery, some critics were surprised by his association with what many considered a tribute to low culture. The sponsors of the hall, however, sought Pei for specifically this reason; they wanted the building to have an aura of respectability from the beginning. As in the past, Pei accepted the commission in part because of the unique challenge it presented.\n\nUsing a glass wall for the entrance, similar in appearance to his Louvre pyramid, Pei coated the exterior of the main building in white metal, and placed a large cylinder on a narrow perch to serve as a performance space. The combination of off-centered wraparounds and angled walls was, Pei said, designed to provide \"a sense of tumultuous youthful energy, rebelling, flailing about\".\n\nThe building opened in 1995, and was received with moderate praise. \"The New York Times\" called it \"a fine building\", but Pei was among those who felt disappointed with the results. The museum's early beginnings in New York combined with an unclear mission created a fuzzy understanding among project leaders for precisely what was needed. Although the city of Cleveland benefited greatly from the new tourist attraction, Pei was unhappy with it.\n\nAt the same time, Pei designed a new museum for Luxembourg, the \"Musée d'art moderne Grand-Duc Jean\", commonly known as the Mudam. Drawing from the original shape of the Fort Thüngen walls where the museum was located, Pei planned to remove a portion of the original foundation. Public resistance to the historical loss forced a revision of his plan, however, and the project was nearly abandoned. The size of the building was halved, and it was set back from the original wall segments to preserve the foundation. Pei was disappointed with the alterations, but remained involved in the building process even during construction.\n\nIn 1995, Pei was hired to design an extension to the \"Deutsches Historisches Museum\", or German Historical Museum in Berlin. Returning to the challenge of the East Building of the U.S. National Gallery, Pei worked to combine a modernist approach with a classical main structure. He described the glass cylinder addition as a \"beacon,\" and topped it with a glass roof to allow plentiful sunlight inside. Pei had difficulty working with German government officials on the project; their utilitarian approach clashed with his passion for aesthetics. \"They thought I was nothing but trouble\", he said.\n\nPei also worked at this time on two projects for a new Japanese religious movement called \"Shinji Shumeikai\". He was approached by the movement's spiritual leader, Kaishu Koyama, who impressed the architect with her sincerity and willingness to give him significant artistic freedom. One of the buildings was a bell tower, designed to resemble the \"bachi\" used when playing traditional instruments like the \"shamisen\". Pei was unfamiliar with the movement's beliefs, but explored them in order to represent something meaningful in the tower. As he said: \"It was a search for the sort of expression that is not at all technical.\"\nThe experience was rewarding for Pei, and he agreed immediately to work with the group again. The new project was the Miho Museum, to display Koyama's collection of tea ceremony artifacts. Pei visited the site in Shiga Prefecture, and during their conversations convinced Koyama to expand her collection. She conducted a global search and acquired more than 300 items showcasing the history of the Silk Road.\n\nOne major challenge was the approach to the museum. The Japanese team proposed a winding road up the mountain, not unlike the approach to the NCAR building in Colorado. Instead, Pei ordered a hole cut through a nearby mountain, connected to a major road via a bridge suspended from ninety-six steel cables and supported by a post set into the mountain. The museum itself was built into the mountain, with 80 percent of the building underground.\n\nWhen designing the exterior, Pei borrowed from the tradition of Japanese temples, particularly those found in nearby Kyoto. He created a concise spaceframe wrapped into French limestone and covered with a glass roof. Pei also oversaw specific decorative details, including a bench in the entrance lobby, carved from a 350-year-old \"keyaki\" tree. Because of Koyama's considerable wealth, money was rarely considered an obstacle; estimates at the time of completion put the cost of the project at US$350 million.\n\nDuring the first decade of the 2000s, Pei designed a variety of buildings, including the Suzhou Museum near his childhood home. He also designed the Museum of Islamic Art in Doha, Qatar at the request of the Al-Thani Family. Although it was originally planned for the corniche road along Doha Bay, Pei convinced the project coordinators to build a new island to provide the needed space. He then spent six months touring the region and surveying mosques in Spain, Syria, and Tunisia. He was especially impressed with the elegant simplicity of the Mosque of Ibn Tulun in Cairo.\n\nOnce again, Pei sought to combine new design elements with the classical aesthetic most appropriate for the location of the building. The sand-colored rectangular boxes rotate evenly to create a subtle movement, with small arched windows at regular intervals into the limestone exterior. Inside, galleries are arranged around a massive atrium, lit from above. The museum's coordinators were pleased with the project; its official website describes its \"true splendour unveiled in the sunlight,\" and speaks of \"the shades of colour and the interplay of shadows paying tribute to the essence of Islamic architecture\".\nThe Macao Science Center in Macau was designed by Pei Partnership Architects in association with I. M. Pei. The project to build the science center was conceived in 2001 and construction started in 2006. The center was completed in 2009 and opened by the Chinese President Hu Jintao. The main part of the building is a distinctive conical shape with a spiral walkway and large atrium inside, similar to that of the Solomon R. Guggenheim Museum in New York City. Galleries lead off the walkway, mainly consisting of interactive exhibits aimed at science education. The building is in a prominent position by the sea and is now a Macau landmark.\n\nPei's career ended with his death in May 2019.\n\nPei's style was described as thoroughly modernist, with significant cubist themes. He was known for combining traditional architectural principles with progressive designs based on simple geometric patterns—circles, squares, and triangles are common elements of his work in both plan and elevation. As one critic wrote: \"Pei has been aptly described as combining a classical sense of form with a contemporary mastery of method.\" In 2000, biographer Carter Wiseman called Pei \"the most distinguished member of his Late-Modernist generation still in practice\". At the same time, Pei himself rejected simple dichotomies of architectural trends. He once said: \"The talk about modernism versus post-modernism is unimportant. It's a side issue. An individual building, the style in which it is going to be designed and built, is not that important. The important thing, really, is the community. How does it affect life?\"\n\nPei's work is celebrated throughout the world of architecture. His colleague John Portman once told him: \"Just once, I'd like to do something like the East Building.\" But this originality did not always bring large financial reward; as Pei replied to the successful architect: \"Just once, I'd like to make the kind of money you do.\" His concepts, moreover, were too individualized and dependent on context to have given rise to a particular school of design. Pei referred to his own \"analytical approach\" when explaining the lack of a \"Pei School\".\n\n\"For me,\" he said, \"the important distinction is between a stylistic approach to the design; and an analytical approach giving the process of due consideration to time, place, and purpose ... My analytical approach requires a full understanding of the three essential elements ... to arrive at an ideal balance among them.\"\n\nIn the words of his biographer, Pei won \"every award of any consequence in his art\", including the Arnold Brunner Award from the National Institute of Arts and Letters (1963), the Gold Medal for Architecture from the American Academy of Arts and Letters (1979), the AIA Gold Medal (1979), the first \"Praemium Imperiale\" for Architecture from the Japan Art Association (1989), the Lifetime Achievement Award from the Cooper-Hewitt, National Design Museum, the 1998 Edward MacDowell Medal in the Arts, and the 2010 Royal Gold Medal from the Royal Institute of British Architects. In 1983 he was awarded the Pritzker Prize, sometimes referred to as the Nobel Prize of architecture. In its citation, the jury said: \"Ieoh Ming Pei has given this century some of its most beautiful interior spaces and exterior forms ... His versatility and skill in the use of materials approach the level of poetry.\" The prize was accompanied by a US$100,000 award, which Pei used to create a scholarship for Chinese students to study architecture in the U.S., on the condition that they return to China to work. In 1986, he was one of twelve recipients of the Medal of Liberty. When he was awarded the 2003 Henry C. Turner Prize by the National Building Museum, museum board chair Carolyn Brody praised his impact on construction innovation: \"His magnificent designs have challenged engineers to devise innovative structural solutions, and his exacting expectations for construction quality have encouraged contractors to achieve high standards.\" In December 1992, Pei was awarded the Presidential Medal of Freedom by President George H. W. Bush. In 1996, Pei became the first person to be elected a foreign member of the Chinese Academy of Engineering.\n\nPei's wife of over 70 years, Eileen Loo, died on 20 June 2014. Together they had three sons, T'ing Chung (1945–2003), Chien Chung (b. 1946; known as Didi), and Li Chung (b. 1949; known as Sandi); and a daughter, Liane (b. 1960). T'ing Chung was an urban planner and alumnus of his father's \"alma mater\" MIT and Harvard. Chieng Chung and Li Chung, who are both Harvard College and Harvard Graduate School of Design alumni, founded and run Pei Partnership Architects. Liane is a lawyer.\n\nIn 2015, Pei's home health aide, Eter Nikolaishvili, grabbed Pei's right forearm and twisted it, resulting in bruising and bleeding and hospital treatment. Pei alleges that the alleged assault occurred when Pei threatened to call the police about Nikolaishvili. Nikolaishvili agreed to plead guilty in 2016.\n\nPei celebrated his 100th birthday on 26 April 2017. He died peacefully in Manhattan on 16 May 2019 at the age of 102. He was survived by three of his children, seven grandchildren, and five great-grandchildren.\n\nBULLET::::- List of I. M. Pei projects\n\nBULLET::::- Boehm, Gero von. \"Conversations with I. M. Pei: Light Is the Key\". Munich: Prestel, 2000. .\nBULLET::::- Cobb, Henry Nichols (2018). \"Henry N. Cobb: Words and Works 1948–2018: Scenes from a Life in Architecture\". New York: Monacelli Press. .\nBULLET::::- Diamonstein, Barbaralee. \"American Architecture Now\". New York: Rizzoli, 1980. .\nBULLET::::- Heyer, Paul. \"Architects on Architecture: New Directions in America\". New York: Van Nostrand Reinhold, 1993. .\nBULLET::::- Lenci, Ruggero. \"I. M. Pei: teoremi spaziali\". Turin, Testo & Immagine, 2004. .\nBULLET::::- Moeller, Gerard M. and Weeks, Christopher. \"AIA Guide to the Architecture of Washington, D.C.\" Baltimore: Johns Hopkins University Press, 2006.\nBULLET::::- Williams, Paul Kelsey. \"Southwest Washington, D.C.\" Charleston, S.C.: Arcadia, 2005.\nBULLET::::- Wiseman, Carter. \"I. M. Pei: A Profile in American Architecture\". New York: H. N. Abrams, 2001. .\n\nBULLET::::- Pei Partnership Architects\nBULLET::::- Pei Cobb Freed & Partners\nBULLET::::- I. M. Pei at the Digital Archive of American Architecture\nBULLET::::- Pritzker Prize information and acceptance speech\nBULLET::::- Concept sketches for The Musée d'Art Moderne\nBULLET::::- I. M. Pei architecture on Google Maps\n"}
{"id": "15156", "url": "https://en.wikipedia.org/wiki?curid=15156", "title": "ICD (disambiguation)", "text": "ICD (disambiguation)\n\nICD is the International Statistical Classification of Diseases and Related Health Problems, an international standard diagnostic tool.\n\nICD may also refer to:\n\nBULLET::::- Information Control Division, a US Army department in occupied Germany after World War II\nBULLET::::- United States Army Medical Research Institute of Chemical Defense (USAMRICD or ICD)\nBULLET::::- Iranian Club, Dubai, a social club in Dubai, U.A.E.\nBULLET::::- Islamic Corporation for the Development of the Private Sector, an entity of the Islamic Development Bank\n\nBULLET::::- In-circuit debugger, in electronic hardware design\nBULLET::::- MPLAB ICD, an in-circuit debugger; see MPLAB devices\nBULLET::::- Initial Capability Document, a description of system requirements used in United States Department of Defense\nBULLET::::- Interface control document, in system engineering and software engineering\n\nBULLET::::- Interatomic Coulombic decay, a property of atoms and molecules which have neighbors\n\nBULLET::::- Immunogenic cell death\nBULLET::::- Implantable cardioverter-defibrillator\nBULLET::::- Impulse control disorder\nBULLET::::- Intercostal drain\nBULLET::::- Irritant contact dermatitis\nBULLET::::- Isobaric counterdiffusion\nBULLET::::- Doctor of Canon Law (Latin: \"Iuris Canonici Doctor\")\nBULLET::::- Incentive-centered design\nBULLET::::- Inland container depot; see Container Corporation of India\n\nBULLET::::- Intelligence Community Directive 301 (ICD-301)\n"}
{"id": "15158", "url": "https://en.wikipedia.org/wiki?curid=15158", "title": "Islamic Jihad", "text": "Islamic Jihad\n\nIslamic Jihad may refer to:\n\nBULLET::::- Islamic Jihad Movement in Palestine (headquartered in Damascus)\nBULLET::::- Islamic Jihad Organization, active mostly in Lebanon\nBULLET::::- Islamic Jihad Union, active in Afghanistan and Pakistan\nBULLET::::- Islamic Jihad of Yemen\nBULLET::::- Turkish Islamic Jihad\nBULLET::::- Egyptian Islamic Jihad\n\nBULLET::::- Jihad, the Islamic theological concept\n"}
{"id": "15161", "url": "https://en.wikipedia.org/wiki?curid=15161", "title": "Intel 80486", "text": "Intel 80486\n\nThe Intel 80486, also known as the i486 or 486, is the successor model of 32-bit x86 microprocessor to the Intel 80386. Introduced in 1989, the 80486 improved on the performance of the 80386DX thanks to on-die L1 cache and floating-point unit, as well as an improved, five-stage tightly-coupled pipelined design. It was the first x86 chip to use more than a million transistors. It represents the fourth generation of binary compatible CPUs since the original 8086 of 1978.\n\nThe initial model, the 80486DX, was introduced with 25 and 33 MHz models. Later a 50 MHz part was added, then clock-doubled DX2/50 and DX2/66 parts, and later still, clock-tripled DX4/75 and DX4/100 ones.\n\nThe 486DX was later supplemented with the cheaper 80486SX, which was also available in 16 and 20 MHz variants. The \"SX\" and \"DX\" designations matched those of the 80386DX and 80386SX, but had different meanings. For the 486, the SX designation indicated no on-chip FPU. In early 486SX units, the FPU was present but disabled; later models removed it entirely. A supplementary 80487DX upgrade chip was also offered, but this was not an FPU; it was an entire replacement processor that disabled the original SX part.\n\nA 50 MHz 80486 executes around 40 million instructions per second on average and is able to reach 50 MIPS peak performance.\n\nThe 80486 was announced at Spring Comdex in April 1989. At the announcement, Intel stated that samples would be available in the third quarter of 1989 and production quantities would ship in the fourth quarter of 1989. The first 80486-based PCs were announced in late 1989, but some advised that people wait until 1990 to purchase an 80486 PC because there were early reports of bugs and software incompatibilities.\n\nalign=\"center\" \"Intel 80486 registers\"\n\ncolspan=\"8\"  Main registers \"(8/16/32 bits)\"\ncolspan=\"8\"  Index registers \"(16/32 bits)\"\ncolspan=\"8\"  Program counter \"(16/32 bits)\"\ncolspan=\"8\"  Segment selectors \"(16 bits)\"\n\ncolspan=\"20\"  Status register\n\ncolspan=\"3\"  Floating-point registers \"(80 bits)\"\n\nThe instruction set of the i486 is very similar to its predecessor, the Intel 80386, with the addition of only a few extra instructions, such as CMPXCHG which implements a compare-and-swap atomic operation and XADD, a fetch-and-add atomic operation returning the original value (unlike a standard ADD which returns flags only).\n\nFrom a performance point of view, the architecture of the i486 is a vast improvement over the 80386. It has an on-chip unified instruction and data cache, an on-chip floating-point unit (FPU) and an enhanced bus interface unit. Due to the tight pipelining, sequences of simple instructions (such as ALU reg,reg and ALU reg,im) could sustain a single clock cycle throughput (one instruction completed every clock). These improvements yielded a rough doubling in integer ALU performance over the 386 at the same clock rate. A 16-MHz 80486 therefore had a performance similar to a 33-MHz 386, and the older design had to reach 50 MHz to be comparable with a 25-MHz 80486 part.\n\nBULLET::::- An 8 KB on-chip (level 1) SRAM cache stores the most recently used instructions and data (16 KB and/or write-back on some later models). The 386 had no such internal cache but supported a slower off-chip cache (which was not a level 2 cache because there was no internal level 1 cache on the 80386).\nBULLET::::- An enhanced external bus protocol to enable cache coherency and a new burst mode for memory accesses to fill a cacheline of 16 bytes within 5 bus cycles. The 386 needed 8 bus cycles to transfer the same amount of data.\nBULLET::::- Tightly-coupled pipelining completes a simple instruction like ALU \"reg,reg\" or ALU \"reg,im\" every clock cycle (after a latency of several cycles). The 386 needed two clock cycles to do this.\nBULLET::::- Integrated FPU (disabled or absent in SX models) with a dedicated local bus; together with faster algorithms on more extensive hardware than in the i387, this performs floating point calculations faster compared to the i386+i387 combination.\nBULLET::::- Improved MMU performance.\nBULLET::::- New instructions: XADD, BSWAP, CMPXCHG, INVD, WBINVD, INVLPG.\n\nJust as in the 80386, a simple flat 4 GB memory model could be implemented by setting all \"segment selector\" registers to a neutral value in protected mode, or setting (the same) \"segment registers\" to zero in real mode, and using only the 32-bit \"offset registers\" (x86-terminology for general CPU registers used as address registers) as a linear 32-bit virtual address bypassing the segmentation logic. Virtual addresses were then normally mapped onto physical addresses by the paging system except when it was disabled. (\"Real\" mode had no \"virtual\" addresses.) Just as with the 80386, circumventing memory segmentation could substantially improve performance in some operating systems and applications.\n\nOn a typical PC motherboard, either four matched 30-pin (8-bit) SIMMs or one 72-pin (32-bit) SIMM per bank were required to fit the 80486's 32-bit data bus. The address bus used 30-bits (A31..A2) complemented by four byte-select pins (instead of A0,A1) to allow for any 8/16/32-bit selection. This meant that the limit of directly addressable physical memory was 4 gigabytes as well (2 \"32-bit\" words = 2 \"8-bit\" words).\n\nThere are several suffixes and variants. (see Table). Other variants include:\nBULLET::::- \"Intel RapidCAD\": a specially packaged Intel 486DX and a dummy floating-point unit (FPU) designed as pin-compatible replacements for an Intel 80386 processor and 80387 FPU.\nBULLET::::- \"i486SL-NM\": i486SL based on i486SX.\nBULLET::::- \"i487SX (P23N)\": i486DX with one extra pin sold as an FPU upgrade to i486SX systems; When the i487SX was installed, it ensured that an i486SX was present on the motherboard but disabled it, taking over all of its functions.\nBULLET::::- \"i486 OverDrive (P23T/P24T)\": i486SX, i486SX2, i486DX2 or i486DX4. Marked as upgrade processors, some models had different pinouts or voltage-handling abilities from \"standard\" chips of the same speed stepping. Fitted to a coprocessor or \"OverDrive\" socket on the motherboard, worked the same as the i487SX.\n\nThe specified maximal internal clock frequency (on Intel's versions) ranged from 16 to 100 MHz. The 16 MHz i486SX model was used by Dell Computers.\n\nOne of the few 80486 models specified for a 50 MHz bus (486DX-50) initially had overheating problems and was moved to the 0.8-micrometre fabrication process. However, problems continued when the 486DX-50 was installed in local-bus systems due to the high bus speed, making it rather unpopular with mainstream consumers, as local-bus video was considered a requirement at the time, though it remained popular with users of EISA systems. The 486DX-50 was soon eclipsed by the clock-doubled i486DX2, which although running the internal CPU logic at twice the external bus speed (50 MHz), was nevertheless slower due to the external bus running at only 25 MHz. The 486DX2 at 66 MHz (with 33 MHz external bus) was faster than the 486DX-50, overall.\n\nMore powerful 80486 iterations such as the OverDrive and DX4 were less popular (the latter available as an OEM part only), as they came out after Intel had released the next-generation P5 Pentium processor family. Certain steppings of the DX4 also officially supported 50 MHz bus operation, but it was a seldom used feature.\n\n!  Model  CPU/busclock speed  Voltage  L1 cache*  Introduced \n! width=\"520px\"  Notes\n\n<nowiki>*</nowiki>\"WT\" = write-through cache strategy, \"WB\" = write-back cache strategy\n\n80486 compatible processors have been produced by other companies such as IBM, Texas Instruments, AMD, Cyrix, UMC, and SGS Thomson. Some were clones (identical at the microarchitectural level), others were clean room implementations of the Intel instruction-set. (IBM's multiple source requirement is one of the reasons behind its x86-manufacturing since the 80286.) The 80486 was, however, covered by many of Intel's patents covering new R&D as well as that of the prior 80386. Intel and IBM have broad cross-licenses of these patents, and AMD was granted rights to the relevant patents in the 1995 settlement of a lawsuit between the companies.\n\nAMD produced several clones of the 80486 using a 40 MHz bus (486DX-40, 486DX/2-80, and 486DX/4-120) which had no equivalent available from Intel, as well as a part specified for 90 MHz, using a 30 MHz external clock, that was sold only to OEMs. The fastest running 80486 CPU, the Am5x86, ran at 133 MHz and was released by AMD in 1995. 150 MHz and 160 MHz parts were planned but never officially released.\n\nCyrix made a variety of 80486-compatible processors, positioned at the cost-sensitive desktop and low-power (laptop) markets. Unlike AMD's 80486 clones, the Cyrix processors were the result of clean-room reverse-engineering. Cyrix's early offerings included the 486DLC and 486SLC, two hybrid chips which plugged into 386DX or SX sockets respectively, and offered 1 KB of cache (versus 8 KB for the then-current Intel/AMD parts). Cyrix also made \"real\" 80486 processors, which plugged into the i486's socket and offered 2 or 8 KB of cache. Clock-for-clock, the Cyrix-made chips were generally slower than their Intel/AMD equivalents, though later products with 8 KB caches were more competitive, if late to market.\n\nThe Motorola 68040, while not compatible with the 80486, was often positioned as the 80486's equivalent in features and performance. Clock-for-clock basis the Motorola 68040 could significantly outperform the Intel 80486 chip. However, the 80486 had the ability to be clocked significantly faster without suffering from overheating problems. The Motorola 68040 performance lagged behind the later production 80486 systems.\n\nEarly 80486 machines were equipped with several ISA slots (using an emulated PC/AT-bus) and sometimes one or two 8-bit–only slots (compatible with the PC/XT-bus). Many motherboards enabled overclocking of these up from the default 6 or 8 MHz to perhaps 16.7 or 20 MHz (half the i486 bus clock) in a number of steps, often from within the BIOS setup. Especially older peripheral cards normally worked well at such speeds as they often used standard MSI chips instead of slower (at the time) custom VLSI designs. This could give significant performance gains (such as for old video cards moved from a 386 or 286 computer, for example). However, operation beyond 8 or 10 MHz could sometimes lead to stability problems, at least in systems equipped with SCSI or sound cards.\n\nSome motherboards came equipped with a 32-bit bus called EISA that was backward compatible with the ISA-standard. EISA offered a number of attractive features such as increased bandwidth, extended addressing, IRQ sharing, and card configuration through software (rather than through jumpers, DIP switches, etc.) However, EISA cards were expensive and therefore mostly employed in servers and workstations. Consumer desktops often used the simpler but faster VESA Local Bus (VLB), unfortunately somewhat prone to electrical and timing-based instability; typical consumer desktops had ISA slots combined with a single VLB slot for a video card. VLB was gradually replaced by PCI during the final years of the 80486 period. Few Pentium class motherboards had VLB support as VLB was based directly on the i486 bus; it was no trivial matter adapting it to the quite different P5 Pentium-bus. ISA persisted through the P5 Pentium generation and was not completely displaced by PCI until the Pentium III era.\n\nLate 80486 boards were normally equipped with both PCI and ISA slots, and sometimes a single VLB slot as well. In this configuration VLB or PCI throughput suffered depending on how buses were bridged. Initially, the VLB slot in these systems was usually fully compatible only with video cards (quite fitting as \"VESA\" stands for \"Video Electronics Standards Association\"); VLB-IDE, multi I/O, or SCSI cards could have problems on motherboards with PCI slots. The VL-Bus operated at the same clock speed as the i486-bus (basically \"being\" a local 80486-bus) while the PCI bus also usually depended on the i486 clock but sometimes had a divider setting available via the BIOS. This could be set to 1/1 or 1/2, sometimes even 2/3 (for 50 MHz CPU clocks). Some motherboards limited the PCI clock to the specified maximum of 33 MHz and certain network cards depended on this frequency for correct bit-rates. The ISA clock was typically generated by a divider of the CPU/VLB/PCI clock (as implied above).\n\nOne of the earliest complete systems to use the 80486 chip was the Apricot VX FT, produced by British hardware manufacturer Apricot Computers. Even overseas in the United States it was popularised as \"The World's First 80486\" in the September 1989 issue of \"Byte\" magazine (shown right).\n\nLater 80486 boards also supported Plug-And-Play, a specification designed by Microsoft that began as a part of Windows 95 to make component installation easier for consumers.\n\nThe 486DX2 66 MHz processor was popular on home-oriented PCs during the early to mid 1990s, toward the end of the MS-DOS gaming era. It was often coupled with a VESA Local Bus video card.\n\nThe introduction of 3D computer graphics spelled the end of the 80486's reign, because 3D graphics make heavy use of floating-point calculations and require a faster CPU cache and more memory bandwidth. Developers began to target the P5 Pentium processor family almost exclusively with x86 assembly language optimizations (e.g., \"Quake\") which led to the usage of terms like \"Pentium-compatible processor\" for software requirements. Many of these games required the speed of the P5 Pentium processor family's double-pipelined architecture.\nThe AMD Am5x86, up to 133 MHz, and Cyrix Cx5x86, up to 120 MHz, were the last 80486 processors that were often used in late generation 80486 motherboards with PCI slots and 72-pin SIMMs that are designed to be able to run Windows 95, and also often used as upgrades for older 80486 motherboards. While the Cyrix Cx5x86 faded quite quickly when the Cyrix 6x86 took over, the AMD Am5x86 was important during the time when the AMD K5 was delayed.\n\n80486-based machines remained popular through the late 1990s, serving as low end processors for entry level PCs. Production for traditional desktop and laptop systems ceased in 1998, when Intel introduced the Celeron brand as an modern replacement for the aging chip, though it continued to be produced for embedded systems through the late 2000's.\n\nIn the general-purpose desktop computer role, 80486-based machines remained in use into the early 2000s, especially as Windows 95, Windows 98, and Windows NT 4.0 were the latest Microsoft operating systems to officially support installation on an 80486-based system. However, as Windows 95/98 and Windows NT 4.0 were eventually overtaken by newer operating systems, 80486 systems likewise fell out of use. Still, a number of 80486 machines have remained in use today, mostly for backward compatibility with older programs (most notably games), especially since many of them have problems running on newer operating systems. However, DOSBox is also available for current operating systems and provides emulation of the 80486 instruction set, as well as full compatibility with most DOS-based programs.\n\nAlthough the 80486 was eventually overtaken by the Pentium for personal computer applications, Intel had continued production for use in embedded systems. In May 2006 Intel announced that production of the 80486 would stop at the end of September 2007.\n\nBULLET::::- List of Intel microprocessors\nBULLET::::- Motorola 68040, although not compatible, was often positioned as the Motorola equivalent to the Intel 80486 in terms of performance and features.\n\nBULLET::::- Intel486 datasheets\nBULLET::::- Low power SX and DX with variable freq. Dec 1992\nBULLET::::- EMBEDDED ULTRA-LOW POWER Intel 486 SX\nBULLET::::- Embedded Write-Back Enhanced Intel DX4. Oct 1995\nBULLET::::- Intel 80486 images and descriptions at cpu-collection.de\nBULLET::::- Die photo of Intel 486DX\n"}
{"id": "15164", "url": "https://en.wikipedia.org/wiki?curid=15164", "title": "Intel 80486SX", "text": "Intel 80486SX\n\nIntel's i486SX was a modified Intel 486DX microprocessor with its floating-point unit (FPU) disabled. It was intended as a lower-cost CPU for use in low-end systems. Computer manufacturers that used these processors include Packard Bell, Compaq, ZEOS and IBM.\n\nIn the early 1990s, common applications did not need or benefit from an FPU. Among the rare exceptions were CAD applications, which could often simulate floating point operations in software, but benefited from a hardware floating point unit immensely. AMD had begun manufacturing its 386DX clone which was faster than Intel's. To respond to this new situation Intel wanted to provide a lower cost i486 CPU for system integrators, but without sacrificing the better profit margins of a \"full\" i486. This was accomplished through a debug feature called Disable Floating Point (DFP), by grounding a certain bond wire in the CPU package. The i486SX was introduced in mid-1991 at 20 Mhz in a PGA package. Later (1992) versions of the i486SX had the FPU entirely removed for cost cutting reasons and comes in surface mount packages as well.\n\nMany systems allowed the user to upgrade the i486SX to a CPU with the FPU enabled. The upgrade was shipped as the i487, which was a full blown i486DX chip with an extra pin. The extra pin prevents the chip from being installed incorrectly. The NC# pin, one of the standard 168 pins, was used to shut off the i486SX. Although i486SX devices were not used at all when the i487 was installed, they were hard to remove because the i486SX was typically installed in non-ZIF sockets or in a plastic package that was surface mounted on the motherboard. Later OverDrive processors also plugged into the socket and offered performance enhancements as well.\n\nBULLET::::- Intel 80486SX images and descriptions at cpu-collection.de\nIntel Datasheets\nBULLET::::- Embedded i486SX\nBULLET::::- Embedded Ultra-Low Power i486SX\n"}
{"id": "15165", "url": "https://en.wikipedia.org/wiki?curid=15165", "title": "Ivory", "text": "Ivory\n\nIvory is a hard, white material from the tusks (traditionally elephants') and teeth of animals, that consists mainly of dentine, one of the physical structures of teeth and tusks. The chemical structure of the teeth and tusks of mammals is the same, regardless of the species of origin. The trade in certain teeth and tusks other than elephant is well established and widespread; therefore, \"ivory\" can correctly be used to describe any mammalian teeth or tusks of commercial interest which are large enough to be carved or scrimshawed. \n\nIvory has been valued since ancient times in art or manufacturing for making a range of items from ivory carvings to false teeth, piano keys, fans, dominoes and joint tubes. Elephant ivory is the most important source, but ivory from mammoth, walrus, hippopotamus, sperm whale, killer whale, narwhal and warthog are used as well. Elk also have two ivory teeth, which are believed to be the remnants of tusks from their ancestors.\n\nThe national and international trade in ivory of threatened species such as African and Asian elephants is illegal. The word \"ivory\" ultimately derives from the ancient Egyptian \"âb, âbu\" (\"elephant\"), through the Latin \"ebor-\" or \"ebur\".\n\nBoth the Greek and Roman civilizations practiced ivory carving to make large quantities of high value works of art, precious religious objects, and decorative boxes for costly objects. Ivory was often used to form the white of the eyes of statues.\n\nThere is some evidence of either whale or walrus ivory used by the ancient Irish. Solinus, a Roman writer in the 3rd century claimed that the Celtic peoples in Ireland would decorate their sword-hilts with the 'teeth of beasts that swim in the sea'. Adomnan of Iona wrote a story about St Columba giving a sword decorated with carved ivory as a gift that a penitent would bring to his master so he could redeem himself from slavery.\n\nThe Syrian and North African elephant populations were reduced to extinction, probably due to the demand for ivory in the Classical world.\n\nThe Chinese have long valued ivory for both art and utilitarian objects. Early reference to the Chinese export of ivory is recorded after the Chinese explorer Zhang Qian ventured to the west to form alliances to enable the eventual free movement of Chinese goods to the west; as early as the first century BC, ivory was moved along the Northern Silk Road for consumption by western nations. Southeast Asian kingdoms included tusks of the Indian elephant in their annual tribute caravans to China. Chinese craftsmen carved ivory to make everything from images of deities to the pipe stems and end pieces of opium pipes.\n\nThe Buddhist cultures of Southeast Asia, including Myanmar, Thailand, Laos and Cambodia, traditionally harvested ivory from their domesticated elephants. Ivory was prized for containers due to its ability to keep an airtight seal. It was also commonly carved into elaborate seals utilized by officials to \"sign\" documents and decrees by stamping them with their unique official seal.\n\nIn Southeast Asian countries, where Muslim Malay peoples live, such as Malaysia, Indonesia and the Philippines, ivory was the material of choice for making the handles of kris daggers. \nIn the Philippines, ivory was also used to craft the faces and hands of Catholic icons and images of saints prevalent in the Santero culture.\n\nTooth and tusk ivory can be carved into a vast variety of shapes and objects. Examples of modern carved ivory objects are okimono, netsukes, jewelry, flatware handles, furniture inlays, and piano keys. Additionally, warthog tusks, and teeth from sperm whales, orcas and hippos can also be scrimshawed or superficially carved, thus retaining their morphologically recognizable shapes.\n\nIvory usage in the last thirty years has moved towards mass production of souvenirs and jewelry. In Japan, the increase in wealth sparked consumption of solid ivory \"hanko\" – name seals – which before this time had been made of wood. These \"hanko\" can be carved out in a matter of seconds using machinery and were partly responsible for massive African elephant decline in the 1980s, when the African elephant population went from 1.3 million to around 600,000 in ten years.\n\nPrior to the introduction of plastics, ivory had many ornamental and practical uses, mainly because of the white color it presents when processed. It was formerly used to make cutlery handles, billiard balls, piano keys, Scottish bagpipes, buttons and a wide range of ornamental items.\n\nSynthetic substitutes for ivory in the use of most of these items have been developed since 1800: the billiard industry challenged inventors to come up with an alternative material that could be manufactured; the piano industry abandoned ivory as a key covering material in the 1970s.\n\nIvory can be taken from dead animals – however, most ivory came from elephants that were killed for their tusks. For example, in 1930 to acquire 40 tons of ivory required the killing of approximately 700 elephants. Other animals which are now endangered were also preyed upon, for example, hippos, which have very hard white ivory prized for making artificial teeth. In the first half of the 20th century, Kenyan elephant herds were devastated because of demand for ivory, to be used for piano keys.\n\nDuring the Art Deco era from 1912 to 1940, dozens (if not hundreds) of European artists used ivory in the production of chryselephantine statues. Two of the most frequent users of ivory in their sculptured artworks were Ferdinand Preiss and Claire Colinet.\n\nOwing to the rapid decline in the populations of the animals that produce it, the importation and sale of ivory in many countries is banned or severely restricted. In the ten years preceding a decision in 1989 by CITES to ban international trade in African elephant ivory, the population of African elephants declined from 1.3 million to around 600,000. It was found by investigators from the Environmental Investigation Agency (EIA) that CITES sales of stockpiles from Singapore and Burundi (270 tonnes and 89.5 tonnes respectively) had created a system that increased the value of ivory on the international market, thus rewarding international smugglers and giving them the ability to control the trade and continue smuggling new ivory.\n\nSince the ivory ban, some Southern African countries have claimed their elephant populations are stable or increasing, and argued that ivory sales would support their conservation efforts. Other African countries oppose this position, stating that renewed ivory trading puts their own elephant populations under greater threat from poachers reacting to demand. CITES allowed the sale of 49 tonnes of ivory from Zimbabwe, Namibia and Botswana in 1997 to Japan.\n\nIn 2007, under pressure from the International Fund for Animal Welfare, eBay banned all international sales of elephant-ivory products. The decision came after several mass slaughters of African elephants, most notably the 2006 Zakouma elephant slaughter in Chad. The IFAW found that up to 90% of the elephant-ivory transactions on eBay violated their own wildlife policies and could potentially be illegal. In October 2008, eBay expanded the ban, disallowing any sales of ivory on eBay.\n\nA more recent sale in 2008 of 108 tonnes from the three countries and South Africa took place to Japan and China. The inclusion of China as an \"approved\" importing country created enormous controversy, despite being supported by CITES, the World Wide Fund for Nature and Traffic. They argued that China had controls in place and the sale might depress prices. However, the price of ivory in China has skyrocketed. Some believe this may be due to deliberate price fixing by those who bought the stockpile, echoing the warnings from the Japan Wildlife Conservation Society on price-fixing after sales to Japan in 1997, and monopoly given to traders who bought stockpiles from Burundi and Singapore in the 1980s.\n\nDespite arguments prevailing on the ivory trade for the last thirty years through CITES, there is one fact upon which virtually all informed parties now agree – poaching of African elephants for ivory is now seriously on the increase.\n\nThe debate surrounding ivory trade has often been depicted as Africa vs the West. However, in reality the southern Africans have always been in a minority within the African elephant range states. To reiterate this point, 19 African countries signed the \"Accra Declaration\" in 2006 calling for a total ivory trade ban, and 20 range states attended a meeting in Kenya calling for a 20-year moratorium in 2007.\n\nThe use and trade of elephant ivory have become controversial because they have contributed to seriously declining elephant populations in many countries. It is estimated that consumption in Great Britain alone in 1831 amounted to the deaths of nearly 4,000 elephants. In 1975, the Asian elephant was placed on Appendix I of the Convention on International Trade in Endangered Species (CITES), which prevents international trade between member states of species that are threatened by trade. The African elephant was placed on Appendix I in January 1990. Since then, some southern African countries have had their populations of elephants \"downlisted\" to Appendix II, allowing the domestic trade of non-ivory items; there have also been two \"one off\" sales of ivory stockpiles.\n\nIn June 2015, more than a ton of confiscated ivory was crushed in New York's Times Square by the Wildlife Conservation Society to send a message that the illegal trade will not be tolerated. The ivory, confiscated in New York and Philadelphia, was sent up a conveyor belt into a rock crusher. The Wildlife Conservation Society has pointed out that the global ivory trade leads to the slaughter of up to 35,000 elephants a year in Africa. In June 2018, Conservative MEPs’ Deputy Leader Jacqueline Foster MEP urged the EU to follow the UK's lead and introduce a tougher ivory ban across Europe.\n\nChina was the biggest market for poached ivory but announced they would phase out the legal domestic manufacture and sale of ivory products in May 2015. In September of the same year, China and the U.S. announced they would \"enact a nearly complete ban on the import and export of ivory.\" The Chinese market has a high degree of influence on the elephant population.\n\nTrade in the ivory from the tusks of dead woolly mammoths frozen in the tundra has occurred for 300 years and continues to be legal. Mammoth ivory is used today to make handcrafted knives and similar implements. Mammoth ivory is rare and costly because mammoths have been extinct for millennia, and scientists are hesitant to sell museum-worthy specimens in pieces. Some estimates suggest that 10 million mammoths are still buried in Siberia.\n\nA species of hard nut is gaining popularity as a replacement for ivory, although its size limits its usability. It is sometimes called vegetable ivory, or tagua, and is the seed endosperm of the ivory nut palm commonly found in coastal rainforests of Ecuador, Peru and Colombia.\n\nFossil walrus ivory from animals that died before 1972 is legal to buy and sell or possess in the United States, unlike many other types of ivory.\n\nBULLET::::- Destruction of ivory\nBULLET::::- Ivory carving\nBULLET::::- Ivory tower\nBULLET::::- Vegetable ivory\nBULLET::::- Walrus ivory\nBULLET::::- Jim Nyamu\n\nBULLET::::- TRAFFIC; \"New report confirms ‘major surge’ in ivory smuggling in 2011\"\nBULLET::::- EIA \"Blood Ivory: Exposing the myth of a regulated market\"\nBULLET::::- Federation of Environmental Organizations Sri Lanka: \"Blood Ivory to Buddhist Temples?\"\nBULLET::::- Gemological properties of ivory\nBULLET::::- The International Ivory Society\n"}
{"id": "15166", "url": "https://en.wikipedia.org/wiki?curid=15166", "title": "Infantry fighting vehicle", "text": "Infantry fighting vehicle\n\nAn infantry fighting vehicle (\"IFV\"), also known as a mechanized infantry combat vehicle (\"MICV\"), is a type of armoured fighting vehicle used to carry infantry into battle and provide direct-fire support. The 1990 Treaty on Conventional Armed Forces in Europe defines an infantry fighting vehicle as \"an armoured combat vehicle which is designed and equipped primarily to transport a combat infantry squad, and which is armed with an integral or organic cannon of at least 20 millimeters calibre and sometimes an antitank missile launcher\". IFVs often serve both as the principal weapons system and as the mode of transport for a mechanized infantry unit. \n\nInfantry fighting vehicles are distinct from armored personnel carriers (APCs), which are transport vehicles armed only for self-defense and not specifically engineered to fight on their own. IFVs are designed to be more mobile than tanks and are equipped with a rapid-firing autocannon or a large conventional gun; they may include side ports for infantrymen to fire their personal weapons while on board. \n\nThe IFV rapidly gained popularity with armies worldwide due to a demand for vehicles with high firepower that were less expensive and easier to maintain than tanks. Nevertheless, it did not supersede the APC concept altogether, due to the latter's continued usefulness in specialized roles. Some armies continue to maintain fleets of both IFVs and APCs.\n\nThe infantry fighting vehicle (IFV) concept evolved directly out of that of the armored personnel carrier (APC). During the Cold War, there was an increasing trend towards fitting heavier and heavier weapons systems on an APC chassis to deliver suppressive covering fire as infantry debussed from the vehicle's troop compartment. With the growing mechanization of infantry units worldwide, some armies also came to believe that the embarked personnel should fire their weapons from inside the protection of the APC and only fight on foot as a last resort. These two trends led to the IFV, which had firing ports in the troop compartment and a crew-manned weapons system. The IFV established a new niche between combat vehicles which functioned primarily as armored weapons-carriers and APCs.\n\nDuring the 1950s, Soviet, US, and most Western European armies had adopted tracked APCs. In 1958, however, the newly-organized Bundeswehr adopted the Schützenpanzer Lang HS.30 (also known simply as the \"SPz 12-3\"), which resembled a conventional tracked APC but carried a turret-mounted 20 mm autocannon that enabled it to engage other armored vehicles. The SPz 12-3 is widely considered the first purpose-built IFV. The Bundeswehr's doctrine called for mounted infantry to fight and maneuver alongside tank formations rather than simply being ferried to the edge of the battlefield before dismounting. Each SPz 12-3 could carry five troops in addition to a three- man crew. Despite this, it lacked firing ports, forcing the embarked infantry to expose themselves through open hatches to return fire.\n\nAs the SPz 12-3 was being inducted into service, the French and Austrian armies adopted new APCs which possessed firing ports, allowing embarked infantry to observe and fire their weapons from inside the vehicle. These were known as the AMX-VCI and Saurer 4K, respectively. Austria subsequently introduced an IFV variant of the Saurer 4K which carried a 20 mm autocannon, making it the first vehicle of this class to possess both firing ports and a turreted weapons system. In the mid-1960s, the Swedish Army also adopted a variant of the Pansarbandvagn 302 APC which carried a 20 mm autocannon. Following the trend towards converting preexisting APCs into IFVs, the Dutch, US, and Belgian armies experimented with a variety of modified M113s during the late 1960s; these were collectively identified as the AIFV. The first US M113-based IFV appeared in 1969; known as the XM765, it had a sharply angled hull, ten vision blocks, a cupola-mounted 20 mm autocannon. The XM765 design was rejected for service but later became the basis for the very similar Dutch YPR-765. The YPR-765 had five firing ports and a 25 mm autocannon with a co-axial machine gun.\n\nThe Soviet Army had fielded its first tracked APC, the BTR-50, in 1957. Its first wheeled APC, the BTR-152, had been designed as early as the late 1940s. Early versions of both these lightly armored vehicles were open-topped and carried only general-purpose machine guns for armament. As Soviet strategists became more preoccupied with the possibility of a war involving weapons of mass destruction, they became convinced of the need to deliver mounted troops to a battlefield without exposing them to the radioactive fallout from an atomic weapon. The IFV concept was received favorably because it would enable a Soviet infantry squad to fight from inside their vehicles when operating in contaminated environments. Design work on a new tracked IFV began in the late 1950s and the first prototype appeared as the \"Obyekt 765\" in 1961. After the Soviets had evaluated and rejected a number of other wheeled and tracked prototypes, the \"Obyekt 765\" was accepted for service; it entered serial production as the BMP-1 in 1966. In addition to being amphibious and superior in cross-country mobility to its predecessors, the BMP-1 carried a 73mm smoothbore cannon, a co-axial PKT machine gun, and a launcher for 9M14 Malyutka anti-tank missiles. Its hull was also heavily armored enough to resist .50 caliber armor-piercing ammunition along its frontal arc. Eight firing ports and vision blocks allowed the embarked infantry squad to observe and engage targets with rifles or machine guns. The BMP-1 was so heavily armed and armored that it was widely regarded as having combined the qualities of a light tank with those of the traditional APC.\nIts use of a relatively large caliber main gun marked a notable departure from the Western trend of fitting IFVs with automatic cannon, which were more suitable for engaging low-flying aircraft, light armor, and dismounted personnel. About 20,000 BMP-1s were produced in the Soviet Union from 1966 to 1983, at which time it was regarded as the most ubiquitous IFV in the world. In Soviet service, the BMP-1 was ultimately superseded by the more sophisticated BMP-2 (in service from 1980) and the BMP-3 (in servce from 1987). A similar vehicle known as the BMD-1 was designed to accompany Soviet airborne infantry and for a number of years was the world's only airborne IFV.\n\nIn 1971 the Bundeswehr adopted the Marder, which became increasingly heavily armored through its successive marks and like the BMP was later fitted as standard with a launcher for anti-tank guided missiles. Between 1973 and 1975, the French and Yugoslav armies developed the AMX-10P and BVP M-80, respectively, which were the first amphibious IFVs to appear outside the Soviet Union. The Marder, AMX-10P, and M-80 were all armed with similar 20 mm autocannon and carried seven to eight passengers. They could also be armed with various anti-tank missile configurations.\n\nWheeled IFVs did not begin appearing until 1976, when the Ratel was introduced in response to a South African Army specification for a wheeled combat vehicle suited to the demands of rapid offensives combining maximum firepower and strategic mobility. Unlike European IFVs, the Ratel was not designed to allow mounted infantrymen to fight in concert with tanks but rather to operate independently across vast distances. South African officials chose a very simple, economical design because it helped reduce the significant logistical commitment necessary to keep heavier combat vehicles operational in undeveloped areas. Excessive track wear was also an issue in the region's abrasive, sandy terrain, making the Ratel's wheeled configuration more attractive. The Ratel was typically armed with a 20 mm autocannon featuring what was then a unique twin-linked ammunition feed, allowing its gunner to rapidly switch between armor-piercing or high-explosive ammunition. Other variants were also fitted with mortars, a bank of anti-tank guided missiles, or a 90 mm cannon. Most notably, the Ratel was the first mine-protected IFV; it had a blastproof hull and was built to withstand the explosive force of anti-tank mines favored by local insurgents. Like the BMP-1, the Ratel proved to be a major watershed in IFV development, albeit for different reasons: until its debut wheeled IFV designs were evaluated unfavorably, since they lacked the weight-carrying capacity and off-road mobility of tracked vehicles, and their wheels were more vulnerable to hostile fire. However, during the 1970s improvements in power trains, suspension technology, and tires had increased their potential strategic mobility. Reduced production, operation, and maintenance costs also helped make wheeled IFVs attractive to several nations.\n\nDuring the late 1960s and early 1970s, the US Army had gradually abandoned its attempts to utilize the M113 as an IFV and refocused on creating a dedicated IFV design able to match the BMP. Although considered reliable, the M113 chassis did not meet the necessary requirements for protection or stealth. The US also considered the M113 too heavy and slow to serve as an IFV capable of keeping pace with tanks. Its MICV-65 program produced a number of unique prototypes, none of which were accepted for service owing to concerns about speed, armor protection, and weight. US Army evaluation staff were sent to Europe to review the AMX-10P and the Marder, both of which were rejected due to high cost, insufficient armor, or lackluster amphibious capabilities.\n\nIn 1973, the FMC Corporation developed and tested the XM723, which was a 21-ton tracked chassis which could accommodate three crew members and eight passengers. It initially carried a single 20 mm autocannon in a one-man turret but in 1976 a two-man turret was introduced; this carried a 25 mm autocannon, a co-axial machine gun, and a TOW anti-tank missile launcher. The XM723 possessed amphibious capability, nine firing ports, and spaced laminate armor on its hull. It was accepted for service with the US Army in 1980 as the Bradley Fighting Vehicle. Successive variants have been retrofitted with improved missile systems, gas particulate filter systems, Kevlar spall liners, and increased stowage. The amount of space taken up by the hull and stowage modifications has reduced the number of passengers to six.\n\nBy 1982 30,000 IFVs had entered service worldwide, and the IFV concept appeared in the doctrines of 30 national armies. The popularity of the IFV was increased by the growing trend on the part of many nations to mechanize armies previously dominated by light infantry. However, contrary to expectation the IFV did not render APCs obsolete. The US, Russian, French, and German armies have all retained large fleets of IFVs and APCs, finding the APC more suitable for multi-purpose or auxiliary roles. The British Army was one of the few Western armies which had neither recognized a niche for IFVs nor adopted a dedicated IFV design by the late 1970s. In 1980, it made the decision to adopt a new tracked armored vehicle, the FV510 Warrior. While normally classified as an IFV, the Warrior fills the role of an APC in British service and infantrymen do not remain embarked during combat.\n\nThe role of the IFV is closely linked to mechanized infantry doctrine. While some IFVs are armed with an organic direct fire gun or anti-tank guided missiles for close infantry support, they are not intended to assault armored and mechanized forces with any type of infantry on their own, mounted or not. Rather, the IFV's role is to give an infantry unit battlefield, tactical, and operational mobility during combined arms operations. Most IFVs either complement tanks as part of an armored battalion, brigade, or division; others perform traditional infantry missions supported by tanks. Early development of IFVs in a number of Western nations was promoted primarily by armor officers who wanted to integrate tanks with supporting infantry in armored divisions. There were a few exceptions to the rule: for example, the Bundeswehr's decision to adopt the SPz 12-3 was largely due to the experiences of Wehrmacht panzergrenadiers who had been inappropriately ordered to undertake combat operations better suited for armor. Hence, the Bundeswehr concluded that infantry should only fight while mounted in their own armored vehicles, ideally supported by tanks. This doctrinal trend was later subsumed into the armies of other Western nations, including the US, leading to the widespread conclusion that IFVs should be confined largely to assisting the forward momentum of tanks. The Soviet Army granted more flexibility in this regard to its IFV doctrine, allowing for the mechanized infantry to occupy terrain that compromised an enemy defense, carry out flanking movements, or lure armor into ill-advised counterattacks. While they still performed an auxiliary role to tanks, the notion of using IFVs in these types of engagements dictated that they be heavily armed, which was reflected in the BMP-1 and its successors. Additionally, Soviet airborne doctrine made use of the BMD series of IFVs to operate in concert with paratroops rather than traditional mechanized or armored formations.\n\nIFVs assumed a new significance after the Yom Kippur War. In addition to heralding the combat debut of the BMP-1, that conflict demonstrated the newfound significance of anti-tank guided missiles and the obsolescence of independent armored attacks. More emphasis was placed on combined arms offensives, and the importance of mechanized infantry to support tanks reemerged. As a result of the Yom Kippur War, the Soviet Union attached more infantry to its armored formations and the US accelerated its long-delayed IFV development program. An IFV capable of accompanying tanks for the purpose of suppressing anti-tank weapons and the hostile infantry which operated them was seen as necessary to avoid the devastation wreaked on purely armored Israeli formations.\n\nThe US Army defines all vehicles classed as IFVs as having three essential characteristics: they are armed with at least a medium-caliber cannon or automatic grenade launcher, at least sufficiently protected against small arms fire, and possess off-road mobility. It also identifies all IFVs as having some characteristics of an APC and a light tank. \n\nThe United Nations Register for Conventional Arms (UNROCA) simply defines an IFV as any armored vehicle \"designed to fight with soldiers on board\" and \"to accompany tanks\". UNROCA makes a clear distinction between IFVs and APCs, as the former's primary mission is combat rather than general transport.\n\nAll IFVs possess armored hulls protected against rifle and machine gun fire, and some are equipped with active protection systems. Most have lighter armor than main battle tanks to ensure mobility. Armies have generally accepted risk in reduced protection to recapitalize on an IFV's mobility, weight and speed. Their fully enclosed hulls offer protection from artillery fragments and residual environmental contaminants as well as limit exposure time to the mounted infantry during extended movements over open ground. Many IFVs also have sharply angled hulls that offer a relatively high degree of protection for their armor thickness. The BMP, Boragh, BVP M-80, and their respective variants all possess steel hulls with a distribution of armor and steep angling that protect them during frontal advances. The BMP-1 was vulnerable to heavy machine guns at close range on its flanks or rear, leading to a variety of more heavily armored marks appearing from 1979 onward. The Bradley possessed a lightweight aluminum alloy hull, which in most successive marks has been bolstered by the addition of explosive reactive and slat armor, spaced laminate belts, and steel track skirts. Throughout its life cycle, an IFV is expected to gain 30% more weight from armor additions.\n\nAs asymmetric conflicts become more common, an increasing concern with regards to IFV protection has been adequate countermeasures against land mines and improvised explosive devices. During the Iraq War, inadequate mine protection in US Bradleys forced their crews to resort to makeshift strategies such as lining the hull floors with sandbags. A few IFVs, such as the Ratel, have been specifically engineered to resist mine explosions.\n\nIFVs are equipped with turrets carrying autocannons of various calibers between 20mm - 57mm, 73mm - 100mm low or medium velocity tank guns, anti-tank guided missiles, or automatic grenade launchers.\n\nWith a few exceptions, such as the BMP-1 and the BMP-3, designs such as the Marder and the BMP-2 have set the trend of arming IFVs with an autocannon suitable for use against lightly armored vehicles, low-flying aircraft, and dismounted infantry. This reflected the growing inclination to view IFVs as auxiliaries of armored formations: a small or medium caliber autocannon was perceived as an ideal suppressive weapon to complement large caliber tank fire. IFVs armed with miniature tank guns did not prove popular because many of the roles they were expected to perform were better performed by accompanying tanks. \n\nThe BMP-1, which was the first IFV to carry a relatively large cannon, came under criticism during the Yom Kippur War for its mediocre individual accuracy, due in part to the low velocities of its projectiles. During the Soviet–Afghan War, BMP-1 crews also complained that their armament lacked the elevation necessary to engage insurgents in mountainous terrain. The effectiveness of large caliber, low-velocity guns like the 2A28 Grom on the BMP-1 and BMD-1 was also much reduced by the appearance of Chobham armor on Western tanks. The Ratel, which included a variant armed with a 90mm low-velocity gun, was utilized in South African combat operations against Angolan and Cuban armored formations during the South African Border War, with mixed results. Although the Ratels succeeded in destroying a large number of Angolan tanks and APCs, they were hampered by many of the same problems as the BMP-1: mediocre standoff ranges, inferior fire control, and a lack of stabilized main gun. The Ratels' heavy armament also tempted South African commanders to utilize them as light tanks rather than in their intended role of infantry support.\n\nAnother design feature of the BMP-1 did prove more successful in establishing a precedent for future IFVs: its inclusion of an anti-tank missile system. This consisted of a rail-launcher firing 9M14 Malyutka missiles which had to be reloaded manually from outside the BMP's turret. Crew members had to expose themselves to enemy fire to reload the missiles, and they could not guide them effectively from inside the confines of the turret space. The BMP-2 and later variants of the BMP-1 made use of semiautonomous guided missile systems. In 1978, the Bundeswehr became the first Western army to embrace this trend when it retrofitted all its Marders with launchers for MILAN anti-tank missiles. The US Army added a launcher for TOW anti-tank missiles to its fleet of Bradleys, despite the fact that this greatly reduced the interior space available for seating the embarked infantry. This was justified on the basis that the Bradley needed to not only engage and destroy other IFVs, but support tanks in the destruction of other tanks during combined arms operations.\n\nIFVs are designed to have the strategic and tactical mobility necessary to keep pace with tanks during rapid maneuvers. Some, like the BMD series, have airborne and amphibious capabilities. IFVs may be either wheeled or tracked; tracked IFVs are usually more heavily armored and possess greater carrying capacity. Wheeled IFVs are cheaper and simpler to produce, maintain, and operate. From a logistical perspective, they are also ideal for an army without widespread access to transporters or a developed rail network to deploy its armor.\n\nBULLET::::- List of AFVs\nBULLET::::- List of modern armoured fighting vehicles\nBULLET::::- Armoured personnel carrier\nBULLET::::- Armoured warfare\nBULLET::::- BMP development\nBULLET::::- Improvised fighting vehicle\nBULLET::::- Mechanized infantry\nBULLET::::- Tank desant\nBULLET::::- Armored car (military)\n"}
{"id": "15167", "url": "https://en.wikipedia.org/wiki?curid=15167", "title": "ICQ", "text": "ICQ\n\nICQ is a cross-platform instant messaging and VoIP client. The name ICQ derives from the English phrase \"I Seek You\". Originally developed by the Israeli company Mirabilis in 1996, the client was bought by AOL in 1998, and then by Mail.Ru Group in 2010.\n\nThe ICQ client application and service were initially released in November 1996, freely available to download. ICQ was among the first stand-alone instant messenger (IM) — while real-time chat was not in itself new (Internet Relay Chat (IRC) being the most common platform at the time), the concept of a fully centralized service with individual user accounts focused on one-on-one conversations set the blueprint for later instant messaging services like AIM, and its influence is seen in modern social media applications. ICQ became the first widely adopted IM platform.\n\nAt its peak around 2001, ICQ had more than 100 million accounts registered. At the time of the Mail.Ru acquisition in 2010, there were around 42 million daily users. Since 2013, ICQ has 11 million monthly users.\n\nBULLET::::- ICQ features include offline user messaging, multi-user chats, free daily-limited SMS sending, resumable file transfers, greeting cards, multiplayer video games and a searchable user directory. Users can use emoticons while chatting with other users.\nBULLET::::- ICQ6 was launched on April 17, 2007, and offered a single communication platform that combines the various user options: instant messaging services, free SMS from ICQ to mobile, voice and video communication. The software's sounds were created by the Israeli psychedelic trance duo Infected Mushroom. Among the new additional features in ICQ6 are Quick IM, which allows users to send a short message without opening a conversation window, a \"follow me\" service directly to the user’s mobile, a multi-chat service and support for Zlango, the animated icons language.\n\nICQ provides all users with additional services and content products:\nBULLET::::1. ICQ TV—An online video magazine. The magazine broadcasts content for teens 24/7.\nBULLET::::2. ICQ SIM Card (together with United Mobile)—A SIM card that enables users traveling across Europe to use their cellular telephones while paying a discount price.\nBULLET::::3. ICQ Game Center—A games platform that enables the user to play with and/or against other users. Available by clicking a button in the contact list.\nBULLET::::4. ICQ2Go—A web instant messaging option for users who cannot download the program onto their computers or use it on the networks they are accessing (for various reasons, like security restrictions or firewalls).\nBULLET::::5. ICQ for Mac (Beta)—Released in February 2010, a version of the client that was developed using the Adobe AIR platform, making it usable on additional operating systems which support the AIR runtime, such as Linux.\nAlso, users can choose and select their own avatars for their profile pages. In this way, they can protect their privacy.\n\nICQ users are identified and distinguished from one another by UIN, or User Identification Numbers, distributed in sequential order. The UIN was invented by Mirabilis, as the user name assigned to each user upon registration. Issued UINs started at '10,000' (5 digits) and every user receives a UIN when first registering with ICQ. As of ICQ6 users are also able to log in using the specific e-mail address they associated with their UIN during the initial registration process.\nUnlike other instant messaging software or web applications, on ICQ the only permanent user info is the UIN, although it is possible to search for other users using their associated e-mail address or any other detail they have made public by updating it in their account's public profile. In addition the user can change all of his or her personal information, including screen name and e-mail address, without having to re-register. Since 2000 ICQ and AIM users were able to add each other to their contact list without the need for any external clients. (The AIM service has since been discontinued.) As a response to UIN theft or sale of attractive UINs, ICQ started to store email addresses previously associated with a UIN. As such UINs that are stolen can sometimes be reclaimed. This applies only if (since 1999 onwards) a valid primary email address was entered into the user profile.\n\nThe founding company of ICQ, Mirabilis, was established in June 1996 by five Israeli developers: Yair Goldfinger, Sefi Vigiser, Amnon Amir, Arik Vardi, and Arik's father Yossi Vardi. They recognized that many people were accessing the internet through non-UNIX operating systems, such as Microsoft Windows, and those users were unfamiliar with established chat technologies, e.g. IRC.\n\nThe technology Mirabilis developed for ICQ was distributed free of charge. The technology's success encouraged AOL to acquire Mirabilis on June 8, 1998, for $287 million up front and $120 million in additional payments over three years based on performance levels. At the time this was the highest price ever paid to purchase an Israeli technology company. In 2002 AOL successfully patented the technology.\n\nAfter the purchase the product was initially managed by Ariel Yarnitsky and Avi Shechter. ICQ's management changed at the end of 2003. Under the leadership of the new CEO, Orey Gilliam, who also assumed the responsibility for all of AOL's messaging business in 2007, ICQ resumed its growth; it was not only a highly profitable company, but one of AOL's most successful businesses. Eliav Moshe replaced Gilliam in 2009 and became ICQ's managing director.\n\nIn April 2010, AOL sold ICQ to Digital Sky Technologies, headed by Alisher Usmanov, for $187.5 million. While ICQ was displaced by AOL Instant Messenger, Google Talk, and other competitors in the U.S. and many other countries over the 2000s, it remained the most popular instant messaging network in Russian-speaking countries, and an important part of online culture. Popular UINs demanded over 11,000 rubles in 2010.\n\nIn September of that year, Digital Sky Technologies changed its name to Mail.Ru Group. Since the acquisition, Mail.ru has invested in turning ICQ from a desktop client to a mobile messaging system. As of 2013, around half of ICQ’s users were using its mobile apps, and in 2014, the number of users began growing for the first time since the purchase.\n\nIn March 2016 the source code of the client was released under the Apache license released on github.com.\n\nBULLET::::- ICQ 99a/b the first releases that were widely available.\nBULLET::::- ICQ 2000 incorporated into \"Notes\" and \"Reminder\" features.\nBULLET::::- ICQ 2001 included server-side storage of the contact list. This provided synchronization between multiple computers and enforced obtaining consent before adding UINs to the contact list by preventing clients from modifying the local contact list directly.\nBULLET::::- On December 19, 2002, AOL Time Warner announced that ICQ had been issued a United States patent for instant messaging.\nBULLET::::- ICQ 2002 was the last completely advertising-free ICQ version.\nBULLET::::- ICQ Pro 2003b was the first ICQ version to use the ICQ protocol version 10. However, \"ICQ 5\" and 5.1 use version 9 of the protocol. \"ICQ 2002\" and \"2003a\" used version 8 of the ICQ protocol. Earlier versions (\"ICQ 2001b\" and all ICQ clients before it) used ICQ protocol version 7.\nBULLET::::- ICQ 4 and later ICQ 5 (released on Monday, February 7, 2005), were upgrades on ICQ Lite. One addition was Xtraz, which offers games and features intended to appeal to younger users of the Internet. ICQ Lite was originally an idea to offer the lighter users of instant messaging an alternative client which was a smaller download and less resource-hungry for relatively slow computers.\nBULLET::::- ICQ 5 introduced skins support. There are few official skins available for the current ICQ 5.1 at the official website; however, a number of user-generated skins have been made available for download.\nBULLET::::- ICQ 6, released on April 17, 2007, was the first major update since ICQ 4. The user interface has been redesigned using Boxely, the same rendering engine used in AIM Triton. This change adds new features such as the ability to send IMs directly from the client's contact list. ICQ has recently started forcing users of v5.1 to upgrade to version 6 (and XP). Those who do not upgrade will find their older version of ICQ does not start up. Although the upgrade to version 6 should be seen as a positive thing, some users may find that useful features such as sending multiple files at one time is no longer supported in the new version. At the beginning of July 2008, a network upgrade forced users to stop using ICQ 5.1 - applications that identified themselves as ICQ 5, such as Pidgin, were forced to identify themselves as ICQ 6. There seems to be no alternative for users other than using a different IM program or patching ICQ 5.1 with a special application.\nBULLET::::- ICQ 7.0, released on January 18, 2010. This update includes integration with Facebook and other websites. It also allows custom personal status similar to Windows Live Messenger (MSN Messenger). ICQ 7.0 does not support traditional Chinese on standard installation or with the addition of an official language pack. This has made its adoption difficult with the established user base from Hong Kong and Taiwan where traditional Chinese is the official language.\nBULLET::::- ICQ 8, released on February 5, 2012 - \"Meet the new generation of ICQ, Enjoy free video calls, messages and SMS, social networks support and more.\"\nBULLET::::- ICQ 10.0, released January 18, 2016. Newest update is 10.0 Build 12393, released on November 8, 2018.\n\nAOL pursued an aggressive policy regarding alternative (\"unauthorized\") ICQ clients.\nBULLET::::- In July 2008 changes were implemented on ICQ servers causing many unofficial clients to stop working. These users received an official notification from \"ICQ System\".\nBULLET::::- On December 9, 2008, another change to the ICQ servers was made. The clients that were sending Client IDs not matching ICQ 5.1 or higher stopped working.\nBULLET::::- On December 29, 2008, ICQ press service distributed a statement characterizing alternative clients as dangerous.\nBULLET::::- On January 21, 2009, ICQ servers started blocking all unofficial clients in Russia and Commonwealth of Independent States countries. Users in Russia and Ukraine received a message from UIN 1:\n\n\"Системное сообщение\nSystem Message\n\nOn icq.com there is an \"important message\" for Russian-speaking ICQ users: \"ICQ осуществляет поддержку только авторизированных версий программ: ICQ Lite и ICQ 6.5.\" (\"ICQ supports only authorized versions of programs: ICQ Lite and ICQ 6.5.\")\nBULLET::::- On February 3, 2009, the events of January 21 have repeated.\nBULLET::::- On December 27, 2018, ICQ announced it was to stop supporting unofficial clients, affecting many users who prefer a compact size using Miranda and clients.\n\nFrom December 28, we will no longer support old versions of ICQ and other unofficial applications.\nTo continue your conversations, you need to update your ICQ here: https://icq.com\nYou can also use the web version here: https://web.icq.com\n\nWith the new version of ICQ you can:\n- edit and delete already sent messages\n- quote and forward messages to another chat\n- send stickers\n- search through chat history and view previously sent media in the chat gallery\n- create group chats\n- make voice and video calls\n\nBULLET::::- On December 28, 2018, ICQ stopped working on some unofficial clients.\nBULLET::::- In late March, 2019, ICQ stopped working on the Pidgin client, as intimated on December 2018.\nBULLET::::- Cooperation with Russian intelligence services\nAccording to a Novaya Gazeta article published in may 2018, Russian intelligence agencies have access to online reading of ICQ users' correspondence. The article examined 34 sentences of Russian courts, during the investigation of which the evidence of the defendants' guilt was obtained by reading correspondence on a PC or mobile devices. Of the fourteen cases in which ICQ was involved, in six cases the capturing of information occurred before the seizure of the device. The reason for the article was the blocking of the Telegram service and the recommendation of the Advisor to the President of the Russian Federation Herman Klimenko to use ICQ instead.\n\nAOL's OSCAR network protocol used by ICQ is proprietary and using a third party client is a violation of ICQ Terms of Service. Nevertheless, a number of third-party clients have been created by using reverse-engineering and protocol descriptions. These clients include:\n\nBULLET::::- Adium: supports ICQ, Yahoo!, AIM, MSN, Google Talk, XMPP, and others, for macOS\nBULLET::::- Ayttm: supports ICQ, Yahoo!, AIM, MSN, IRC, and XMPP\nBULLET::::- bitlbee: IRC gateway, supports ICQ, Yahoo!, AIM, MSN, Google Talk, and XMPP\nBULLET::::- centericq: supports ICQ, Yahoo!, AIM, MSN, IRC and XMPP, text-based\nBULLET::::- climm (formerly mICQ): text-based\nBULLET::::- Fire: supports ICQ, Yahoo!, AIM, MSN, IRC, and XMPP, for macOS\nBULLET::::- Jimm: supports ICQ, for Java ME mobile devices\nBULLET::::- Kopete: supports AIM, ICQ, MSN, Yahoo, XMPP, Google Talk, IRC, Gadu-Gadu, Novell GroupWise Messenger and others, for Unix-like\nBULLET::::- Meetro: IM and social networking combined with location; supports AIM, ICQ, MSN, Yahoo!\nBULLET::::- Miranda IM: supports ICQ, Yahoo!, AIM, MSN, IRC, Google Talk, XMPP, Gadu-Gadu, BNet and others, for Windows\nBULLET::::- Naim: ncurses-based\nBULLET::::- Pidgin (formerly Gaim): supports ICQ, Yahoo!, AIM, Gtalk, MSN, IRC, XMPP, Gadu-Gadu, SILC, Meanwhile, (IBM Lotus Sametime) and others\nBULLET::::- QIP: supports ICQ, AIM, XMPP and XIMSS\nBULLET::::- stICQ: supports ICQ, for Symbian OS\nBULLET::::- Trillian: supports ICQ, IRC, Google Talk, XMPP and others\n\nAOL supported clients include:\nBULLET::::- AOL Instant Messenger\nBULLET::::- Messages/iChat: uses ICQ's UIN as an AIM screenname, for macOS\n\nBULLET::::- Comparison of instant messaging clients\nBULLET::::- Comparison of instant messaging protocols\nBULLET::::- LAN messenger\nBULLET::::- Online chat\nBULLET::::- Windows Live Messenger\nBULLET::::- Tencent QQ\n\nBULLET::::- Official ICQ Website\n"}
{"id": "15169", "url": "https://en.wikipedia.org/wiki?curid=15169", "title": "Impressionism", "text": "Impressionism\n\nImpressionism is a 19th-century art movement characterized by relatively small, thin, yet visible brush strokes, open composition, emphasis on accurate depiction of light in its changing qualities (often accentuating the effects of the passage of time), ordinary subject matter, inclusion of \"movement\" as a crucial element of human perception and experience, and unusual visual angles. Impressionism originated with a group of Paris-based artists whose independent exhibitions brought them to prominence during the 1870s and 1880s.\n\nThe Impressionists faced harsh opposition from the conventional art community in France. The name of the style derives from the title of a Claude Monet work, \"Impression, soleil levant\" (\"Impression, Sunrise\"), which provoked the critic Louis Leroy to coin the term in a satirical review published in the Parisian newspaper \"Le Charivari\".\n\nThe development of Impressionism in the visual arts was soon followed by analogous styles in other media that became known as impressionist music and impressionist literature.\n\nRadicals in their time, early Impressionists violated the rules of academic painting. They constructed their pictures from freely brushed colours that took precedence over lines and contours, following the example of painters such as Eugène Delacroix and J. M. W. Turner. They also painted realistic scenes of modern life, and often painted outdoors. Previously, still lifes and portraits as well as landscapes were usually painted in a studio. The Impressionists found that they could capture the momentary and transient effects of sunlight by painting outdoors or \"en plein air\". They portrayed overall visual effects instead of details, and used short \"broken\" brush strokes of mixed and pure unmixed colour—not blended smoothly or shaded, as was customary—to achieve an effect of intense colour vibration.\n\nImpressionism emerged in France at the same time that a number of other painters, including the Italian artists known as the Macchiaioli, and Winslow Homer in the United States, were also exploring \"plein-air\" painting. The Impressionists, however, developed new techniques specific to the style. Encompassing what its adherents argued was a different way of seeing, it is an art of immediacy and movement, of candid poses and compositions, of the play of light expressed in a bright and varied use of colour.\n\nThe public, at first hostile, gradually came to believe that the Impressionists had captured a fresh and original vision, even if the art critics and art establishment disapproved of the new style. By recreating the sensation in the eye that views the subject, rather than delineating the details of the subject, and by creating a welter of techniques and forms, Impressionism is a precursor of various painting styles, including Neo-Impressionism, Post-Impressionism, Fauvism, and Cubism.\n\nIn the middle of the 19th century—a time of change, as Emperor Napoleon III rebuilt Paris and waged war—the Académie des Beaux-Arts dominated French art. The Académie was the preserver of traditional French painting standards of content and style. Historical subjects, religious themes, and portraits were valued; landscape and still life were not. The Académie preferred carefully finished images that looked realistic when examined closely. Paintings in this style were made up of precise brush strokes carefully blended to hide the artist's hand in the work. Colour was restrained and often toned down further by the application of a golden varnish.\n\nThe Académie had an annual, juried art show, the Salon de Paris, and artists whose work was displayed in the show won prizes, garnered commissions, and enhanced their prestige. The standards of the juries represented the values of the Académie, represented by the works of such artists as Jean-Léon Gérôme and Alexandre Cabanel.\n\nIn the early 1860s, four young painters—Claude Monet, Pierre-Auguste Renoir, Alfred Sisley, and Frédéric Bazille—met while studying under the academic artist Charles Gleyre. They discovered that they shared an interest in painting landscape and contemporary life rather than historical or mythological scenes. Following a practice that had become increasingly popular by mid-century, they often ventured into the countryside together to paint in the open air, but not for the purpose of making sketches to be developed into carefully finished works in the studio, as was the usual custom. By painting in sunlight directly from nature, and making bold use of the vivid synthetic pigments that had become available since the beginning of the century, they began to develop a lighter and brighter manner of painting that extended further the Realism of Gustave Courbet and the Barbizon school. A favourite meeting place for the artists was the Café Guerbois on Avenue de Clichy in Paris, where the discussions were often led by Édouard Manet, whom the younger artists greatly admired. They were soon joined by Camille Pissarro, Paul Cézanne, and Armand Guillaumin.\nDuring the 1860s, the Salon jury routinely rejected about half of the works submitted by Monet and his friends in favour of works by artists faithful to the approved style. In 1863, the Salon jury rejected Manet's \"The Luncheon on the Grass\" \"(Le déjeuner sur l'herbe)\" primarily because it depicted a nude woman with two clothed men at a picnic. While the Salon jury routinely accepted nudes in historical and allegorical paintings, they condemned Manet for placing a realistic nude in a contemporary setting. The jury's severely worded rejection of Manet's painting appalled his admirers, and the unusually large number of rejected works that year perturbed many French artists.\n\nAfter Emperor Napoleon III saw the rejected works of 1863, he decreed that the public be allowed to judge the work themselves, and the Salon des Refusés (Salon of the Refused) was organized. While many viewers came only to laugh, the Salon des Refusés drew attention to the existence of a new tendency in art and attracted more visitors than the regular Salon.\n\nArtists' petitions requesting a new Salon des Refusés in 1867, and again in 1872, were denied. In December 1873, Monet, Renoir, Pissarro, Sisley, Cézanne, Berthe Morisot, Edgar Degas and several other artists founded the \"Société Anonyme Coopérative des Artistes Peintres, Sculpteurs, Graveurs\" (\"Cooperative and Anonymous Association of Painters, Sculptors, and Engravers\") to exhibit their artworks independently. Members of the association were expected to forswear participation in the Salon. The organizers invited a number of other progressive artists to join them in their inaugural exhibition, including the older Eugène Boudin, whose example had first persuaded Monet to adopt \"plein air\" painting years before. Another painter who greatly influenced Monet and his friends, Johan Jongkind, declined to participate, as did Édouard Manet. In total, thirty artists participated in their first exhibition, held in April 1874 at the studio of the photographer Nadar.\nThe critical response was mixed. Monet and Cézanne received the harshest attacks. Critic and humorist Louis Leroy wrote a scathing review in the newspaper \"Le Charivari\" in which, making wordplay with the title of Claude Monet's \"Impression, Sunrise\" \"(Impression, soleil levant)\", he gave the artists the name by which they became known. Derisively titling his article \"\", Leroy declared that Monet's painting was at most, a sketch, and could hardly be termed a finished work.\n\nHe wrote, in the form of a dialog between viewers,\n\nThe term \"Impressionist\" quickly gained favour with the public. It was also accepted by the artists themselves, even though they were a diverse group in style and temperament, unified primarily by their spirit of independence and rebellion. They exhibited together—albeit with shifting membership—eight times between 1874 and 1886. The Impressionists' style, with its loose, spontaneous brushstrokes, would soon become synonymous with modern life.\n\nMonet, Sisley, Morisot, and Pissarro may be considered the \"purest\" Impressionists, in their consistent pursuit of an art of spontaneity, sunlight, and colour. Degas rejected much of this, as he believed in the primacy of drawing over colour and belittled the practice of painting outdoors. Renoir turned away from Impressionism for a time during the 1880s, and never entirely regained his commitment to its ideas. Édouard Manet, although regarded by the Impressionists as their leader, never abandoned his liberal use of black as a colour (while Impressionists avoided its use and preferred to obtain darker colours by mixing), and never participated in the Impressionist exhibitions. He continued to submit his works to the Salon, where his painting \"Spanish Singer\" had won a 2nd class medal in 1861, and he urged the others to do likewise, arguing that \"the Salon is the real field of battle\" where a reputation could be made.\nAmong the artists of the core group (minus Bazille, who had died in the Franco-Prussian War in 1870), defections occurred as Cézanne, followed later by Renoir, Sisley, and Monet, abstained from the group exhibitions so they could submit their works to the Salon. Disagreements arose from issues such as Guillaumin's membership in the group, championed by Pissarro and Cézanne against opposition from Monet and Degas, who thought him unworthy. Degas invited Mary Cassatt to display her work in the 1879 exhibition, but also insisted on the inclusion of Jean-François Raffaëlli, Ludovic Lepic, and other realists who did not represent Impressionist practices, causing Monet in 1880 to accuse the Impressionists of \"opening doors to first-come daubers\". The group divided over invitations to Paul Signac and Georges Seurat to exhibit with them in 1886. Pissarro was the only artist to show at all eight Impressionist exhibitions.\n\nThe individual artists achieved few financial rewards from the Impressionist exhibitions, but their art gradually won a degree of public acceptance and support. Their dealer, Durand-Ruel, played a major role in this as he kept their work before the public and arranged shows for them in London and New York. Although Sisley died in poverty in 1899, Renoir had a great Salon success in 1879. Monet became secure financially during the early 1880s and so did Pissarro by the early 1890s. By this time the methods of Impressionist painting, in a diluted form, had become commonplace in Salon art.\n\nFrench painters who prepared the way for Impressionism include the Romantic colourist Eugène Delacroix, the leader of the realists Gustave Courbet, and painters of the Barbizon school such as Théodore Rousseau. The Impressionists learned much from the work of Johan Barthold Jongkind, Jean-Baptiste-Camille Corot and Eugène Boudin, who painted from nature in a direct and spontaneous style that prefigured Impressionism, and who befriended and advised the younger artists.\n\nA number of identifiable techniques and working habits contributed to the innovative style of the Impressionists. Although these methods had been used by previous artists—and are often conspicuous in the work of artists such as Frans Hals, Diego Velázquez, Peter Paul Rubens, John Constable, and J. M. W. Turner—the Impressionists were the first to use them all together, and with such consistency. These techniques include:\n\nBULLET::::- Short, thick strokes of paint quickly capture the essence of the subject, rather than its details. The paint is often applied impasto.\nBULLET::::- Colours are applied side-by-side with as little mixing as possible, a technique that exploits the principle of simultaneous contrast to make the colour appear more vivid to the viewer.\nBULLET::::- Greys and dark tones are produced by mixing complementary colours. Pure impressionism avoids the use of black paint.\nBULLET::::- Wet paint is placed into wet paint without waiting for successive applications to dry, producing softer edges and intermingling of colour.\nBULLET::::- Impressionist paintings do not exploit the transparency of thin paint films (glazes), which earlier artists manipulated carefully to produce effects. The impressionist painting surface is typically opaque.\nBULLET::::- The paint is applied to a white or light-coloured ground. Previously, painters often used dark grey or strongly coloured grounds.\nBULLET::::- The play of natural light is emphasized. Close attention is paid to the reflection of colours from object to object. Painters often worked in the evening to produce \"effets de soir\"—the shadowy effects of evening or twilight.\nBULLET::::- In paintings made \"en plein air\" (outdoors), shadows are boldly painted with the blue of the sky as it is reflected onto surfaces, giving a sense of freshness previously not represented in painting. (Blue shadows on snow inspired the technique.)\n\nNew technology played a role in the development of the style. Impressionists took advantage of the mid-century introduction of premixed paints in tin tubes (resembling modern toothpaste tubes), which allowed artists to work more spontaneously, both outdoors and indoors. Previously, painters made their own paints individually, by grinding and mixing dry pigment powders with linseed oil, which were then stored in animal bladders.\n\nMany vivid synthetic pigments became commercially available to artists for the first time during the 19th century. These included cobalt blue, viridian, cadmium yellow, and synthetic ultramarine blue, all of which were in use by the 1840s, before Impressionism. The Impressionists' manner of painting made bold use of these pigments, and of even newer colours such as cerulean blue, which became commercially available to artists in the 1860s.\n\nThe Impressionists' progress toward a brighter style of painting was gradual. During the 1860s, Monet and Renoir sometimes painted on canvases prepared with the traditional red-brown or grey ground. By the 1870s, Monet, Renoir, and Pissarro usually chose to paint on grounds of a lighter grey or beige colour, which functioned as a middle tone in the finished painting. By the 1880s, some of the Impressionists had come to prefer white or slightly off-white grounds, and no longer allowed the ground colour a significant role in the finished painting.\n\nPrior to the Impressionists, other painters, notably such 17th-century Dutch painters as Jan Steen, had emphasized common subjects, but their methods of composition were traditional. They arranged their compositions so that the main subject commanded the viewer's attention. J. M. W. Turner, while an artist of the Romantic era, anticipated the style of impressionism with his artwork . The Impressionists relaxed the boundary between subject and background so that the effect of an Impressionist painting often resembles a snapshot, a part of a larger reality captured as if by chance. Photography was gaining popularity, and as cameras became more portable, photographs became more candid. Photography inspired Impressionists to represent momentary action, not only in the fleeting lights of a landscape, but in the day-to-day lives of people.\nThe development of Impressionism can be considered partly as a reaction by artists to the challenge presented by photography, which seemed to devalue the artist's skill in reproducing reality. Both portrait and landscape paintings were deemed somewhat deficient and lacking in truth as photography \"produced lifelike images much more efficiently and reliably\".\n\nIn spite of this, photography actually inspired artists to pursue other means of creative expression, and rather than compete with photography to emulate reality, artists focused \"on the one thing they could inevitably do better than the photograph—by further developing into an art form its very subjectivity in the conception of the image, the very subjectivity that photography eliminated\". The Impressionists sought to express their perceptions of nature, rather than create exact representations. This allowed artists to depict subjectively what they saw with their \"tacit imperatives of taste and conscience\". Photography encouraged painters to exploit aspects of the painting medium, like colour, which photography then lacked: \"The Impressionists were the first to consciously offer a subjective alternative to the photograph\".\n\nAnother major influence was Japanese ukiyo-e art prints (Japonism). The art of these prints contributed significantly to the \"snapshot\" angles and unconventional compositions that became characteristic of Impressionism. An example is Monet's \"Jardin à Sainte-Adresse\", 1867, with its bold blocks of colour and composition on a strong diagonal slant showing the influence of Japanese prints\n\nEdgar Degas was both an avid photographer and a collector of Japanese prints. His \"The Dance Class\" \"(La classe de danse)\" of 1874 shows both influences in its asymmetrical composition. The dancers are seemingly caught off guard in various awkward poses, leaving an expanse of empty floor space in the lower right quadrant. He also captured his dancers in sculpture, such as the \"Little Dancer of Fourteen Years\".\n\nImpressionists, in varying degrees, were looking for ways to depict visual experience and contemporary subjects. Women Impressionists were interested in these same ideals but had many social and career limitations compared to male Impressionists. In particular, they were excluded from the imagery of the bourgeois social sphere of the boulevard, cafe, and dance hall. As well as imagery, women were excluded from the formative discussions that resulted in meetings in those places; that was where male Impressionists were able to form and share ideas about Impressionism. In the academic realm, women were believed to be incapable of handling complex subjects which led teachers to restrict what they taught female students. It was also considered unladylike to excel in art since women's true talents were then believed to center on homemaking and mothering.\n\nYet several women were able to find success during their lifetime, even though their careers were affected by personal circumstances – Bracquemond, for example, had a husband who was resentful of her work which caused her to give up painting. The four most well known, namely, Mary Cassatt, Eva Gonzalès, Marie Bracquemond, and Berthe Morisot, are, and were, often referred to as the 'Women Impressionists'. Their participation in the series of eight Impressionist exhibitions that took place in Paris from 1874 to 1886 varied: Morisot participated in seven, Cassatt in four, Bracquemond in three, and Gonzalès did not participate. \n\nThe critics of the time lumped these four together without regard to their personal styles, techniques, or subject matter. Critics viewing their works at the exhibitions often attempted to acknowledge the women artists' talents but circumscribed them within a limited notion of femininity. Arguing for the suitability of Impressionist technique to women's manner of perception, Parisian critic S.C. de Soissons wrote:One can understand that women have no originality of thought, and that literature and music have no feminine character; but surely women know how to observe, and what they see is quite different from that which men see, and the art which they put in their gestures, in their toilet, in the decoration of their environment is sufficient to give is the idea of an instinctive, of a peculiar genius which resides in each one of them. While Impressionism legitimized the domestic social life as subject matter, of which women had intimate knowledge, it also tended to limit them to that subject matter. Portrayals of often-identifiable sitters in domestic settings (which could offer commissions) were dominant in the exhibitions. The subjects of the paintings were often women interacting with their environment by either their gaze or movement. Cassatt, in particular, was aware of her placement of subjects: she kept her predominantly female figures from objectification and cliche; when they are not reading, they converse, sew, drink tea, and when they are inactive, they seem lost in thought.\nThe women Impressionists, like their male counterparts, were striving for \"truth,\" for new ways of seeing and new painting techniques; each artist had an individual painting style. Women Impressionists (particularly Morisot and Cassatt) were conscious of the balance of power between women and objects in their paintings – the bourgeois women depicted are not defined by decorative objects, but instead, interact with and dominate the things with which they live. There are many similarities in their depictions of women who seem both at ease and subtly confined. Gonzalès' \"Box at the Italian Opera\" depicts a woman staring into the distance, at ease in a social sphere but confined by the box and the man standing next to her. Cassatt's painting \"Young Girl at a Window\" is brighter in color but remains constrained by the canvas edge as she looks out the window. \n\nDespite their success in their ability to have a career and Impressionism's demise attributed to its allegedly feminine characteristics (its sensuality, dependence on sensation, physicality, and fluidity) the four women artists (and other, lesser-known women Impressionists) were largely omitted from art historical textbooks covering Impressionist artists until Tamar Garb's \"Women Impressionists\" published in 1986. For example, \"Impressionism\" by Jean Leymarie, published in 1955 included no information on any women Impressionists.\n\nThe central figures in the development of Impressionism in France, listed alphabetically, were:\nBULLET::::- Frédéric Bazille (who only posthumously participated in the Impressionist exhibitions) (1841–1870)\nBULLET::::- Gustave Caillebotte (who, younger than the others, joined forces with them in the mid-1870s) (1848–1894)\nBULLET::::- Mary Cassatt (American-born, she lived in Paris and participated in four Impressionist exhibitions) (1844–1926)\nBULLET::::- Paul Cézanne (although he later broke away from the Impressionists) (1839–1906)\nBULLET::::- Edgar Degas (who despised the term \"Impressionist\") (1834–1917)\nBULLET::::- Armand Guillaumin (1841–1927)\nBULLET::::- Édouard Manet (who did not participate in any of the Impressionist exhibitions) (1832–1883)\nBULLET::::- Claude Monet (the most prolific of the Impressionists and the one who embodies their aesthetic most obviously) (1840–1926)\nBULLET::::- Berthe Morisot (who participated in all Impressionist exhibitions except in 1879) (1841–1895)\nBULLET::::- Camille Pissarro (1830–1903)\nBULLET::::- Pierre-Auguste Renoir (who participated in Impressionist exhibitions in 1874, 1876, 1877 and 1882) (1841–1919)\nBULLET::::- Alfred Sisley (1839–1899)\n\nAmong the close associates of the Impressionists were several painters who adopted their methods to some degree. These include Jean-Louis Forain (who participated in Impressionist exhibitions in 1879, 1880, 1881 and 1886) and Giuseppe De Nittis, an Italian artist living in Paris who participated in the first Impressionist exhibit at the invitation of Degas, although the other Impressionists disparaged his work. Federico Zandomeneghi was another Italian friend of Degas who showed with the Impressionists. Eva Gonzalès was a follower of Manet who did not exhibit with the group. James Abbott McNeill Whistler was an American-born painter who played a part in Impressionism although he did not join the group and preferred grayed colours. Walter Sickert, an English artist, was initially a follower of Whistler, and later an important disciple of Degas; he did not exhibit with the Impressionists. In 1904 the artist and writer Wynford Dewhurst wrote the first important study of the French painters published in English, \"Impressionist Painting: its genesis and development\", which did much to popularize Impressionism in Great Britain.\n\nBy the early 1880s, Impressionist methods were affecting, at least superficially, the art of the Salon. Fashionable painters such as Jean Béraud and Henri Gervex found critical and financial success by brightening their palettes while retaining the smooth finish expected of Salon art. Works by these artists are sometimes casually referred to as Impressionism, despite their remoteness from Impressionist practice.\n\nThe influence of the French Impressionists lasted long after most of them had died. Artists like J.D. Kirszenbaum were borrowing Impressionist techniques throughout the twentieth century.\n\nAs the influence of Impressionism spread beyond France, artists, too numerous to list, became identified as practitioners of the new style. Some of the more important examples are:\nBULLET::::- The American Impressionists, including Mary Cassatt, William Merritt Chase, Frederick Carl Frieseke, Childe Hassam, Willard Metcalf, Lilla Cabot Perry, Theodore Robinson, Edmund Charles Tarbell, John Henry Twachtman, Catherine Wiley and J. Alden Weir.\nBULLET::::- The Australian Impressionists, including Tom Roberts, Arthur Streeton, Walter Withers, Charles Conder and Frederick McCubbin (who were prominent members of the Heidelberg School), and John Russell, a friend of Van Gogh, Rodin, Monet and Matisse.\nBULLET::::- The Amsterdam Impressionists in the Netherlands, including George Hendrik Breitner, Isaac Israëls, Willem Bastiaan Tholen, Willem de Zwart, Willem Witsen and Jan Toorop.\nBULLET::::- Anna Boch, Vincent van Gogh's friend Eugène Boch, Georges Lemmen and Théo van Rysselberghe, Impressionist painters from Belgium.\nBULLET::::- Ivan Grohar, Rihard Jakopič, Matija Jama, and Matej Sternen, Impressionists from Slovenia. Their beginning was in the school of Anton Ažbe in Munich and they were influenced by Jurij Šubic and Ivana Kobilca, Slovenian painters working in Paris\nBULLET::::- Wynford Dewhurst, Walter Richard Sickert, and Philip Wilson Steer were well known Impressionist painters from the United Kingdom. Pierre Adolphe Valette, who was born in France but who worked in Manchester, was the tutor of L. S. Lowry.\nBULLET::::- The German Impressionists, including Lovis Corinth, Max Liebermann, Ernst Oppler, Max Slevogt and August von Brandis.\nBULLET::::- László Mednyánszky in Hungary\nBULLET::::- Theodor von Ehrmanns and Hugo Charlemont who were rare Impressionists among the more dominant Vienna Secessionist painters in Austria\nBULLET::::- William John Leech, Roderic O'Conor, and Walter Osborne in Ireland\nBULLET::::- Konstantin Korovin and Valentin Serov in Russia\nBULLET::::- Francisco Oller y Cestero, a native of Puerto Rico and a friend of Pissarro and Cézanne\nBULLET::::- James Nairn in New Zealand.\nBULLET::::- William McTaggart in Scotland.\nBULLET::::- Laura Muntz Lyall, a Canadian artist\nBULLET::::- Władysław Podkowiński, a Polish Impressionist and symbolist\nBULLET::::- Nicolae Grigorescu in Romania\nBULLET::::- Nazmi Ziya Güran, who brought Impressionism to Turkey\nBULLET::::- Chafik Charobim in Egypt\nBULLET::::- Eliseu Visconti in Brazil\nBULLET::::- Joaquín Sorolla in Spain\nBULLET::::- Faustino Brughetti, Fernando Fader, Candido Lopez, Martín Malharro, Walter de Navazio, Ramón Silva in Argentina\nBULLET::::- Skagen Painters a group of Scandinavian artists who painted in a small Danish fishing village\nBULLET::::- Nadežda Petrović in Serbia\nBULLET::::- Ásgrímur Jónsson in Iceland\nBULLET::::- Fujishima Takeji in Japan\nBULLET::::- Frits Thaulow in Norway and later France.\n\nThe sculptor Auguste Rodin is sometimes called an Impressionist for the way he used roughly modeled surfaces to suggest transient light effects.\n\nPictorialist photographers whose work is characterized by soft focus and atmospheric effects have also been called Impressionists.\n\nFrench Impressionist Cinema is a term applied to a loosely defined group of films and filmmakers in France from 1919–1929, although these years are debatable. French Impressionist filmmakers include Abel Gance, Jean Epstein, Germaine Dulac, Marcel L’Herbier, Louis Delluc, and Dmitry Kirsanoff.\n\nMusical Impressionism is the name given to a movement in European classical music that arose in the late 19th century and continued into the middle of the 20th century. Originating in France, musical Impressionism is characterized by suggestion and atmosphere, and eschews the emotional excesses of the Romantic era. Impressionist composers favoured short forms such as the nocturne, arabesque, and prelude, and often explored uncommon scales such as the whole tone scale. Perhaps the most notable innovations of Impressionist composers were the introduction of major 7th chords and the extension of chord structures in 3rds to five- and six-part harmonies.\n\nThe influence of visual Impressionism on its musical counterpart is debatable. Claude Debussy and Maurice Ravel are generally considered the greatest Impressionist composers, but Debussy disavowed the term, calling it the invention of critics. Erik Satie was also considered in this category, though his approach was regarded as less serious, more musical novelty in nature. Paul Dukas is another French composer sometimes considered an Impressionist, but his style is perhaps more closely aligned to the late Romanticists. Musical Impressionism beyond France includes the work of such composers as Ottorino Respighi (Italy), Ralph Vaughan Williams, Cyril Scott, and John Ireland (England), Manuel De Falla and Isaac Albeniz (Spain), and Charles Griffes (America). \n\nThe term Impressionism has also been used to describe works of literature in which a few select details suffice to convey the sensory impressions of an incident or scene. Impressionist literature is closely related to Symbolism, with its major exemplars being Baudelaire, Mallarmé, Rimbaud, and Verlaine. Authors such as Virginia Woolf, D.H. Lawrence, and Joseph Conrad have written works that are Impressionistic in the way that they describe, rather than interpret, the impressions, sensations and emotions that constitute a character's mental life.\n\nDuring the 1880s several artists began to develop different precepts for the use of colour, pattern, form, and line, derived from the Impressionist example: Vincent van Gogh, Paul Gauguin, Georges Seurat, and Henri de Toulouse-Lautrec. These artists were slightly younger than the Impressionists, and their work is known as post-Impressionism. Some of the original Impressionist artists also ventured into this new territory; Camille Pissarro briefly painted in a pointillist manner, and even Monet abandoned strict \"plein air\" painting. Paul Cézanne, who participated in the first and third Impressionist exhibitions, developed a highly individual vision emphasising pictorial structure, and he is more often called a post-Impressionist. Although these cases illustrate the difficulty of assigning labels, the work of the original Impressionist painters may, by definition, be categorised as Impressionism.\n\nBULLET::::- Art periods\nBULLET::::- Expressionism (as a reaction to Impressionism)\nBULLET::::- Les XX\nBULLET::::- Luminism (Impressionism)\nBULLET::::- Macchiaioli\nBULLET::::- Cantonese school of painting\n\nBULLET::::- Baumann, Felix Andreas, Marianne Karabelnik-Matta, Jean Sutherland Boggs, and Tobia Bezzola (1994). \"Degas Portraits\". London: Merrell Holberton.\nBULLET::::- Bomford, David, Jo Kirby, John Leighton, Ashok Roy, and Raymond White (1990). \"Impressionism\". London: National Gallery.\nBULLET::::- Denvir, Bernard (1990). \"The Thames and Hudson Encyclopaedia of Impressionism\". London: Thames and Hudson.\nBULLET::::- Distel, Anne, Michel Hoog, and Charles S. Moffett (1974). \"Impressionism; a centenary exhibition, the Metropolitan Museum of Art, December 12, 1974-February 10, 1975\". New York: Metropolitan Museum of Art.\nBULLET::::- Eisenman, Stephen F (2011). \"From Corot to Monet: The Ecology of Impressionism\". Milan: Skira. .\nBULLET::::- Gordon, Robert; Forge, Andrew (1988). \"Degas\". New York: Harry N. Abrams.\nBULLET::::- Gowing, Lawrence, with Adriani, Götz; Krumrine, Mary Louise; Lewis, Mary Tompkins; Patin, Sylvie; Rewald, John (1988). \"Cézanne: The Early Years 1859-1872\". New York: Harry N. Abrams.\nBULLET::::- Jensen, Robert (1994). \"Marketing modernism in fin-de-siècle Europe\". Princeton, N.J.: Princeton University Press. .\nBULLET::::- Moskowitz, Ira; Sérullaz, Maurice (1962). \"French Impressionists: A Selection of Drawings of the French 19th Century\". Boston and Toronto: Little, Brown and Company.\nBULLET::::- Rewald, John (1973). \"The History of Impressionism\" (4th, Revised Ed.). New York: The Museum of Modern Art.\nBULLET::::- Richardson, John (1976). \"Manet\" (3rd Ed.). Oxford: Phaidon Press Ltd.\nBULLET::::- Rosenblum, Robert (1989). \"Paintings in the Musée d'Orsay\". New York: Stewart, Tabori & Chang.\nBULLET::::- Moffett, Charles S. (1986). \"The New Painting, Impressionism 1874-1886\". Geneva: Richard Burton SA.\n\nBULLET::::- Hecht Museum\nBULLET::::- Mauclair, Camille (1903):\nBULLET::::- Museumsportal Schleswig-Holstein\nBULLET::::- Suburban Pastoral \"The Guardian\", 24 February 2007\nBULLET::::- \"Impressionism: Paintings collected by European Museums\" (1999) was an art exhibition co-organized by the High Museum of Art, Atlanta, the Seattle Art Museum, and the Denver Art Museum, touring from May through December 1999. Online guided tour\nBULLET::::- \"Monet's Years at Giverny: Beyond Impressionism\", exhibition catalogue fully online as PDF from The Metropolitan Museum of Art, which discusses Monet's role in this movement\nBULLET::::- \"Degas: The Artist's Mind\", exhibition catalogue fully online as PDF from The Metropolitan Museum of Art, which discusses Degas's role in this movement\nBULLET::::- Definition of impressionism on the Tate Art Glossary\n"}
{"id": "15172", "url": "https://en.wikipedia.org/wiki?curid=15172", "title": "Internet slang", "text": "Internet slang\n\nInternet slang (Internet shorthand, cyber-slang, netspeak, or chatspeak) refers to various kinds of slang used by different people on the Internet. An example of Internet slang is \"LOL\" meaning \"laugh out loud\". It is difficult to provide a standardized definition of Internet slang due to the constant changes made to its nature. However, it can be understood to be any type of slang that Internet users have popularized, and in many cases, have coined. Such terms often originate with the purpose of saving keystrokes or to compensate for small character limits. Many people use the same abbreviations in texting and instant messaging, and social networking websites. Acronyms, keyboard symbols and abbreviations are common types of Internet slang. New dialects of slang, such as leet or Lolspeak, develop as ingroup internet memes rather than time savers. Some people only use LOL for fun. Many people use this internet slang not only on the Internet but also face-to-face.\n\nInternet slang originated in the early days of the Internet with some terms predating the Internet. Internet slang is used in chat rooms, social networking services, online games, video games and in the online community. Since 1979, users of communications networks like Usenet created their own shorthand.\n\nIn Japanese, the term moe has come into common use among slang users to mean something extremely cute and appealing.\n\nAside from the more frequent abbreviations, acronyms, and emoticons, Internet slang also uses archaic words or the lesser-known meanings of mainstream terms. Regular words can also be altered into something with a similar pronunciation but altogether different meaning, or attributed new meanings altogether. Phonetic transcriptions of foreign words, such as the transformation of \"impossible\" into \"impossibru\" in Japanese and then [the transliteration of that] back to [the character set used for] English, also occur. In places where logographic languages are used, such as China, a visual Internet slang exists, giving characters dual meanings, one direct and one implied.\n\nThe primary motivation for using a slang unique to the Internet is to ease communication. However, while Internet slang shortcuts save time for the writer, they take two times as long for the reader to understand, according to a study by the University of Tasmania. On the other hand, similar to the use of slang in traditional face-to-face speech or written language, slang on the Internet is often a way of indicating group membership.\n\nInternet slang provides a channel which facilitates and constrains our ability to communicate in ways that are fundamentally different from those found in other semiotic situations. Many of the expectations and practices which we associate with spoken and written language are no longer applicable. The Internet itself is ideal for new slang to emerge because of the richness of the medium and the availability of information. Slang is also thus motivated for the \"creation and sustenance of online communities\". These communities, in turn, play a role in solidarity or identification or an exclusive or common cause.\n\nDavid Crystal distinguishes among five areas of the Internet where slang is used- The Web itself, email, asynchronous chat (for example, mailing lists), synchronous chat (for example, Internet Relay Chat), and virtual worlds. The electronic character of the channel has a fundamental influence on the language of the medium. Options for communication are constrained by the nature of the hardware needed in order to gain Internet access. Thus, productive linguistic capacity (the type of information that can be sent) is determined by the preassigned characters on a keyboard, and receptive linguistic capacity (the type of information that can be seen) is determined by the size and configuration of the screen. Additionally, both sender and receiver are constrained linguistically by the properties of the internet software, computer hardware, and networking hardware linking them. Electronic discourse refers to writing that is \"very often reads as if it were being spoken – that is, as if the sender were writing talking\".\n\nInternet slang does not constitute a homogeneous language variety. Rather, it differs according to the user and type of Internet situation. However, within the language of Internet slang, there is still an element of prescriptivism, as seen in style guides, for example \"Wired Style\", which are specifically aimed at usage on the Internet. Even so, few users consciously heed these prescriptive recommendations on CMC, but rather adapt their styles based on what they encounter online. Although it is difficult to produce a clear definition of Internet slang, the following types of slang may be observed. This list is not exhaustive.\n\n! Class !! Description\n\nMany debates about how the use of slang on the Internet influences language outside of the digital sphere go on. Even though the direct causal relationship between the Internet and language has yet to be proven by any scientific research, Internet slang has invited split views on its influence on the standard of language use in non-computer-mediated communications.\n\nPrescriptivists tend to have the widespread belief that the Internet has a negative influence on the future of language, and that it would lead to a degradation of standard. Some would even attribute any decline of standard formal English to the increase in usage of electronic communication. It has also been suggested that the linguistic differences between Standard English and CMC can have implications for literacy education. This is illustrated by the widely reported example of a school essay submitted by a Scottish teenager, which contained many abbreviations and acronyms likened to SMS language. There was great condemnation of this style by the mass media as well as educationists, who expressed that this showed diminishing literacy or linguistic abilities.\n\nOn the other hand, descriptivists have counter-argued that the Internet allows better expressions of a language. Rather than established linguistic conventions, linguistic choices sometimes reflect personal taste. It has also been suggested that as opposed to intentionally flouting language conventions, Internet slang is a result of a lack of motivation to monitor speech online. Hale and Scanlon describe language in Emails as being derived from \"writing the way people talk\", and that there is no need to insist on 'Standard' English. English users, in particular, have an extensive tradition of etiquette guides, instead of traditional prescriptive treatises, that offer pointers on linguistic appropriateness. Using and spreading Internet slang also adds onto the cultural currency of a language. It is important to the speakers of the language due to the foundation it provides for identifying within a group, and also for defining a person's individual linguistic and communicative competence. The result is a specialized subculture based on its use of slang.\n\nIn scholarly research, attention has, for example, been drawn to the effect of the use of Internet slang in ethnography, and more importantly to how conversational relationships online change structurally because slang is used.\n\nIn German, there is already considerable controversy regarding the use of anglicisms outside of CMC. This situation is even more problematic within CMC, since the jargon of the medium is dominated by English terms. An extreme example of an anti-anglicisms perspective can be observed from the chatroom rules of a Christian site, which bans all anglicisms (\"\" [Using anglicisms is strictly prohibited!]), and also translates even fundamental terms into German equivalents.\n\nIn April 2014, Gawker's editor-in-chief Max Read instituted new writing style guidelines banning internet slang for his writing staff.\n\nInternet slang has crossed from being mediated by the computer into other non-physical domains. Here, these domains are taken to refer to any domain of interaction where interlocutors need not be geographically proximate to one another, and where the Internet is not primarily used. Internet slang is now prevalent in telephony, mainly through short messages (SMS) communication. Abbreviations and interjections, especially, have been popularized in this medium, perhaps due to the limited character space for writing messages on mobile phones. Another possible reason for this spread is the convenience of transferring the existing mappings between expression and meaning into a similar space of interaction.\n\nAt the same time, Internet slang has also taken a place as part of everyday offline language, among those with digital access. The nature and content of online conversation is brought forward to direct offline communication through the telephone and direct talking, as well as through written language, such as in writing notes or letters. In the case of interjections, such as numerically based and abbreviated Internet slang, are not pronounced as they are written physically or replaced by any actual action. Rather, they become lexicalized and spoken like non-slang words in a \"stage direction\" like fashion, where the actual action is not carried out but substituted with a verbal signal. The notions of flaming and trolling have also extended outside the computer, and are used in the same circumstances of deliberate or unintentional implicatures.\n\nThe expansion of Internet slang has been furthered through codification and the promotion of digital literacy. The subsequently existing and growing popularity of such references among those online as well as offline has thus advanced Internet slang literacy and globalized it. Awareness and proficiency in manipulating Internet slang in both online and offline communication indicates digital literacy and teaching materials have even been developed to further this knowledge. A South Korean publisher, for example, has published a textbook that details the meaning and context of use for common Internet slang instances and is targeted at young children who will soon be using the Internet. Similarly, Internet slang has been recommended as language teaching material in second language classrooms in order to raise communicative competence by imparting some of the cultural value attached to a language that is available only in slang.\n\nMeanwhile, well-known dictionaries such as the ODE and Merriam-Webster have been updated with a significant and growing body of slang jargon. Besides common examples, lesser known slang and slang with a non-English etymology have also found a place in standardized linguistic references. Along with these instances, literature in user-contributed dictionaries such as Urban Dictionary has also been added to. Codification seems to be qualified through frequency of use, and novel creations are often not accepted by other users of slang.\n\nAlthough Internet slang began as a means of \"opposition\" to mainstream language, its popularity with today's globalized digitally literate population has shifted it into a part of everyday language, where it also leaves a profound impact.\n\nFrequently used slang also have become conventionalised into memetic \"unit[s] of cultural information\". These memes in turn are further spread through their use on the Internet, prominently through websites. The Internet as an \"information superhighway\" is also catalysed through slang. The evolution of slang has also created a 'slang union' as part of a unique, specialised subculture. Such impacts are, however, limited and requires further discussion especially from the non-English world. This is because Internet slang is prevalent in languages more actively used on the Internet, like English, which is the Internet's lingua franca.\n\nThe Internet has helped people from all over the world to become connected to one another, enabling \"global\" relationships to be formed. As such, it is important for the various types of slang used online to be recognizable for everyone. It is also important to do so because of how other languages are quickly catching up with English on the Internet, following the increase in Internet usage in predominantly non-English speaking countries. In fact, as of May 31, 2011, only approximately 27% of the online population is made up of English speakers.\n\nDifferent cultures tend to have different motivations behind their choice of slang, on top of the difference in language used. For example, in China, because of the tough Internet regulations imposed, users tend to use certain slang to talk about issues deemed as sensitive to the government. These include using symbols to separate the characters of a word to avoid detection from manual or automated text pattern scanning and consequential censorship. An outstanding example is the use of the term river crab to denote censorship. River crab (hexie) is pronounced the same as \"harmony\"—the official term used to justify political discipline and censorship. As such Chinese netizens reappropriate the official terms in a sarcastic way.\n\nAbbreviations are popular across different cultures, including countries like Japan, China, France, Portugal, etc., and are used according to the particular language the Internet users speak. Significantly, this same style of slang creation is also found in non-alphabetical languages as, for example, a form of \"e gao\" or alternative political discourse.\n\nThe difference in language often results in miscommunication, as seen in an onomatopoeic example, \"555\", which sounds like \"crying\" in Chinese, and \"laughing\" in Thai. A similar example is between the English \"haha\" and the Spanish \"jaja\", where both are onomatopoeic expressions of laughter, but the difference in language also meant a different consonant for the same sound to be produced. For more examples of how other languages express \"laughing out loud\", see also: LOL\n\nIn terms of culture, in Chinese, the numerically based onomatopoeia \"770880\" (), which means to 'kiss and hug you', is used. This is comparable to \"XOXO\", which many Internet users use. In French, \"pk\" or \"pq\" is used in the place of pourquoi, which means 'why'. This is an example of a combination of onomatopoeia and shortening of the original word for convenience when writing online.\n\nIn conclusion, every different country has their own language background and cultural differences and hence, they tend to have their own rules and motivations for their own Internet slang. However, at present, there is still a lack of studies done by researchers on some differences between the countries.\n\nOn the whole, the popular use of Internet slang has resulted in a unique online and offline community as well as a couple sub-categories of \"special internet slang which is different from other slang spread on the whole internet... similar to jargon... usually decided by the sharing community\". It has also led to virtual communities marked by the specific slang they use and led to a more homogenized yet diverse online culture.\n\nBULLET::::- TL;DR\nBULLET::::- Computer-mediated communication\nBULLET::::- Cyberculture: social culture contained and created within cyberspace\nBULLET::::- English language spelling reform\nBULLET::::- Internet linguistics\nBULLET::::- Internet meme\nBULLET::::- Jargon File\nBULLET::::- Languages used on the Internet\nBULLET::::- List of acronyms\nBULLET::::- Chinese Internet slang\nBULLET::::- Netiquette\nBULLET::::- Padonkaffsky jargon, a description of Russian Internet jargon\nBULLET::::- SMS language, a description on language as used in SMSes. Relevant to Internet slang due to transfer of slang into SMS conversation.\nBULLET::::- Tironian notes, scribal abbreviations and ligatures: Roman and medieval abbreviations used to save space on manuscripts and epigraphs\nBULLET::::- Troll (Internet)\n\nBULLET::::- Dictionaries of slang and abbreviations:\n\nBULLET::::- All Acronyms\nBULLET::::- FOLDOC, computing\nBULLET::::- InternetSlang.com\nBULLET::::- SlangInternet.com\nBULLET::::- Internet Slangs\nBULLET::::- Slang Dictionary\nBULLET::::- Full Form Dictionary\nBULLET::::- Full Forms Portal\n"}
{"id": "15174", "url": "https://en.wikipedia.org/wiki?curid=15174", "title": "Impi", "text": "Impi\n\nImpi is a Zulu word meaning war or combat, and by association any body of men gathered for war, for example \"impi ya mashosha\" is a term denoting 'an army'. However, in English \"impi\" is often used to refer to a Zulu regiment, which is called an \"ibutho\" in Zulu. Its beginnings lie far back in historic tribal warfare customs, when groups of armed men called \"impis\" battled. They were systematised radically by the Zulu king Shaka, who was then only the exiled illegitimate son of king Senzangakhona kaJama, but already showing much prowess as a general in the army of Mthethwa king Dingiswayo in the Ndwandwe–Zulu War of 1817–1819.\n\nThe Zulu impi is popularly identified with the ascent of Shaka, ruler of the relatively small Zulu tribe before its explosion across the landscape of southern Africa, but its earliest shape as an instrument of statecraft lies in the innovations of the Mthethwa chieftain Dingiswayo, according to some historians (Morris 1965). These innovations in turn drew upon existing tribal customs, such as the \"iNtanga\". This was an age grade tradition common among many of the Bantu peoples of the continent's southern region. Youths were organised into age groups, with each cohort responsible for certain duties and tribal ceremonies. Periodically, the older age grades were summoned to the kraals of sub-chieftains, or \"inDunas\", for consultations, assignments, and an induction ceremony that marked their transition from boys to full-fledged adults and warriors, the \"ukuButbwa\". Kraal or settlement elders generally handled local disputes and issues. Above them were the inDunas, and above the inDunas stood the chief of a particular clan lineage or tribe. The inDunas handled administrative matters for their chiefs – ranging from settlement of disputes, to the collection of taxes. In time of war, the inDunas supervised the fighting men in their areas, forming leadership of the military forces deployed for combat. The age grade \"iNtangas\", under the guidance of the inDunas, formed the basis for the systematic regimental organisation that would become known worldwide as the impi.\n\nMilitarily warfare was mild among the Bantu prior to the rise of Shaka, though it occurred frequently. Objectives were typically limited to such matters as cattle raiding, avenging some personal insult, or resolving disputes over segments of grazing land. Generally a loose mob, called an \"impi\" participated in these melees. There were no campaigns of extermination against the defeated. They simply moved on to other open spaces on the veldt, and equilibrium was restored. The bow and arrow were known but seldom used. Warfare, like the hunt, depended on skilled spearmen and trackers. The primary weapon was a thin 6-foot throwing spear, the \"assegai\". Several were carried into combat. Defensive weapons included a small cowhide shield, which was later improved by King Shaka. Many battles were prearranged, with the clan warriors meeting at an assigned place and time, while women and children of the clan watched the festivities from some distance away. Ritualized taunts, single combats and tentative charges were the typical pattern. If the affair did not dissipate before, one side might find enough courage to mount a sustained attack, driving off their enemies. Casualties were usually light. The defeated clan might pay in lands or cattle and have captives to be ransomed, but extermination and mass casualties were rare. Tactics were rudimentary. Outside the ritual battles, the quick raid was the most frequent combat action, marked by burning kraals, seizure of captives, and the driving off of cattle. Pastoral herders and light agriculturalists, the Bantu did not usually build permanent fortifications to fend off enemies. A clan under threat simply packed their meager material possessions, rounded up their cattle and fled until the marauders were gone. If the marauders did not stay to permanently dispossess them of grazing areas, the fleeing clan might return to rebuild in a day or two. The genesis of the Zulu impi thus lies in tribal structures existing long before the coming of Europeans or the Shaka era.\n\nIn the early 19th century, a combination of factors began to change the customary pattern. These included rising populations, the growth of white settlement and slaving that dispossessed native peoples both at the Cape and in Portuguese Mozambique, and the rise of ambitious \"new men.\" One such man, a warrior called Dingiswayo (\"the Troubled One\") of the Mthethwa rose to prominence. Historians such as Donald Morris hold that his political genius laid the basis for a relatively light hegemony. This was established through a combination of diplomacy and conquest, using not extermination or slavery, but strategic reconciliation and judicious force of arms. This hegemony reduced the frequent feuding and fighting among the small clans in the Mthethwa's orbit, transferring their energies to more centralised forces. Under Dingiswayo the age grades came to be regarded as military drafts, deployed more frequently to maintain the new order. It was from these small clans, including among them the eLangeni and the Zulu, that Shaka sprung.\n\nShaka proved himself to be one of Dingiswayo's most able warriors after the military call up of his age grade to serve in the Mthethwa forces. He fought with his iziCwe regiment wherever he was assigned during this early period, but from the beginning, Shaka's approach to battle did not fit the traditional mould. He began to implement his own individual methods and style, designing the famous short stabbing spear the \"iKlwa\", a larger, stronger shield, and discarding the oxhide sandals that he felt slowed him down. These methods proved effective on a small scale, but Shaka himself was restrained by his overlord. His conception of warfare was far more extreme than the reconcilitory methods of Dingiswayo. He sought to bring combat to a swift and bloody decision, as opposed to duels of individual champions, scattered raids, or limited skirmishes where casualties were comparatively light. While his mentor and overlord Dingiswayo lived, Shakan methods were reined in, but the removal of this check gave the Zulu chieftain much broader scope. It was under his rule that a much more rigorous mode of tribal warfare came into being. This newer, brutal focus demanded changes in weapons, organisation and tactics.\n\nShaka is credited with introducing a new variant of the traditional weapon, demoting the long, spindly throwing spear in favour of a heavy-bladed, short-shafted stabbing spear. He is also said to have introduced a larger, heavier cowhide shield (\"isihlangu\"), and trained his forces to thus close with the enemy in more effective hand-to-hand combat. The throwing spear was not discarded, but standardised like the stabbing implement and carried as a missile weapon, typically discharged at the foe, before close contact. These weapons changes integrated with and facilitated an aggressive mobility and tactical organisation.\n\nAs weapons, the Zulu warrior carried the \"iklwa\" stabbing spear (losing one could result in execution) and a club or cudgel fashioned from dense hardwood known in Zulu as the \"iwisa\", usually called the knobkerrie or knobkerry English and knopkierie in Afrikaans, for beating an enemy in the manner of a mace. Zulu officers often carried the half-moon-shaped Zulu ax, but this weapon was more of a symbol to show their rank. The iklwa – so named because of the sucking sound it made when withdrawn from a human body – with its long and broad blade was an invention of Shaka that superseded the older thrown \"ipapa\" (so named because of the \"pa-pa\" sound it made as it flew through the air). It could theoretically be used both in melee and as a thrown weapon, but warriors were forbidden in Shaka's day from throwing it, which would disarm them and give their opponents something to throw back. Moreover, Shaka felt it discouraged warriors from closing into hand-to-hand combat.\n\nShaka's brother, and successor, Dingane kaSenzangakhona reintroduced greater use of the throwing spear, perhaps as a counter to Boer firearms.\n\nAs early as Shaka's reign small numbers of firearms, often obsolete muskets and rifles, were obtained by the Zulus from Europeans by trade. In the aftermath of the defeat of the British Empire at the Battle of Isandlwana in 1879, many Martini–Henry rifles were captured by the Zulus together with considerable amounts of ammunition. The advantage of this capture is debatable due to the alleged tendency of Zulu warriors to close their eyes when firing such weapons. The possession of firearms did little to change Zulu tactics, which continued to rely on a swift approach to the enemy to bring him into close combat.\n\nAll warriors carried a shield made of oxhide, which retained the hair, with a central stiffening shaft of wood, the \"mgobo\". Shields were the property of the king; they were stored in specialised structures raised off the ground for protection from vermin when not issued to the relevant regiment. The large \"isihlangu\" shield of Shaka's day was about five feet in length and was later partially replaced by the smaller \"umbumbuluzo,\" a shield of identical manufacture but around three and a half feet in length. Close combat relied on co-ordinated use of the \"iklwa\" and shield. The warrior sought to get the edge of his shield behind the edge of his enemy's, so that he could pull the enemy's shield to the side, thus opening him to a thrust with the \"iklwa\" deep into the abdomen or chest.\n\nThe fast-moving host, like all military formations, needed supplies. These were provided by young boys, who were attached to a force and carried rations, cooking pots, sleeping mats, extra weapons and other material. Cattle were sometimes driven on the hoof as a movable larder. Again, such arrangements in the local context were probably nothing unusual. What was different was the systematisation and organisation, a pattern yielding major benefits when the Zulu were dispatched on raiding missions.\n\nAge-grade groupings of various sorts were common in the Bantu tribal culture of the day, and indeed are still important in much of Africa. Age grades were responsible for a variety of activities, from guarding the camp, to cattle herding, to certain rituals and ceremonies. It was customary in Zulu culture for young men to provide limited service to their local chiefs until they were married and recognised as official householders. Shaka manipulated this system, transferring the customary service period from the regional clan leaders to himself, strengthening his personal hegemony. Such groupings on the basis of age, did not constitute a permanent, paid military in the modern Western sense, nevertheless they did provide a stable basis for sustained armed mobilisation, much more so than ad hoc tribal levies or war parties.\n\nShaka organised the various age grades into regiments, and quartered them in special military kraals, with each regiment having its own distinctive names and insignia. Some historians argue that the large military establishment was a drain on the Zulu economy and necessitated continual raiding and expansion. This may be true since large numbers of the society's men were isolated from normal occupations, but whatever the resource impact, the regimental system clearly built on existing tribal cultural elements that could be adapted and shaped to fit an expansionist agenda.\n\nAfter their 20th birthdays, young men would be sorted into formal \"ibutho\" (plural \"amabutho\") or regiments. They would build their \"i=handa\" (often referred to as a 'homestead', as it was basically a stockaded group of huts surrounding a corral for cattle), their gathering place when summoned for active service. Active service continued until a man married, a privilege only the king bestowed. The amabutho were recruited on the basis of age rather than regional or tribal origin. The reason for this was to enhance the centralised power of the Zulu king at the expense of clan and tribal leaders. They swore loyalty to the king of the Zulu nation.\n\nShaka discarded sandals to enable his warriors to run faster. Initially the move was unpopular, but those who objected were simply killed, a practice that quickly concentrated the minds of remaining personnel. Zulu tradition indicates that Shaka hardened the feet of his troops by having them stamp thorny tree and bush branches flat. Shaka drilled his troops frequently, implementing forced marches covering more than fifty miles a day. He also drilled the troops to carry out encirclement tactics (see below). Such mobility gave the Zulu a significant impact in their local region and beyond. Upkeep of the regimental system and training seems to have continued after Shaka's death, although Zulu defeats by the Boers, and growing encroachment by British colonists, sharply curtailed raiding operations prior to the War of 1879. Morris (1965, 1982) records one such mission under King Mpande to give green warriors of the uThulwana regiment experience: a raid into Swaziland, dubbed \"\"Fund' uThulwana\"\" by the Zulu, or \"Teach the uThulwana\".\n\nImpi warriors were trained as early as age six, joining the army as \"udibi\" porters at first, being enrolled into same-age groups (\"intanga\"). Until they were \"buta\"'d, Zulu boys accompanied their fathers and brothers on campaign as servants. Eventually, they would go to the nearest \"ikhanda\" to \"kleza\" (literally, \"to drink directly from the udder\"), at which time the boys would become \"inkwebane\", cadets. They would spend their time training until they were formally enlisted by the king. They would challenge each other to stick fights, which had to be accepted on pain of dishonor.\n\nIn Shaka's day, warriors often wore elaborate plumes and cow tail regalia in battle, but by the Anglo-Zulu War of 1879, many warriors wore only a loin cloth and a minimal form of headdress. The later period Zulu soldier went into battle relatively simply dressed, painting his upper body and face with chalk and red ochre, despite the popular conception of elaborately panoplied warriors. Each \"ibutho\" had a singular arrangement of headdress and other adornments, so that the Zulu army could be said to have had regimental uniforms; latterly the 'full-dress' was only worn on festive occasions. The men of senior regiments would wear, in addition to their other headdress, the head-ring (\"isicoco\") denoting their married state. A gradation of shield colour was found, junior regiments having largely dark shields the more senior ones having shields with more light colouring; Shaka's personal regiment \"Fasimba\" (The Haze) having white shields with only a small patch of darker colour. This shield uniformity was facilitated by the custom of separating the king's cattle into herds based on their coat colours.\n\nCertain adornments were awarded to individual warriors for conspicuous courage in action; these included a type of heavy brass arm-ring (\"ingxotha\") and an intricate necklace composed of interlocking wooden pegs (\"iziqu\").\n\nThe Zulu typically took the offensive, deploying in the well-known \"buffalo horns\" formation (). It comprised three elements:\n\nBULLET::::1. the \"horns\", or flanking right and left wing elements, to encircle and pin the enemy. Generally the \"horns\" were made up of younger, greener troops.\nBULLET::::2. the \"chest\" sometimes referred to as “head” or central main force which delivered the coup de grace. The prime fighters made up the composition of the main force.\nBULLET::::3. the \"loins\" or reserves used to exploit success or reinforce elsewhere. Often these were older veterans. Sometimes these were positioned with their backs to the battle so as not to get unduly excited.\n\nEncirclement tactics are not unique in warfare, and historians note that attempts to surround an enemy were not unknown even in the ritualised battles. The use of separate manoeuvre elements to support a stronger central group is also well known in pre-mechanised tribal warfare, as is the use of reserve echelons farther back. What was unique about the Zulu was the degree of organisation, consistency with which they used these tactics, and the speed at which they executed them. Developments and refinements may have taken place after Shaka's death, as witnessed by the use of larger groupings of regiments by the Zulu against the British in 1879. Missions, available manpower and enemies varied, but whether facing native spear, or European bullet, the impis generally fought in and adhered to the classical buffalo horns pattern.\n\nRegiments and corps. The Zulu forces were generally grouped into three levels: regiments, corps of several regiments, and \"armies\" or bigger formations, although the Zulu did not use these terms in the modern sense. Although size distinctions were taken account of, any grouping of men on a mission could collectively be called an impi, whether a raiding party of 100 or horde of 10,000. Numbers were not uniform but dependent on a variety of factors, including assignments by the king, or the manpower mustered by various clan chiefs or localities. A regiment might be 400 or 4000 men. These were grouped into corps that took their name from the military kraals where they were mustered, or sometimes the dominant regiment of that locality. There were 4 basic ranks: herdboy assistants, warriors, inDunas and higher ranked supremos for a particular mission.\n\nHigher command and unit leadership. Leadership was not a complicated affair. An inDuna guided each regiment, and he in turn answered to senior izinduna who controlled the corps grouping. Overall guidance of the host was furnished by elder izinduna usually with many years of experience. One or more of these elder chiefs might accompany a big force on an important mission, but there was no single \"field marshal\" in supreme command of all Zulu forces. Regimental izinduna, like the non-coms of today's army, and yesterday's Roman Centurions, were extremely important to morale and discipline. This was shown during the battle of Isandhlwana. Blanketed by a hail of British bullets, rockets and artillery, the advance of the Zulu faltered. Echoing from the mountain, however, were the shouted cadences and fiery exhortations of their regimental izinduna, who reminded the warriors that their king did not send them to run away. Thus encouraged, the encircling regiments remained in place, maintaining continual pressure, until weakened British dispositions enabled the host to make a final surge forward. (See Morris ref below—\"The Washing of the Spears\").\n\nAs noted above, Shaka was neither the originator of the impi, or the age grade structure, nor the concept of a bigger grouping than the small clan system. His major innovations were to blend these traditional elements in a new way, to systematise the approach to battle, and to standardise organization, methods and weapons, particularly in his adoption of the \"ilkwa\" – the Zulu thrusting spear, unique long-term regimental units, and the \"buffalo horns\" formation. Dingswayo's approach was of a loose federation of allies under his hegemony, combining to fight, each with their own contingents, under their own leaders. Shaka dispensed with this, insisting instead on a standardised organisation and weapons package that swept away and replaced old clan allegiances with loyalty to himself. This uniform approach also encouraged the loyalty and identification of warriors with their own distinctive military regiments. In time, these warriors, from many conquered tribes and clans came to regard themselves as one nation- the Zulu. The Marian reforms of Rome in the military sphere are referenced by some writers as similar. While other ancient powers such as the Carthaginians maintained a patchwork of force types, and the legions retained such phalanx-style holdovers like the \"triarii,\" Marius implemented one consistent standardised approach for all the infantry. This enabled more disciplined formations and efficient execution of tactics over time against a variety of enemies. As one military historian notes: \n\nThe impi, in its Shakan form, is best known among Western readers from the Anglo-Zulu War of 1879, particularly the famous Zulu victory at Isandhlwana, but its development was over 60 years in coming before that great clash. To understand the full scope of the impi's performance in battle, military historians of the Zulu typically look to its early operations against internal African enemies, not merely the British interlude. In terms of numbers, the operations of the impi would change- from the Western equivalent of small company and battalion size forces, to manoeuvres in multi-divisional strength of between 10,000 and 40,000 men. The victory won by Zulu king Cetawasyo at Ndondakusuka, for example, two decades before the British invasion involved a deployment of 30,000 troops. These were sizeable formations in regional context but represented the bulk of prime Zulu fighting strength. Few impi-style formations were to routinely achieve this level of mobilisation for a single battle. For example, at Cannae, the Romans deployed 80,000 men, and generally could put tens of thousands more into smaller combat actions). The popular notion of countless attacking black spearmen is a distorted one. Manpower supplies on the continent were often limited. In the words of one historian: \"The savage hordes of popular lore seldom materialized on African battlefields.\" This limited resource base would hurt the Zulu when they confronted technologically advanced world powers such as Britain. The advent of new weapons like firearms would also have a profound impact on the African battlefield, but as will be seen, the impi-style forces largely eschewed firearms, or used them in a minor way. Whether facing native spear or European bullet, impis largely fought as they had since the days of Shaka, from Zululand to Zimbabwe, and from Mozambique to Tanzania.\n\nUpon his accession to power, Shaka was confronted by two potent threats, the Ndwandwes under Zwide, and the Qwabes. Both clans were twice as large as the Zulu. The first key test of the \"new model\" Shakan impis would be against the Ndwandwe, and the battle offers insight into both Shaka as a commander and the performance of his reorganised combat team. The Zulu king deployed his troops in a strong position on top of Gqokli Hill, using a deep depression on the summit to hide a large central reserve, while grouping his other warriors forward in defensive formation. Shaka also made a decoy gambit -- sending the Zulu cattle off with a small escort, luring Zwide into splitting his force. The battle began in the early morning as the Ndwandwe, under Zwide's son Nomahlanjana, made a series of frontal attacks up the steep hill. Slowed by the incline, and armed only with traditional throwing spears, they were badly mauled by Shaka's men in close quarters fighting. By mid-afternoon, the Ndwandwe were exhausted and their force weakened further by small groups of men going off in search of water. Shaka however had cunningly positioned himself so that his troops had access to a small stream nearby. In the late afternoon the Ndwandwe made a final attack. Leaving a part of their army surrounding the bottom of the hill, they pushed a huge column up to the top, hoping to drive the Zulu down into the blocking forces below. Shaka waited until the column was almost at the top, then ordered his fresh reserves to make a flanking \"horn\" attack, sprinting down both sides of the hill to encircle and liquidate the ascending Ndwandwe. The rest of the enemy force, which could not clearly see what was happening on the summit was next attacked in another encircling manoeuvre that sent it fleeing. In its first major battle, the Shakan impi had pulled off a multiple envelopment. On the negative side, the Ndwandwe remnants had been able to withdraw intact, and all the Zulu cattle were captured. Shaka furthermore was forced eventually to recall and pull back the warriors to his kraal at kwaBulawayo. Nevertheless, the impi had badly beaten an enemy force over twice its size, killing 5 of Zwide's sons in the process and succeeding in its first major test. A period of rebuilding now commenced and new recruits, either by conquest or alliance were incorporated into the growing Shakan force. Among the newcomers was one Mzilikazi, a small-time chieftain of the Kumalo, and a grandson of Zwide whose father had been killed by Zwide. Mzilikazi would eventually fall out with Shaka, and in fleeing, would extend the concept of the impi even further across the landscape of southern and eastern Africa.\n\nIn this period Shaka's power grew, defeating several powerful local rivals and creating a vast monolith that was the most powerful nation in its region.\n\nShaka's success was to spawn several offshoots of the impi-style formation. Chief among these was the Matebele, under Mzilkhazi, and the Shangaan, under the redoubtable Soshangane. The greatest expansion of the impi outside the Zululand/Zimbabwe area however was to come in East Africa, where bands of Ngoni fighting men, conquered large swathes of territory, using the methods first laid down by Shaka.\n\nThe impi clashed with another tactical system introduced by European settlers: the horse-gun system of the Boer Commando. This conflict is often popularly conceived of in terms of the well known battles between Zulu King Dingane and the Boers, most notably at the Battle of Blood River. As will be seen however, this tells only part of the story. The impi was to clash with the mobile commando on the open fields of the high veldt in a series of epic confrontations, in which each force both suffered defeat and enjoyed victory, and both sides acquitted themselves well.\n\nNearly 35,000 strong, well motivated and supremely confident, the Zulu were a formidable force on their own home ground, despite the almost total lack of modern weaponry. Their greatest assets were their morale, unit leadership, mobility and numbers. Tactically the Zulu acquitted themselves well in at least 3 encounters, Isandhlwana, Hlobane and the smaller Intombi action. Their stealthy approach march, camouflage and noise discipline at Isandhlwana, while not perfect, put them within excellent striking distance of their opponents, where they were able to exploit weaknesses in the camp layout. At Hlobane they caught a British column on the move rather than in the usual fortified position, partially cutting off its retreat and forcing it to withdraw.\n\nStrategically (and perhaps understandably in their own traditional tribal context) they lacked any clear vision of fighting their most challenging war, aside from smashing the three British columns by the weight and speed of their regiments. Despite the Isandhlwana victory, tactically there were major problems as well. They rigidly and predictably applied their three-pronged \"buffalo horns\" attack, paradoxically their greatest strength, but also their greatest weakness when facing concentrated firepower. The Zulu failed to make use of their superior mobility by attacking the British rear area such as Natal or in interdicting vulnerable British supply lines. However, an important consideration, which King Cetshwayo appreciated, was that there was a clear difference between defending one's territory, and encroaching on another, regardless of the fact that they are at war with the holder of that land. The King realised that peace would be impossible if a real invasion of Natal was launched, and that it would only provoke a more concerted effort on the part of the British against them. The attack on Rorke's Drift, in Natal, was an opportunist raid, as opposed to a real invasion. When they did, they achieved some success, such as the liquidation of a supply detachment at the Intombi River. A more expansive mobile strategy might have cut British communications and brought their lumbering advance to a halt, bottling up the redcoats in scattered strongpoints while the impis ran rampant between them. Just such a scenario developed with the No. 1 British column, which was penned up static and immobile in garrison for over two months at Eshowe.\n\nThe Zulu also allowed their opponents too much time to set up fortified strongpoints, assaulting well defended camps and positions with painful losses. A policy of attacking the redcoats while they were strung out on the move, or crossing difficult obstacles like rivers, might have yielded more satisfactory results. For example, four miles past the Ineyzane River, after the British had comfortably crossed, and after they had spent a day consolidating their advance, the Zulu finally launched a typical \"buffalo horn\" encirclement attack that was seen off with withering fire from not only breech-loading Martini-Henry rifles, but 7-pounder artillery and Gatling guns. In fairness, the Zulu commanders could not conjure regiments out of thin air at the optimum time and place. They too needed time to marshal, supply and position their forces, and sort out final assignments to the three-prongs of attack. Still, the Battle of Hlobane Mountain offers just a glimpse of an alternative mobile scenario, where the manoeuvering Zulu \"horns\" cut off and drove back Buller's column when it was dangerously strung out on the mountain.\n\nCommand and control of the impis was problematic at times. Indeed, the Zulu attacks on the British strongpoints at Rorke's Drift and at Kambula, (both bloody defeats) seemed to have been carried out by over-enthusiastic leaders and warriors despite contrary orders of the Zulu King, Cetshwayo. Popular film re-enactments display a grizzled \"izinduna\" directing the host from a promontory with elegant sweeps of the hand. This might have happened during the initial marshaling of forces from a jump off point, or the deployment of reserves, but once the great encircling sweep of frenzied warriors in the \"horns\" and \"chest\" was in motion, the \"izinduna\" could not generally exercise detailed control.\n\nAlthough the \"loins\" or reserves were on hand to theoretically correct or adjust an unfavorable situation, a shattered attack could make the reserves irrelevant. Against the Boers at Blood River, massed gunfire broke the back of the Zulu assault, and the Boers were later able to mount a cavalry sweep in counterattack that became a turkey shoot against fleeing Zulu remnants. Perhaps the Zulu threw everything forward and had little left. In similar manner, after exhausting themselves against British firepower at Kambula and Ulindi, few of the Zulu reserves were available to do anything constructive, although the tribal warriors still remained dangerous at the guerrilla level when scattered. At Isandhlwana however, the \"classical\" Zulu system struck gold, and after liquidating the British position, it was a relatively fresh reserve force that swept down on Rorke's Drift.\n\nThe Zulu had greater numbers than their opponents, but greater numbers massed together in compact arrays simply presented easy targets in the age of modern firearms and artillery. African tribes that fought in smaller guerrilla detachments typically held out against European invaders for a much longer time, as witnessed by the 7-year resistance of the Lobi against the French in West Africa, or the operations of the Berbers in Algeria against the French.\n\nWhen the Zulu did acquire firearms, most notably captured stocks after the great victory at Isandhlwana, they lacked training and used them ineffectively, consistently firing high to give the bullets \"strength.\" Southern Africa, including the areas near Natal, was teeming with bands like the Griquas who had learned to use guns. Indeed, one such group not only mastered the way of the gun, but became proficient horsemen as well, skills that helped build the Basotho tribe, in what is now the nation of Lesotho. In addition, numerous European renegades or adventurers (both Boer and non-Boer) skilled in firearms were known to the Zulu. Some had even led detachments for the Zulu kings on military missions.\n\nThe Zulu thus had clear scope and opportunity to master and adapt the new weaponry. They also had already experienced defeat against the Boers, by concentrated firearms. They had had at least four decades to adjust their tactics to this new threat. A well-drilled corps of gunmen or grenadiers, or a battery of artillery operated by European mercenaries for example, might have provided much needed covering fire as the regiments manoeuvred into position.\n\nNo such adjustments were on hand when they faced the redcoats. Immensely proud of their system, and failing to learn from their earlier defeats, they persisted in \"human wave\" attacks against well defended European positions where massed firepower devastated their ranks. The ministrations of an \"isAngoma\" (plural: \"izAngoma\") Zulu diviner or \"witch doctor\", and the bravery of individual regiments were ultimately of little use against the volleys of modern rifles, Gatling guns and artillery at the Ineyzane River, Rorke's Drift, Kambula, Gingingdlovu and finally Ulindi.\n\nUndoubtedly, Cetshwayo and his war leaders faced a tough and extremely daunting task – overcoming the challenge of concentrated rifle, Gatling gun, and artillery fire on the battlefield. It was one that also taxed European military leaders, as the carnage of the American Civil War and the later Boer War attests. Nevertheless, Shaka's successors could argue that within the context of their experience and knowledge, they had done the best they could, following his classical template, which had advanced the Zulu from a small, obscure tribe to a respectable regional power known for its fierce warriors.\n\nThe demise of the impi finally came about with the success of European colonisation of Africa- first in southern Africa by the British, and finally in German East Africa as German colonialists defeated the last of the impi-style formations under Mkwawa, chief of the Hehe of Tanzania. The Boers, another major challenger to the impi, also saw defeat by imperial forces, in the Boer War of 1902. In its relatively brief history, the impi inspired both scorn (During the Anglo-Zulu War, British commander Lord Chelmsford complained that they did not 'fight fair') and admiration in its opponents, epitomised in Kipling's poem \"Fuzzy Wuzzy\":\n\nToday the impi lives on in popular lore and culture, even in the West. While the term \"impi\" has become synonymous with the Zulu nation in international popular culture, it appears in various video games such as \"Civilization III\", \"\", \"\", and \"\", where the Impi is the unique unit for the Zulu faction with Shaka as their leader and also as an appearance as unique unit of the Bantu nation in \"Rise of Nations\" (Zulus are among many tribes who make up the Bantu people) . 'Impi' is also the title of a very famous South Africa song by Johnny Clegg and the band Juluka which has become something of an unofficial national anthem, especially at major international sports events and especially when the opponent is England.\n\nLyrics:\n\nBefore stage seven of the 2013 Tour de France, the Orica-GreenEDGE cycling team played 'Impi' on their team bus in honor of teammate Daryl Impey, the first South African Tour de France leader.\n\nBULLET::::- Knight, Ian. \"Brave Men's Blood\", London, 1990. .\nBULLET::::- Knight, Ian. \"The Zulus\".\nBULLET::::- Knight, Ian. \"Anatomy of the Zulu Army\".\n\nBULLET::::- Whybra, Julian. \"England's Sons\", Billericay, (7th ed.), 2010.\n\nBULLET::::- Article about origin and weapons use of Zulu Impi\n\nBULLET::::- African military systems to 1800\nBULLET::::- African military systems after 1900\nBULLET::::- Military history of Africa\nBULLET::::- Ashanti Empire\nBULLET::::- Impi\nBULLET::::- Military history of Africa\nBULLET::::- Mali Empire\nBULLET::::- Military history of the Mali Empire\nBULLET::::- Kingdom of Ndongo\nBULLET::::- Kingdom of Matamba\nBULLET::::- Kingdom of Kongo\nBULLET::::- Nzinga of Ndongo and Matamba\nBULLET::::- Battle of Mbwila\nBULLET::::- Battle of Zama\nBULLET::::- Battle of Isandlwana\n"}
{"id": "15175", "url": "https://en.wikipedia.org/wiki?curid=15175", "title": "Irish mythology", "text": "Irish mythology\n\nThe mythology of pre-Christian Ireland was preserved in a highly-conservative oral tradition. With the arrival of Christianity, the first manuscripts were written in Ireland, preserving many of these tales in medieval Irish literature. Though the Christian influence is also seen in these manuscripts, this literature represents the most extensive and best preserved of all the branches of Celtic mythology. Although many of the manuscripts have not survived and much more material was probably never committed to writing, there is enough remaining to enable the identification of distinct, if overlapping, cycles: the Mythological Cycle, the Ulster Cycle, the Fenian Cycle and the Historical Cycle. There are also a number of extant mythological texts that do not fit into any of the cycles, and many recorded folk tales that continued as the oral tradition ran parallel to the manuscript tradition which, while not strictly mythological, feature personages from one or more of these four cycles.\n\nToday some of the best known tales are of Tír na nÓg, Fionn MacCumhaill, Na Fianna, The Aos Sí / Aes Sídhe, Sétanta (CúChulainn), The Tuatha Dé Danann (Gods), the Children of Lir, Táin Bó Cúailnge & the Salmon of Knowledge.\n\nDepending on the sources, the importance of gods and goddesses in Irish mythology varies. The geographical tales, Dindshenchas, emphasize the importance of female divinities and powerful ancestors, while the historical tradition focuses on the colonizers, inventors, or male warriors with the female characters only intervening in episodes.\n\nThe primal and ancestral goddesses are connected to the land, the waters, sovereignty, and often seen as the oldest ancestors of the people in the region or nation. They are maternal figures caring for the earth itself as well as their descendants, but also fierce defenders, teachers and warriors. More personalized deities may be connected to cultural qualities such as, in the case of Brigid, poetry, smith craft, and healing. Some of the female figures associated with the druids are prophetic, especially when foretelling death and doom. Zoomorphism is an important feature for many Irish deities. Badb Catha, for instance, is \"the Raven of Battle\", and in the \"Táin Bó Cúailnge\", The Morrígan changes into an eel, a wolf and a cow.\n\nThe Celtic goddesses are not divided by singular qualities such as \"love goddess\", but are more of the nature of well-rounded humans, who have areas of special interests or skills. In this way, they do not correspond directly to other pantheons such as those of the Greeks or Romans.\n\nThe mother of the Tuatha Dé Danann is generally considered to be Anu or Danu.\n\nA number of the goddesses are associated with sacred sites where seasonal festivals are held. They include Macha of Eamhain Mhacha, Carman, and Tailtiu, among others.\n\nWarrior Goddesses are often depicted as a triad, and connected with sovereignty and sacred animals. The animals may be associated with carnage, such as wolves and crows, or the abundance of the land, such as cattle. They guard the battlefield and those who do battle, and according to the stories in the \"Táin Bó Cúailnge\", some of these goddesses may be the instigators and directors of the entire war themselves. The main goddesses of battle are The Morrígan, Macha, and Badb. Other warrior women are seen in the role of training warriors in the Fianna bands, such as Liath Luachra, one of the women who trained the hero Fionn mac Cumhaill.\n\nThe Irish Gods are divided into four main groups. Group one encompasses the older gods of Gaul and Britain. The second group is the main focus of much of the mythology and surrounds the native Irish gods with their homes in burial mounds (The Great Barrows of the Dead). The third group are the gods that dwell in the sea and the fourth group includes stories of the Otherworld. The gods that appear most often are Dagda and Lug. Some scholars have argued that the stories of these gods align with the Greek stories and gods.\n\nDruids were held in high esteem by the community as religious leaders, teachers, and skilled members of various professions.\n\nHeroes in Irish mythology can be found in two distinct groups. There is the lawful hero who exists within the boundaries of the community, protecting their people from outsiders. Within the kin-group or \"túath \", heroes are human and gods are not.\n\nThe Fianna warrior bands are seen as outsiders, connected with the wilderness, youth, and liminal states. They are considered outsiders who protect the community from other outsiders; though they may winter with a settled community, they spend the summers living wild, training adolescents and providing a space for war-damaged veterans. They live under the authority of their own leaders, or may be somewhat anarchic, and may follow other deities or spirits than the settled communities.\n\nThe three main manuscript sources for Irish mythology are the late 11th/early 12th century \"Lebor na hUidre\" (Book of the Dun Cow) which is in the library of the Royal Irish Academy, the early 12th century \"Book of Leinster\" in the Library of Trinity College, Dublin, and the Bodleian Library, MS Rawlinson B 502 (\"Rawl.\"), housed in the Bodleian Library at Oxford University. Despite the dates of these sources, most of the material they contain predates their composition. It is the oldest surviving manuscript written entirely in the Irish language. The stories in this manuscript are a part of the Ulster Cycle of Irish Mythology.\n\nOther important sources include a group of four manuscripts originating in the west of Ireland in the late 14th or early 15th century: \"The Yellow Book of Lecan\", \"The Great Book of Lecan\", and \"The Book of Ballymote\". The first is these is housed in Trinity College as well as three others are in the Royal Academy. The Yellow Book of Lecan is composed of sixteen parts and includes the legends of Fionn Mac Cumhail, selections of legends of Irish Saints, and the earliest known version of the \"Táin Bó Cúailnge\" (\"The Driving-off of Cattle of Cooley\"). This is one of Europe's oldest epics written in a vernacular language. Other 15th-century manuscripts, such as \"The Book of Fermoy\" also contain interesting materials, as do such later syncretic works such as Geoffrey Keating's \"Foras Feasa ar Éirinn\" (\"The History of Ireland\") (ca. 1640), particularly as these later compilers and writers may have had access to manuscript sources that have since disappeared.\n\nWhen using these sources, it is, as always, important to question the impact of the circumstances in which they were produced. Most of the manuscripts were created by Christian monks, who may well have been torn between the desire to record their native culture and their religious hostility to pagan beliefs resulting in some of the gods being euhemerised. Many of the later sources may also have formed part of a propaganda effort designed to create a history for the people of Ireland that could bear comparison with the mythological descent of their British invaders from the founders of Rome that was promulgated by Geoffrey of Monmouth and others. There was also a tendency to rework Irish genealogies to fit into the known schema of Greek or Biblical genealogy.\n\nIt was once unquestioned that medieval Irish literature preserved truly ancient traditions in a form virtually unchanged through centuries of oral tradition back to the ancient Celts of Europe. Kenneth Jackson famously described the Ulster Cycle as a \"window on the Iron Age\", and Garret Olmsted has attempted to draw parallels between \"Táin Bó Cuailnge\", the Ulster Cycle epic, and the iconography of the Gundestrup Cauldron. However, this \"nativist\" position has been challenged by \"revisionist\" scholars who believe that much of it was created in Christian times in deliberate imitation of the epics of classical literature that came with Latin learning. The revisionists would indicate passages apparently influenced by the Iliad in \"Táin Bó Cuailnge\", and the existence of \"Togail Troí\", an Irish adaptation of Dares Phrygius' \"De excidio Troiae historia\", found in the Book of Leinster, and note that the material culture of the stories is generally closer to the time of the stories' composition than to the distant past. A consensus has emerged which encourages the critical reading of the material.\n\nThe Mythological Cycle, comprising stories of the former gods and origins of the Irish, is the least well preserved of the four cycles. It is about the principal people who invaded and inhabited the island. The people include Cessair and her followers, The Formorians, The Partholinians, The Nemedians, The Firbolgs, the Tuatha Dé Danann, and the Milesians. The most important sources are the \"Metrical Dindshenchas\" or \"Lore of Places\" and the \"Lebor Gabála Érenn\" or \"Book of Invasions\". Other manuscripts preserve such mythological tales as \"The Dream of Aengus\", \"The Wooing Of Étain\" and \"Cath Maige Tuireadh\", \"The (second) Battle of Magh Tuireadh\". One of the best known of all Irish stories, \"Oidheadh Clainne Lir\", or \"The Tragedy of the Children of Lir\", is also part of this cycle.\n\"Lebor Gabála Érenn\" is a pseudo-history of Ireland, tracing the ancestry of the Irish back to before Noah. It tells of a series of invasions or \"takings\" of Ireland by a succession of peoples, the fifth of whom was the people known as the Tuatha Dé Danann (\"Peoples of the Goddess Danu\"), who were believed to have inhabited the island before the arrival of the Gaels, or Milesians. They faced opposition from their enemies, the Fomorians, led by Balor of the Evil Eye. Balor was eventually slain by Lugh Lámfada (Lugh of the Long Arm) at the second battle of Magh Tuireadh. With the arrival of the Gaels, the Tuatha Dé Danann retired underground to become the fairy people of later myth and legend.\n\nThe \"Metrical Dindshenchas\" is the great onomastics work of early Ireland, giving the naming legends of significant places in a sequence of poems. It includes a lot of important information on Mythological Cycle figures and stories, including the Battle of Tailtiu, in which the Tuatha Dé Danann were defeated by the Milesians.\n\nIt is important to note that by the Middle Ages the Tuatha Dé Danann were not viewed so much as gods as the shape-shifting magician population of an earlier Golden Age Ireland. Texts such as \"Lebor Gabála Érenn\" and \"Cath Maige Tuireadh\" present them as kings and heroes of the distant past, complete with death-tales. However, there is considerable evidence, both in the texts and from the wider Celtic world, that they were once considered deities.\n\nEven after they are displaced as the rulers of Ireland, characters such as Lugh, the Mórrígan, Aengus and Manannán Mac Lir appear in stories set centuries later, betraying their immortality. A poem in the Book of Leinster lists many of the Tuatha Dé, but ends \"Although [the author] enumerates them, he does not worship them\". Goibniu, Creidhne and Luchta are referred to as \"Trí Dé Dána\" (\"three gods of craftsmanship\"), and the Dagda's name is interpreted in medieval texts as \"the good god\". Nuada is cognate with the British god Nodens; Lugh is a reflex of the pan-Celtic deity Lugus, the name of whom may indicate \"Light\"; Tuireann may be related to the Gaulish Taranis; Ogma to Ogmios; the Badb to Catubodua.\n\nThe Ulster Cycle is traditionally set around the first century CE, and most of the action takes place in the provinces of Ulster and Connacht. It consists of a group of heroic tales dealing with the lives of Conchobar mac Nessa, king of Ulster, the great hero Cú Chulainn, who was the son of Lug (Lugh), and of their friends, lovers, and enemies. These are the Ulaid, or people of the North-Eastern corner of Ireland and the action of the stories centres round the royal court at Emain Macha (known in English as Navan Fort), close to the modern town of Armagh. The Ulaid had close links with the Irish colony in Scotland, and part of Cú Chulainn's training takes place in that colony.\n\nThe cycle consists of stories of the births, early lives and training, wooings, battles, feastings, and deaths of the heroes and reflects a warrior society in which warfare consists mainly of single combats and wealth is measured mainly in cattle. These stories are written mainly in prose. The centrepiece of the Ulster Cycle is the \"Táin Bó Cúailnge\". Other important Ulster Cycle tales include \"The Tragic Death of Aife's only Son\", \"Bricriu's Feast\", and \"The Destruction of Da Derga's Hostel\". \"The Exile of the Sons of Usnach\", better known as the tragedy of Deirdre and the source of plays by John Millington Synge, William Butler Yeats, and Vincent Woods, is also part of this cycle.\n\nThis cycle is, in some respects, close to the mythological cycle. Some of the characters from the latter reappear, and the same sort of shape-shifting magic is much in evidence, side by side with a grim, almost callous realism. While we may suspect a few characters, such as Medb or Cú Roí, of once being deities, and Cú Chulainn in particular displays superhuman prowess, the characters are mortal and associated with a specific time and place. If the Mythological Cycle represents a Golden Age, the Ulster Cycle is Ireland's Heroic Age.\n\nLike the Ulster Cycle, the Fenian Cycle, also referred to as the Ossianic Cycle, is concerned with the deeds of Irish heroes. The stories of the Fenian Cycle appear to be set around the 3rd century and mainly in the provinces of Leinster and Munster. They differ from the other cycles in the strength of their links with the Gaelic-speaking community in Scotland and there are many extant Fenian texts from that country. They also differ from the Ulster Cycle in that the stories are told mainly in verse and that in tone they are nearer to the tradition of romance than the tradition of epic. The stories concern the doings of Fionn mac Cumhaill and his band of soldiers, the Fianna.\nThe single most important source for the Fenian Cycle is the \"Acallam na Senórach\" (\"Colloquy of the Old Men\"), which is found in two 15th-century manuscripts, the \"Book of Lismore\" and Laud 610, as well as a 17th-century manuscript from Killiney, County Dublin. The text is dated from linguistic evidence to the 12th century. The text records conversations between Caílte mac Rónáin and Oisín, the last surviving members of the Fianna, and Saint Patrick, and consists of about 8,000 lines. The late dates of the manuscripts may reflect a longer oral tradition for the Fenian stories.\n\nThe Fianna of the story are divided into the Clann Baiscne, led by Fionn mac Cumhaill (often rendered as \"Finn MacCool\", Finn Son of Cumhall), and the Clann Morna, led by his enemy, Goll mac Morna. Goll killed Fionn's father, Cumhal, in battle and the boy Fionn was brought up in secrecy. As a youth, while being trained in the art of poetry, he accidentally burned his thumb while cooking the Salmon of Knowledge, which allowed him to suck or bite his thumb to receive bursts of stupendous wisdom. He took his place as the leader of his band and numerous tales are told of their adventures. Two of the greatest of the Irish tales, \"Tóraigheacht Dhiarmada agus Ghráinne\" (\"The Pursuit of Diarmuid and Gráinne)\" and \"Oisín in Tír na nÓg\" form part of the cycle. The Diarmuid and Grainne story, which is one of the few Fenian prose tales, is a probable source of \"Tristan and Iseult\".\n\nThe world of the Fenian Cycle is one in which professional warriors spend their time hunting, fighting, and engaging in adventures in the spirit world. New entrants into the band are expected to be knowledgeable in poetry as well as undergo a number of physical tests or ordeals. Most of the poems are attributed to being composed by Oisín\".\" This cycle creates a bridge between pre-Christian and Christian times.\n\nIt was part of the duty of the medieval Irish bards, or court poets, to record the history of the family and the genealogy of the king they served. This they did in poems that blended the mythological and the historical to a greater or lesser degree. The resulting stories form what has come to be known as the Historical Cycle or Cycles of the Kings, or more correctly Cycles, as there are a number of independent groupings.\n\nThe kings that are included range from the almost entirely mythological Labraid Loingsech, who allegedly became High King of Ireland around 431 BC, to the entirely historical Brian Boru. However, the greatest glory of the Historical Cycle is the \"Buile Shuibhne\" (\"The Frenzy of Sweeney\"), a 12th-century tale told in verse and prose. Suibhne, king of Dál nAraidi, was cursed by St Ronan and became a kind of half-man, half bird, condemned to live out his life in the woods, fleeing from his human companions. The story has captured the imaginations of contemporary Irish poets and has been translated by Trevor Joyce and Seamus Heaney.\n\nThe adventures, or \"echtrae\", are a group of stories of visits to the Irish Other World (which may be westward across the sea, underground, or simply invisible to mortals). The most famous, \"Oisin in Tir na nÓg\" belongs to the Fenian Cycle, but several free-standing adventures survive, including \"The Adventure of Conle\", \"The Voyage of Bran mac Ferbail\", and \"The Adventure of Lóegaire\".\n\nThe voyages, or \"immrama\", are tales of sea journeys and the wonders seen on them that may have resulted from the combination of the experiences of fishermen combined and the Other World elements that inform the adventures. Of the seven \"immrama\" mentioned in the manuscripts, only three have survived: the \"Voyage of Mael Dúin\", the \"Voyage of the Uí Chorra\", and the \"Voyage of Snedgus and Mac Riagla\". \"The Voyage of Mael Duin\" is the forerunner of the later \"Voyage of St. Brendan\". While not as ancient, later 8th century AD works, that influenced European literature, include The Vision of Adamnán.\n\nDuring the first few years of the 20th Century, Herminie T. Kavanagh wrote down many Irish folk tales which she published in magazines and in two books. Twenty-six years after her death, the tales from her two books, \"Darby O'Gill and the Good People\", and \"Ashes of Old Wishes\" were made into the film Darby O'Gill and the Little People. Noted Irish playwright Lady Gregory also collected folk stories to preserve Irish history.\n\nBULLET::::- Cross, Tom Peete and Clark Harris Slover. \"Ancient Irish Tales\". Barnes and Noble Books, Totowa, New Jersey, 1936 repr. 1988. .\nBULLET::::- Dillon, Myles. \"The Cycles of the Kings\". Oxford University Press, 1946; reprinted Four Courts Press: Dublin and Portland, OR, 1994. .\nBULLET::::- Dillon, Myles. \"Early Irish Literature\". Chicago: University of Chicago Press, 1948; reprinted : Four Courts Press, Dublin and Portland, OR, 1994. .\nBULLET::::- Joseph Dunn: \"The Ancient Irish Epic Tale Táin Bó Cúailnge\" (1914)\nBULLET::::- Winifred Faraday: \"The Cattle-Raid of Cualng\". London, 1904. This is a partial translation of the text in the Yellow Book of Lecan, partially censored by Faraday.\nBULLET::::- Gantz, Jeffrey. \"Early Irish Myths and Sagas\". London: Penguin Books, 1981. .\nBULLET::::- Kinsella, Thomas. \"The Tain\". Oxford: Oxford University Press, 1970. .\nBULLET::::- Gregory, Lady Augusta. \"Cuchulain of Muirtheme\". First Published 1902.\n\nBULLET::::- \"Cath Maige Tuired: The Second Battle of Mag Tuired\". Elizabeth A. Gray, Ed. Dublin: Irish Texts Society, 1982. Series: Irish Texts Society (Series) ; v. 52. Irish text, English translation and philological notes.\nBULLET::::- \"Táin Bo Cuailnge from the Book of Leinster\". Cecile O'Rahilly, Ed. Dublin Institute for Advanced Studies, 1984.\nBULLET::::- \"Táin Bo Cuailnge Recension I\". Cecile O'Rahilly, Ed. Dublin Institute for Advanced Studies 1976. Irish text, English translation and philological notes.\n\nBULLET::::- Coghlan, Ronan \"Pocket Dictionary of Irish Myth and Legend\". Belfast: Appletree, 1985.\nBULLET::::- Mallory, J. P. Ed. \"Aspects of the Tain\". Belfast: December Publications, 1992. .\nBULLET::::- O'Rahilly, T. F. \"Early Irish History and Mythology\" (1946)\nBULLET::::- O hOgain, Daithi \"Myth, Legend and Romance: An Encyclopedia of the Irish Folk Tradition\" Prentice Hall Press, (1991) : (the only dictionary/encyclopedia with source references for every entry)\nBULLET::::- Rees, Brinley and Alwyn Rees. \"Celtic Heritage: Ancient Tradition in Ireland and Wales\". New York: Thames and Hudson, 1961; repr. 1989. .\nBULLET::::- Sjoestedt, M. L. \"Gods and Heroes of the Celts\". 1949; translated by Myles Dillon. repr. Berkeley, CA: Turtle Press, 1990. .\nBULLET::::- Williams, J. F. Caerwyn. \"Irish Literary History\". Trans. Patrick K. Ford. University of Wales Press, Cardiff, Wales, and Ford and Bailie, Belmont, Massachusetts. Welsh edition 1958, English translation 1992. .\n\nBULLET::::- Lady Francesca Speranza Wilde, \"Ancient Legends, Mystic Charms, and Superstitions of Ireland\" (1887)\nBULLET::::- James Bonwick, \"Irish Druids and Old Irish Religions\" (1894)\nBULLET::::- Lady Augusta Gregory : \"Cuchulain of Muirthemne\" (1902), and \"Gods and Fighting Men\" (1904)\nBULLET::::- Juliet Marillier : \"Daughter of the Forest\", \"Son of the Shadows\", and \"Child of the Prophecy\" (Sevenwaters trilogy, 1999-2001).\nBULLET::::- Gregory Frost : \"Tain\" (1986), and \"Remscela\" (1988)\nBULLET::::- Morgan Llywelyn : \"Red Branch\" (1989), \"Finn MacCool\" (1994), and \"\" (1984)\nBULLET::::- James Stephens : \"Irish Fairy Tales\" (1920)\nBULLET::::- Lenihan, Eddie and Carolyn Eve Green. \"Meeting the Other Crowd\": \"The Fairy Stories of Hidden Ireland\". New York. Jeremy P. Tarcher/Penguin. 2004.\n\nBULLET::::- Department of Irish Folklore, Dublin. Includes the National Folklore Archives\nBULLET::::- The Celtic Literature Collection\nBULLET::::- Legendary Fictions of the Irish Celts\nBULLET::::- Timeless Myths: Celtic Mythology\n"}
{"id": "15176", "url": "https://en.wikipedia.org/wiki?curid=15176", "title": "Insurance", "text": "Insurance\n\nInsurance is a means of protection from financial loss. It is a form of risk management, primarily used to hedge against the risk of a contingent or uncertain loss.\n\nAn entity which provides insurance is known as an insurer, insurance company, insurance carrier or underwriter. A person or entity who buys insurance is known as an insured or as a policyholder. The insurance transaction involves the insured assuming a guaranteed and known relatively small loss in the form of payment to the insurer in exchange for the insurer's promise to compensate the insured in the event of a covered loss. The loss may or may not be financial, but it must be reducible to financial terms, and usually involves something in which the insured has an insurable interest established by ownership, possession, or pre-existing relationship.\n\nThe insured receives a contract, called the insurance policy, which details the conditions and circumstances under which the insurer will compensate the insured. The amount of money charged by the insurer to the policyholder for the coverage set forth in the insurance policy is called the premium. If the insured experiences a loss which is potentially covered by the insurance policy, the insured submits a claim to the insurer for processing by a claims adjuster. The insurer may hedge its own risk by taking out reinsurance, whereby another insurance company agrees to carry some of the risk, especially if the primary insurer deems the risk too large for it to carry.\n\nMethods for transferring or distributing risk were practiced by Chinese and Babylonian traders as long ago as the 3rd and 2nd millennia BC, respectively. Chinese merchants travelling treacherous river rapids would redistribute their wares across many vessels to limit the loss due to any single vessel's capsizing. The Babylonians developed a system which was recorded in the famous Code of Hammurabi, c. 1750 BC, and practiced by early Mediterranean sailing merchants. If a merchant received a loan to fund his shipment, he would pay the lender an additional sum in exchange for the lender's guarantee to cancel the loan should the shipment be stolen, or lost at sea.\n\nCirca 800 BC, the inhabitants of Rhodes created the 'general average'. This allowed groups of merchants to pay to insure their goods being shipped together. The collected premiums would be used to reimburse any merchant whose goods were jettisoned during transport, whether due to storm or sinkage.\n\nSeparate insurance contracts (i.e., insurance policies not bundled with loans or other kinds of contracts) were invented in Genoa in the 14th century, as were insurance pools backed by pledges of landed estates. The first known insurance contract dates from Genoa in 1347, and in the next century maritime insurance developed widely and premiums were intuitively varied with risks. These new insurance contracts allowed insurance to be separated from investment, a separation of roles that first proved useful in marine insurance.\n\nInsurance became far more sophisticated in Enlightenment era Europe, and specialized varieties developed.\nProperty insurance as we know it today can be traced to the Great Fire of London, which in 1666 devoured more than 13,000 houses. The devastating effects of the fire converted the development of insurance \"from a matter of convenience into one of urgency, a change of opinion reflected in Sir Christopher Wren's inclusion of a site for 'the Insurance Office' in his new plan for London in 1667.\" A number of attempted fire insurance schemes came to nothing, but in 1681, economist Nicholas Barbon and eleven associates established the first fire insurance company, the \"Insurance Office for Houses\", at the back of the Royal Exchange to insure brick and frame homes. Initially, 5,000 homes were insured by his Insurance Office.\n\nAt the same time, the first insurance schemes for the underwriting of business ventures became available. By the end of the seventeenth century, London's growing importance as a center for trade was increasing demand for marine insurance. In the late 1680s, Edward Lloyd opened a coffee house, which became the meeting place for parties in the shipping industry wishing to insure cargoes and ships, and those willing to underwrite such ventures. These informal beginnings led to the establishment of the insurance market Lloyd's of London and several related shipping and insurance businesses.\nThe first life insurance policies were taken out in the early 18th century. The first company to offer life insurance was the Amicable Society for a Perpetual Assurance Office, founded in London in 1706 by William Talbot and Sir Thomas Allen. Edward Rowe Mores established the Society for Equitable Assurances on Lives and Survivorship in 1762.\n\nIt was the world's first mutual insurer and it pioneered age based premiums based on mortality rate laying \"the framework for scientific insurance practice and development\" and \"the basis of modern life assurance upon which all life assurance schemes were subsequently based.\"\n\nIn the late 19th century \"accident insurance\" began to become available. The first company to offer accident insurance was the Railway Passengers Assurance Company, formed in 1848 in England to insure against the rising number of fatalities on the nascent railway system.\n\nBy the late 19th century governments began to initiate national insurance programs against sickness and old age. Germany built on a tradition of welfare programs in Prussia and Saxony that began as early as in the 1840s. In the 1880s Chancellor Otto von Bismarck introduced old age pensions, accident insurance and medical care that formed the basis for Germany's welfare state. In Britain more extensive legislation was introduced by the Liberal government in the 1911 National Insurance Act. This gave the British working classes the first contributory system of insurance against illness and unemployment. This system was greatly expanded after the Second World War under the influence of the Beveridge Report, to form the first modern welfare state.\n\nInsurance involves pooling funds from \"many\" insured entities (known as exposures) to pay for the losses that some may incur. The insured entities are therefore protected from risk for a fee, with the fee being dependent upon the frequency and severity of the event occurring. In order to be an insurable risk, the risk insured against must meet certain characteristics. Insurance as a financial intermediary is a commercial enterprise and a major part of the financial services industry, but individual entities can also self-insure through saving money for possible future losses.\n\nRisk which can be insured by private companies typically shares seven common characteristics:\n\nBULLET::::1. Large number of similar exposure units: Since insurance operates through pooling resources, the majority of insurance policies are provided for individual members of large classes, allowing insurers to benefit from the law of large numbers in which predicted losses are similar to the actual losses. Exceptions include Lloyd's of London, which is famous for ensuring the life or health of actors, sports figures, and other famous individuals. However, all exposures will have particular differences, which may lead to different premium rates.\nBULLET::::2. Definite loss: The loss takes place at a known time, in a known place, and from a known cause. The classic example is death of an insured person on a life insurance policy. Fire, automobile accidents, and worker injuries may all easily meet this criterion. Other types of losses may only be definite in theory. Occupational disease, for instance, may involve prolonged exposure to injurious conditions where no specific time, place, or cause is identifiable. Ideally, the time, place, and cause of a loss should be clear enough that a reasonable person, with sufficient information, could objectively verify all three elements.\nBULLET::::3. Accidental loss: The event that constitutes the trigger of a claim should be fortuitous, or at least outside the control of the beneficiary of the insurance. The loss should be pure, in the sense that it results from an event for which there is only the opportunity for cost. Events that contain speculative elements such as ordinary business risks or even purchasing a lottery ticket are generally not considered insurable.\nBULLET::::4. Large loss: The size of the loss must be meaningful from the perspective of the insured. Insurance premiums need to cover both the expected cost of losses, plus the cost of issuing and administering the policy, adjusting losses, and supplying the capital needed to reasonably assure that the insurer will be able to pay claims. For small losses, these latter costs may be several times the size of the expected cost of losses. There is hardly any point in paying such costs unless the protection offered has real value to a buyer.\nBULLET::::5. Affordable premium: If the likelihood of an insured event is so high, or the cost of the event so large, that the resulting premium is large relative to the amount of protection offered, then it is not likely that the insurance will be purchased, even if on offer. Furthermore, as the accounting profession formally recognizes in financial accounting standards, the premium cannot be so large that there is not a reasonable chance of a significant loss to the insurer. If there is no such chance of loss, then the transaction may have the form of insurance, but not the substance (see the U.S. Financial Accounting Standards Board pronouncement number 113: \"Accounting and Reporting for Reinsurance of Short-Duration and Long-Duration Contracts\").\nBULLET::::6. Calculable loss: There are two elements that must be at least estimable, if not formally calculable: the probability of loss, and the attendant cost. Probability of loss is generally an empirical exercise, while cost has more to do with the ability of a reasonable person in possession of a copy of the insurance policy and a proof of loss associated with a claim presented under that policy to make a reasonably definite and objective evaluation of the amount of the loss recoverable as a result of the claim.\nBULLET::::7. Limited risk of catastrophically large losses: Insurable losses are ideally independent and non-catastrophic, meaning that the losses do not happen all at once and individual losses are not severe enough to bankrupt the insurer; insurers may prefer to limit their exposure to a loss from a single event to some small portion of their capital base. Capital constrains insurers' ability to sell earthquake insurance as well as wind insurance in hurricane zones. In the United States, flood risk is insured by the federal government. In commercial fire insurance, it is possible to find single properties whose total exposed value is well in excess of any individual insurer's capital constraint. Such properties are generally shared among several insurers, or are insured by a single insurer who syndicates the risk into the reinsurance market.\n\nWhen a company insures an individual entity, there are basic legal requirements and regulations. Several commonly cited legal principles of insurance include:\nBULLET::::1. Indemnity – the insurance company indemnifies, or compensates, the insured in the case of certain losses only up to the insured's interest.\nBULLET::::2. Benefit insurance – as it is stated in the study books of The Chartered Insurance Institute, the insurance company does not have the right of recovery from the party who caused the injury and is to compensate the Insured regardless of the fact that Insured had already sued the negligent party for the damages (for example, personal accident insurance)\nBULLET::::3. Insurable interest – the insured typically must directly suffer from the loss. Insurable interest must exist whether property insurance or insurance on a person is involved. The concept requires that the insured have a \"stake\" in the loss or damage to the life or property insured. What that \"stake\" is will be determined by the kind of insurance involved and the nature of the property ownership or relationship between the persons. The requirement of an insurable interest is what distinguishes insurance from gambling.\nBULLET::::4. Utmost good faith – (Uberrima fides) the insured and the insurer are bound by a good faith bond of honesty and fairness. Material facts must be disclosed.\nBULLET::::5. Contribution – insurers which have similar obligations to the insured contribute in the indemnification, according to some method.\nBULLET::::6. Subrogation – the insurance company acquires legal rights to pursue recoveries on behalf of the insured; for example, the insurer may sue those liable for the insured's loss. The Insurers can waive their subrogation rights by using the special clauses.\nBULLET::::7. Causa proxima, or proximate cause – the cause of loss (the peril) must be covered under the insuring agreement of the policy, and the dominant cause must not be excluded\nBULLET::::8. Mitigation – In case of any loss or casualty, the asset owner must attempt to keep loss to a minimum, as if the asset was not insured.\n\nTo \"indemnify\" means to make whole again, or to be reinstated to the position that one was in, to the extent possible, prior to the happening of a specified event or peril. Accordingly, life insurance is generally not considered to be indemnity insurance, but rather \"contingent\" insurance (i.e., a claim arises on the occurrence of a specified event). There are generally three types of insurance contracts that seek to indemnify an insured:\nBULLET::::1. A \"reimbursement\" policy\nBULLET::::2. A \"pay on behalf\" or \"on behalf of policy\"\nBULLET::::3. An \"indemnification\" policy\n\nFrom an insured's standpoint, the result is usually the same: the insurer pays the loss and claims expenses.\n\nIf the Insured has a \"reimbursement\" policy, the insured can be required to pay for a loss and then be \"reimbursed\" by the insurance carrier for the loss and out of pocket costs including, with the permission of the insurer, claim expenses.\n\nUnder a \"pay on behalf\" policy, the insurance carrier would defend and pay a claim on behalf of the insured who would not be out of pocket for anything. Most modern liability insurance is written on the basis of \"pay on behalf\" language which enables the insurance carrier to manage and control the claim.\n\nUnder an \"indemnification\" policy, the insurance carrier can generally either \"reimburse\" or \"pay on behalf of\", whichever is more beneficial to it and the insured in the claim handling process.\n\nAn entity seeking to transfer risk (an individual, corporation, or association of any type, etc.) becomes the 'insured' party once risk is assumed by an 'insurer', the insuring party, by means of a contract, called an insurance policy. Generally, an insurance contract includes, at a minimum, the following elements: identification of participating parties (the insurer, the insured, the beneficiaries), the premium, the period of coverage, the particular loss event covered, the amount of coverage (i.e., the amount to be paid to the insured or beneficiary in the event of a loss), and exclusions (events not covered). An insured is thus said to be \"indemnified\" against the loss covered in the policy.\n\nWhen insured parties experience a loss for a specified peril, the coverage entitles the policyholder to make a claim against the insurer for the covered amount of loss as specified by the policy. The fee paid by the insured to the insurer for assuming the risk is called the premium. Insurance premiums from many insureds are used to fund accounts reserved for later payment of claims – in theory for a relatively few claimants – and for overhead costs. So long as an insurer maintains adequate funds set aside for anticipated losses (called reserves), the remaining margin is an insurer's profit.\n\nPolicies typically include a number of exclusions, including typically:\nBULLET::::- Nuclear exclusion clause, excluding damage caused by nuclear and radiation accidents\nBULLET::::- War exclusion clause, excluding damage from acts of war or terrorism\n\nInsurance can have various effects on society through the way that it changes who bears the cost of losses and damage. On one hand it can increase fraud; on the other it can help societies and individuals prepare for catastrophes and mitigate the effects of catastrophes on both households and societies.\n\nInsurance can influence the probability of losses through moral hazard, insurance fraud, and preventive steps by the insurance company. Insurance scholars have typically used moral hazard to refer to the increased loss due to unintentional carelessness and insurance fraud to refer to increased risk due to intentional carelessness or indifference. Insurers attempt to address carelessness through inspections, policy provisions requiring certain types of maintenance, and possible discounts for loss mitigation efforts. While in theory insurers could encourage investment in loss reduction, some commentators have argued that in practice insurers had historically not aggressively pursued loss control measures—particularly to prevent disaster losses such as hurricanes—because of concerns over rate reductions and legal battles. However, since about 1996 insurers have begun to take a more active role in loss mitigation, such as through building codes.\n\nAccording to the study books of The Chartered Insurance Institute, there are variant methods of insurance as follows:\nBULLET::::1. Co-insurance – risks shared between insurers\nBULLET::::2. Dual insurance – having two or more policies with overlapping coverage of a risk (both the individual policies would not pay separately – under a concept named contribution, they would contribute together to make up the policyholder's losses. However, in case of contingency insurances such as life insurance, dual payment is allowed)\nBULLET::::3. Self-insurance – situations where risk is not transferred to insurance companies and solely retained by the entities or individuals themselves\nBULLET::::4. Reinsurance – situations when the insurer passes some part of or all risks to another Insurer, called the reinsurer\n\nThe business model is to collect more in premium and investment income than is paid out in losses, and to also offer a competitive price which consumers will accept. Profit can be reduced to a simple equation:\n\nInsurers make money in two ways:\nBULLET::::- Through underwriting, the process by which insurers select the risks to insure and decide how much in premiums to charge for accepting those risks\nBULLET::::- By investing the premiums they collect from insured parties\n\nThe most complicated aspect of the insurance business is the actuarial science of ratemaking (price-setting) of policies, which uses statistics and probability to approximate the rate of future claims based on a given risk. After producing rates, the insurer will use discretion to reject or accept risks through the underwriting process.\n\nAt the most basic level, initial ratemaking involves looking at the frequency and severity of insured perils and the expected average payout resulting from these perils. Thereafter an insurance company will collect historical loss data, bring the loss data to present value, and compare these prior losses to the premium collected in order to assess rate adequacy. Loss ratios and expense loads are also used. Rating for different risk characteristics involves at the most basic level comparing the losses with \"loss relativities\"—a policy with twice as many losses would therefore be charged twice as much. More complex multivariate analyses are sometimes used when multiple characteristics are involved and a univariate analysis could produce confounded results. Other statistical methods may be used in assessing the probability of future losses.\n\nUpon termination of a given policy, the amount of premium collected minus the amount paid out in claims is the insurer's underwriting profit on that policy. Underwriting performance is measured by something called the \"combined ratio\", which is the ratio of expenses/losses to premiums. A combined ratio of less than 100% indicates an underwriting profit, while anything over 100 indicates an underwriting loss. A company with a combined ratio over 100% may nevertheless remain profitable due to investment earnings.\n\nInsurance companies earn investment profits on \"float\". Float, or available reserve, is the amount of money on hand at any given moment that an insurer has collected in insurance premiums but has not paid out in claims. Insurers start investing insurance premiums as soon as they are collected and continue to earn interest or other income on them until claims are paid out. The Association of British Insurers (gathering 400 insurance companies and 94% of UK insurance services) has almost 20% of the investments in the London Stock Exchange. In 2007, U.S. industry profits from float totaled $58 billion. In a 2009 letter to investors, Warren Buffett wrote, \"we were \"paid\" $2.8 billion to hold our float in 2008.\"\n\nIn the United States, the underwriting loss of property and casualty insurance companies was $142.3 billion in the five years ending 2003. But overall profit for the same period was $68.4 billion, as the result of float. Some insurance industry insiders, most notably Hank Greenberg, do not believe that it is forever possible to sustain a profit from float without an underwriting profit as well, but this opinion is not universally held. Reliance on float for profit has led some industry experts to call insurance companies \"investment companies that raise the money for their investments by selling insurance.\"\n\nNaturally, the float method is difficult to carry out in an economically depressed period. Bear markets do cause insurers to shift away from investments and to toughen up their underwriting standards, so a poor economy generally means high insurance premiums. This tendency to swing between profitable and unprofitable periods over time is commonly known as the underwriting, or insurance, cycle.\n\nClaims and loss handling is the materialized utility of insurance; it is the actual \"product\" paid for. Claims may be filed by insureds directly with the insurer or through brokers or agents. The insurer may require that the claim be filed on its own proprietary forms, or may accept claims on a standard industry form, such as those produced by ACORD.\n\nInsurance company claims departments employ a large number of claims adjusters supported by a staff of records management and data entry clerks. Incoming claims are classified based on severity and are assigned to adjusters whose settlement authority varies with their knowledge and experience. The adjuster undertakes an investigation of each claim, usually in close cooperation with the insured, determines if coverage is available under the terms of the insurance contract, and if so, the reasonable monetary value of the claim, and authorizes payment.\n\nThe policyholder may hire their own public adjuster to negotiate the settlement with the insurance company on their behalf. For policies that are complicated, where claims may be complex, the insured may take out a separate insurance policy add-on, called loss recovery insurance, which covers the cost of a public adjuster in the case of a claim.\n\nAdjusting liability insurance claims is particularly difficult because there is a third party involved, the plaintiff, who is under no contractual obligation to cooperate with the insurer and may in fact regard the insurer as a deep pocket. The adjuster must obtain legal counsel for the insured (either inside \"house\" counsel or outside \"panel\" counsel), monitor litigation that may take years to complete, and appear in person or over the telephone with settlement authority at a mandatory settlement conference when requested by the judge.\n\nIf a claims adjuster suspects under-insurance, the condition of average may come into play to limit the insurance company's exposure.\n\nIn managing the claims handling function, insurers seek to balance the elements of customer satisfaction, administrative handling expenses, and claims overpayment leakages. As part of this balancing act, fraudulent insurance practices are a major business risk that must be managed and overcome. Disputes between insurers and insureds over the validity of claims or claims handling practices occasionally escalate into litigation (see insurance bad faith).\n\nInsurers will often use insurance agents to initially market or underwrite their customers. Agents can be captive, meaning they write only for one company, or independent, meaning that they can issue policies from several companies. The existence and success of companies using insurance agents is likely due to improved and personalized service. Companies also use Broking firms, Banks and other corporate entities (like Self Help Groups, Microfinance Institutions, NGOs, etc.) to market their products.\n\nAny risk that can be quantified can potentially be insured. Specific kinds of risk that may give rise to claims are known as perils. An insurance policy will set out in detail which perils are covered by the policy and which are not. Below are non-exhaustive lists of the many different types of insurance that exist. A single policy that may cover risks in one or more of the categories set out below. For example, vehicle insurance would typically cover both the property risk (theft or damage to the vehicle) and the liability risk (legal claims arising from an accident). A home insurance policy in the United States typically includes coverage for damage to the home and the owner's belongings, certain legal claims against the owner, and even a small amount of coverage for medical expenses of guests who are injured on the owner's property.\n\nBusiness insurance can take a number of different forms, such as the various kinds of professional liability insurance, also called professional indemnity (PI), which are discussed below under that name; and the business owner's policy (BOP), which packages into one policy many of the kinds of coverage that a business owner needs, in a way analogous to how homeowners' insurance packages the coverages that a homeowner needs.\n\nAuto insurance protects the policyholder against financial loss in the event of an incident involving a vehicle they own, such as in a traffic collision.\n\nCoverage typically includes:\nBULLET::::- Property coverage, for damage to or theft of the car\nBULLET::::- Liability coverage, for the legal responsibility to others for bodily injury or property damage\nBULLET::::- Medical coverage, for the cost of treating injuries, rehabilitation and sometimes lost wages and funeral expenses\n\nGap insurance covers the excess amount on your auto loan in an instance where your insurance company does not cover the entire loan. Depending on the company's specific policies it might or might not cover the deductible as well. This coverage is marketed for those who put low down payments, have high interest rates on their loans, and those with 60-month or longer terms. Gap insurance is typically offered by a finance company when the vehicle owner purchases their vehicle, but many auto insurance companies offer this coverage to consumers as well.\n\nHealth insurance policies cover the cost of medical treatments. Dental insurance, like medical insurance, protects policyholders for dental costs. In most developed countries, all citizens receive some health coverage from their governments, paid through taxation. In most countries, health insurance is often part of an employer's benefits.\n\nBULLET::::- Disability insurance policies provide financial support in the event of the policyholder becoming unable to work because of disabling illness or injury. It provides monthly support to help pay such obligations as mortgage loans and credit cards. Short-term and long-term disability policies are available to individuals, but considering the expense, long-term policies are generally obtained only by those with at least six-figure incomes, such as doctors, lawyers, etc. Short-term disability insurance covers a person for a period typically up to six months, paying a stipend each month to cover medical bills and other necessities.\nBULLET::::- Long-term disability insurance covers an individual's expenses for the long term, up until such time as they are considered permanently disabled and thereafter Insurance companies will often try to encourage the person back into employment in preference to and before declaring them unable to work at all and therefore totally disabled.\nBULLET::::- Disability overhead insurance allows business owners to cover the overhead expenses of their business while they are unable to work.\nBULLET::::- Total permanent disability insurance provides benefits when a person is permanently disabled and can no longer work in their profession, often taken as an adjunct to life insurance.\nBULLET::::- Workers' compensation insurance replaces all or part of a worker's wages lost and accompanying medical expenses incurred because of a job-related injury.\n\nCasualty insurance insures against accidents, not necessarily tied to any specific property. It is a broad spectrum of insurance that a number of other types of insurance could be classified, such as auto, workers compensation, and some liability insurances.\nBULLET::::- Crime insurance is a form of casualty insurance that covers the policyholder against losses arising from the criminal acts of third parties. For example, a company can obtain crime insurance to cover losses arising from theft or embezzlement.\nBULLET::::- Terrorism insurance provides protection against any loss or damage caused by terrorist activities. In the United States in the wake of 9/11, the Terrorism Risk Insurance Act 2002 (TRIA) set up a federal program providing a transparent system of shared public and private compensation for insured losses resulting from acts of terrorism. The program was extended until the end of 2014 by the Terrorism Risk Insurance Program Reauthorization Act 2007 (TRIPRA).\nBULLET::::- Kidnap and ransom insurance is designed to protect individuals and corporations operating in high-risk areas around the world against the perils of kidnap, extortion, wrongful detention and hijacking.\nBULLET::::- Political risk insurance is a form of casualty insurance that can be taken out by businesses with operations in countries in which there is a risk that revolution or other political conditions could result in a loss.\n\nLife insurance provides a monetary benefit to a decedent's family or other designated beneficiary, and may specifically provide for income to an insured person's family, burial, funeral and other final expenses. Life insurance policies often allow the option of having the proceeds paid to the beneficiary either in a lump sum cash payment or an annuity. In most states, a person cannot purchase a policy on another person without their knowledge.\n\nAnnuities provide a stream of payments and are generally classified as insurance because they are issued by insurance companies, are regulated as insurance, and require the same kinds of actuarial and investment management expertise that life insurance requires. Annuities and pensions that pay a benefit for life are sometimes regarded as insurance against the possibility that a retiree will outlive his or her financial resources. In that sense, they are the complement of life insurance and, from an underwriting perspective, are the mirror image of life insurance.\n\nCertain life insurance contracts accumulate cash values, which may be taken by the insured if the policy is surrendered or which may be borrowed against. Some policies, such as annuities and endowment policies, are financial instruments to accumulate or liquidate wealth when it is needed.\n\nIn many countries, such as the United States and the UK, the tax law provides that the interest on this cash value is not taxable under certain circumstances. This leads to widespread use of life insurance as a tax-efficient method of saving as well as protection in the event of early death.\n\nIn the United States, the tax on interest income on life insurance policies and annuities is generally deferred. However, in some cases the benefit derived from tax deferral may be offset by a low return. This depends upon the insuring company, the type of policy and other variables (mortality, market return, etc.). Moreover, other income tax saving vehicles (e.g., IRAs, 401(k) plans, Roth IRAs) may be better alternatives for value accumulation.\n\nBurial insurance is a very old type of life insurance which is paid out upon death to cover final expenses, such as the cost of a funeral. The Greeks and Romans introduced burial insurance c. 600 CE when they organized guilds called \"benevolent societies\" which cared for the surviving families and paid funeral expenses of members upon death. Guilds in the Middle Ages served a similar purpose, as did friendly societies during Victorian times.\n\nProperty insurance provides protection against risks to property, such as fire, theft or weather damage. This may include specialized forms of insurance such as fire insurance, flood insurance, earthquake insurance, home insurance, inland marine insurance or boiler insurance.\nThe term \"property insurance\" may, like casualty insurance, be used as a broad category of various subtypes of insurance, some of which are listed below:\nBULLET::::- Aviation insurance protects aircraft hulls and spares, and associated liability risks, such as passenger and third-party liability. Airports may also appear under this subcategory, including air traffic control and refuelling operations for international airports through to smaller domestic exposures.\nBULLET::::- Boiler insurance (also known as boiler and machinery insurance, or equipment breakdown insurance) insures against accidental physical damage to boilers, equipment or machinery.\nBULLET::::- Builder's risk insurance insures against the risk of physical loss or damage to property during construction. Builder's risk insurance is typically written on an \"all risk\" basis covering damage arising from any cause (including the negligence of the insured) not otherwise expressly excluded. Builder's risk insurance is coverage that protects a person's or organization's insurable interest in materials, fixtures or equipment being used in the construction or renovation of a building or structure should those items sustain physical loss or damage from an insured peril.\nBULLET::::- Crop insurance may be purchased by farmers to reduce or manage various risks associated with growing crops. Such risks include crop loss or damage caused by weather, hail, drought, frost damage, insects, or disease. Index-based insurance uses models of how climate extremes affect crop production to define certain climate triggers that if surpassed have high probabilities of causing substantial crop loss. When harvest losses occur associated with exceeding the climate trigger threshold, the index-insured farmer is entitled to a compensation payment.\nBULLET::::- Earthquake insurance is a form of property insurance that pays the policyholder in the event of an earthquake that causes damage to the property. Most ordinary home insurance policies do not cover earthquake damage. Earthquake insurance policies generally feature a high deductible. Rates depend on location and hence the likelihood of an earthquake, as well as the construction of the home.\nBULLET::::- Fidelity bond is a form of casualty insurance that covers policyholders for losses incurred as a result of fraudulent acts by specified individuals. It usually insures a business for losses caused by the dishonest acts of its employees.\nBULLET::::- Flood insurance protects against property loss due to flooding. Many U.S. insurers do not provide flood insurance in some parts of the country. In response to this, the federal government created the National Flood Insurance Program which serves as the insurer of last resort.\nBULLET::::- Home insurance, also commonly called hazard insurance or homeowners insurance (often abbreviated in the real estate industry as HOI), provides coverage for damage or destruction of the policyholder's home. In some geographical areas, the policy may exclude certain types of risks, such as flood or earthquake, that require additional coverage. Maintenance-related issues are typically the homeowner's responsibility. The policy may include inventory, or this can be bought as a separate policy, especially for people who rent housing. In some countries, insurers offer a package which may include liability and legal responsibility for injuries and property damage caused by members of the household, including pets.\nBULLET::::- Landlord insurance covers residential or commercial property that is rented to tenants. It also covers the landlord's liability for the occupants at the property. Most homeowners' insurance, meanwhile, cover only owner-occupied homes and not liability or damages related to tenants.\nBULLET::::- Marine insurance and marine cargo insurance cover the loss or damage of vessels at sea or on inland waterways, and of cargo in transit, regardless of the method of transit. When the owner of the cargo and the carrier are separate corporations, marine cargo insurance typically compensates the owner of cargo for losses sustained from fire, shipwreck, etc., but excludes losses that can be recovered from the carrier or the carrier's insurance. Many marine insurance underwriters will include \"time element\" coverage in such policies, which extends the indemnity to cover loss of profit and other business expenses attributable to the delay caused by a covered loss.\nBULLET::::- Renters' insurance, often called tenants' insurance, is an insurance policy that provides some of the benefits of homeowners' insurance, but does not include coverage for the dwelling, or structure, with the exception of small alterations that a tenant makes to the structure.\nBULLET::::- Supplemental natural disaster insurance covers specified expenses after a natural disaster renders the policyholder's home uninhabitable. Periodic payments are made directly to the insured until the home is rebuilt or a specified time period has elapsed.\nBULLET::::- Surety bond insurance is a three-party insurance guaranteeing the performance of the principal.\n\nBULLET::::- Volcano insurance is a specialized insurance protecting against damage arising specifically from volcanic eruptions.\nBULLET::::- Windstorm insurance is an insurance covering the damage that can be caused by wind events such as hurricanes.\n\nLiability insurance is a very broad superset that covers legal claims against the insured. Many types of insurance include an aspect of liability coverage. For example, a homeowner's insurance policy will normally include liability coverage which protects the insured in the event of a claim brought by someone who slips and falls on the property; automobile insurance also includes an aspect of liability insurance that indemnifies against the harm that a crashing car can cause to others' lives, health, or property. The protection offered by a liability insurance policy is twofold: a legal defense in the event of a lawsuit commenced against the policyholder and indemnification (payment on behalf of the insured) with respect to a settlement or court verdict. Liability policies typically cover only the negligence of the insured, and will not apply to results of wilful or intentional acts by the insured.\nBULLET::::- Public liability insurance or general liability insurance covers a business or organization against claims should its operations injure a member of the public or damage their property in some way.\nBULLET::::- Directors and officers liability insurance (D&O) protects an organization (usually a corporation) from costs associated with litigation resulting from errors made by directors and officers for which they are liable.\nBULLET::::- Environmental liability or environmental impairment insurance protects the insured from bodily injury, property damage and cleanup costs as a result of the dispersal, release or escape of pollutants.\nBULLET::::- Errors and omissions insurance (E&O) is business liability insurance for professionals such as insurance agents, real estate agents and brokers, architects, third-party administrators (TPAs) and other business professionals.\nBULLET::::- Prize indemnity insurance protects the insured from giving away a large prize at a specific event. Examples would include offering prizes to contestants who can make a half-court shot at a basketball game, or a hole-in-one at a golf tournament.\nBULLET::::- Professional liability insurance, also called professional indemnity insurance (PI), protects insured professionals such as architectural corporations and medical practitioners against potential negligence claims made by their patients/clients. Professional liability insurance may take on different names depending on the profession. For example, professional liability insurance in reference to the medical profession may be called medical malpractice insurance.\nOften a commercial insured's liability insurance program consists of several layers. The first layer of insurance generally consists of primary insurance, which provides first dollar indemnity for judgments and settlements up to the limits of liability of the primary policy. Generally, primary insurance is subject to a deductible and obligates the insured to defend the insured against lawsuits, which is normally accomplished by assigning counsel to defend the insured. In many instances, a commercial insured may elect to self-insure. Above the primary insurance or self-insured retention, the insured may have one or more layers of excess insurance to provide coverage additional limits of indemnity protection. There are a variety of types of excess insurance, including \"stand-alone\" excess policies (policies that contain their own terms, conditions, and exclusions), \"follow form\" excess insurance (policies that follow the terms of the underlying policy except as specifically provided), and \"umbrella\" insurance policies (excess insurance that in some circumstances could provide coverage that is broader than the underlying insurance).\n\nCredit insurance repays some or all of a loan when the borrower is insolvent.\nBULLET::::- Mortgage insurance insures the lender against default by the borrower. Mortgage insurance is a form of credit insurance, although the name \"credit insurance\" more often is used to refer to policies that cover other kinds of debt.\nBULLET::::- Many credit cards offer payment protection plans which are a form of credit insurance.\nBULLET::::- Trade credit insurance is business insurance over the accounts receivable of the insured. The policy pays the policy holder for covered accounts receivable if the debtor defaults on payment.\nBULLET::::- Collateral protection insurance (CPI) insures property (primarily vehicles) held as collateral for loans made by lending institutions.\n\nBULLET::::- All-risk insurance is an insurance that covers a wide range of incidents and perils, except those noted in the policy. All-risk insurance is different from peril-specific insurance that cover losses from only those perils listed in the policy. In car insurance, all-risk policy includes also the damages caused by the own driver.\n\nBULLET::::- Bloodstock insurance covers individual horses or a number of horses under common ownership. Coverage is typically for mortality as a result of accident, illness or disease but may extend to include infertility, in-transit loss, veterinary fees, and prospective foal.\nBULLET::::- Business interruption insurance covers the loss of income, and the expenses incurred, after a covered peril interrupts normal business operations.\nBULLET::::- Defense Base Act (DBA) insurance provides coverage for civilian workers hired by the government to perform contracts outside the United States and Canada. DBA is required for all U.S. citizens, U.S. residents, U.S. Green Card holders, and all employees or subcontractors hired on overseas government contracts. Depending on the country, foreign nationals must also be covered under DBA. This coverage typically includes expenses related to medical treatment and loss of wages, as well as disability and death benefits.\nBULLET::::- Expatriate insurance provides individuals and organizations operating outside of their home country with protection for automobiles, property, health, liability and business pursuits.\nBULLET::::- Legal expenses insurance covers policyholders for the potential costs of legal action against an institution or an individual. When something happens which triggers the need for legal action, it is known as \"the event\". There are two main types of legal expenses insurance: before the event insurance and after the event insurance.\nBULLET::::- Livestock insurance is a specialist policy provided to, for example, commercial or hobby farms, aquariums, fish farms or any other animal holding. Cover is available for mortality or economic slaughter as a result of accident, illness or disease but can extend to include destruction by government order.\nBULLET::::- Media liability insurance is designed to cover professionals that engage in film and television production and print, against risks such as defamation.\nBULLET::::- Nuclear incident insurance covers damages resulting from an incident involving radioactive materials and is generally arranged at the national level. (See the nuclear exclusion clause and, for the United States, the Price–Anderson Nuclear Industries Indemnity Act.)\nBULLET::::- Pet insurance insures pets against accidents and illnesses; some companies cover routine/wellness care and burial, as well.\nBULLET::::- Pollution insurance usually takes the form of first-party coverage for contamination of insured property either by external or on-site sources. Coverage is also afforded for liability to third parties arising from contamination of air, water, or land due to the sudden and accidental release of hazardous materials from the insured site. The policy usually covers the costs of cleanup and may include coverage for releases from underground storage tanks. Intentional acts are specifically excluded.\nBULLET::::- Purchase insurance is aimed at providing protection on the products people purchase. Purchase insurance can cover individual purchase protection, warranties, guarantees, care plans and even mobile phone insurance. Such insurance is normally very limited in the scope of problems that are covered by the policy.\nBULLET::::- Tax insurance is increasingly being used in corporate transactions to protect taxpayers in the event that a tax position it has taken is challenged by the IRS or a state, local, or foreign taxing authority\nBULLET::::- Title insurance provides a guarantee that title to real property is vested in the purchaser or mortgagee, free and clear of liens or encumbrances. It is usually issued in conjunction with a search of the public records performed at the time of a real estate transaction.\nBULLET::::- Travel insurance is an insurance cover taken by those who travel abroad, which covers certain losses such as medical expenses, loss of personal belongings, travel delay, and personal liabilities.\nBULLET::::- Tuition insurance insures students against involuntary withdrawal from cost-intensive educational institutions\nBULLET::::- Interest rate insurance protects the holder from adverse changes in interest rates, for instance for those with a variable rate loan or mortgage\nBULLET::::- Divorce insurance is a form of contractual liability insurance that pays the insured a cash benefit if their marriage ends in divorce.\n\nBULLET::::- Fraternal insurance is provided on a cooperative basis by fraternal benefit societies or other social organizations.\nBULLET::::- No-fault insurance is a type of insurance policy (typically automobile insurance) where insureds are indemnified by their own insurer regardless of fault in the incident.\nBULLET::::- Protected self-insurance is an alternative risk financing mechanism in which an organization retains the mathematically calculated cost of risk within the organization and transfers the catastrophic risk with specific and aggregate limits to an insurer so the maximum total cost of the program is known. A properly designed and underwritten Protected Self-Insurance Program reduces and stabilizes the cost of insurance and provides valuable risk management information.\nBULLET::::- Retrospectively rated insurance is a method of establishing a premium on large commercial accounts. The final premium is based on the insured's actual loss experience during the policy term, sometimes subject to a minimum and maximum premium, with the final premium determined by a formula. Under this plan, the current year's premium is based partially (or wholly) on the current year's losses, although the premium adjustments may take months or years beyond the current year's expiration date. The rating formula is guaranteed in the insurance contract. Formula: retrospective premium = converted loss + basic premium × tax multiplier. Numerous variations of this formula have been developed and are in use.\nBULLET::::- Formal self-insurance is the deliberate decision to pay for otherwise insurable losses out of one's own money. This can be done on a formal basis by establishing a separate fund into which funds are deposited on a periodic basis, or by simply forgoing the purchase of available insurance and paying out-of-pocket. Self-insurance is usually used to pay for high-frequency, low-severity losses. Such losses, if covered by conventional insurance, mean having to pay a premium that includes loadings for the company's general expenses, cost of putting the policy on the books, acquisition expenses, premium taxes, and contingencies. While this is true for all insurance, for small, frequent losses the transaction costs may exceed the benefit of volatility reduction that insurance otherwise affords.\nBULLET::::- Reinsurance is a type of insurance purchased by insurance companies or self-insured employers to protect against unexpected losses. Financial reinsurance is a form of reinsurance that is primarily used for capital management rather than to transfer insurance risk.\nBULLET::::- Social insurance can be many things to many people in many countries. But a summary of its essence is that it is a collection of insurance coverages (including components of life insurance, disability income insurance, unemployment insurance, health insurance, and others), plus retirement savings, that requires participation by all citizens. By forcing everyone in society to be a policyholder and pay premiums, it ensures that everyone can become a claimant when or if he/she needs to. Along the way, this inevitably becomes related to other concepts such as the justice system and the welfare state. This is a large, complicated topic that engenders tremendous debate, which can be further studied in the following articles (and others):\nBULLET::::- National Insurance\nBULLET::::- Social safety net\nBULLET::::- Social security\nBULLET::::- Social Security debate (United States)\nBULLET::::- Social Security (United States)\nBULLET::::- Social welfare provision\nBULLET::::- Stop-loss insurance provides protection against catastrophic or unpredictable losses. It is purchased by organizations who do not want to assume 100% of the liability for losses arising from the plans. Under a stop-loss policy, the insurance company becomes liable for losses that exceed certain limits called deductibles.\n\nSome communities prefer to create virtual insurance amongst themselves by other means than contractual risk transfer, which assigns explicit numerical values to risk. A number of religious groups, including the Amish and some Muslim groups, depend on support provided by their communities when disasters strike. The risk presented by any given person is assumed collectively by the community who all bear the cost of rebuilding lost property and supporting people whose needs are suddenly greater after a loss of some kind. In supportive communities where others can be trusted to follow community leaders, this tacit form of insurance can work. In this manner the community can even out the extreme differences in insurability that exist among its members. Some further justification is also provided by invoking the moral hazard of explicit insurance contracts.\n\nIn the United Kingdom, The Crown (which, for practical purposes, meant the civil service) did not insure property such as government buildings. If a government building was damaged, the cost of repair would be met from public funds because, in the long run, this was cheaper than paying insurance premiums. Since many UK government buildings have been sold to property companies and rented back, this arrangement is now less common and may have disappeared altogether.\n\nIn the United States, the most prevalent form of self-insurance is governmental risk management pools. They are self-funded cooperatives, operating as carriers of coverage for the majority of governmental entities today, such as county governments, municipalities, and school districts. Rather than these entities independently self-insure and risk bankruptcy from a large judgment or catastrophic loss, such governmental entities form a risk pool. Such pools begin their operations by capitalization through member deposits or bond issuance. Coverage (such as general liability, auto liability, professional liability, workers compensation, and property) is offered by the pool to its members, similar to coverage offered by insurance companies. However, self-insured pools offer members lower rates (due to not needing insurance brokers), increased benefits (such as loss prevention services) and subject matter expertise. Of approximately 91,000 distinct governmental entities operating in the United States, 75,000 are members of self-insured pools in various lines of coverage, forming approximately 500 pools. Although a relatively small corner of the insurance market, the annual contributions (self-insured premiums) to such pools have been estimated up to 17 billion dollars annually.\n\nInsurance companies may sell any combination of insurance types, but are often classified into three groups:\n\nBULLET::::- Life insurance companies, which sell life insurance, annuities and pensions products and bear similarities to asset management businesses\nBULLET::::- Non-life or property/casualty insurance companies, which sell other types of insurance.\nBULLET::::- Health insurance companies, which sometimes sell life insurance or employee benefits as well\n\nGeneral insurance companies can be further divided into these sub categories.\nBULLET::::- Standard lines\nBULLET::::- Excess lines\n\nIn most countries, life and non-life insurers are subject to different regulatory regimes and different tax and accounting rules. The main reason for the distinction between the two types of company is that life, annuity, and pension business is very long-term in nature – coverage for life assurance or a pension can cover risks over many decades. By contrast, non-life insurance cover usually covers a shorter period, such as one year.\n\nInsurance companies are generally classified as either mutual or proprietary companies. Mutual companies are owned by the policyholders, while shareholders (who may or may not own policies) own proprietary insurance companies.\n\nDemutualization of mutual insurers to form stock companies, as well as the formation of a hybrid known as a mutual holding company, became common in some countries, such as the United States, in the late 20th century. However, not all states permit mutual holding companies.\n\nReinsurance companies are insurance companies that sell policies to other insurance companies, allowing them to reduce their risks and protect themselves from very large losses. The reinsurance market is dominated by a few very large companies, with huge reserves. A reinsurer may also be a direct writer of insurance risks as well.\n\nCaptive insurance companies may be defined as limited-purpose insurance companies established with the specific objective of financing risks emanating from their parent group or groups. This definition can sometimes be extended to include some of the risks of the parent company's customers. In short, it is an in-house self-insurance vehicle. Captives may take the form of a \"pure\" entity (which is a 100% subsidiary of the self-insured parent company); of a \"mutual\" captive (which insures the collective risks of members of an industry); and of an \"association\" captive (which self-insures individual risks of the members of a professional, commercial or industrial association). Captives represent commercial, economic and tax advantages to their sponsors because of the reductions in costs they help create and for the ease of insurance risk management and the flexibility for cash flows they generate. Additionally, they may provide coverage of risks which is neither available nor offered in the traditional insurance market at reasonable prices.\n\nThe types of risk that a captive can underwrite for their parents include property damage, public and product liability, professional indemnity, employee benefits, employers' liability, motor and medical aid expenses. The captive's exposure to such risks may be limited by the use of reinsurance.\n\nCaptives are becoming an increasingly important component of the risk management and risk financing strategy of their parent. This can be understood against the following background:\nBULLET::::- Heavy and increasing premium costs in almost every line of coverage\nBULLET::::- Difficulties in insuring certain types of fortuitous risk\nBULLET::::- Differential coverage standards in various parts of the world\nBULLET::::- Rating structures which reflect market trends rather than individual loss experience\nBULLET::::- Insufficient credit for deductibles or loss control efforts\n\nOther possible forms for an insurance company include reciprocals, in which policyholders reciprocate in sharing risks, and Lloyd's organizations.\n\nAdmitted insurance companies are those in the United States that have been admitted or licensed by the state licensing agency. The insurance they sell is called admitted insurance. Non-admitted companies have not been approved by the state licensing agency, but are allowed to sell insurance under special circumstances when they meet an insurance need that admitted companies cannot or will not meet.\n\nThere are also companies known as \"insurance consultants\". Like a mortgage broker, these companies are paid a fee by the customer to shop around for the best insurance policy amongst many companies. Similar to an insurance consultant, an 'insurance broker' also shops around for the best insurance policy amongst many companies. However, with insurance brokers, the fee is usually paid in the form of commission from the insurer that is selected rather than directly from the client.\n\nNeither insurance consultants nor insurance brokers are insurance companies and no risks are transferred to them in insurance transactions. Third party administrators are companies that perform underwriting and sometimes claims handling services for insurance companies. These companies often have special expertise that the insurance companies do not have.\n\nThe financial stability and strength of an insurance company should be a major consideration when buying an insurance contract. An insurance premium paid currently provides coverage for losses that might arise many years in the future. For that reason, the viability of the insurance carrier is very important. In recent years, a number of insurance companies have become insolvent, leaving their policyholders with no coverage (or coverage only from a government-backed insurance pool or other arrangement with less attractive payouts for losses). A number of independent rating agencies provide information and rate the financial viability of insurance companies.\n\nInsurance companies are rated by various agencies such as A. M. Best. The ratings include the company's financial strength, which measures its ability to pay claims. It also rates financial instruments issued by the insurance company, such as bonds, notes, and securitization products.\n\nGlobal insurance premiums grew by 2.7% in inflation-adjusted terms in 2010 to $4.3 trillion, climbing above pre-crisis levels. The return to growth and record premiums generated during the year followed two years of decline in real terms. Life insurance premiums increased by 3.2% in 2010 and non-life premiums by 2.1%. While industrialised countries saw an increase in premiums of around 1.4%, insurance markets in emerging economies saw rapid expansion with 11% growth in premium income. The global insurance industry was sufficiently capitalised to withstand the financial crisis of 2008 and 2009 and most insurance companies restored their capital to pre-crisis levels by the end of 2010. With the continuation of the gradual recovery of the global economy, it is likely the insurance industry will continue to see growth in premium income both in industrialised countries and emerging markets in 2011.\n\nAdvanced economies account for the bulk of global insurance. With premium income of $1.62 trillion, Europe was the most important region in 2010, followed by North America $1.41 trillion and Asia $1.16 trillion. Europe has however seen a decline in premium income during the year in contrast to the growth seen in North America and Asia. The top four countries generated more than a half of premiums. The United States and Japan alone accounted for 40% of world insurance, much higher than their 7% share of the global population. Emerging economies accounted for over 85% of the world's population but only around 15% of premiums. Their markets are however growing at a quicker pace. The country expected to have the biggest impact on the insurance share distribution across the world is China. According to Sam Radwan of ENHANCE International LLC, low premium penetration (insurance premium as a % of GDP), an ageing population and the largest car market in terms of new sales, premium growth has averaged 15–20% in the past five years, and China is expected to be the largest insurance market in the next decade or two.\n\nIn the United States, insurance is regulated by the states under the McCarran-Ferguson Act, with \"periodic proposals for federal intervention\", and a nonprofit coalition of state insurance agencies called the National Association of Insurance Commissioners works to harmonize the country's different laws and regulations. The National Conference of Insurance Legislators (NCOIL) also works to harmonize the different state laws.\n\nIn the European Union, the Third Non-Life Directive and the Third Life Directive, both passed in 1992 and effective 1994, created a single insurance market in Europe and allowed insurance companies to offer insurance anywhere in the EU (subject to permission from authority in the head office) and allowed insurance consumers to purchase insurance from any insurer in the EU. As far as insurance in the United Kingdom, the Financial Services Authority took over insurance regulation from the General Insurance Standards Council in 2005; laws passed include the Insurance Companies Act 1973 and another in 1982, and reforms to warranty and other aspects under discussion .\n\nThe insurance industry in China was nationalized in 1949 and thereafter offered by only a single state-owned company, the People's Insurance Company of China, which was eventually suspended as demand declined in a communist environment. In 1978, market reforms led to an increase in the market and by 1995 a comprehensive Insurance Law of the People's Republic of China was passed, followed in 1998 by the formation of China Insurance Regulatory Commission (CIRC), which has broad regulatory authority over the insurance market of China.\n\nIn India IRDA is insurance regulatory authority. As per the section 4 of IRDA Act 1999, Insurance Regulatory and Development Authority (IRDA), which was constituted by an act of parliament. National Insurance Academy, Pune is apex insurance capacity builder institute promoted with support from Ministry of Finance and by LIC, Life & General Insurance companies.\n\nIn 2017, within the framework of the joint project of the Bank of Russia and Yandex, a special check mark (a green circle with a tick and 'Реестр ЦБ РФ' (Unified state register of insurance entities) text box) appeared in the search for Yandex system, informing the consumer that the company's financial services are offered on the marked website, which has the status of an insurance company, a broker or a mutual insurance association.\n\nInsurance is just a risk transfer mechanism wherein the financial burden which may arise due to some fortuitous event is transferred to a bigger entity called an Insurance Company by way of paying premiums. This only reduces the financial burden and not the actual chances of happening of an event. Insurance is a risk for both the insurance company and the insured. The insurance company understands the risk involved and will perform a risk assessment when writing the policy. As a result, the premiums may go up if they determine that the policyholder will file a claim. If a person is financially stable and plans for life's unexpected events, they may be able to go without insurance. However, they must have enough to cover a total and complete loss of employment and of their possessions. Some states will accept a surety bond, a government bond, or even making a cash deposit with the state.\n\nAn insurance company may inadvertently find that its insureds may not be as risk-averse as they might otherwise be (since, by definition, the insured has transferred the risk to the insurer), a concept known as moral hazard. This 'insulates' many from the\ntrue costs of living with risk, negating measures that can mitigate or adapt to risk and leading some to describe insurance schemes as potentially maladaptive. To reduce their own financial exposure, insurance companies have contractual clauses that mitigate their obligation to provide coverage if the insured engages in behavior that grossly magnifies their risk of loss or liability.\n\nFor example, life insurance companies may require higher premiums or deny coverage altogether to people who work in hazardous occupations or engage in dangerous sports. Liability insurance providers do not provide coverage for liability arising from intentional torts committed by or at the direction of the insured. Even if a provider desired to provide such coverage, it is against the public policy of most countries to allow such insurance to exist, and thus it is usually illegal.\n\nInsurance policies can be complex and some policyholders may not understand all the fees and coverages included in a policy. As a result, people may buy policies on unfavorable terms. In response to these issues, many countries have enacted detailed statutory and regulatory regimes governing every aspect of the insurance business, including minimum standards for policies and the ways in which they may be advertised and sold.\n\nFor example, most insurance policies in the English language today have been carefully drafted in plain English; the industry learned the hard way that many courts will not enforce policies against insureds when the judges themselves cannot understand what the policies are saying. Typically, courts construe ambiguities in insurance policies against the insurance company and in favor of coverage under the policy.\n\nMany institutional insurance purchasers buy insurance through an insurance broker. While on the surface it appears the broker represents the buyer (not the insurance company), and typically counsels the buyer on appropriate coverage and policy limitations, in the vast majority of cases a broker's compensation comes in the form of a commission as a percentage of the insurance premium, creating a conflict of interest in that the broker's financial interest is tilted towards encouraging an insured to purchase more insurance than might be necessary at a higher price. A broker generally holds contracts with many insurers, thereby allowing the broker to \"shop\" the market for the best rates and coverage possible.\n\nInsurance may also be purchased through an agent. A tied agent, working exclusively with one insurer, represents the insurance company from whom the policyholder buys (while a free agent sells policies of various insurance companies). Just as there is a potential conflict of interest with a broker, an agent has a different type of conflict. Because agents work directly for the insurance company, if there is a claim the agent may advise the client to the benefit of the insurance company. Agents generally cannot offer as broad a range of selection compared to an insurance broker.\n\nAn independent insurance consultant advises insureds on a fee-for-service retainer, similar to an attorney, and thus offers completely independent advice, free of the financial conflict of interest of brokers or agents. However, such a consultant must still work through brokers or agents in order to secure coverage for their clients.\n\nIn the United States, economists and consumer advocates generally consider insurance to be worthwhile for low-probability, catastrophic losses, but not for high-probability, small losses. Because of this, consumers are advised to select high deductibles and to not insure losses which would not cause a disruption in their life. However, consumers have shown a tendency to prefer low deductibles and to prefer to insure relatively high-probability, small losses over low-probability, perhaps due to not understanding or ignoring the low-probability risk. This is associated with reduced purchasing of insurance against low-probability losses, and may result in increased inefficiencies from moral hazard.\n\nRedlining is the practice of denying insurance coverage in specific geographic areas, supposedly because of a high likelihood of loss, while the alleged motivation is unlawful discrimination. Racial profiling or redlining has a long history in the property insurance industry in the United States. From a review of industry underwriting and marketing materials, court documents, and research by government agencies, industry and community groups, and academics, it is clear that race has long affected and continues to affect the policies and practices of the insurance industry.\n\nIn July 2007, The Federal Trade Commission (FTC) released a report presenting the results of a study concerning credit-based insurance scores in automobile insurance. The study found that these scores are effective predictors of risk. It also showed that African-Americans and Hispanics are substantially overrepresented in the lowest credit scores, and substantially underrepresented in the highest, while Caucasians and Asians are more evenly spread across the scores. The credit scores were also found to predict risk within each of the ethnic groups, leading the FTC to conclude that the scoring models are not solely proxies for redlining. The FTC indicated little data was available to evaluate benefit of insurance scores to consumers. The report was disputed by representatives of the Consumer Federation of America, the National Fair Housing Alliance, the National Consumer Law Center, and the Center for Economic Justice, for relying on data provided by the insurance industry.\n\nAll states have provisions in their rate regulation laws or in their fair trade practice acts that prohibit unfair discrimination, often called redlining, in setting rates and making insurance available.\n\nIn determining premiums and premium rate structures, insurers consider quantifiable factors, including location, credit scores, gender, occupation, marital status, and education level. However, the use of such factors is often considered to be unfair or unlawfully discriminatory, and the reaction against this practice has in some instances led to political disputes about the ways in which insurers determine premiums and regulatory intervention to limit the factors used.\n\nAn insurance underwriter's job is to evaluate a given risk as to the likelihood that a loss will occur. Any factor that causes a greater likelihood of loss should theoretically be charged a higher rate. This basic principle of insurance must be followed if insurance companies are to remain solvent. Thus, \"discrimination\" against (i.e., negative differential treatment of) potential insureds in the risk evaluation and premium-setting process is a necessary by-product of the fundamentals of insurance underwriting. For instance, insurers charge older people significantly higher premiums than they charge younger people for term life insurance. Older people are thus treated differently from younger people (i.e., a distinction is made, discrimination occurs). The rationale for the differential treatment goes to the heart of the risk a life insurer takes: Old people are likely to die sooner than young people, so the risk of loss (the insured's death) is greater in any given period of time and therefore the risk premium must be higher to cover the greater risk. However, treating insureds differently when there is no actuarially sound reason for doing so is unlawful discrimination.\n\nNew assurance products can now be protected from copying with a business method patent in the United States.\n\nA recent example of a new insurance product that is patented is Usage Based auto insurance. Early versions were independently invented and patented by a major US auto insurance company, Progressive Auto Insurance () and a Spanish independent inventor, Salvador Minguijon Perez ().\n\nMany independent inventors are in favor of patenting new insurance products since it gives them protection from big companies when they bring their new insurance products to market. Independent inventors account for 70% of the new U.S. patent applications in this area.\n\nMany insurance executives are opposed to patenting insurance products because it creates a new risk for them. The Hartford insurance company, for example, recently had to pay $80 million to an independent inventor, Bancorp Services, in order to settle a patent infringement and theft of trade secret lawsuit for a type of corporate owned life insurance product invented and patented by Bancorp.\n\nThere are currently about 150 new patent applications on insurance inventions filed per year in the United States. The rate at which patents have been issued has steadily risen from 15 in 2002 to 44 in 2006.\n\nThe first insurance patent to be granted was including another example of an application posted was US2009005522 \"risk assessment company\". It was posted on 6 March 2009. This patent application describes a method for increasing the ease of changing insurance companies.\n\nInsurance on demand (also IoD) is an insurance service that provides clients with insurance protection when they need, i.e. only episodic rather than on 24/7 basis as typically provided by traditional insurers (e.g. clients can purchase an insurance for one single flight rather than a longer-lasting travel insurance plan).\n\nCertain insurance products and practices have been described as rent-seeking by critics. That is, some insurance products or practices are useful primarily because of legal benefits, such as reducing taxes, as opposed to providing protection against risks of adverse events. Under United States tax law, for example, most owners of variable annuities and variable life insurance can invest their premium payments in the stock market and defer or eliminate paying any taxes on their investments until withdrawals are made. Sometimes this tax deferral is the only reason people use these products. Another example is the legal infrastructure which allows life insurance to be held in an irrevocable trust which is used to pay an estate tax while the proceeds themselves are immune from the estate tax.\n\nMuslim scholars have varying opinions about life insurance. Life insurance policies that earn interest (or guaranteed bonus/NAV) are generally considered to be a form of \"riba\" (usury) and some consider even policies that do not earn interest to be a form of \"gharar\" (speculation). Some argue that \"gharar\" is not present due to the actuarial science behind the underwriting.\nJewish rabbinical scholars also have expressed reservations regarding insurance as an avoidance of God's will but most find it acceptable in moderation.\n\nSome Christians believe insurance represents a lack of faith and there is a long history of resistance to commercial insurance in Anabaptist communities (Mennonites, Amish, Hutterites, Brethren in Christ) but many participate in community-based self-insurance programs that spread risk within their communities.\n\nBULLET::::- Agent of Record\nBULLET::::- Earthquake loss\nBULLET::::- Financial adviser\nBULLET::::- Financial services (broader industry to which insurance belongs)\nBULLET::::- Geneva Association (the International Association for the Study of Insurance Economics)\nBULLET::::- Global assets under management\nBULLET::::- Insurance broker\nBULLET::::- Insurance fraud\nBULLET::::- Insurance Hall of Fame\nBULLET::::- Insurance law\nBULLET::::- Insurance Premium Tax (UK)\nBULLET::::- List of Acts of Parliament of the United Kingdom Parliament, 1960-1979\nBULLET::::- Loss-control consultant\nBULLET::::- Reinsurance\nBULLET::::- Intergovernmental Risk Pool\nBULLET::::- \"\" (book)\nBULLET::::- List of finance topics\nBULLET::::- List of insurance topics\nBULLET::::- List of United States insurance companies\nBULLET::::- Social security\nBULLET::::- \"Uberrima fides\"\nBULLET::::- Universal health care\nBULLET::::- Welfare state\nCountry-specific articles:\n\nBULLET::::- Congressional Research Service (CRS) Reports regarding the US Insurance industry\nBULLET::::- Federation of European Risk Management Associations\nBULLET::::- Insurance Bureau of Canada\nBULLET::::- Insurance Information Institute\nBULLET::::- National Association of Insurance Commissioners\nBULLET::::- The British Library – finding information on the insurance industry (UK focus)\n"}
