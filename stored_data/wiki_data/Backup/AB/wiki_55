{"id": "15289", "url": "https://en.wikipedia.org/wiki?curid=15289", "title": "Interrupt", "text": "Interrupt\n\nIn digital computers, an interrupt is an input signal to the processor indicating an event that needs immediate attention. An interrupt signal alerts the processor and serves as a request for the processor to interrupt the currently executing code, so that the event can be processed in a timely manner. If the request is accepted, the processor responds by suspending its current activities, saving its state, and executing a function called an \"interrupt handler\" (or an interrupt service routine, ISR) to deal with the event. This interruption is temporary, and, unless the interrupt indicates a fatal error, the processor resumes normal activities after the interrupt handler finishes.\n\nInterrupts are commonly used by hardware devices to indicate electronic or physical state changes that require attention. Interrupts are also commonly used to implement computer multitasking, especially in real-time computing. Systems that use interrupts in these ways are said to be interrupt-driven.\n\nInterrupt signals may be issued in response to hardware or software events. These are classified as hardware interrupts or software interrupts, respectively. For any particular processor, the number of hardware interrupts is limited by the number of interrupt request (IRQ) signals to the processor, whereas the number of software interrupts is determined by the processor design.\n\nA hardware interrupt request (IRQ) is an electronic signal issued by an external (to the processor) hardware device, to communicate that it needs attention from the operating system (OS) or, if there is no OS, from the \"bare-metal\" program running on the CPU. Such external devices may be part of the computer (e.g., disk controller) or they may be external peripherals. For example, pressing a keyboard key or moving the mouse triggers hardware interrupts that cause the processor to read the keystroke or mouse position.\n\nUnlike software interrupts, hardware interrupts can arrive asynchronously with respect to the processor clock, and at any time during instruction execution. Consequently, all hardware interrupt signals are conditioned by synchronizing them to the processor clock, and acted upon only at instruction execution boundaries.\n\nIn many systems, each device is associated with a particular IRQ signal. This makes it possible to quickly determine which hardware device is requesting service, and to expedite servicing of that device.\n\nProcessors typically have an internal \"interrupt mask\" register which allows selective enabling and disabling of hardware interrupts. Each interrupt signal is associated with a bit in the mask register; the interrupt is enabled when the bit is set and disabled when the bit is clear, or vice versa. When the interrupt is disabled, the associated interrupt signal will be ignored by the processor. Signals which are affected by the mask are called \"maskable interrupts\".\n\nSome interrupt signals are not affected by the interrupt mask and therefore cannot be disabled; these are called \"non-maskable interrupts\" (NMI). NMIs indicate high priority events which cannot be ignored under any circumstances, such as the timeout signal from a watchdog timer.\n\nA \"spurious interrupt\" is an invalid, short-duration signal on an interrupt input. These are usually caused by glitches resulting from electrical interference, race conditions, or malfunctioning devices.\n\nA software interrupt is requested by the processor itself upon executing particular instructions or when certain conditions are met. Every software interrupt signal is associated with a particular interrupt handler.\n\nA software interrupt may be intentionally caused by executing a special instruction which, by design, invokes an interrupt when executed. Such instructions function similarly to subroutine calls and are used for a variety of purposes, such as requesting operating system services and interacting with device drivers (e.g., to read or write storage media).\n\nSoftware interrupts may also be unexpectedly triggered by program execution errors. These interrupts typically are called \"traps\" or \"exceptions\". For example, a divide-by-zero exception will be \"thrown\" (a software interrupt is requested) if the processor executes a divide instruction with divisor equal to zero. Typically, the operating system will catch and handle this exception.\n\nEach interrupt signal input is designed to be triggered by either a logic signal level or a particular signal edge (level transition). Level-sensitive inputs continuously request processor service so long as a particular (high or low) logic level is applied to the input. Edge-sensitive inputs react to signal edges: a particular (rising or falling) edge will cause a service request to be latched; the processor resets the latch when the interrupt handler executes.\n\nA \"level-triggered interrupt\" is requested by holding the interrupt signal at its particular (high or low) active logic level. A device invokes a level-triggered interrupt by driving the signal to and holding it at the active level. It negates the signal when the processor commands it to do so, typically after the device has been serviced.\n\nThe processor samples the interrupt input signal during each instruction cycle. The processor will recognize the interrupt request if the signal is asserted when sampling occurs.\n\nLevel-triggered inputs allow multiple devices to share a common interrupt signal via wired-OR connections. The processor polls to determine which devices are requesting service. After servicing a device, the processor may again poll and, if necessary, service other devices before exiting the ISR.\n\nAn \"edge-triggered interrupt\" is an interrupt signaled by a level transition on the interrupt line, either a falling edge (high to low) or a rising edge (low to high). A device wishing to signal an interrupt drives a pulse onto the line and then releases the line to its inactive state. If the pulse is too short to be detected by polled I/O then special hardware may be required to detect it.\n\nThe processor samples the interrupt trigger signal during each instruction cycle, and will respond to the trigger only if the signal is asserted when sampling occurs.\nRegardless of the triggering method, the processor will begin interrupt processing at the next instruction boundary following a detected trigger, thus ensuring:\nBULLET::::- The Program Counter (PC) is saved in a known place.\nBULLET::::- All instructions before the one pointed to by the PC have fully executed.\nBULLET::::- No instruction beyond the one pointed to by the PC has been executed, or any such instructions are undone before handling the interrupt.\nBULLET::::- The execution state of the instruction pointed to by the PC is known.\n\nInterrupts may be implemented in hardware as a distinct component with control lines, or they may be integrated into the memory subsystem.\n\nIf implemented in hardware as a distinct component, an interrupt controller circuit such as the IBM PC's Programmable Interrupt Controller (PIC) may be connected between the interrupting device and the processor's interrupt pin to multiplex several sources of interrupt onto the one or two CPU lines typically available. If implemented as part of the memory controller, interrupts are mapped into the system's memory address space.\n\nMultiple devices may share an edge-triggered interrupt line if they are designed to. The interrupt line must have a pull-down or pull-up resistor so that when not actively driven it settles to its inactive state, which is the default state of it. Devices signal an interrupt by briefly driving the line to its non-default state, and let the line float (do not actively drive it) when not signaling an interrupt. This type of connection is also referred to as open collector. The line then carries all the pulses generated by all the devices. (This is analogous to the pull cord on some buses and trolleys that any passenger can pull to signal the driver that they are requesting a stop.) However, interrupt pulses from different devices may merge if they occur close in time. To avoid losing interrupts the CPU must trigger on the trailing edge of the pulse (e.g. the rising edge if the line is pulled up and driven low). After detecting an interrupt the CPU must check all the devices for service requirements.\n\nEdge-triggered interrupts do not suffer the problems that level-triggered interrupts have with sharing. Service of a low-priority device can be postponed arbitrarily, while interrupts from high-priority devices continue to be received and get serviced. If there is a device that the CPU does not know how to service, which may raise spurious interrupts, it won't interfere with interrupt signaling of other devices. However, it is easy for an edge-triggered interrupt to be missed - for example, when interrupts are masked for a period - and unless there is some type of hardware latch that records the event it is impossible to recover. This problem caused many \"lockups\" in early computer hardware because the processor did not know it was expected to do something. More modern hardware often has one or more interrupt status registers that latch interrupts requests; well-written edge-driven interrupt handling code can check these registers to ensure no events are missed.\n\nThe elderly Industry Standard Architecture (ISA) bus uses edge-triggered interrupts, without mandating that devices be able to share IRQ lines, but all mainstream ISA motherboards include pull-up resistors on their IRQ lines, so well-behaved ISA devices sharing IRQ lines should just work fine. The parallel port also uses edge-triggered interrupts. Many older devices assume that they have exclusive use of IRQ lines, making it electrically unsafe to share them.\n\nThere are 3 ways multiple devices \"sharing the same line\" can be raised. First is by exclusive conduction (switching) or exclusive connection (to pins). Next is by bus (all connected to the same line listening): cards on a bus must know when they are to talk and not talk (ie, the ISA bus). Talking can be triggered in two ways: by accumulation latch or by logic gates. Logic gates expect a continual data flow that is monitored for key signals. Accumulators only trigger when the remote side excites the gate beyond a threshold, thus no negotiated speed is required. Each has its speed versus distance advantages. A trigger, generally, is the method in which excitation is detected: rising edge, falling edge, threshold (oscilloscope can trigger a wide variety of shapes and conditions).\n\nTriggering for software interrupts must be built into the software (both in OS and app). A 'C' app has a trigger table (a table of functions) in its header, which both the app and OS know of and use appropriately that is not related to hardware. However do not confuse this with hardware interrupts which signal the CPU (the CPU enacts software from a table of functions, similarly to software interrupts).\n\nMultiple devices sharing an interrupt line (of any triggering style) all act as spurious interrupt sources with respect to each other. With many devices on one line, the workload in servicing interrupts grows in proportion to the square of the number of devices. It is therefore preferred to spread devices evenly across the available interrupt lines. Shortage of interrupt lines is a problem in older system designs where the interrupt lines are distinct physical conductors. Message-signaled interrupts, where the interrupt line is virtual, are favored in new system architectures (such as PCI Express) and relieve this problem to a considerable extent.\n\nSome devices with a poorly designed programming interface provide no way to determine whether they have requested service. They may lock up or otherwise misbehave if serviced when they do not want it. Such devices cannot tolerate spurious interrupts, and so also cannot tolerate sharing an interrupt line. ISA cards, due to often cheap design and construction, are notorious for this problem. Such devices are becoming much rarer, as hardware logic becomes cheaper and new system architectures mandate shareable interrupts.\n\nSome systems use a hybrid of level-triggered and edge-triggered signaling. The hardware not only looks for an edge, but it also verifies that the interrupt signal stays active for a certain period of time.\n\nA common use of a hybrid interrupt is for the NMI (non-maskable interrupt) input. Because NMIs generally signal major – or even catastrophic – system events, a good implementation of this signal tries to ensure that the interrupt is valid by verifying that it remains active for a period of time. This 2-step approach helps to eliminate false interrupts from affecting the system.\n\nA \"message-signaled interrupt\" does not use a physical interrupt line. Instead, a device signals its request for service by sending a short message over some communications medium, typically a computer bus. The message might be of a type reserved for interrupts, or it might be of some pre-existing type such as a memory write.\n\nMessage-signalled interrupts behave very much like edge-triggered interrupts, in that the interrupt is a momentary signal rather than a continuous condition. Interrupt-handling software treats the two in much the same manner. Typically, multiple pending message-signaled interrupts with the same message (the same virtual interrupt line) are allowed to merge, just as closely spaced edge-triggered interrupts can merge.\n\nMessage-signalled interrupt vectors can be shared, to the extent that the underlying communication medium can be shared. No additional effort is required.\n\nBecause the identity of the interrupt is indicated by a pattern of data bits, not requiring a separate physical conductor, many more distinct interrupts can be efficiently handled. This reduces the need for sharing. Interrupt messages can also be passed over a serial bus, not requiring any additional lines.\n\nPCI Express, a serial computer bus, uses message-signaled interrupts exclusively.\n\nIn a push button analogy applied to computer systems, the term \"doorbell\" or \"doorbell interrupt\" is often used to describe a mechanism whereby a software system can signal or notify a computer hardware device that there is some work to be done. Typically, the software system will place data in some well-known and mutually agreed upon memory location(s), and \"ring the doorbell\" by writing to a different memory location. This different memory location is often called the doorbell region, and there may even be multiple doorbells serving different purposes in this region. It is this act of writing to the doorbell region of memory that \"rings the bell\" and notifies the hardware device that the data are ready and waiting. The hardware device would now know that the data are valid and can be acted upon. It would typically write the data to a hard disk drive, or send them over a network, or encrypt them, etc.\n\nThe term \"doorbell interrupt\" is usually a misnomer. It is similar to an interrupt, because it causes some work to be done by the device; however, the doorbell region is sometimes implemented as a polled region, sometimes the doorbell region writes through to physical device registers, and sometimes the doorbell region is hardwired directly to physical device registers. When either writing through or directly to physical device registers, this may cause a real interrupt to occur at the device's central processor unit (CPU), if it has one.\n\nDoorbell interrupts can be compared to Message Signaled Interrupts, as they have some similarities.\n\nIn multiprocessor systems, a processor may send an interrupt request to another processor via inter-processor interrupts\" (IPI).\n\nInterrupts provide low overhead and good latency at low load, but degrade significantly at high interrupt rate unless care is taken to prevent several pathologies. The phenomenon where the overall system performance is severely hindered by excessive amounts of processing time spent handling interrupts is called an interrupt storm.\n\nThere are various forms of livelocks, when the system spends all of its time processing interrupts to the exclusion of other required tasks.\nUnder extreme conditions, a large number of interrupts (like very high network traffic) may completely stall the system. To avoid such problems, an operating system must schedule network interrupt handling as carefully as it schedules process execution.\n\nWith multi-core processors, additional performance improvements in interrupt handling can be achieved through receive-side scaling (RSS) when multiqueue NICs are used. Such NICs provide multiple receive queues associated to separate interrupts; by routing each of those interrupts to different cores, processing of the interrupt requests triggered by the network traffic received by a single NIC can be distributed among multiple cores. Distribution of the interrupts among cores can be performed automatically by the operating system, or the routing of interrupts (usually referred to as \"IRQ affinity\") can be manually configured.\n\nA purely software-based implementation of the receiving traffic distribution, known as \"receive packet steering\" (RPS), distributes received traffic among cores later in the data path, as part of the interrupt handler functionality. Advantages of RPS over RSS include no requirements for specific hardware, more advanced traffic distribution filters, and reduced rate of interrupts produced by a NIC. As a downside, RPS increases the rate of inter-processor interrupts (IPIs). \"Receive flow steering\" (RFS) takes the software-based approach further by accounting for application locality; further performance improvements are achieved by processing interrupt requests by the same cores on which particular network packets will be consumed by the targeted application.\n\nInterrupts are commonly used to service hardware timers, transfer data to and from storage (e.g., disk I/O) and communication interfaces (e.g., UART, Ethernet), handle keyboard and mouse events, and to respond to any other time-sensitive events as required by the application system. Non-maskable interrupts are typically used to respond to high-priority requests such as watchdog timer timeouts, power-down signals and traps. \n\nHardware timers are often used to generate periodic interrupts. In some applications, such interrupts are counted by the interrupt handler to keep track of absolute or elapsed time, or used by the OS task scheduler to manage execution of running processes, or both. Periodic interrupts are also commonly used to invoke sampling from input devices such as analog-to-digital converters, incremental encoder interfaces, and GPIO inputs, and to program output devices such as digital-to-analog converters, motor controllers, and GPIO outputs.\n\nA disk interrupt signals the completion of a data transfer from or to the disk peripheral; this may cause a process to run which is waiting to read or write. A power-off interrupt predicts imminent loss of power, allowing the computer to perform an orderly shut-down while there still remains enough power to do so. Keyboard interrupts typically cause keystrokes to be buffered so as to implement typeahead.\n\nInterrupts are sometimes used to emulate instructions which are unimplemented on some computers in a product family. For example floating point instructions may be implemented in hardware on some systems and emulated on lower-cost systems. In the latter case, execution of an unimplemented floating point instruction will cause an \"illegal instruction\" exception interrupt. The interrupt handler will implement the floating point function in software and then return to the interrupted program as if the hardware-implemented instruction had been executed. This provides application software portability across the entire line.\n\nInterrupts are similar to signals, the difference being that signals are used for inter-process communication (IPC), mediated by the kernel (possibly via system calls) and handled by processes, while interrupts are mediated by the processor and handled by the kernel. The kernel may pass an interrupt as a signal to the process that caused it (typical examples are SIGSEGV, SIGBUS, SIGILL and SIGFPE).\n\nHardware interrupts were introduced as an optimization, eliminating unproductive waiting time in polling loops, waiting for external events. The first system to use this approach was the DYSEAC, completed in 1954, although earlier systems provided error trap functions. \n\nThe UNIVAC 1103 computer is generally credited with the earliest use of interrupts in 1953. Earlier, on the UNIVAC I (1951) \"Arithmetic overflow either triggered the execution a two-instruction fix-up routine at address 0, or, at the programmer's option, caused the computer to stop.\" The IBM 650 (1954) incorporated the first occurrence of interrupt masking. The National Bureau of Standards DYSEAC (1954) was the first to use interrupts for I/O. The IBM 704 was the first to use interrupts for debugging, with a \"transfer trap\", which could invoke a special routine when a branch instruction was encountered.The MIT Lincoln Laboratory TX-2 system (1957) was the first to provide multiple levels of priority interrupts.\n\nBULLET::::- Advanced Programmable Interrupt Controller (APIC)\nBULLET::::- BIOS interrupt call\nBULLET::::- Event-driven programming\nBULLET::::- Exception handling\nBULLET::::- INT (x86 instruction)\nBULLET::::- Interrupt coalescing\nBULLET::::- Interrupt handler\nBULLET::::- Interrupt latency\nBULLET::::- Interrupts in 65xx processors\nBULLET::::- Ralf Brown's Interrupt List\nBULLET::::- Interrupts on IBM System/360 architecture\nBULLET::::- Time-triggered system\nBULLET::::- Autonomous peripheral operation\nBULLET::::- Interrupts Made Easy\nBULLET::::- Interrupts for Microchip PIC Microcontroller\nBULLET::::- IBM PC Interrupt Table\nBULLET::::- University of Alberta CMPUT 296 Concrete Computing Notes on Interrupts, archived from the original on March 13, 2012\n"}
{"id": "15290", "url": "https://en.wikipedia.org/wiki?curid=15290", "title": "Intercalation (timekeeping)", "text": "Intercalation (timekeeping)\n\nIntercalation or embolism in timekeeping is the insertion of a leap day, week, or month into some calendar years to make the calendar follow the seasons or moon phases. Lunisolar calendars may require intercalations of both days and months.\n\nThe solar or tropical year does not have a whole number of days (it is about 365.24 days), but a calendar year must have a whole number of days. The most common way to reconcile the two is to vary the number of days in the calendar year.\n\nIn solar calendars, this is done by adding to a common year of 365 days, an extra day (\"leap day\" or \"intercalary day\") about every four years, causing a leap year to have 366 days (Julian, Gregorian and Indian national calendars).\n\nThe Decree of Canopus, which was issued by the pharaoh Ptolemy III Euergetes of Ancient Egypt in 239 BCE, decreed a solar leap day system; an Egyptian leap year was not adopted until 25 BC, when the Roman Emperor Augustus successfully instituted a reformed Alexandrian calendar.\n\nIn the Julian calendar, as well as in the Gregorian calendar, which improved upon it, intercalation is done by adding an extra day to February in each leap year. In the Julian calendar this was done every four years. In the Gregorian, years divisible by 100 but not 400 were exempted in order to improve accuracy. Thus, 2000 was a leap year; 1700, 1800, and 1900 were not.\n\nEpagomenal days are days within a solar calendar that are outside any regular month. Usually five epagomenal days are included within every year (Egyptian, Coptic, Ethiopian, Mayan Haab' and French Republican Calendars), but a sixth epagomenal day is intercalated every four years in some (Coptic, Ethiopian and French Republican calendars).\n\nThe Bahá'í calendar includes enough epagomenal days (usually 4 or 5) before the last month (, \"ʿalāʾ\") to ensure that the following year starts on the March equinox. These are known as the Ayyám-i-Há.\n\nThe solar year does not have a whole number of lunar months (it is about 12.37 lunations), so a lunisolar calendar must have a variable number of months in a year. Regular years have 12 months, but embolismic years insert a 13th \"intercalary\" or \"leap\" or \"embolismic\" month every second or third year (see blue moon). Whether to insert an intercalary month in a given year may be determined using regular cycles such as the 19-year Metonic cycle (Hebrew calendar and in the determination of Easter) or using calculations of lunar phases (Hindu lunisolar and Chinese calendars). The Buddhist calendar adds both an intercalary day and month on a usually regular cycle.\n\nThe tabular Islamic calendar usually has 12 lunar months that alternate between 30 and 29 days every year, but an intercalary day is added to the last month of the year 11 times within a 30-year cycle. Some historians also linked the pre-Islamic practice of Nasi' to intercalation.\n\nThe Solar Hijri calendar is based on solar calculations and is similar to the Gregorian calendar in its structure, and hence the intercalation, with the exception that the year date starts with the Hegira.\n\nThe International Earth Rotation and Reference Systems Service can insert or remove leap seconds from the last day of any month (June and December are preferred). These are sometimes described as intercalary.\n\nISO 8601 includes a specification for a 52/53-week year. Any year that has 53 Thursdays has 53 weeks; this extra week may be regarded as intercalary.\n\nThe \"xiuhpōhualli\" (year count) system of the Aztec calendar had five intercalary days after the eighteenth and final month, the \"nēmontēmi\", in which the people reflect on the past year and do fasting.\n\nBULLET::::- Lunisolar calendar\nBULLET::::- Egyptian, Coptic, and Ethiopian calendars\nBULLET::::- Iranian calendar\nBULLET::::- Islamic calendar\nBULLET::::- Celtic calendar\nBULLET::::- Thai lunar calendar\nBULLET::::- Bengali calendar\nBULLET::::- Igbo calendar\nBULLET::::- The World Calendar\nBULLET::::- Intercalated Games\n"}
{"id": "15291", "url": "https://en.wikipedia.org/wiki?curid=15291", "title": "Intercourse", "text": "Intercourse\n\nIntercourse may refer to:\n\nBULLET::::- Sexual intercourse, the most common penetrative sex\nBULLET::::- Interpersonal communication, talk, any kind of human communication and/or interaction\n\nBULLET::::- Intercourse, Alabama, USA\nBULLET::::- Intercourse, Pennsylvania, USA\nBULLET::::- Intercourse Island, in Western Australia\n\nBULLET::::- \"Intercourse\" (book), the title of a 1987 book by author Andrea Dworkin\nBULLET::::- \"InterCourses: An Aphrodisiac Cookbook\", a 1997 book by Martha Hopkins and Randall Lockridge with photography by Ben Fink\n\nBULLET::::- \"Intercourse\" (The Tokens album), a 1971 album by American vocal group the Tokens\nBULLET::::- \"Intercourse\" (S'Express album), a 1991 studio album by English dance music act S'Express\n\nBULLET::::- The Intercourse (arts center), an arts center in Red Hook, Brooklyn, New York\nBULLET::::- \"Intercourse\" (magazine), a literary magazine published in Montreal from 1966 to 1971\n\nBULLET::::- Non-Intercourse Act (1809), regarding trade\nBULLET::::- Nonintercourse Act, a collective name given to six statutes to set Amerindian boundaries of reservations, instituted between 1790 and 1834\n"}
{"id": "15292", "url": "https://en.wikipedia.org/wiki?curid=15292", "title": "Ink", "text": "Ink\n\nInk is a liquid or paste that contains pigments or dyes and is used to color a surface to produce an image, text, or design. Ink is used for drawing or writing with a pen, brush, or quill. Thicker inks, in paste form, are used extensively in letterpress and lithographic printing.\n\nInk can be a complex medium, composed of solvents, pigments, dyes, resins, lubricants, solubilizers, surfactants, particulate matter, fluorescents, and other materials. The components of inks serve many purposes; the ink's carrier, colorants, and other additives affect the flow and thickness of the ink and its dry appearance.\n\nIn 2011 worldwide consumption of printing inks generated revenues of more than 20 billion US dollars. Demand by traditional print media is shrinking, on the other hand more and more printing inks are consumed for packagings.\n\n Many ancient cultures around the world have independently discovered and formulated inks for the purposes of writing and drawing. The knowledge of the inks, their recipes and the techniques for their production comes from archaeological analysis or from written text itself. The earliest inks from all civilisations are believed to have been made with \"lampblack\", a kind of soot, as this would have been easily collected as a by-product of fire.\n\nInk was used in Ancient Egypt for writing and drawing on papyrus from at least the 26th century BC. Chinese inks may go back as far as three or maybe four millennia, to the Chinese Neolithic Period. These used plants, animal, and mineral inks based on such materials as graphite that were ground with water and applied with ink brushes. Direct evidence for the earliest Chinese inks, similar to modern inksticks, is around 256 BC in the end of the Warring States period and produced from soot and animal glue. The best inks for drawing or painting on paper or silk are produced from the resin of the pine tree. They must be between 50 and 100 years old. The Chinese inkstick is produced with a fish glue, whereas Japanese glue (膠 \"nikawa\") is from cow or stag.\n\nIndia ink was first invented in China, though materials were often traded from India, hence the name. The traditional Chinese method of making the ink was to grind a mixture of hide glue, carbon black, lampblack, and bone black pigment with a pestle and mortar, then pouring it into a ceramic dish to dry. To use the dry mixture, a wet brush would be applied until it reliquified. The manufacture of India ink was well-established by the Cao Wei Dynasty (220–265 AD). Indian documents written in Kharosthi with ink have been unearthed in Chinese Turkestan. The practice of writing with ink and a sharp pointed needle was common in early South India. Several Buddhist and Jain sutras in India were compiled in ink.\n\nIn ancient Rome, atramentum was used; in an article for the \"Christian Science Monitor\", Sharon J. Huntington describes these other historical inks:\n\nAbout 1,600 years ago, a popular ink recipe was created. The recipe was used for centuries. Iron salts, such as ferrous sulfate (made by treating iron with sulfuric acid), were mixed with tannin from gallnuts (they grow on trees) and a thickener. When first put to paper, this ink is bluish-black. Over time it fades to a dull brown.\n\nScribes in medieval Europe (about AD 800 to 1500) wrote principally on parchment or vellum. One 12th century ink recipe called for hawthorn branches to be cut in the spring and left to dry. Then the bark was pounded from the branches and soaked in water for eight days. The water was boiled until it thickened and turned black. Wine was added during boiling. The ink was poured into special bags and hung in the sun. Once dried, the mixture was mixed with wine and iron salt over a fire to make the final ink.\n\nThe reservoir pen, which may have been the first fountain pen, dates back to 953, when Ma'ād al-Mu'izz, the caliph of Egypt, demanded a pen that would not stain his hands or clothes, and was provided with a pen that held ink in a reservoir.\n\nIn the 15th century, a new type of ink had to be developed in Europe for the printing press by Johannes Gutenberg. According to Martyn Lyons in his book \"Books: A Living History\", Gutenberg's dye was indelible, oil-based, and made from the soot of lamps (lamp-black) mixed with varnish and egg white. Two types of ink were prevalent at the time: the Greek and Roman writing ink (soot, glue, and water) and the 12th century variety composed of ferrous sulfate, gall, gum, and water. Neither of these handwriting inks could adhere to printing surfaces without creating blurs. Eventually an oily, varnish-like ink made of soot, turpentine, and walnut oil was created specifically for the printing press.\n\nInk formulas vary, but commonly involve two components:\nBULLET::::- Colorants\nBULLET::::- Vehicles (binders)\n\nInks generally fall into four classes:\nBULLET::::- Aqueous\nBULLET::::- Liquid\nBULLET::::- Paste\nBULLET::::- Powder\n\nPigment inks are used more frequently than dyes because they are more color-fast, but they are also more expensive, less consistent in color, and have less of a color range than dyes.\nPigments are solid, opaque particles suspended in ink to provide color. Pigment molecules typically link together in crystalline structures that are 0.1–2 µm in size and comprise 5–30 percent of the ink volume. Qualities such as hue, saturation, and lightness vary depending on the source and type of pigment.\n\nDye-based inks are generally much stronger than pigment-based inks and can produce much more color of a given density per unit of mass. However, because dyes are dissolved in the liquid phase, they have a tendency to soak into paper, potentially allowing the ink to bleed at the edges of an image.\n\nTo circumvent this problem, dye-based inks are made with solvents that dry rapidly or are used with quick-drying methods of printing, such as blowing hot air on the fresh print. Other methods include harder paper sizing and more specialized paper coatings. The latter is particularly suited to inks used in non-industrial settings (which must conform to tighter toxicity and emission controls), such as inkjet printer inks. Another technique involves coating the paper with a charged coating. If the dye has the opposite charge, it is attracted to and retained by this coating, while the solvent soaks into the paper. Cellulose, the wood-derived material most paper is made of, is naturally charged, and so a compound that complexes with both the dye and the paper's surface aids retention at the surface. Such a compound is commonly used in ink-jet printing inks.\n\nAn additional advantage of dye-based ink systems is that the dye molecules can interact with other ink ingredients, potentially allowing greater benefit as compared to pigmented inks from optical brighteners and color-enhancing agents designed to increase the intensity and appearance of dyes.\n\nA more recent development in dye-based inks are dyes that react with cellulose to permanently color the paper. Such inks are not affected by water, alcohol, and other solvents. As such, their use is recommended to prevent frauds that involve removing signatures, such as check washing. This kind of ink is most commonly found in gel inks and in certain fountain pen inks.\n\nThere is a misconception that ink is non-toxic even if swallowed. Once ingested, ink can be hazardous to one's health. Certain inks, such as those used in digital printers, and even those found in a common pen can be harmful. Though ink does not easily cause death, repeated skin contact or ingestion can cause effects such as severe headaches, skin irritation, or nervous system damage. These effects can be caused by solvents, or by pigment ingredients such as \"p\"-Anisidine, which helps create some inks' color and shine.\n\nThree main environmental issues with ink are:\nBULLET::::- Heavy metals\nBULLET::::- Non-renewable oils\nBULLET::::- Volatile organic compounds\n\nSome regulatory bodies have set standards for the amount of heavy metals in ink. There is a trend toward vegetable oils rather than petroleum oils in recent years in response to a demand for better environmental sustainability performance.\n\nInk uses up non-renewable oils and metals, which has a negative impact on the environment.\n\nCarbon inks were commonly made from lampblack or soot and a binding agent such as gum arabic or animal glue. The binding agent keeps carbon particles in suspension and adhered to paper. Carbon particles do not fade over time even when bleached or when in sunlight. One benefit is that carbon ink does not harm paper. Over time, the ink is chemically stable and therefore does not threaten the paper's strength. Despite these benefits, carbon ink is not ideal for permanence and ease of preservation. Carbon ink tends to smudge in humid environments and can be washed off surfaces. The best method of preserving a document written in carbon ink is to store it in a dry environment (Barrow 1972).\n\nRecently, carbon inks made from carbon nanotubes have been successfully created. They are similar in composition to traditional inks in that they use a polymer to suspend the carbon nanotubes. These inks can be used in inkjet printers and produce electrically conductive patterns.\n\nIron gall inks became prominent in the early 12th century; they were used for centuries and were widely thought to be the best type of ink. However, iron gall ink is corrosive and damages paper over time (Waters 1940). Items containing this ink can become brittle and the writing fades to brown. The original scores of Johann Sebastian Bach are threatened by the destructive properties of iron gall ink. The majority of his works are held by the German State Library, and about 25% of those are in advanced stages of decay (American Libraries 2000). The rate at which the writing fades is based on several factors, such as proportions of ink ingredients, amount deposited on the paper, and paper composition (Barrow 1972:16). Corrosion is caused by acid catalysed hydrolysis and iron(II)-catalysed oxidation of cellulose (Rouchon-Quillet 2004:389).\n\nTreatment is a controversial subject. No treatment undoes damage already caused by acidic ink. Deterioration can only be stopped or slowed. Some think it best not to treat the item at all for fear of the consequences. Others believe that non-aqueous procedures are the best solution. Yet others think an aqueous procedure may preserve items written with iron gall ink. Aqueous treatments include distilled water at different temperatures, calcium hydroxide, calcium bicarbonate, magnesium carbonate, magnesium bicarbonate, and calcium phytate. There are many possible side effects from these treatments. There can be mechanical damage, which further weakens the paper. Paper color or ink color may change, and ink may bleed. Other consequences of aqueous treatment are a change of ink texture or formation of plaque on the surface of the ink (Reibland & de Groot 1999).\n\nIron gall inks require storage in a stable environment, because fluctuating relative humidity increases the rate that formic acid, acetic acid, and furan derivatives form in the material the ink was used on. Sulfuric acid acts as a catalyst to cellulose hydrolysis, and iron (II) sulfate acts as a catalyst to cellulose oxidation. These chemical reactions physically weaken the paper, causing brittleness.\n\n\"Indelible\" means \"unremovable\". Some types of indelible ink have a very short shelf life because of the quickly evaporating solvents used. India, Mexico, Indonesia, Malaysia and other developing countries have used indelible ink in the form of electoral stain to prevent electoral fraud. The Indian Scientist Dr. M.L. Goel is the founding father of indelible ink in India and gave the secret formula to NPL (National Physical Laboratory) of India.\n\nThe Election Commission in India has used indelible ink for many elections. Indonesia used it in its last election in Aceh. In Mali, the ink is applied to the fingernail. Indelible ink itself is not infallible as it can be used to commit electoral fraud by marking opponent party members before they have chances to cast their votes. There are also reports of \"indelible\" ink washing off voters' fingers in Afghanistan.\n\nBULLET::::- Blue Wool Scale\nBULLET::::- De-inked pulp\nBULLET::::- Election ink\nBULLET::::- Fountain pen inks\nBULLET::::- Gel pen\nBULLET::::- Ink eraser\nBULLET::::- Lightfastness\nBULLET::::- Inksaving typeface\nBULLET::::- Invisible ink\nBULLET::::- Pharmaceutical ink\nBULLET::::- Preservation (library and archival science)\nBULLET::::- Preservation of illuminated manuscripts\nBULLET::::- Soy ink\nBULLET::::- Squid ink\nBULLET::::- Stark's ink\nBULLET::::- Tattoo ink\nBULLET::::- Toner\nBULLET::::- Inkjet printing\n\nBULLET::::- \"Think Ink!\" by Sharon J. Huntington, Christian Science Monitor, September 21, 2004, retrieved January 17, 2006.\nBULLET::::- \"A History of Technology and Invention\" by Maurice Audin, page 630.\nBULLET::::- Ainsworth, Mitchell, C., \"Inks and Their Composition and Manufacture,\" Charles Griffin and Company Ltd, 1904.\nBULLET::::- Martín-Gil J, Ramos-Sánchez MC, Martín-Gil FJ and José-Yacamán M. \"Chemical composition of a fountain pen ink\". \"Journal of Chemical Education\", 2006, 83, 1476–78\nBULLET::::- Banerji, Sures Chandra (1989). \"A Companion to Sanskrit Literature\". Motilal Banarsidass. .\nBULLET::::- Sircar, D.C. (1996).\"Indian epigraphy\". Motilal Banarsidass. .\nBULLET::::- \"Ink Chemistry\" Joy T. Kunjappu, https://www.chemistryworld.com/news/ink-chemistry/3002158.article\nBULLET::::- \"Essays in Ink Chemistry (For Paints and Coatings Too)\" Joy T. Kunjappu, Nova Science Publishers, New York, 2001\n\n\nBULLET::::- Cueppers, Christoph (1989). \"On the Manufacture of Ink.\" \"Ancient Nepal – Journal of the Department of Archaeology\", Number 113, August–September 1989, pp. 1–7. [The Tibetan text and translation of a section of the work called, \"Bzo gnas nyer mkho'i za ma tog\" by 'Jam-mgon 'Ju Mi-pham-rgya-mtsho (1846–1912) describing various traditional Tibetan techniques of making inks from different sources of soot, and from earth, puffballs, dung, \"ser-sha\" – a yellow fungus, and the fruit of \"tsi dra ka\" (\"Ricinus communis\").]\n\nBULLET::::- Forty Centuries of Ink (David N. Carvalho); A detailed online textbook\nBULLET::::- Roman ink article by Alexander Allen In Smith's Dictionary Greek and Roman Antiquities (1875), in LacusCurtius\nBULLET::::- Ancient and Modern Ink Recipes (David N. Carvalho)\nBULLET::::- Gorgeous Portrayal Of How Ink Is Made – video at \"The Huffington Post\"\nBULLET::::- \"A Light Note on the Science of Writing and Inks\" is a manuscript, in Arabic, from 1852. It discusses the process of making inks.\n"}
{"id": "15294", "url": "https://en.wikipedia.org/wiki?curid=15294", "title": "Islamabad Capital Territory", "text": "Islamabad Capital Territory\n\nIslamabad Capital Territory () is the only federal territory of Pakistan. Located in north-central Pakistan between the provinces of Punjab and Khyber Pakhtunkhwa, it includes the country's federal capital Islamabad. The territory is represented in the National Assembly constituencies NA-52, NA-53 and NA-54.\n\nIn 1960, land was transferred from Rawalpindi District of Punjab province to establish Pakistan's new capital. According to the 1960s master plan, the Capital Territory included Rawalpindi, and was to be composed of the following parts:\nBULLET::::- Rawalpindi,\nBULLET::::- Islamabad,\nBULLET::::- Margalla Hills,\nBULLET::::- Islamabad rural,\n\nHowever, Rawalpindi was eventually excluded from the Islamabad master plan in the 1980s.\n\nIslamabad is subdivided into five zones:\nBULLET::::- Zone I: Designated for urban development and federal government institutions\nBULLET::::- Zone II: Designated for urban development\nBULLET::::- Zone III: Designated for rural development\nBULLET::::- Zone IV: Designated for rural development\nBULLET::::- Zone V: Designated for rural development\n\nIslamabad Capital Territory comprises urban and rural areas. The rural consists of 23 union councils, comprising 133 villages, while urban has 27 union councils.\n\n+Union Councils of Islamabad Capital Territory\n! UC #\n! Chief locality\n! Localities within jurisdiction\nMal Pur\nKot Hathial (Shamal)\nKot Hathial (Janoob)\nCharah\nKirpa\nMughal\nDarwala\nKhana Dak\nShahrak-e-Rawal\n\nBokra\nJhangi Saydan\n\nBadhana Kalan\n\nTarno\n\nSarai Kharbooza\n\nThe climate of Islamabad has a humid subtropical climate (Köppen: Cwa), with five seasons: Winter (November–February), Spring (March and April), Summer (May and June), Rainy Monsoon (July and August) and Autumn (September and October). The hottest month is June, where average highs routinely exceed . Wettest month is July, with heavy rainfalls and evening thunderstorms with the possibility of cloudburst and flooding. Coolest month is January. Islamabad's micro-climate is regulated by three artificial reservoirs: Rawal, Simli, and Khanpur Dam. Last one is located on the Haro River near the town of Khanpur, about from Islamabad. Simli Dam is north of Islamabad. of the city consists of Margalla Hills National Park. Loi Bher Forest is situated along the Islamabad Highway, covering an area of . Highest monthly rainfall of was recorded during July 1995. Winters generally feature dense fog in the mornings and sunny afternoons. In the city, temperatures stay mild, with snowfall over the higher elevations points on nearby hill stations, notably Murree and Nathia Gali. The temperatures range from in January to in June. The highest recorded temperature was on 23 June 2005 while the lowest temperature was on 17 January 1967. The city has \"recorded\" snowfall. On 23 July 2001, Islamabad received a record breaking of rainfall in just 10 hours. It was the heaviest rainfall in Islamabad in the past 100 years and the highest rainfall in 24 hours as well.\n\nThe main administrative authority of the city is Islamabad Capital Territory Administration with some help from Metropolitan Corporation Islamabad and Capital Development Authority (CDA), which oversees the planning, development, construction, and administration of the city. Islamabad Capital Territory is divided into eight zones: Administrative Zone, Commercial District, Educational Sector, Industrial Sector, Diplomatic Enclave, Residential Areas, Rural Areas and Green Area.\n\nIslamabad city is divided into five major zones: Zone I, Zone II, Zone III, Zone IV, and Zone V. Out of these, Zone IV is the largest in area. All sectors of ghouri town (1, 2, 3, VIP, 5, 4-A, 4-B, 4-C, 5-A, 5-B and sector 7) are located in this zone. Zone I consists mainly of all the developed residential sectors, while Zone II consists of the under-developed residential sectors. Each residential sector is identified by a letter of the alphabet and a number, and covers an area of approximately 4 square kilometres. The sectors are lettered from A to I, and each sector is divided into four numbered sub-sectors.\n\nSeries A, B, and C are still underdeveloped. The D series has seven sectors (D-11 to D-17), of which only sector D-12 is completely developed. This series is located at the foot of Margalla Hills. The E Sectors are named from E-7 to E-17. Many foreigners and diplomatic personnel are housed in these sectors. In the revised Master Plan of the city, CDA has decided to develop a park on the pattern of Fatima Jinnah Park in sector E-14. Sectors E-8 and E-9 contain the campuses of Bahria University, Air University, and the National Defence University. The F and G series contains the most developed sectors. F series contains sectors F-5 to F-17; some sectors are still under-developed. F-5 is an important sector for the software industry in Islamabad, as the two software technology parks are located here. The entire F-9 sector is covered with Fatima Jinnah Park. The Centaurus complex will be one of the major landmarks of the F-8 sector. G sectors are numbered G-5 through G-17. Some important places include the Jinnah Convention Center and Serena Hotel in G-5, the Red Mosque in G-6, and the Pakistan Institute of Medical Sciences, the largest medical complex in the capital, located in G-8.\n\nThe H sectors are numbered H-8 through H-17. The H sectors are mostly dedicated to educational and health institutions. National University of Sciences and Technology covers a major portion of sector H-12. The I sectors are numbered from I-8 to I-18. With the exception of I-8, which is a well-developed residential area, these sectors are primarily part of the industrial zone. Currently two sub-sectors of I-9 and one sub-sector of I-10 are used as industrial areas. CDA is planning to set up Islamabad Railway Station in Sector I-18 and Industrial City in sector I-17. Zone III consists primarily of the Margalla Hills and Margalla Hills National Park. Rawal Lake is in this zone. Zone IV and V consist of Islamabad Park, and rural areas of the city. The Soan River flows into the city through Zone V.\n\nWhile urban Islamabad is home to people from all over Pakistan as well as expatriates, in the rural areas a number of Pothohari speaking tribal communities can still be recognised.\n\nWhen the master plan for Islamabad was drawn up in 1960, Islamabad and Rawalpindi, along with the adjoining areas, was to be integrated to form a large metropolitan area called Islamabad/Rawalpindi Metropolitan Area. The area would consist of the developing Islamabad, the old colonial cantonment city of Rawalpindi, and Margalla Hills National Park, including surrounding rural areas. However, Islamabad city is part of the Islamabad Capital Territory, while Rawalpindi is part of Rawalpindi District, which is part of province of Punjab.\n\nInitially, it was proposed that the three areas would be connected by four major highways: Murree Highway, Islamabad Highway, Soan Highway, and Capital Highway. However, to date only two highways have been constructed: Kashmir Highway (the former Murree Highway) and Islamabad Highway. Plans of constructing Margalla Avenue are also underway. Islamabad is the hub all the governmental activities while Rawalpindi is the centre of all industrial, commercial, and military activities. The two cities are considered sister cities and are highly interdependent.\nIslamabad is a net contributor to the Pakistani economy, as whilst having only 0.8% of the country's population, it contributes 1% to the country's GDP. Islamabad Stock Exchange, founded in 1989, is Pakistan's third largest stock exchange after Karachi Stock Exchange and Lahore Stock Exchange. The exchange has 118 members with 104 corporate bodies and 18 individual members. The average daily turnover of the stock exchange is over 1 million shares. As of 2012, Islamabad LTU (Large Tax Unit) was responsible for Rs 371 billion in tax revenue, which amounts to 20% of all the revenue collected by Federal Board of Revenue.\n\nIslamabad has seen an expansion in information and communications technology with the addition two Software Technology Parks, which house numerous national and foreign technological and information technology companies. The tech parks are located in Evacuee Trust Complex and Awami Markaz. Awami Markaz houses 36 IT companies while Evacuee Trust house 29 companies. Call centres for foreign companies have been targeted as another significant area of growth, with the government making efforts to reduce taxes by as much as 10% to encourage foreign investments in the information technology sector. Most of Pakistan's state-owned companies like PIA, PTV, PTCL, OGDCL, and Zarai Taraqiati Bank Ltd. are based in Islamabad. Headquarters of all major telecommunication operators such as PTCL, Mobilink, Telenor, Ufone, and China Mobile are located in Islamabad.\n\nBULLET::::- Airports: Islamabad is connected to major destinations around the world through Benazir Bhutto International Airport, previously known as Islamabad International Airport. The airport is the third largest in Pakistan and is located outside Islamabad, in Chaklala, Rawalpindi. In fiscal year 2004–2005, over 2.88 million passengers used Benazir Bhutto International Airport and 23,436 aircraft movements were registered. Islamabad Gandhara International Airport is under construction at Fateh Jang to cope with the increasing number of passengers. When completed, the airport will be the largest in Pakistan. The airport will be built at a cost of $400 million and is expected to be complete and operational by 2017. This will be the first green field airport in Pakistan with an area of .\n\nThe Rawalpindi-Islamabad Metrobus is a bus rapid transit system that serves the twin cities of Rawalpindi and Islamabad in Pakistan. It uses dedicated bus lanes for all of its route covering 24 bus stations. Islamabad is well connected with other parts of the country through car rental services such as Alvi Transport Network and Pakistan Car Rentals.\n\nAll major cities and towns are accessible through regular trains and bus services running mostly from the neighbouring city of Rawalpindi. Lahore and Peshawar are linked to Islamabad through a network of motorways, which has significantly reduced travelling times between these cities. M-2 Motorway is long and connect Islamabad and Lahore. M-1 Motorway connects Islamabad with Peshawar and is long. Islamabad is linked to Rawalpindi through the Faizabad Interchange, which has a daily traffic volume of about 48,000 vehicles.\n\nIslamabad has the highest literacy rate of Pakistan at 95%. Islamabad also has some of Pakistan's major universities, including Quaid-i-Azam University, the International Islamic University, and the National University of Sciences and Technology and Pakistan Institute of Engineering and Applied Sciences\n\nPrivate School Network Islamabad is working for private educational institutions. The president of PSN is Dr. Muhammad Afzal Babur from Bhara Kahu. PSN is divided into eight zones in Islamabad. In Tarlai Zone Chaudhary Faisal Ali from Faisal Academy Tarlai Kalan is Zonal General Sectary of PSN.\n\nQuaid-e-Azam University has several faculties. The institute is located in a semi-hilly area, east of the Secretariat buildings and near the base of Margalla Hills. This Post-Graduate institute is spread over . The nucleus of the campus has been designed as an axial spine with a library as its center.\nOther universities include the following:\n\nBULLET::::- Bahria University\nBULLET::::- Air University\nBULLET::::- Quaid-e-Azam University\nBULLET::::- Allama Iqbal Open University (AIOU)\nBULLET::::- Alkauthar Islamic University\nBULLET::::- COMSATS Institute of Information Technology (CIIT)\nBULLET::::- Capital University of Science and Technology (CUST) [Formally Mohammad Ali Jinnah University, Islamabad Campus]\nBULLET::::- Federal Urdu University of Arts, Science & Technology (FUUAST)\nBULLET::::- National University of Sciences and Technology (NUST)\nBULLET::::- National Defense University, Islamabad(NDU)\nBULLET::::- National University of Modern Languages (NUML)\nBULLET::::- Institute of Space Technology\nBULLET::::- International Islamic University Islamabad\nBULLET::::- Institute of Cost and Management Accountants of Pakistan (ICMAP)\nBULLET::::- Pakistan Institute of Development Economics (PIDE)\nBULLET::::- Pakistan Institute of Engineering and Applied Sciences (PIEAS)\nBULLET::::- Shifa College of Medicine\nBULLET::::- Foundation University Islamabad (FUI)\nBULLET::::- National University of Computer & Emerging Sciences(FAST-NUCES)\nBULLET::::- Riphah International University\nBULLET::::- University of Lahore\nBULLET::::- Center for Advanced Studies in Engineering\nBULLET::::- Preston University Islamabad Campus\nBULLET::::- Iqra University Islamabad Campus\nBULLET::::- Shaheed Zulfiqar Ali Bhutto Institute of Science and Technology (ZABIST)\nBULLET::::- Hamdard University Islamabad Campus\n\nIslamabad United became the first ever team to win Pakistan Super League in 2016. And now the federal team Is participating in the Pakistan Cup. The team is under the captaincy of Misbah-ul-Haq, former captain of Pakistan, The Islamabad United was also under Misbah.\n\nBULLET::::- Islamabad Capital Territory Administration\nBULLET::::- Developments in Islamabad\nBULLET::::- Model Town Humak\n\nBULLET::::- Islamabad Capital Territory Administration website\n\nBULLET::::- Capital Development Authority\n"}
{"id": "15295", "url": "https://en.wikipedia.org/wiki?curid=15295", "title": "Intelligent design", "text": "Intelligent design\n\nIntelligent design (ID) is a pseudoscientific argument for the existence of God, presented by its proponents as \"an evidence-based scientific theory about life's origins\". Proponents claim that \"certain features of the universe and of living things are best explained by an intelligent cause, not an undirected process such as natural selection.\" ID is a form of creationism that lacks empirical support and offers no testable or tenable hypotheses, so it is not science. The leading proponents of ID are associated with the Discovery Institute, a fundamentalist Christian and politically conservative think tank based in the United States.\n\nThough the phrase \"intelligent design\" had featured previously in theological discussions of the argument from design, the first publication of the term \"intelligent design\" in its present use as an alternative term for creationism was in \"Of Pandas and People\", a 1989 creationist textbook intended for high school biology classes. The term was substituted into drafts of the book, directly replacing references to \"creation science\" and \"creationism\", after the 1987 United States Supreme Court's \"Edwards v. Aguillard\" decision which barred the teaching of \"creation science\" in public schools on constitutional grounds. From the mid-1990s, the intelligent design movement (IDM), supported by the Discovery Institute, advocated inclusion of intelligent design in public school biology curricula. This led to the 2005 \"Kitzmiller v. Dover Area School District\" trial in which U.S. District Judge John E. Jones III found that intelligent design was not science, that it \"cannot uncouple itself from its creationist, and thus religious, antecedents,\" and that the school district's promotion of it therefore violated the Establishment Clause of the First Amendment to the United States Constitution.\n\nID presents two main arguments against evolutionary explanations: irreducible complexity and specified complexity. These arguments assert that certain features (biological and informational, respectively) are too complex to be the result of natural processes. As a positive argument against evolution, ID proposes an analogy between natural systems and human artifacts, a version of the theological argument from design for the existence of God. ID proponents then conclude by analogy that the complex features, as defined by ID, are evidence of design.\n\nDetailed scientific examination has rebutted the claims that evolutionary explanations are inadequate, and this premise of intelligent design—that evidence against evolution constitutes evidence for design—is a false dichotomy. It is asserted that ID challenges the methodological naturalism inherent in modern science though proponents concede that they have yet to produce a scientific theory.\n\nIn 1910, evolution was not a topic of major religious controversy in America, but in the 1920s, the Fundamentalist–Modernist Controversy in theology resulted in Fundamentalist Christian opposition to teaching evolution, and the origins of modern creationism. Teaching of evolution was effectively suspended in U.S. public schools until the 1960s, and when evolution was then reintroduced into the curriculum, there was a series of court cases in which attempts were made to get creationism taught alongside evolution in science classes. Young Earth creationists (YEC) promoted creation science as \"an alternative scientific explanation of the world in which we live\". This frequently invoked the argument from design to explain complexity in nature as demonstrating the existence of God.\n\nThe argument from design, also known as the teleological argument or \"argument from intelligent design\", has been advanced in theology for centuries. It can be summarised briefly as \"Wherever complex design exists, there must have been a designer; nature is complex; therefore nature must have had an intelligent designer.\" Thomas Aquinas presented it in his fifth proof of God's existence as a syllogism. In 1802, William Paley's \"Natural Theology\" presented examples of intricate purpose in organisms. His version of the watchmaker analogy argued that, in the same way that a watch has evidently been designed by a craftsman, complexity and adaptation seen in nature must have been designed, and the perfection and diversity of these designs shows the designer to be omnipotent, the Christian God. Like creation science, intelligent design centers on Paley's religious argument from design, but while Paley's natural theology was open to deistic design through God-given laws, intelligent design seeks scientific confirmation of repeated miraculous interventions in the history of life. Creation science prefigured the intelligent design arguments of irreducible complexity, even featuring the bacterial flagellum. In the United States, attempts to introduce creation science in schools led to court rulings that it is religious in nature, and thus cannot be taught in public school science classrooms. Intelligent design is also presented as science, and shares other arguments with creation science but avoids literal Biblical references to such things as the Flood story from the Book of Genesis or using Bible verses to age the Earth.\n\nBarbara Forrest writes that the intelligent design movement began in 1984 with the book \"The Mystery of Life's Origin: Reassessing Current Theories\", co-written by creationist Charles B. Thaxton, a chemist, with two other authors, and published by Jon A. Buell's Foundation for Thought and Ethics.\n\nIn March 1986, Stephen C. Meyer published a review of the book, discussing how information theory could suggest that messages transmitted by DNA in the cell show \"specified complexity\" specified by intelligence, and must have originated with an intelligent agent. He also argued that science is based upon \"foundational assumptions\" of naturalism which were as much a matter of faith as those of \"creation theory\". In November of that year, Thaxton described his reasoning as a more sophisticated form of Paley's argument from design. At the \"Sources of Information Content in DNA\" conference which Thaxton held in 1988, he said that his intelligent cause view was compatible with both metaphysical naturalism and supernaturalism.\n\nIntelligent design avoids identifying or naming the intelligent designer—it merely states that one (or more) must exist—but leaders of the movement have said the designer is the Christian God. Whether this lack of specificity about the designer's identity in public discussions is a genuine feature of the concept, or just a posture taken to avoid alienating those who would separate religion from the teaching of science, has been a matter of great debate between supporters and critics of intelligent design. The \"Kitzmiller v. Dover Area School District\" court ruling held the latter to be the case.\n\nSince the Middle Ages, discussion of the religious \"argument from design\" or \"teleological argument\" in theology, with its concept of \"intelligent design\", has persistently referred to the theistic Creator God. Although ID proponents chose this provocative label for their proposed alternative to evolutionary explanations, they have de-emphasized their religious antecedents and denied that ID is natural theology, while still presenting ID as supporting the argument for the existence of God.\n\nWhile intelligent design proponents have pointed out past examples of the phrase \"intelligent design\" that they said were not creationist and faith-based, they have failed to show that these usages had any influence on those who introduced the label in the intelligent design movement.\n\nVariations on the phrase appeared in Young Earth creationist publications: a 1967 book co-written by Percival Davis referred to \"design according to which basic organisms were created\". In 1970, A. E. Wilder-Smith published \"The Creation of Life: A Cybernetic Approach to Evolution\" which defended Paley's design argument with computer calculations of the improbability of genetic sequences, which he said could not be explained by evolution but required \"the abhorred necessity of divine intelligent activity behind nature\", and that \"the same problem would be expected to beset the relationship between the designer behind nature and the intelligently designed part of nature known as man.\" In a 1984 article as well as in his affidavit to \"Edwards v. Aguillard\", Dean H. Kenyon defended creation science by stating that \"biomolecular systems require intelligent design and engineering know-how\", citing Wilder-Smith. Creationist Richard B. Bliss used the phrase \"creative design\" in \"Origins: Two Models: Evolution, Creation\" (1976), and in \"Origins: Creation or Evolution\" (1988) wrote that \"while evolutionists are trying to find non-intelligent ways for life to occur, the creationist insists that an intelligent design must have been there in the first place.\" The first systematic use of the term, defined in a glossary and claimed to be other than creationism, was in \"Of Pandas and People\", co-authored by Davis and Kenyon.\n\nThe most common modern use of the words \"intelligent design\" as a term intended to describe a field of inquiry began after the United States Supreme Court ruled in June 1987 in the case of \"Edwards v. Aguillard\" that it is unconstitutional for a state to require the teaching of creationism in public school science curricula.\n\nA Discovery Institute report says that Charles B. Thaxton, editor of \"Pandas\", had picked the phrase up from a NASA scientist, and thought, \"That's just what I need, it's a good engineering term.\" In two successive 1987 drafts of the book, over one hundred uses of the root word \"creation\", such as \"creationism\" and \"Creation Science\", were changed, almost without exception, to \"intelligent design\", while \"creationists\" was changed to \"design proponents\" or, in one instance, \"cdesign proponentsists\". In June 1988, Thaxton held a conference titled \"Sources of Information Content in DNA\" in Tacoma, Washington. Stephen C. Meyer was at the conference, and later recalled that \"The term \"intelligent design\" came up...\" In December 1988 Thaxton decided to use the label \"intelligent design\" for his new creationist movement.\n\n\"Of Pandas and People\" was published in 1989, and in addition to including all the current arguments for ID, was the first book to make systematic use of the terms \"intelligent design\" and \"design proponents\" as well as the phrase \"design theory\", defining the term \"intelligent design\" in a glossary and representing it as not being creationism. It thus represents the start of the modern intelligent design movement. \"Intelligent design\" was the most prominent of around fifteen new terms it introduced as a new lexicon of creationist terminology to oppose evolution without using religious language. It was the first place where the phrase \"intelligent design\" appeared in its primary present use, as stated both by its publisher Jon A. Buell, and by William A. Dembski in his expert witness report for \"Kitzmiller v. Dover Area School District\".\n\nThe National Center for Science Education (NCSE) has criticized the book for presenting all of the basic arguments of intelligent design proponents and being actively promoted for use in public schools before any research had been done to support these arguments. Although presented as a scientific textbook, philosopher of science Michael Ruse considers the contents \"worthless and dishonest\". An American Civil Liberties Union lawyer described it as a political tool aimed at students who did not \"know science or understand the controversy over evolution and creationism\". One of the authors of the science framework used by California schools, Kevin Padian, condemned it for its \"sub-text\", \"intolerance for honest science\" and \"incompetence\".\n\nThe term \"irreducible complexity\" was introduced by biochemist Michael Behe in his 1996 book \"Darwin's Black Box\", though he had already described the concept in his contributions to the 1993 revised edition of \"Of Pandas and People\". Behe defines it as \"a single system which is composed of several well-matched interacting parts that contribute to the basic function, wherein the removal of any one of the parts causes the system to effectively cease functioning\".\n\nBehe uses the analogy of a mousetrap to illustrate this concept. A mousetrap consists of several interacting pieces—the base, the catch, the spring and the hammer—all of which must be in place for the mousetrap to work. Removal of any one piece destroys the function of the mousetrap. Intelligent design advocates assert that natural selection could not create irreducibly complex systems, because the selectable function is present only when all parts are assembled. Behe argued that irreducibly complex biological mechanisms include the bacterial flagellum of \"E. coli\", the blood clotting cascade, cilia, and the adaptive immune system.\n\nCritics point out that the irreducible complexity argument assumes that the necessary parts of a system have always been necessary and therefore could not have been added sequentially. They argue that something that is at first merely advantageous can later become necessary as other components change. Furthermore, they argue, evolution often proceeds by altering preexisting parts or by removing them from a system, rather than by adding them. This is sometimes called the \"scaffolding objection\" by an analogy with scaffolding, which can support an \"irreducibly complex\" building until it is complete and able to stand on its own.\nBehe has acknowledged using \"sloppy prose\", and that his \"argument against Darwinism does not add up to a logical proof.\" Irreducible complexity has remained a popular argument among advocates of intelligent design; in the Dover trial, the court held that \"Professor Behe's claim for irreducible complexity has been refuted in peer-reviewed research papers and has been rejected by the scientific community at large.\"\n\nIn 1986, Charles B. Thaxton, a physical chemist and creationist, used the term \"specified complexity\" from information theory when claiming that messages transmitted by DNA in the cell were specified by intelligence, and must have originated with an intelligent agent.\nThe intelligent design concept of \"specified complexity\" was developed in the 1990s by mathematician, philosopher, and theologian William A. Dembski. Dembski states that when something exhibits specified complexity (i.e., is both complex and \"specified\", simultaneously), one can infer that it was produced by an intelligent cause (i.e., that it was designed) rather than being the result of natural processes. He provides the following examples: \"A single letter of the alphabet is specified without being complex. A long sentence of random letters is complex without being specified. A Shakespearean sonnet is both complex and specified.\" He states that details of living things can be similarly characterized, especially the \"patterns\" of molecular sequences in functional biological molecules such as DNA.\nDembski defines complex specified information (CSI) as anything with a less than 1 in 10 chance of occurring by (natural) chance. Critics say that this renders the argument a tautology: complex specified information cannot occur naturally because Dembski has defined it thus, so the real question becomes whether or not CSI actually exists in nature.\n\nThe conceptual soundness of Dembski's specified complexity/CSI argument has been discredited in the scientific and mathematical communities. Specified complexity has yet to be shown to have wide applications in other fields, as Dembski asserts. John Wilkins and Wesley R. Elsberry characterize Dembski's \"explanatory filter\" as \"eliminative\" because it eliminates explanations sequentially: first regularity, then chance, finally defaulting to design. They argue that this procedure is flawed as a model for scientific inference because the asymmetric way it treats the different possible explanations renders it prone to making false conclusions.\n\nRichard Dawkins, another critic of intelligent design, argues in \"The God Delusion\" (2006) that allowing for an intelligent designer to account for unlikely complexity only postpones the problem, as such a designer would need to be at least as complex. Other scientists have argued that evolution through selection is better able to explain the observed complexity, as is evident from the use of selective evolution to design certain electronic, aeronautic and automotive systems that are considered problems too complex for human \"intelligent designers\".\n\nIntelligent design proponents have also occasionally appealed to broader teleological arguments outside of biology, most notably an argument based on the fine-tuning of universal constants that make matter and life possible and which are argued not to be solely attributable to chance. These include the values of fundamental physical constants, the relative strength of nuclear forces, electromagnetism, and gravity between fundamental particles, as well as the ratios of masses of such particles. Intelligent design proponent and Center for Science and Culture fellow Guillermo Gonzalez argues that if any of these values were even slightly different, the universe would be dramatically different, making it impossible for many chemical elements and features of the Universe, such as galaxies, to form. Thus, proponents argue, an intelligent designer of life was needed to ensure that the requisite features were present to achieve that particular outcome.\n\nScientists have generally responded that these arguments are poorly supported by existing evidence. Victor J. Stenger and other critics say both intelligent design and the weak form of the anthropic principle are essentially a tautology; in his view, these arguments amount to the claim that life is able to exist because the Universe is able to support life. The claim of the improbability of a life-supporting universe has also been criticized as an argument by lack of imagination for assuming no other forms of life are possible. Life as we know it might not exist if things were different, but a different sort of life might exist in its place. A number of critics also suggest that many of the stated variables appear to be interconnected and that calculations made by mathematicians and physicists suggest that the emergence of a universe similar to ours is quite probable.\n\nThe contemporary intelligent design movement formulates its arguments in secular terms and intentionally avoids identifying the intelligent agent (or agents) they posit. Although they do not state that God is the designer, the designer is often implicitly hypothesized to have intervened in a way that only a god could intervene. Dembski, in \"The Design Inference\" (1998), speculates that an alien culture could fulfill these requirements. \"Of Pandas and People\" proposes that SETI illustrates an appeal to intelligent design in science. In 2000, philosopher of science Robert T. Pennock suggested the Raëlian UFO religion as a real-life example of an extraterrestrial intelligent designer view that \"make[s] many of the same bad arguments against evolutionary theory as creationists\". The authoritative description of intelligent design, however, explicitly states that the \"Universe\" displays features of having been designed. Acknowledging the paradox, Dembski concludes that \"no intelligent agent who is strictly physical could have presided over the origin of the universe or the origin of life.\" The leading proponents have made statements to their supporters that they believe the designer to be the Christian God, to the exclusion of all other religions.\n\nBeyond the debate over whether intelligent design is scientific, a number of critics argue that existing evidence makes the design hypothesis appear unlikely, irrespective of its status in the world of science. For example, Jerry Coyne asks why a designer would \"give us a pathway for making vitamin C, but then destroy it by disabling one of its enzymes\" (see pseudogene) and why a designer would not \"stock oceanic islands with reptiles, mammals, amphibians, and freshwater fish, despite the suitability of such islands for these species\". Coyne also points to the fact that \"the flora and fauna on those islands resemble that of the nearest mainland, even when the environments are very different\" as evidence that species were not placed there by a designer. Previously, in \"Darwin's Black Box\", Behe had argued that we are simply incapable of understanding the designer's motives, so such questions cannot be answered definitively. Odd designs could, for example, \"...have been placed there by the designer for a reason—for artistic reasons, for variety, to show off, for some as-yet-undetected practical purpose, or for some unguessable reason—or they might not.\" Coyne responds that in light of the evidence, \"either life resulted not from intelligent design, but from evolution; or the intelligent designer is a cosmic prankster who designed everything to make it look as though it had evolved.\"\n\nIntelligent design proponents such as Paul Nelson avoid the problem of poor design in nature by insisting that we have simply failed to understand the perfection of the design. Behe cites Paley as his inspiration, but he differs from Paley's expectation of a perfect Creation and proposes that designers do not necessarily produce the best design they can. Behe suggests that, like a parent not wanting to spoil a child with extravagant toys, the designer can have multiple motives for not giving priority to excellence in engineering. He says that \"Another problem with the argument from imperfection is that it critically depends on a psychoanalysis of the unidentified designer. Yet the reasons that a designer would or would not do anything are virtually impossible to know unless the designer tells you specifically what those reasons are.\" This reliance on inexplicable motives of the designer makes intelligent design scientifically untestable. Retired UC Berkeley law professor, author and intelligent design advocate Phillip E. Johnson puts forward a core definition that the designer creates for a purpose, giving the example that in his view AIDS was created to punish immorality and is not caused by HIV, but such motives cannot be tested by scientific methods.\n\nAsserting the need for a designer of complexity also raises the question \"What designed the designer?\" Intelligent design proponents say that the question is irrelevant to or outside the scope of intelligent design. Richard Wein counters that \"...scientific explanations often create new unanswered questions. But, in assessing the value of an explanation, these questions are not irrelevant. They must be balanced against the improvements in our understanding which the explanation provides. Invoking an unexplained being to explain the origin of other beings (ourselves) is little more than question-begging. The new question raised by the explanation is as problematic as the question which the explanation purports to answer.\" Richard Dawkins sees the assertion that the designer does not need to be explained as a thought-terminating cliché. In the absence of observable, measurable evidence, the very question \"What designed the designer?\" leads to an infinite regression from which intelligent design proponents can only escape by resorting to religious creationism or logical contradiction.\n\nThe intelligent design movement is a direct outgrowth of the creationism of the 1980s. The scientific and academic communities, along with a U.S. federal court, view intelligent design as either a form of creationism or as a direct descendant that is closely intertwined with traditional creationism; and several authors explicitly refer to it as \"intelligent design creationism\".\n\nThe movement is headquartered in the Center for Science and Culture, established in 1996 as the creationist wing of the Discovery Institute to promote a religious agenda calling for broad social, academic and political changes. The Discovery Institute's intelligent design campaigns have been staged primarily in the United States, although efforts have been made in other countries to promote intelligent design. Leaders of the movement say intelligent design exposes the limitations of scientific orthodoxy and of the secular philosophy of naturalism. Intelligent design proponents allege that science should not be limited to naturalism and should not demand the adoption of a naturalistic philosophy that dismisses out-of-hand any explanation that includes a supernatural cause. The overall goal of the movement is to \"reverse the stifling dominance of the materialist worldview\" represented by the theory of evolution in favor of \"a science consonant with Christian and theistic convictions\".\n\nPhillip E. Johnson stated that the goal of intelligent design is to cast creationism as a scientific concept. All leading intelligent design proponents are fellows or staff of the Discovery Institute and its Center for Science and Culture. Nearly all intelligent design concepts and the associated movement are the products of the Discovery Institute, which guides the movement and follows its wedge strategy while conducting its \"Teach the Controversy\" campaign and their other related programs.\n\nLeading intelligent design proponents have made conflicting statements regarding intelligent design. In statements directed at the general public, they say intelligent design is not religious; when addressing conservative Christian supporters, they state that intelligent design has its foundation in the Bible. Recognizing the need for support, the Institute affirms its Christian, evangelistic orientation:\n\nBarbara Forrest, an expert who has written extensively on the movement, describes this as being due to the Discovery Institute's obfuscating its agenda as a matter of policy. She has written that the movement's \"activities betray an aggressive, systematic agenda for promoting not only intelligent design creationism, but the religious worldview that undergirds it.\"\n\nAlthough arguments for intelligent design by the intelligent design movement are formulated in secular terms and intentionally avoid positing the identity of the designer, the majority of principal intelligent design advocates are publicly religious Christians who have stated that, in their view, the designer proposed in intelligent design is the Christian conception of God. Stuart Burgess, Phillip E. Johnson, William A. Dembski, and Stephen C. Meyer are evangelical Protestants; Michael Behe is a Roman Catholic; Paul Nelson supports young Earth creationism; and Jonathan Wells is a member of the Unification Church. Non-Christian proponents include David Klinghoffer, who is Jewish, Michael Denton and David Berlinski, who are agnostic, and Muzaffar Iqbal, a Pakistani-Canadian Muslim. Phillip E. Johnson has stated that cultivating ambiguity by employing secular language in arguments that are carefully crafted to avoid overtones of theistic creationism is a necessary first step for ultimately reintroducing the Christian concept of God as the designer. Johnson explicitly calls for intelligent design proponents to obfuscate their religious motivations so as to avoid having intelligent design identified \"as just another way of packaging the Christian evangelical message.\" Johnson emphasizes that \"...the first thing that has to be done is to get the Bible out of the discussion. ...This is not to say that the biblical issues are unimportant; the point is rather that the time to address them will be after we have separated materialist prejudice from scientific fact.\"\n\nThe strategy of deliberately disguising the religious intent of intelligent design has been described by William A. Dembski in \"The Design Inference\". In this work, Dembski lists a god or an \"alien life force\" as two possible options for the identity of the designer; however, in his book \"Intelligent Design: The Bridge Between Science and Theology\" (1999), Dembski states:\n\nDembski also stated, \"ID is part of God's general revelation [...] Not only does intelligent design rid us of this ideology materialism , which suffocates the human spirit, but, in my personal experience, I've found that it opens the path for people to come to Christ.\" Both Johnson and Dembski cite the Bible's Gospel of John as the foundation of intelligent design.\n\nBarbara Forrest contends such statements reveal that leading proponents see intelligent design as essentially religious in nature, not merely a scientific concept that has implications with which their personal religious beliefs happen to coincide. She writes that the leading proponents of intelligent design are closely allied with the ultra-conservative Christian Reconstructionism movement. She lists connections of (current and former) Discovery Institute Fellows Phillip E. Johnson, Charles B. Thaxton, Michael Behe, Richard Weikart, Jonathan Wells and Francis J. Beckwith to leading Christian Reconstructionist organizations, and the extent of the funding provided the Institute by Howard Ahmanson, Jr., a leading figure in the Reconstructionist movement.\n\nNot all creationist organizations have embraced the intelligent design movement. According to Thomas Dixon, \"Religious leaders have come out against ID too. An open letter affirming the compatibility of Christian faith and the teaching of evolution, first produced in response to controversies in Wisconsin in 2004, has now been signed by over ten thousand clergy from different Christian denominations across America.\" Hugh Ross of Reasons to Believe, a proponent of Old Earth creationism, believes that the efforts of intelligent design proponents to divorce the concept from Biblical Christianity make its hypothesis too vague. In 2002, he wrote: \"Winning the argument for design without identifying the designer yields, at best, a sketchy origins model. Such a model makes little if any positive impact on the community of scientists and other scholars. [...] ...the time is right for a direct approach, a single leap into the origins fray. Introducing a biblically based, scientifically verifiable creation model represents such a leap.\"\n\nLikewise, two of the most prominent YEC organizations in the world have attempted to distinguish their views from those of the intelligent design movement. Henry M. Morris of the Institute for Creation Research (ICR) wrote, in 1999, that ID, \"even if well-meaning and effectively articulated, will not work! It has often been tried in the past and has failed, and it will fail today. The reason it won't work is because it is not the Biblical method.\" According to Morris: \"The evidence of intelligent design ... must be either followed by or accompanied by a sound presentation of true Biblical creationism if it is to be meaningful and lasting.\" In 2002, Carl Wieland, then of Answers in Genesis (AiG), criticized design advocates who, though well-intentioned, \"'left the Bible out of it'\" and thereby unwittingly aided and abetted the modern rejection of the Bible. Wieland explained that \"AiG's major 'strategy' is to boldly, but humbly, call the church back to its Biblical foundations ... [so] we neither count ourselves a part of this movement nor campaign against it.\"\n\nThe unequivocal consensus in the scientific community is that intelligent design is not science and has no place in a science curriculum. The U.S. National Academy of Sciences has stated that \"creationism, intelligent design, and other claims of supernatural intervention in the origin of life or of species are not science because they are not testable by the methods of science.\" The U.S. National Science Teachers Association and the American Association for the Advancement of Science have termed it pseudoscience. Others in the scientific community have denounced its tactics, accusing the ID movement of manufacturing false attacks against evolution, of engaging in misinformation and misrepresentation about science, and marginalizing those who teach it. More recently, in September 2012, Bill Nye warned that creationist views threaten science education and innovations in the United States.\n\nIn 2001, the Discovery Institute published advertisements under the heading \"A Scientific Dissent From Darwinism\", with the claim that listed scientists had signed this statement expressing skepticism:\n\nThe ambiguous statement did not exclude other known evolutionary mechanisms, and most signatories were not scientists in relevant fields, but starting in 2004 the Institute claimed the increasing number of signatures indicated mounting doubts about evolution among scientists. The statement formed a key component of Discovery Institute campaigns to present intelligent design as scientifically valid by claiming that evolution lacks broad scientific support, with Institute members continued to cite the list through at least 2011. As part of a strategy to counter these claims, scientists organised Project Steve, which gained more signatories named Steve (or variants) than the Institute's petition, and a counter-petition, \"A Scientific Support for Darwinism\", which quickly gained similar numbers of signatories.\n\nSeveral surveys were conducted prior to the December 2005 decision in \"Kitzmiller v. Dover School District\", which sought to determine the level of support for intelligent design among certain groups. According to a 2005 Harris poll, 10% of adults in the United States viewed human beings as \"so complex that they required a powerful force or intelligent being to help create them.\" Although Zogby polls commissioned by the Discovery Institute show more support, these polls suffer from considerable flaws, such as having a very low response rate (248 out of 16,000), being conducted on behalf of an organization with an expressed interest in the outcome of the poll, and containing leading questions.\n\nThe 2017 Gallup creationism survey found that 38% of adults in the United States hold the view that \"God created humans in their present form at one time within the last 10,000 years\" when asked for their views on the origin and development of human beings, which was noted as being at the lowest level in 35 years. Previously, a series of Gallup polls in the United States from 1982 through 2014 on \"Evolution, Creationism, Intelligent Design\" found support for \"human beings have developed over millions of years from less advanced formed of life, but God guided the process\" of between 31% and 40%, support for \"God created human beings in pretty much their present form at one time within the last 10,000 years or so\" varied from 40% to 47%, and support for \"human beings have developed over millions of years from less advanced forms of life, but God had no part in the process\" varied from 9% to 19%. The polls also noted answers to a series of more detailed questions.\n\nThere have been allegations that ID proponents have met discrimination, such as being refused tenure or being harshly criticized on the Internet. In the documentary film \"\", released in 2008, host Ben Stein presents five such cases. The film contends that the mainstream science establishment, in a \"scientific conspiracy to keep God out of the nation's laboratories and classrooms\", suppresses academics who believe they see evidence of intelligent design in nature or criticize evidence of evolution. Investigation into these allegations turned up alternative explanations for perceived persecution.\n\nThe film portrays intelligent design as motivated by science, rather than religion, though it does not give a detailed definition of the phrase or attempt to explain it on a scientific level. Other than briefly addressing issues of irreducible complexity, \"Expelled\" examines it as a political issue. The scientific theory of evolution is portrayed by the film as contributing to fascism, the Holocaust, communism, atheism, and eugenics.\n\n\"Expelled\" has been used in private screenings to legislators as part of the Discovery Institute intelligent design campaign for Academic Freedom bills. Review screenings were restricted to churches and Christian groups, and at a special pre-release showing, one of the interviewees, PZ Myers, was refused admission. The American Association for the Advancement of Science describes the film as dishonest and divisive propaganda aimed at introducing religious ideas into public school science classrooms, and the Anti-Defamation League has denounced the film's allegation that evolutionary theory influenced the Holocaust. The film includes interviews with scientists and academics who were misled into taking part by misrepresentation of the topic and title of the film. Skeptic Michael Shermer describes his experience of being repeatedly asked the same question without context as \"surreal\".\n\nAdvocates of intelligent design seek to keep God and the Bible out of the discussion, and present intelligent design in the language of science as though it were a scientific hypothesis. For a theory to qualify as scientific, it is expected to be:\n\nBULLET::::- Consistent\nBULLET::::- Parsimonious (sparing in its proposed entities or explanations; see Occam's razor)\nBULLET::::- Useful (describes and explains observed phenomena, and can be used in a predictive manner)\nBULLET::::- Empirically testable and falsifiable (potentially confirmable or disprovable by experiment or observation)\nBULLET::::- Based on multiple observations (often in the form of controlled, repeated experiments)\nBULLET::::- Correctable and dynamic (modified in the light of observations that do not support it)\nBULLET::::- Progressive (refines previous theories)\nBULLET::::- Provisional or tentative (is open to experimental checking, and does not assert certainty)\n\nFor any theory, hypothesis, or conjecture to be considered scientific, it must meet most, and ideally all, of these criteria. The fewer criteria are met, the less scientific it is; if it meets only a few or none at all, then it cannot be treated as scientific in any meaningful sense of the word. Typical objections to defining intelligent design as science are that it lacks consistency, violates the principle of parsimony, is not scientifically useful, is not falsifiable, is not empirically testable, and is not correctable, dynamic, progressive, or provisional.\n\nIntelligent design proponents seek to change this fundamental basis of science by eliminating \"methodological naturalism\" from science and replacing it with what the leader of the intelligent design movement, Phillip E. Johnson, calls \"theistic realism\". Intelligent design proponents argue that naturalistic explanations fail to explain certain phenomena and that supernatural explanations provide a very simple and intuitive explanation for the origins of life and the universe. Many intelligent design followers believe that \"scientism\" is itself a religion that promotes secularism and materialism in an attempt to erase theism from public life, and they view their work in the promotion of intelligent design as a way to return religion to a central role in education and other public spheres.\n\nIt has been argued that methodological naturalism is not an \"assumption\" of science, but a \"result\" of science well done: the God explanation is the least parsimonious, so according to Occam's razor, it cannot be a scientific explanation.\n\nThe failure to follow the procedures of scientific discourse and the failure to submit work to the scientific community that withstands scrutiny have weighed against intelligent design being accepted as valid science. The intelligent design movement has not published a properly peer-reviewed article supporting ID in a scientific journal, and has failed to publish supporting peer-reviewed research or data. The only article published in a peer-reviewed scientific journal that made a case for intelligent design was quickly withdrawn by the publisher for having circumvented the journal's peer-review standards. The Discovery Institute says that a number of intelligent design articles have been published in peer-reviewed journals, but critics, largely members of the scientific community, reject this claim and state intelligent design proponents have set up their own journals with peer review that lack impartiality and rigor, consisting entirely of intelligent design supporters.\n\nFurther criticism stems from the fact that the phrase \"intelligent\" design makes use of an assumption of the quality of an observable intelligence, a concept that has no scientific consensus definition. The characteristics of intelligence are assumed by intelligent design proponents to be observable without specifying what the criteria for the measurement of intelligence should be. Critics say that the design detection methods proposed by intelligent design proponents are radically different from conventional design detection, undermining the key elements that make it possible as legitimate science. Intelligent design proponents, they say, are proposing both searching for a designer without knowing anything about that designer's abilities, parameters, or intentions (which scientists do know when searching for the results of human intelligence), as well as denying the very distinction between natural/artificial design that allows scientists to compare complex designed artifacts against the background of the sorts of complexity found in nature.\n\nAmong a significant proportion of the general public in the United States, the major concern is whether conventional evolutionary biology is compatible with belief in God and in the Bible, and how this issue is taught in schools. The Discovery Institute's \"Teach the Controversy\" campaign promotes intelligent design while attempting to discredit evolution in United States public high school science courses. The scientific community and science education organizations have replied that there is no scientific controversy regarding the validity of evolution and that the controversy exists solely in terms of religion and politics.\n\nEugenie C. Scott, along with Glenn Branch and other critics, has argued that many points raised by intelligent design proponents are arguments from ignorance.\nIn the argument from ignorance, a lack of evidence for one view is erroneously argued to constitute proof of the correctness of another view. Scott and Branch say that intelligent design is an argument from ignorance because it relies on a lack of knowledge for its conclusion: lacking a natural explanation for certain specific aspects of evolution, we assume intelligent cause. They contend most scientists would reply that the unexplained is not unexplainable, and that \"we don't know yet\" is a more appropriate response than invoking a cause outside science. Particularly, Michael Behe's demands for ever more detailed explanations of the historical evolution of molecular systems seem to assume a false dichotomy, where either evolution or design is the proper explanation, and any perceived failure of evolution becomes a victory for design. Scott and Branch also contend that the supposedly novel contributions proposed by intelligent design proponents have not served as the basis for any productive scientific research.\n\nIn his conclusion to the Kitzmiller trial, Judge John E. Jones III wrote that \"ID is at bottom premised upon a false dichotomy, namely, that to the extent evolutionary theory is discredited, ID is confirmed.\" This same argument had been put forward to support creation science at the \"McLean v. Arkansas\" (1982) trial, which found it was \"contrived dualism\", the false premise of a \"two model approach\". Behe's argument of irreducible complexity puts forward negative arguments against evolution but does not make any positive scientific case for intelligent design. It fails to allow for scientific explanations continuing to be found, as has been the case with several examples previously put forward as supposed cases of irreducible complexity.\n\nIntelligent design proponents often insist that their claims do not require a religious component. However, various philosophical and theological issues are naturally raised by the claims of intelligent design.\n\nIntelligent design proponents attempt to demonstrate scientifically that features such as irreducible complexity and specified complexity could not arise through natural processes, and therefore required repeated direct miraculous interventions by a Designer (often a Christian concept of God). They reject the possibility of a Designer who works merely through setting natural laws in motion at the outset, in contrast to theistic evolution (to which even Charles Darwin was open). Intelligent design is distinct because it asserts repeated miraculous interventions in addition to designed laws. This contrasts with other major religious traditions of a created world in which God's interactions and influences do not work in the same way as physical causes. The Roman Catholic tradition makes a careful distinction between ultimate metaphysical explanations and secondary, natural causes.\n\nThe concept of direct miraculous intervention raises other potential theological implications. If such a Designer does not intervene to alleviate suffering even though capable of intervening for other reasons, some imply the designer is not omnibenevolent (see problem of evil and related theodicy).\n\nFurther, repeated interventions imply that the original design was not perfect and final, and thus pose a problem for any who believe that the Creator's work had been both perfect and final. Intelligent design proponents seek to explain the problem of poor design in nature by insisting that we have simply failed to understand the perfection of the design (for example, proposing that vestigial organs have unknown purposes), or by proposing that designers do not necessarily produce the best design they can, and may have unknowable motives for their actions.\n\nIn 2005 the director of the Vatican Observatory, the Jesuit astronomer George Coyne, set out theological reasons for accepting evolution in an August 2005 article in \"The Tablet\", and said that \"Intelligent design isn't science even though it pretends to be\". It should not be included in the science curriculum for public schools. \"If you want to teach it in schools, intelligent design should be taught when religion or cultural history is taught, not science.\" In 2006, he \"condemned ID as a kind of ‘crude creationism’ which reduced God to a mere engineer.\"\n\nIntelligent design has also been characterized as a God-of-the-gaps argument, which has the following form:\nBULLET::::- There is a gap in scientific knowledge.\nBULLET::::- The gap is filled with acts of God (or intelligent designer) and therefore proves the existence of God (or intelligent designer).\n\nA God-of-the-gaps argument is the theological version of an argument from ignorance. A key feature of this type of argument is that it merely answers outstanding questions with explanations (often supernatural) that are unverifiable and ultimately themselves subject to unanswerable questions. Historians of science observe that the astronomy of the earliest civilizations, although astonishing and incorporating mathematical constructions far in excess of any practical value, proved to be misdirected and of little importance to the development of science because they failed to inquire more carefully into the mechanisms that drove the heavenly bodies across the sky. It was the Greek civilization that first practiced science, although not yet as a formally defined experimental science, but nevertheless an attempt to rationalize the world of natural experience without recourse to divine intervention. In this historically motivated definition of science any appeal to an intelligent creator is explicitly excluded for the paralysing effect it may have on scientific progress.\n\n\"Kitzmiller v. Dover Area School District\" was the first direct challenge brought in the United States federal courts against a public school district that required the presentation of intelligent design as an alternative to evolution. The plaintiffs successfully argued that intelligent design is a form of creationism, and that the school board policy thus violated the Establishment Clause of the First Amendment to the United States Constitution.\n\nEleven parents of students in Dover, Pennsylvania, sued the Dover Area School District over a statement that the school board required be read aloud in ninth-grade science classes when evolution was taught. The plaintiffs were represented by the American Civil Liberties Union (ACLU), Americans United for Separation of Church and State (AU) and Pepper Hamilton LLP. The National Center for Science Education acted as consultants for the plaintiffs. The defendants were represented by the Thomas More Law Center. The suit was tried in a bench trial from September 26 to November 4, 2005, before Judge John E. Jones III. Kenneth R. Miller, Kevin Padian, Brian Alters, Robert T. Pennock, Barbara Forrest and John F. Haught served as expert witnesses for the plaintiffs. Michael Behe, Steve Fuller and Scott Minnich served as expert witnesses for the defense.\n\nOn December 20, 2005, Judge Jones issued his 139-page findings of fact and decision, ruling that the Dover mandate was unconstitutional, and barring intelligent design from being taught in Pennsylvania's Middle District public school science classrooms. On November 8, 2005, there had been an election in which the eight Dover school board members who voted for the intelligent design requirement were all defeated by challengers who opposed the teaching of intelligent design in a science class, and the current school board president stated that the board did not intend to appeal the ruling.\n\nIn his finding of facts, Judge Jones made the following condemnation of the \"Teach the Controversy\" strategy:\n\nJudge Jones himself anticipated that his ruling would be criticized, saying in his decision that:\n\nAs Jones had predicted, John G. West, Associate Director of the Center for Science and Culture, said:\n\nNewspapers have noted that the judge is \"a Republican and a churchgoer\".\n\nThe decision has been examined in a search for flaws and conclusions, partly by intelligent design supporters aiming to avoid future defeats in court. In its Winter issue of 2007, the \"Montana Law Review\" published three articles.\nIn the first, David K. DeWolf, John G. West and Casey Luskin, all of the Discovery Institute, argued that intelligent design is a valid scientific theory, the Jones court should not have addressed the question of whether it was a scientific theory, and that the Kitzmiller decision will have no effect at all on the development and adoption of intelligent design as an alternative to standard evolutionary theory. In the second Peter H. Irons responded, arguing that the decision was extremely well reasoned and spells the death knell for the intelligent design efforts to introduce creationism in public schools, while in the third, DeWolf, \"et al.\", answer the points made by Irons. However, fear of a similar lawsuit has resulted in other school boards abandoning intelligent design \"teach the controversy\" proposals.\n\nA number of anti-evolution bills have been introduced in the United States Congress and State legislatures since 2001, based largely upon language drafted by the Discovery Institute for the Santorum Amendment. Their aim has been to expose more students to articles and videos produced by advocates of intelligent design that criticise evolution. They have been presented as supporting \"academic freedom\", on the supposition that teachers, students, and college professors face intimidation and retaliation when discussing scientific criticisms of evolution, and therefore require protection. Critics of the legislation have pointed out that there are no credible scientific critiques of evolution, and an investigation in Florida of allegations of intimidation and retaliation found no evidence that it had occurred. The vast majority of the bills have been unsuccessful, with the one exception being Louisiana's Louisiana Science Education Act, which was enacted in 2008.\n\nIn April 2010, the American Academy of Religion issued \"Guidelines for Teaching About Religion in K‐12 Public Schools in the United States\", which included guidance that creation science or intelligent design should not be taught in science classes, as \"Creation science and intelligent design represent worldviews that fall outside of the realm of science that is defined as (and limited to) a method of inquiry based on gathering observable and measurable evidence subject to specific principles of reasoning.\" However, these worldviews as well as others \"that focus on speculation regarding the origins of life represent another important and relevant form of human inquiry that is appropriately studied in literature or social sciences courses. Such study, however, must include a diversity of worldviews representing a variety of religious and philosophical perspectives and must avoid privileging one view as more legitimate than others.\"\n\nIn June 2007, the Council of Europe's Committee on Culture, Science and Education issued a report, \"The dangers of creationism in education\", which states \"Creationism in any of its forms, such as 'intelligent design', is not based on facts, does not use any scientific reasoning and its contents are pathetically inadequate for science classes.\" In describing the dangers posed to education by teaching creationism, it described intelligent design as \"anti-science\" and involving \"blatant scientific fraud\" and \"intellectual deception\" that \"blurs the nature, objectives and limits of science\" and links it and other forms of creationism to denialism. On October 4, 2007, the Council of Europe's Parliamentary Assembly approved a resolution stating that schools should \"resist presentation of creationist ideas in any discipline other than religion\", including \"intelligent design\", which it described as \"the latest, more refined version of creationism\", \"presented in a more subtle way\". The resolution emphasises that the aim of the report is not to question or to fight a belief, but to \"warn against certain tendencies to pass off a belief as science\".\n\nIn the United Kingdom, public education includes religious education as a compulsory subject, and there are many faith schools that teach the ethos of particular denominations. When it was revealed that a group called Truth in Science had distributed DVDs produced by Illustra Media featuring Discovery Institute fellows making the case for design in nature, and claimed they were being used by 59 schools, the Department for Education and Skills (DfES) stated that \"Neither creationism nor intelligent design are taught as a subject in schools, and are not specified in the science curriculum\" (part of the National Curriculum, which does not apply to independent schools or to education in Scotland). The DfES subsequently stated that \"Intelligent design is not a recognised scientific theory; therefore, it is not included in the science curriculum\", but left the way open for it to be explored in religious education in relation to different beliefs, as part of a syllabus set by a local Standing Advisory Council on Religious Education. In 2006, the Qualifications and Curriculum Authority produced a \"Religious Education\" model unit in which pupils can learn about religious and nonreligious\nviews about creationism, intelligent design and evolution by natural selection.\n\nOn June 25, 2007, the UK Government responded to an e-petition by saying that creationism and intelligent design should not be taught as science, though teachers would be expected to answer pupils' questions within the standard framework of established scientific theories. Detailed government \"Creationism teaching guidance\" for schools in England was published on September 18, 2007. It states that \"Intelligent design lies wholly outside of science\", has no underpinning scientific principles, or explanations, and is not accepted by the science community as a whole. Though it should not be taught as science, \"Any questions about creationism and intelligent design which arise in science lessons, for example as a result of media coverage, could provide the opportunity to explain or explore why they are not considered to be scientific theories and, in the right context, why evolution is considered to be a scientific theory.\" However, \"Teachers of subjects such as RE, history or citizenship may deal with creationism and intelligent design in their lessons.\"\n\nThe British Centre for Science Education lobbying group has the goal of \"countering creationism within the UK\" and has been involved in government lobbying in the UK in this regard. Northern Ireland's Department for Education says that the curriculum provides an opportunity for alternative theories to be taught. The Democratic Unionist Party (DUP)—which has links to fundamentalist Christianity—has been campaigning to have intelligent design taught in science classes. A DUP former Member of Parliament, David Simpson, has sought assurances from the education minister that pupils will not lose marks if they give creationist or intelligent design answers to science questions. In 2007, Lisburn city council voted in favor of a DUP recommendation to write to post-primary schools asking what their plans are to develop teaching material in relation to \"creation, intelligent design and other theories of origin\".\n\nPlans by Dutch Education Minister Maria van der Hoeven to \"stimulate an academic debate\" on the subject in 2005 caused a severe public backlash. After the 2006 elections, she was succeeded by Ronald Plasterk, described as a \"molecular geneticist, staunch atheist and opponent of intelligent design\". As a reaction on this situation in the Netherlands, the Director General of the Flemish Secretariat of Catholic Education () in Belgium, , declared that: \"Catholic scientists already accepted the theory of evolution for a long time and that intelligent design and creationism doesn't belong in Flemish Catholic schools. It's not the tasks of the politics to introduce new ideas, that's task and goal of science.\"\n\nThe status of intelligent design in Australia is somewhat similar to that in the UK (see Education in Australia). In 2005, the Australian Minister for Education, Science and Training, Brendan Nelson, raised the notion of intelligent design being taught in science classes. The public outcry caused the minister to quickly concede that the correct forum for intelligent design, if it were to be taught, is in religion or philosophy classes. The Australian chapter of Campus Crusade for Christ distributed a DVD of the Discovery Institute's documentary \"Unlocking the Mystery of Life\" (2002) to Australian secondary schools. Tim Hawkes, the head of The King's School, one of Australia's leading private schools, supported use of the DVD in the classroom at the discretion of teachers and principals.\n\nMuzaffar Iqbal, a notable Pakistani-Canadian Muslim, signed \"A Scientific Dissent From Darwinism\", a petition from the Discovery Institute. Ideas similar to intelligent design have been considered respected intellectual options among Muslims, and in Turkey many intelligent design books have been translated. In Istanbul in 2007, public meetings promoting intelligent design were sponsored by the local government, and David Berlinski of the Discovery Institute was the keynote speaker at a meeting in May 2007.\n\nIn 2011, the International Society for Krishna Consciousness (ISKCON) Bhaktivedanta Book Trust published an intelligent design book titled \"Rethinking Darwin: A Vedic Study of Darwinism and Intelligent Design\". The book included contributions from intelligent design advocates William A. Dembski, Jonathan Wells and Michael Behe as well as from Hindu creationists Leif A. Jensen and Michael Cremo.\n\nBULLET::::- Abiogenesis\nBULLET::::- Buddhism and evolution\nBULLET::::- Clockwork universe\nBULLET::::- Creation and evolution in public education\nBULLET::::- Day-age creationism\nBULLET::::- Evolution as fact and theory\nBULLET::::- Gap creationism\nBULLET::::- Genetic entropy\nBULLET::::- Haldane's dilemma\nBULLET::::- Hindu views on evolution\nBULLET::::- History of evolutionary thought\nBULLET::::- History of the creation–evolution controversy\nBULLET::::- Intelligent design in politics\nBULLET::::- Intelligent design and science\nBULLET::::- Intelligent falling\nBULLET::::- International Society for Complexity, Information, and Design\nBULLET::::- Islamic views on evolution\nBULLET::::- Jainism and non-creationism\nBULLET::::- List of topics characterized as pseudoscience\nBULLET::::- List of works on intelligent design\nBULLET::::- Materialism\nBULLET::::- Modern evolutionary synthesis\nBULLET::::- Naturalism (philosophy)\nBULLET::::- Neo-creationism\nBULLET::::- Neo-Darwinism\nBULLET::::- Objections to evolution\nBULLET::::- Philosophy of science\nBULLET::::- Progressive creationism\nBULLET::::- Raëlian intelligent design\nBULLET::::- Santorum Amendment\nBULLET::::- Scientific method\nBULLET::::- Social Darwinism\nBULLET::::- Sternberg peer review controversy\nBULLET::::- \"Strengths and weaknesses of evolution\"\nBULLET::::- The eclipse of Darwinism\nBULLET::::- Unintelligent design\n\nBULLET::::- The book is available in the PDF format from The Complete Work of Charles Darwin Online.\nBULLET::::- ACLU site on Intelligent Design\nBULLET::::- \"Are There Any Important Differences between Intelligent Design and Creationism?\" (PDF) by Jason Rosenhouse for the Committee for Skeptical Inquiry, February 24, 2006\nBULLET::::- \"The Design Argument\" (PDF) by Elliott Sober, 2004\nBULLET::::- \"Design Arguments for the Existence of God\" An entry in the \"Internet Encyclopedia of Philosophy\" (), founded by James Fieser\nBULLET::::- \"Intelligent Design?\" Special report prepared by Richard Milner and Vittorio Maestro for \"Natural History\" magazine\nBULLET::::- \"Kitzmiller: An Intelligent Ruling on 'Intelligent Design'\" by JURIST guest columnist Stephen G. Gey, December 29, 2005\nBULLET::::- \"Kitzmiller v. Dover Area School District\" (PDF) A 139-page in-depth opinion of intelligent design, irreducible complexity, and the book \"Of Pandas and People\" by U.S. District Judge John E. Jones III\nBULLET::::- \"Natural 'Knowledge' and Natural 'Design'\" by Richard Dawkins, May 15, 2006\nBULLET::::- TalkOrigins Archive Archive of the Usenet discussion group talk.origins\nBULLET::::- Texas Citizens for Science\nBULLET::::- \"What Is Intelligent Design Creationism?\" National Center for Science Education, October 17, 2008\n"}
{"id": "15302", "url": "https://en.wikipedia.org/wiki?curid=15302", "title": "Integrin", "text": "Integrin\n\nIntegrins are transmembrane receptors that facilitate cell-extracellular matrix (ECM) adhesion. Upon ligand binding, integrins activate signal transduction pathways that mediate cellular signals such as regulation of the cell cycle, organization of the intracellular cytoskeleton, and movement of new receptors to the cell membrane. The presence of integrins allows rapid and flexible responses to events at the cell surface (\"e.g\". signal platelets to initiate an interaction with coagulation factors).\n\nSeveral types of integrins exist, and one cell may have multiple different types on its surface. Integrins are found in all animals while integrin-like receptors are found in plant cells.\n\nIntegrins work alongside other receptors such as cadherins, the immunoglobulin superfamily cell adhesion molecules, selectins and syndecans, to mediate cell–cell and cell–matrix interaction. Ligands for integrins include fibronectin, vitronectin, collagen and laminin.\n\nIntegrins are obligate heterodimers, meaning that they have two subunits: α (alpha) and β (beta). Integrins in mammals have eighteen α and eight β subunits, in \"Drosophila\" five α and two β subunits, and in \"Caenorhabditis\" nematodes two α subunits and one β subunit. The α and β subunits each penetrate the plasma membrane and possess several cytoplasmic domains.\n\n+ alpha \n! gene\n! protein\n! synonyms\n\n+ beta \n! gene\n! protein\n! synonyms\n\nVariants of some subunits are formed by differential RNA splicing; for example, four variants of the beta-1 subunit exist. Through different combinations of the α and β subunits, around 24 unique integrins are generated.\n\nIntegrin subunits span the cell membrane and have short cytoplasmic domains of 40–70 amino acids. The exception is the beta-4 subunit, which has a cytoplasmic domain of 1,088 amino acids, one of the largest of any membrane protein. Outside the cell membrane, the α and β chains lie close together along a length of about 23 nm; the final 5 nm N-termini of each chain forms a ligand-binding region for the ECM. They have been compared to lobster claws, although they don't actually \"pinch\" their ligand, they chemically interact with it at the insides of the \"tips\" of their \"pinchers\".\n\nThe molecular mass of the integrin subunits can vary from 90 kDa to 160 kDa. Beta subunits have four cysteine-rich repeated sequences. Both α and β subunits bind several divalent cations. The role of divalent cations in the α subunit is unknown, but may stabilize the folds of the protein. The cations in the β subunits are more interesting: they are directly involved in coordinating at least some of the ligands that integrins bind.\n\nIntegrins can be categorized in multiple ways. For example, some α chains have an additional structural element (or \"domain\") inserted toward the N-terminal, the alpha-A domain (so called because it has a similar structure to the A-domains found in the protein von Willebrand factor; it is also termed the α-I domain). Integrins carrying this domain either bind to collagens (e.g. integrins α1 β1, and α2 β1), or act as cell-cell adhesion molecules (integrins of the β2 family). This α-I domain is the binding site for ligands of such integrins. Those integrins that don't carry this inserted domain also have an A-domain in their ligand binding site, but \"this\" A-domain is found on the β subunit.\n\nIn both cases, the A-domains carry up to three divalent cation binding sites. One is permanently occupied in physiological concentrations of divalent cations, and carries either a calcium or magnesium ion, the principal divalent cations in blood at median concentrations of 1.4 mM (calcium) and 0.8 mM (magnesium). The other two sites become occupied by cations when ligands bind—at least for those ligands involving an acidic amino acid in their interaction sites. An acidic amino acid features in the integrin-interaction site of many ECM proteins, for example as part of the amino acid sequence Arginine-Glycine-Aspartic acid (\"RGD\" in the one-letter amino acid code).\n\nDespite many years of effort, discovering the high-resolution structure of integrins proved to be challenging, as membrane proteins are classically difficult to purify, and as integrins are large, complex and linked to many sugar trees (\"highly glycosylated\"). Low-resolution images of detergent extracts of intact integrin GPIIbIIIa, obtained using electron microscopy, and even data from indirect techniques that investigate the solution properties of integrins using ultracentrifugation and light scattering, were combined with fragmentary high-resolution crystallographic or NMR data from single or paired domains of single integrin chains, and molecular models postulated for the rest of the chains.\n\nThe X-ray crystal structure obtained for the complete extracellular region of one integrin, αvβ3, shows the molecule to be folded into an inverted V-shape that potentially brings the ligand-binding sites close to the cell membrane. Perhaps more importantly, the crystal structure was also obtained for the same integrin bound to a small ligand containing the RGD-sequence, the drug cilengitide. As detailed above, this finally revealed why divalent cations (in the A-domains) are critical for RGD-ligand binding to integrins. The interaction of such sequences with integrins is believed to be a primary switch by which ECM exerts its effects on cell behaviour.\n\nThe structure poses many questions, especially regarding ligand binding and signal transduction. The ligand binding site is directed towards the C-terminal of the integrin, the region where the molecule emerges from the cell membrane. If it emerges orthogonally from the membrane, the ligand binding site would apparently be obstructed, especially as integrin ligands are typically massive and well cross-linked components of the ECM. In fact, little is known about the angle that membrane proteins subtend to the plane of the membrane; this is a problem difficult to address with available technologies. The default assumption is that they emerge rather like little lollipops, but the evidence for this sweet supposition is noticeable by its absence. The integrin structure has drawn attention to this problem, which may have general implications for how membrane proteins work. It appears that the integrin transmembrane helices are tilted (see \"Activation\" below), which hints that the extracellular chains may also not be orthogonal with respect to the membrane surface.\n\nAlthough the crystal structure changed surprisingly little after binding to cilengitide, the current hypothesis is that integrin function involves changes in shape to move the ligand-binding site into a more accessible position, away from the cell surface, and this shape change also triggers intracellular signaling. There is a wide body of cell-biological and biochemical literature that supports this view. Perhaps the most convincing evidence involves the use of antibodies that only recognize integrins when they have bound to their ligands, or are activated. As the \"footprint\" that an antibody makes on its binding target is roughly a circle about 3 nm in diameter, the resolution of this technique is low. Nevertheless, these so-called LIBS (Ligand-Induced-Binding-Sites) antibodies unequivocally show that dramatic changes in integrin shape routinely occur. However, how the changes detected with antibodies look on the structure is still unknown.\n\nWhen released into the cell membrane, newly synthesized integrin dimers are speculated to be found in the same \"bent\" conformation revealed by the structural studies described above. One school of thought claims that this bent form prevents them from interacting with their ligands, although bent forms can predominate in high-resolution EM structures of integrin bound to an ECM ligand. Therefore, at least in biochemical experiments, integrin dimers must apparently not be 'unbent' in order to prime them and allow their binding to the ECM. In cells, the priming is accomplished by a protein talin, which binds to the β tail of the integrin dimer and changes its conformation. The α and β integrin chains are both class-I transmembrane proteins: they pass the plasma membrane as single transmembrane alpha-helices. Unfortunately, the helices are too long, and recent studies suggest that, for integrin gpIIbIIIa, they are tilted with respect both to one another and to the plane of the membrane. Talin binding alters the angle of tilt of the β3 chain transmembrane helix in model systems and this may reflect a stage in the process of inside-out signalling which primes integrins. Moreover, talin proteins are able to dimerize and thus are thought to intervene in the clustering of integrin dimers which leads to the formation of a focal adhesion. Recently, the Kindlin-1 and Kindlin-2 proteins have also been found to interact with integrin and activate it.\n\nIntegrins have two main functions, attachment of the cells to the ECM and signal transduction from the ECM to the cells. They are also involved in a wide range of other biological activities, including extravasation, cell-to-cell adhesion, cell migration, and as receptors for certain viruses, such as adenovirus, echovirus, hantavirus, and foot-and-mouth disease viruses.\n\nA prominent function of the integrins is seen in the molecule GpIIb/IIIa, an integrin on the surface of blood platelets (thrombocytes) responsible for attachment to fibrin within a developing blood clot. This molecule dramatically increases its binding affinity for fibrin/fibrinogen through association of platelets with exposed collagens in the wound site. Upon association of platelets with collagen, GPIIb/IIIa changes shape, allowing it to bind to fibrin and other blood components to form the clot matrix and stop blood loss.\n\nIntegrins couple the ECM outside a cell to the cytoskeleton (in particular, the microfilaments) inside the cell. Which ligand in the ECM the integrin can bind to is defined by which α and β subunits the integrin is made of. Among the ligands of integrins are fibronectin, vitronectin, collagen, and laminin. The connection between the cell and the ECM may help the cell to endure pulling forces without being ripped out of the ECM. The ability of a cell to create this kind of bond is also of vital importance in ontogeny.\n\nCell attachment to the ECM is a basic requirement to build a multicellular organism. Integrins are not simply hooks, but give the cell critical signals about the nature of its surroundings. Together with signals arising from receptors for soluble growth factors like VEGF, EGF, and many others, they enforce a cellular decision on what biological action to take, be it attachment, movement, death, or differentiation. Thus integrins lie at the heart of many cellular biological processes. The attachment of the cell takes place through formation of cell adhesion complexes, which consist of integrins and many cytoplasmic proteins, such as talin, vinculin, paxillin, and alpha-actinin. These act by regulating kinases such as FAK (focal adhesion kinase) and Src kinase family members to phosphorylate substrates such as p130CAS thereby recruiting signaling adaptors such as CRK. These adhesion complexes attach to the actin cytoskeleton. The integrins thus serve to link two networks across the plasma membrane: the extracellular ECM and the intracellular actin filamentous system. Integrin α6β4 is an exception: it links to the keratin intermediate filament system in epithelial cells.\n\nFocal adhesions are large molecular complexes, which are generated following interaction of integrins with ECM, then their clustering. The clusters likely provide sufficient intracellular binding sites to permit the formation of stable signaling complexes on the cytoplasmic side of the cell membrane. So the focal adhesions contain integrin ligand, integrin molecule, and associate plaque proteins. Binding is propelled by changes in free energy. As previously stated, these complexes connect the extracellular matrix to actin bundles. Cryo-electron tomography reveals that the adhesion contains particles on the cell membrane with diameter of 25 +/- 5 nm and spaced at approximately 45 nm. Treatment with Rho-kinase inhibitor Y-27632 reduces the size of the particle, and it is extremely mechanosensitive.\n\nOne important function of integrins on cells in tissue culture is their role in cell migration. Cells adhere to a substrate through their integrins. During movement, the cell makes new attachments to the substrate at its front and concurrently releases those at its rear. When released from the substrate, integrin molecules are taken back into the cell by endocytosis; they are transported through the cell to its front by the endocytic cycle, where they are added back to the surface. In this way they are cycled for reuse, enabling the cell to make fresh attachments at its leading front. It is not yet clear whether cell migration in tissue culture is an artefact of integrin processing, or whether such integrin-dependent cell migration also occurs in living organisms.\n\nIntegrins play an important role in cell signaling by modulating the cell signaling pathways of transmembrane protein kinases such as receptor tyrosine kinases (RTK). While the interaction between integrin and receptor tyrosine kinases originally was thought of as uni-directional and supportive, recent studies indicate that integrins have additional, multi-faceted roles in cell signaling. \nIntegrins can regulate the receptor tyrosine kinase signaling by recruiting specific adaptors to the plasma membrane. For example, β1c integrin recruits Gab1/Shp2 and presents Shp2 to IGF1R, resulting in dephosphorylation of the receptor. In a reverse direction, when a receptor tyrosine kinase is activated, integrins co-localise at focal adhesion with the receptor tyrosine kinases and their associated signaling molecules.\n\nThe repertoire of integrins expressed on a particular cell can specify the signaling pathway due to the differential binding affinity of ECM ligands for the integrins. The tissue stiffness and matrix composition can initiate specific signaling pathways regulating cell behavior. Clustering and activation of the integrins/actin complexes strengthen the focal adhesion interaction and initiate the framework for cell signaling through assembly of adhesomes.\n\nDepending on the integrin's regulatory impact on specific receptor tyrosine kinases, the cell can experience:\nBULLET::::- cell growth,\nBULLET::::- cell division,\nBULLET::::- cell survival,\nBULLET::::- cellular differentiation, and\nBULLET::::- apoptosis (programmed cell death).\n\nKnowledge of the relationship between integrins and receptor tyrosine kinase has laid a foundation for new approaches to cancer therapy. Specifically, targeting integrins associated with RTKs is an emerging approach for inhibiting angiogenesis.\n\nIntegrins have an important function in neuroregeneration after injury of the peripheral nervous system (PNS). Integrins are present at the growth cone of damaged PNS neurons and attach to ligands in the ECM to promote axon regeneration. It is unclear whether integrins can promote axon regeneration in the adult central nervous system (CNS). There are two obstacles that prevent integrin-mediated regeneration in the CNS: 1) integrins are not localised in the axon of most adult CNS neurons and 2) integrins become inactivated by molecules in the scar tissue after injury.\n\nThe following are 16 of the ~24 integrins found in vertebrates:\n\nBeta-1 integrins interact with many alpha integrin chains. Gene knockouts of integrins in mice are not always lethal, which suggests that during embryonal development, one integrin may substitute its function for another in order to allow survival. Some integrins are on the cell surface in an inactive state, and can be rapidly primed, or put into a state capable of binding their ligands, by cytokines. Integrins can assume several different well-defined shapes or \"conformational states\". Once primed, the conformational state changes to stimulate ligand binding, which then activates the receptors — also by inducing a shape change — to trigger outside-in signal transduction.\n\nBULLET::::- Talin substrate for calpain – PMAP The Proteolysis Map animation.\n"}
{"id": "15303", "url": "https://en.wikipedia.org/wiki?curid=15303", "title": "Ion channel", "text": "Ion channel\n\nIon channels are pore-forming membrane proteins that allow ions to pass through the channel pore. Their functions include establishing a resting membrane potential, shaping action potentials and other electrical signals by gating the flow of ions across the cell membrane, controlling the flow of ions across secretory and epithelial cells, and regulating cell volume. Ion channels are present in the membranes of all excitable cells. Ion channels are one of the two classes of ionophoric proteins, the other being ion transporters.\n\nThe study of ion channels often involves biophysics, electrophysiology, and pharmacology, while using techniques including voltage clamp, patch clamp, immunohistochemistry, X-ray crystallography, fluoroscopy, and RT-PCR. Their classification as molecules is referred to as channelomics.\n\nThere are two distinctive features of ion channels that differentiate them from other types of ion transporter proteins:\nBULLET::::1. The rate of ion transport through the channel is very high (often 10 ions per second or greater).\nBULLET::::2. Ions pass through channels down their electrochemical gradient, which is a function of ion concentration and membrane potential, \"downhill\", without the input (or help) of metabolic energy (e.g. ATP, co-transport mechanisms, or active transport mechanisms).\nIon channels are located within the membrane of all excitable cells, and of many intracellular organelles. They are often described as narrow, water-filled tunnels that allow only ions of a certain size and/or charge to pass through. This characteristic is called selective permeability. The archetypal channel pore is just one or two atoms wide at its narrowest point and is selective for specific species of ion, such as sodium or potassium. However, some channels may be permeable to the passage of more than one type of ion, typically sharing a common charge: positive (cations) or negative (anions). Ions often move through the segments of the channel pore in single file nearly as quickly as the ions move through free solution. In many ion channels, passage through the pore is governed by a \"gate\", which may be opened or closed in response to chemical or electrical signals, temperature, or mechanical force.\n\nIon channels are integral membrane proteins, typically formed as assemblies of several individual proteins. Such \"multi-subunit\" assemblies usually involve a circular arrangement of identical or homologous proteins closely packed around a water-filled pore through the plane of the membrane or lipid bilayer. For most voltage-gated ion channels, the pore-forming subunit(s) are called the α subunit, while the auxiliary subunits are denoted β, γ, and so on.\n\nBecause channels underlie the nerve impulse and because \"transmitter-activated\" channels mediate conduction across the synapses, channels are especially prominent components of the nervous system. Indeed, numerous toxins that organisms have evolved for shutting down the nervous systems of predators and prey (e.g., the venoms produced by spiders, scorpions, snakes, fish, bees, sea snails, and others) work by modulating ion channel conductance and/or kinetics. In addition, ion channels are key components in a wide variety of biological processes that involve rapid changes in cells, such as cardiac, skeletal, and smooth muscle contraction, epithelial transport of nutrients and ions, T-cell activation and pancreatic beta-cell insulin release. In the search for new drugs, ion channels are a frequent target.\n\nThere are over 300 types of ion channels just in the cells of the inner ear. Ion channels may be classified by the nature of their gating, the species of ions passing through those gates, the number of gates (pores) and localization of proteins.\n\nFurther heterogeneity of ion channels arises when channels with different constitutive subunits give rise to a specific kind of current. Absence or mutation of one or more of the contributing types of channel subunits can result in loss of function and, potentially, underlie neurologic diseases.\n\nIon channels may be classified by gating, i.e. what opens and closes the channels. For example, voltage-gated ion channels open or close depending on the voltage gradient across the plasma membrane, while ligand-gated ion channels open or close depending on binding of ligands to the channel.\n\nVoltage-gated ion channels open and close in response to membrane potential.\n\nBULLET::::- Voltage-gated sodium channels: This family contains at least 9 members and is largely responsible for action potential creation and propagation. The pore-forming α subunits are very large (up to 4,000 amino acids) and consist of four homologous repeat domains (I-IV) each comprising six transmembrane segments (S1-S6) for a total of 24 transmembrane segments. The members of this family also coassemble with auxiliary β subunits, each spanning the membrane once. Both α and β subunits are extensively glycosylated.\nBULLET::::- Voltage-gated calcium channels: This family contains 10 members, though these members are known to coassemble with αδ, β, and γ subunits. These channels play an important role in both linking muscle excitation with contraction as well as neuronal excitation with transmitter release. The α subunits have an overall structural resemblance to those of the sodium channels and are equally large.\nBULLET::::- Cation channels of sperm: This small family of channels, normally referred to as Catsper channels, is related to the two-pore channels and distantly related to TRP channels.\nBULLET::::- Voltage-gated potassium channels (K): This family contains almost 40 members, which are further divided into 12 subfamilies. These channels are known mainly for their role in repolarizing the cell membrane following action potentials. The α subunits have six transmembrane segments, homologous to a single domain of the sodium channels. Correspondingly, they assemble as tetramers to produce a functioning channel.\nBULLET::::- Some transient receptor potential channels: This group of channels, normally referred to simply as TRP channels, is named after their role in Drosophila phototransduction. This family, containing at least 28 members, is incredibly diverse in its method of activation. Some TRP channels seem to be constitutively open, while others are gated by voltage, intracellular Ca, pH, redox state, osmolarity, and mechanical stretch. These channels also vary according to the ion(s) they pass, some being selective for Ca while others are less selective, acting as cation channels. This family is subdivided into 6 subfamilies based on homology: classical (TRPC), vanilloid receptors (TRPV), melastatin (TRPM), polycystins (TRPP), mucolipins (TRPML), and ankyrin transmembrane protein 1 (TRPA).\nBULLET::::- Hyperpolarization-activated cyclic nucleotide-gated channels: The opening of these channels is due to hyperpolarization rather than the depolarization required for other cyclic nucleotide-gated channels. These channels are also sensitive to the cyclic nucleotides cAMP and cGMP, which alter the voltage sensitivity of the channel's opening. These channels are permeable to the monovalent cations K and Na. There are 4 members of this family, all of which form tetramers of six-transmembrane α subunits. As these channels open under hyperpolarizing conditions, they function as pacemaking channels in the heart, particularly the SA node.\nBULLET::::- Voltage-gated proton channels: Voltage-gated proton channels open with depolarization, but in a strongly pH-sensitive manner. The result is that these channels open only when the electrochemical gradient is outward, such that their opening will only allow protons to leave cells. Their function thus appears to be acid extrusion from cells. Another important function occurs in phagocytes (e.g. eosinophils, neutrophils, macrophages) during the \"respiratory burst.\" When bacteria or other microbes are engulfed by phagocytes, the enzyme NADPH oxidase assembles in the membrane and begins to produce reactive oxygen species (ROS) that help kill bacteria. NADPH oxidase is electrogenic, moving electrons across the membrane, and proton channels open to allow proton flux to balance the electron movement electrically.\n\nAlso known as ionotropic receptors, this group of channels open in response to specific ligand molecules binding to the extracellular domain of the receptor protein. Ligand binding causes a conformational change in the structure of the channel protein that ultimately leads to the opening of the channel gate and subsequent ion flux across the plasma membrane. Examples of such channels include the cation-permeable \"nicotinic\" Acetylcholine receptor, ionotropic glutamate-gated receptors, acid sensing ion channels (ASICs), ATP-gated P2X receptors, and the anion-permeable γ-aminobutyric acid-gated GABA receptor.\n\nIon channels activated by second messengers may also be categorized in this group, although ligands and second messengers are otherwise distinguished from each other.\n\nThis group of channels opens in response to specific lipid molecules binding to the channel's transmembrane domain typically near the inner leaflet of the plasma membrane. Phosphatidylinositol 4,5-bisphosphate (PIP) and phosphatidic acid (PA) are the best-characterized lipids to gate these channels. Many of the leak potassium channels are gated by lipids including the inward-rectifier potassium channels and two pore domain potassium channels TREK-1 and TRAAK. KCNQ potassium channel family are gated by PIP. The voltage activated potassium channel (Kv) is regulated by PA. Its midpoint of activation shifts +50 mV upon PA hydrolysis, near resting membrane potentials. This suggests Kv could be opened by lipid hydrolysis independent of voltage and may qualify this channel as dual lipid and voltage gated channel.\n\nGating also includes activation and inactivation by second messengers from the inside of the cell membrane – rather than from outside the cell, as in the case for ligands.\n\nBULLET::::- Some potassium channels:\nBULLET::::- Inward-rectifier potassium channels: These channels allow potassium ions to flow into the cell in an \"inwardly rectifying\" manner: potassium flows more efficiently into than out of the cell. This family is composed of 15 official and 1 unofficial member and is further subdivided into 7 subfamilies based on homology. These channels are affected by intracellular ATP, PIP, and G-protein βγ subunits. They are involved in important physiological processes such as pacemaker activity in the heart, insulin release, and potassium uptake in glial cells. They contain only two transmembrane segments, corresponding to the core pore-forming segments of the K and K channels. Their α subunits form tetramers.\nBULLET::::- Calcium-activated potassium channels: This family of channels is activated by intracellular Ca and contains 8 members.\nBULLET::::- Tandem pore domain potassium channel: This family of 15 members form what are known as leak channels, and they display Goldman-Hodgkin-Katz (open) rectification. Contrary to their common name of 'Two-pore-domain potassium channels', these channels have only one pore but two pore domains per subunit.\nBULLET::::- Two-pore channels include ligand-gated and voltage-gated cation channels, so-named because they contain two pore-forming subunits. As their name suggests, they have two pores.\nBULLET::::- Light-gated channels like channelrhodopsin are directly opened by photons.\nBULLET::::- Mechanosensitive ion channels open under the influence of stretch, pressure, shear, and displacement.\nBULLET::::- Cyclic nucleotide-gated channels: This superfamily of channels contains two families: the cyclic nucleotide-gated (CNG) channels and the hyperpolarization-activated, cyclic nucleotide-gated (HCN) channels. This grouping is functional rather than evolutionary.\nBULLET::::- Cyclic nucleotide-gated channels: This family of channels is characterized by activation by either intracellular cAMP or cGMP. These channels are primarily permeable to monovalent cations such as K and Na. They are also permeable to Ca, though it acts to close them. There are 6 members of this family, which is divided into 2 subfamilies.\nBULLET::::- Hyperpolarization-activated cyclic nucleotide-gated channels\nBULLET::::- Temperature-gated channels: Members of the transient receptor potential ion channel superfamily, such as TRPV1 or TRPM8, are opened either by hot or cold temperatures.\n\nBULLET::::- Chloride channels: This superfamily of channels consists of approximately 13 members. They include ClCs, CLICs, Bestrophins and CFTRs. These channels are non-selective for small anions; however chloride is the most abundant anion, and hence they are known as chloride channels.\nBULLET::::- Potassium channels\nBULLET::::- Voltage-gated potassium channels e.g., Kvs, Kirs etc.\nBULLET::::- Calcium-activated potassium channels e.g., BKCa or MaxiK, SK, etc.\nBULLET::::- Inward-rectifier potassium channels\nBULLET::::- Two-pore-domain potassium channels: This family of 15 members form what is known as leak channels, and they display Goldman-Hodgkin-Katz (open) rectification.\nBULLET::::- Sodium channels\nBULLET::::- Voltage-gated sodium channels (NaVs)\nBULLET::::- Epithelial sodium channels (ENaCs)\nBULLET::::- Calcium channels (CaVs)\nBULLET::::- Proton channels\nBULLET::::- Voltage-gated proton channels\nBULLET::::- \"Non-selective cation channels\": These non-selectively allow many types of cations, mainly Na, K and Ca, through the channel.\nBULLET::::- Most transient receptor potential channels\n\nIon channels are also classified according to their subcellular localization. The plasma membrane accounts for around 2% of the total membrane in the cell, whereas intracellular organelles contain 98% of the cell's membrane. The major intracellular compartments are endoplasmic reticulum, Golgi apparatus, and mitochondria. On the basis of localization, ion channels are classified as:\n\nBULLET::::- Plasma membrane channels\nBULLET::::- Examples: Voltage-gated potassium channels (Kv), Sodium channels (Nav), Calcium channels (Cav) and Chloride channels (ClC)\nBULLET::::- Intracellular channels, which are further classified into different organelles\nBULLET::::- Endoplasmic reticulum channels: RyR, SERCA, ORAi\nBULLET::::- Mitochondrial channels: mPTP, KATP, BK, IK, CLIC5, Kv7.4 at the inner membrane and VDAC and CLIC4 as outer membrane channels.\n\nSome ion channels are classified by the duration of their response to stimuli:\n\nBULLET::::- Transient receptor potential channels: This group of channels, normally referred to simply as TRP channels, is named after their role in \"Drosophila\" visual phototransduction. This family, containing at least 28 members, is diverse in its mechanisms of activation. Some TRP channels remain constitutively open, while others are gated by voltage, intracellular Ca, pH, redox state, osmolarity, and mechanical stretch. These channels also vary according to the ion(s) they pass, some being selective for Ca while others are less selective cation channels. This family is subdivided into 6 subfamilies based on homology: canonical TRP (TRPC), vanilloid receptors (TRPV), melastatin (TRPM), polycystins (TRPP), mucolipins (TRPML), and ankyrin transmembrane protein 1 (TRPA).\n\nChannels differ with respect to the ion they let pass (for example, Na, K, Cl), the ways in which they may be regulated, the number of subunits of which they are composed and other aspects of structure. Channels belonging to the largest class, which includes the voltage-gated channels that underlie the nerve impulse, consists of four subunits with six transmembrane helices each. On activation, these helices move about and open the pore. Two of these six helices are separated by a loop that lines the pore and is the primary determinant of ion selectivity and conductance in this channel class and some others. The existence and mechanism for ion selectivity was first postulated in the late 1960s by Bertil Hille and Clay Armstrong. The idea of the ionic selectivity for potassium channels was that the carbonyl oxygens of the protein backbones of the \"selectivity filter\" (named by Bertil Hille) could efficiently replace the water molecules that normally shield potassium ions, but that sodium ions were smaller and cannot be completely dehydrated to allow such shielding, and therefore could not pass through. This mechanism was finally confirmed when the first structure of an ion channel was elucidated. A bacterial potassium channel KcsA, consisting of just the selectivity filter, \"P\" loop and two transmembrane helices was used as a model to study the permeability and the selectivity of ion channels in the Mackinnon lab. The determination of the molecular structure of KcsA by Roderick MacKinnon using X-ray crystallography won a share of the 2003 Nobel Prize in Chemistry.\n\nBecause of their small size and the difficulty of crystallizing integral membrane proteins for X-ray analysis, it is only very recently that scientists have been able to directly examine what channels \"look like.\" Particularly in cases where the crystallography required removing channels from their membranes with detergent, many researchers regard images that have been obtained as tentative. An example is the long-awaited crystal structure of a voltage-gated potassium channel, which was reported in May 2003. One inevitable ambiguity about these structures relates to the strong evidence that channels change conformation as they operate (they open and close, for example), such that the structure in the crystal could represent any one of these operational states. Most of what researchers have deduced about channel operation so far they have established through electrophysiology, biochemistry, gene sequence comparison and mutagenesis.\n\nChannels can have single (CLICs) to multiple transmembrane (K channels, P2X receptors, Na channels) domains which span plasma membrane to form pores. Pore can determine the selectivity of the channel. Gate can be formed either inside or outside the pore region.\n\nChemical substances can modulate the activity of ion channels, for example by blocking or activating them.\n\nA variety of ion channel blockers (inorganic and organic molecules) can modulate ion channel activity and conductance.\nSome commonly used blockers include:\n\nBULLET::::- Tetrodotoxin (TTX), used by puffer fish and some types of newts for defense. It blocks sodium channels.\nBULLET::::- Saxitoxin is produced by a dinoflagellate also known as \"red tide\". It blocks voltage-dependent sodium channels.\nBULLET::::- Conotoxin is used by cone snails to hunt prey.\nBULLET::::- Lidocaine and Novocaine belong to a class of local anesthetics which block sodium ion channels.\nBULLET::::- Dendrotoxin is produced by mamba snakes, and blocks potassium channels.\nBULLET::::- Iberiotoxin is produced by the \"Buthus tamulus\" (Eastern Indian scorpion) and blocks potassium channels.\nBULLET::::- Heteropodatoxin is produced by \"Heteropoda venatoria\" (brown huntsman spider or laya) and blocks potassium channels.\n\nThere are a number of disorders which disrupt normal functioning of ion channels and have disastrous consequences for the organism. Genetic and autoimmune disorders of ion channels and their modifiers are known as channelopathies. See for a full list.\n\nBULLET::::- Shaker gene mutations cause a defect in the voltage gated ion channels, slowing down the repolarization of the cell.\nBULLET::::- Equine hyperkalaemic periodic paralysis as well as human hyperkalaemic periodic paralysis (HyperPP) are caused by a defect in voltage-dependent sodium channels.\nBULLET::::- Paramyotonia congenita (PC) and potassium-aggravated myotonias (PAM)\nBULLET::::- Generalized epilepsy with febrile seizures plus (GEFS+)\nBULLET::::- Episodic ataxia (EA), characterized by sporadic bouts of severe discoordination with or without myokymia, and can be provoked by stress, startle, or heavy exertion such as exercise.\nBULLET::::- Familial hemiplegic migraine (FHM)\nBULLET::::- Spinocerebellar ataxia type 13\nBULLET::::- Long QT syndrome is a ventricular arrhythmia syndrome caused by mutations in one or more of presently ten different genes, most of which are potassium channels and all of which affect cardiac repolarization.\nBULLET::::- Brugada syndrome is another ventricular arrhythmia caused by voltage-gated sodium channel gene mutations.\nBULLET::::- Cystic fibrosis is caused by mutations in the CFTR gene, which is a chloride channel.\nBULLET::::- Mucolipidosis type IV is caused by mutations in the gene encoding the TRPML1 channel\nBULLET::::- Mutations in and overexpression of ion channels are important events in cancer cells. In Glioblastoma multiforme, upregulation of gBK potassium channels and ClC-3 chloride channels enables glioblastoma cells to migrate within the brain, which may lead to the diffuse growth patterns of these tumors.\n\nThe fundamental properties of currents mediated by ion channels were analyzed by the British biophysicists Alan Hodgkin and Andrew Huxley as part of their Nobel Prize-winning research on the action potential, published in 1952. They built on the work of other physiologists, such as Cole and Baker's research into voltage-gated membrane pores from 1941. The existence of ion channels was confirmed in the 1970s by Bernard Katz and Ricardo Miledi using noise analysis. It was then shown more directly with an electrical recording technique known as the \"patch clamp\", which led to a Nobel Prize to Erwin Neher and Bert Sakmann, the technique's inventors. Hundreds if not thousands of researchers continue to pursue a more detailed understanding of how these proteins work. In recent years the development of automated patch clamp devices helped to increase significantly the throughput in ion channel screening.\n\nThe Nobel Prize in Chemistry for 2003 was awarded to Roderick MacKinnon for his studies on the physico-chemical properties of ion channel structure and function, including x-ray crystallographic structure studies.\n\nRoderick MacKinnon commissioned \"Birth of an Idea\", a tall sculpture based on the KcsA potassium channel. The artwork contains a wire object representing the channel's interior with a blown glass object representing the main cavity of the channel structure.\n\nBULLET::::- Alpha helix\nBULLET::::- Ion channel family as defined in Pfam and InterPro\nBULLET::::- K Database\nBULLET::::- Lipid bilayer ion channels\nBULLET::::- Magnesium transport\nBULLET::::- Neurotoxin\nBULLET::::- Passive transport\nBULLET::::- Synthetic ion channels\nBULLET::::- Transmembrane receptor\n\n"}
{"id": "15304", "url": "https://en.wikipedia.org/wiki?curid=15304", "title": "IDE", "text": "IDE\n\nIDE, iDE, or Ide may refer to:\n\nBULLET::::- \"Institut für Dokumentologie und Editorik\", a German think tank for the application of digital methods on historical documents\nBULLET::::- Institute of Developing Economies, a semi-governmental research institute in Japan\nBULLET::::- Institute for Democratic Education, founded by Yaacov Hecht\nBULLET::::- \"Instituto de Desenvolvimento Educacional\", a Brazilian institution linked with Fundação Getúlio Vargas\nBULLET::::- International Development Enterprises, a development NGO based in Denver, Colorado\nBULLET::::- Party of Internet Democracy, a political party in Hungary\n\nBULLET::::- Ide (fish), a freshwater fish\nBULLET::::- Intact dilation and extraction, a form of abortion\nBULLET::::- Insulin-degrading enzyme, Insulysin, an enzyme\nBULLET::::- Infectious disease epidemiology, the study of the patterns of communicable diseases at the population level\nBULLET::::- Investigational Device Exemption, a US Food and Drug Administration regulatory status\n\nBULLET::::- Suffix \"-ide\" for some molecules in the IUPAC nomenclature of inorganic chemistry\n\nBULLET::::- Integrated development environment, a software application for software development\nBULLET::::- Integrated Drive Electronics, a computer hardware bus for disk drives, retroactively termed Parallel ATA\n\nBULLET::::- Ide, Devon, a village in England\nBULLET::::- Ide, Kyoto, a town in Japan\n\nBULLET::::- Ida (mother of Minos), daughter of Corybas, the wife of Lycastus king of Crete, and the mother of the \"second\" king Minos of Crete\nBULLET::::- Ida (nurse of Zeus), who along with her sister Adrasteia, nursed Zeus on Crete\n\nBULLET::::- Samuel Krafsur (1913–1983), (KGB codename)\n\nBULLET::::- Íde, a feminine name of Gaelic origin\n\nBULLET::::- Charlie Ide (born 1988), English footballer\nBULLET::::- , Japanese footballer\nBULLET::::- Henry Clay Ide (1844–1921), American commissioner to Samoa and the Philippines\nBULLET::::- , Japanese shogi player\nBULLET::::- , Japanese speed skater\nBULLET::::- , Japanese screenwriter\nBULLET::::- William B. Ide (1796–1852), author of the California Republic's proclamation of independence from Mexico\nBULLET::::- Yuji Ide (born 1975), Japanese racing driver\nBULLET::::- Yasunori Ide, Japanese anime creator\n\nBULLET::::- Ides (disambiguation)\n"}
{"id": "15305", "url": "https://en.wikipedia.org/wiki?curid=15305", "title": "Integrated development environment", "text": "Integrated development environment\n\nAn integrated development environment (IDE) is a software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of at least a source code editor, build automation tools and a debugger. Some IDEs, such as NetBeans and Eclipse, contain the necessary compiler, interpreter, or both; others, such as SharpDevelop and Lazarus, do not.\n\nThe boundary between an IDE and other parts of the broader software development environment is not well-defined; sometimes a version control system or various tools to simplify the construction of a graphical user interface (GUI) are integrated. Many modern IDEs also have a class browser, an object browser, and a class hierarchy diagram for use in object-oriented software development.\n\nIntegrated development environments are designed to maximize programmer productivity by providing tight-knit components with similar user interfaces. IDEs present a single program in which all development is done. This program typically provides many features for authoring, modifying, compiling, deploying and debugging software. This contrasts with software development using unrelated tools, such as vi, GCC or make.\n\nOne aim of the IDE is to reduce the configuration necessary to piece together multiple development utilities, instead it provides the same set of capabilities as one cohesive unit. Reducing setup time can increase developer productivity, especially in cases where learning to use the IDE is faster than manually integrating and learning all of the individual tools. Tighter integration of all development tasks has the potential to improve overall productivity beyond just helping with setup tasks. For example, code can be continuously parsed while it is being edited, providing instant feedback when syntax errors are introduced, thus allowing developers to debug code much faster and more easily with an IDE. \n\nSome IDEs are dedicated to a specific programming language, allowing a feature set that most closely matches the programming paradigms of the language. However, there are many multiple-language IDEs.\n\nWhile most modern IDEs are graphical, text-based IDEs such as Turbo Pascal were in popular use before the availability of windowing systems like Microsoft Windows and the X Window System (X11). They commonly use function keys or hotkeys to execute frequently used commands or macros.\n\nIDEs initially became possible when developing via a console or terminal. Early systems could not support one, since programs were prepared using flowcharts, entering programs with punched cards (or paper tape, etc.) before submitting them to a compiler. Dartmouth BASIC was the first language to be created with an IDE (and was also the first to be designed for use while sitting in front of a console or terminal). Its IDE (part of the Dartmouth Time Sharing System) was command-based, and therefore did not look much like the menu-driven, graphical IDEs popular after the advent of the Graphical User Interface. However it integrated editing, file management, compilation, debugging and execution in a manner consistent with a modern IDE.\n\nSee also Structured Programming Facility from IBM (1974).\n\nMaestro I is a product from Softlab Munich and was the world's first integrated development environment for software. Maestro I was installed for 22,000 programmers worldwide. Until 1989, 6,000 installations existed in the Federal Republic of Germany. Maestro was arguably the world leader in this field during the 1970s and 1980s. Today one of the last Maestro I can be found in the Museum of Information Technology at Arlington.\n\nOne of the first IDEs with a plug-in concept was Softbench. In 1995 \"Computerwoche\" commented that the use of an IDE was not well received by developers since it would fence in their creativity.\n\nAs of March 2015, the most popular IDEs are Eclipse and Visual Studio.\n\nThe IDE editor usually provides syntax highlighting, it can show both the structures, the language keywords and the syntax errors with visually distinct colors and font effects.\n\nCode completion is an important IDE feature, intended to speed up programming. Modern IDEs even have intelligent code completion.\n\nAdvanced IDEs provide support for automated refactoring.\n\nAn IDE is expected to provide integrated version control, in order to interact with source repositories.\n\nIDEs are also used for debugging, using an integrated debugger, with support for setting breakpoints in the editor, visual rendering of steps, etc.\n\nIDEs may provide advanced support for code search: in order to find class and function declarations, usages, variable and field read/write, etc. IDEs can use different kinds of user interface for code search, for example form-based widgets and natural-language based interfaces.\n\nVisual programming is a usage scenario in which an IDE is generally required. Visual Basic allows users to create new applications by moving programming, building blocks, or code nodes to create flowcharts or structure diagrams that are then compiled or interpreted. These flowcharts often are based on the Unified Modeling Language.\n\nThis interface has been popularized with the Lego Mindstorms system, and is being actively pursued by a number of companies wishing to capitalize on the power of custom browsers like those found at Mozilla. KTechlab supports flowcode and is a popular opensource IDE and Simulator for developing software for microcontrollers. Visual programming is also responsible for the power of distributed programming (cf. LabVIEW and EICASLAB software). An early visual programming system, Max, was modeled after analog synthesizer design and has been used to develop real-time music performance software since the 1980s. Another early example was Prograph, a dataflow-based system originally developed for the Macintosh. The graphical programming environment \"Grape\" is used to program qfix robot kits.\n\nThis approach is also used in specialist software such as Openlab, where the end users want the flexibility of a full programming language, without the traditional learning curve associated with one.\n\nSome IDEs support multiple languages, such as GNU Emacs based on C and Emacs Lisp, and IntelliJ IDEA, Eclipse, MyEclipse or NetBeans, all based on Java, or MonoDevelop, based on C#, or PlayCode.\n\nSupport for alternative languages is often provided by plugins, allowing them to be installed on the same IDE at the same time. For example, Flycheck is a modern on-the-fly syntax checking extension for GNU Emacs 24 with support for 39 languages. Eclipse, and Netbeans have plugins for C/C++, Ada, GNAT (for example AdaGIDE), Perl, Python, Ruby, and PHP, which are selected between automatically based on file extension, environment or project settings.\n\nUnix programmers can combine command-line POSIX tools into a complete development environment, capable of developing large programs such as the Linux kernel and its environment. In this sense, the entire Unix system functions as an IDE. The free software GNU tools (GNU Compiler Collection (GCC), GNU Debugger (gdb), and GNU make) are available on many platforms, including Windows. The pervasive Unix philosophy of \"everything is a text stream\" enables developers who favor command-line oriented tools to use editors with support for many of the standard Unix and GNU build tools, building an IDE with programs like\nEmacs\nor Vim. Data Display Debugger is intended to be an advanced graphical front-end for many text-based debugger standard tools. Some programmers prefer managing makefiles and their derivatives to the similar code building tools included in a full IDE. For example, most contributors to the PostgreSQL database use make and gdb directly to develop new features. Even when building PostgreSQL for Microsoft Windows using Visual C++, Perl scripts are used as a replacement for make rather than relying on any IDE features. Some Linux IDEs such as Geany attempt to provide a graphical front end to traditional build operations.\n\nOn the various Microsoft Windows platforms, command-line tools for development are seldom used. Accordingly, there are many commercial and non-commercial products. However, each has a different design commonly creating incompatibilities. Most major compiler vendors for Windows still provide free copies of their command-line tools, including Microsoft (Visual C++, Platform SDK, .NET Framework SDK, nmake utility).\n\nIDEs have always been popular on the Apple Macintosh's classic Mac OS and macOS, dating back to Macintosh Programmer's Workshop, Turbo Pascal, THINK Pascal and THINK C environments of the mid-1980s. Currently macOS programmers can choose between native IDEs like Xcode and open-source tools such as Eclipse and Netbeans. ActiveState Komodo is a proprietary multilanguage IDE supported on macOS.\n\nSome features of IDEs can benefit from advances in AI. In particular, one can collect information from IDE actions across developers in order to augment IDE features. For instance, a data-driven approach to code completion results in intelligent code completion.\n\nAn web integrated development environment (Web IDE), also known as an Online IDE or Cloud IDE, is a browser based IDE that allows for software development or web development. A web IDE can be accessed from a web browser, such as Google Chrome or Internet Explorer, allowing for a portable work environment. A web IDE does not usually contain all of the same features as a traditional, or desktop, IDE, although all of the basic IDE features, such as syntax highlighting, are typically present.\n"}
{"id": "15308", "url": "https://en.wikipedia.org/wiki?curid=15308", "title": "Ian McKellen", "text": "Ian McKellen\n\nSir Ian Murray McKellen (born 25 May 1939) is an English actor. His career spans genres ranging from Shakespearean and modern theatre to popular fantasy and science fiction.\nHe is the recipient of six Laurence Olivier Awards, a Tony Award, a Golden Globe Award, a Screen Actors Guild Award, a BIF Award, two Saturn Awards, four Drama Desk Awards, and two Critics' Choice Awards. He has also received nominations for two Academy Awards, five Primetime Emmy Awards, and four BAFTAs.\nHe achieved worldwide fame for his film roles, including the titular King in \"Richard III\" (1995), James Whale in \"Gods and Monsters\" (1998), Magneto in the \"X-Men\" films, and Gandalf in \"The Lord of the Rings\" and \"The Hobbit\" trilogies.\n\nThe BBC states that his \"performances have guaranteed him a place in the canon of English stage and film actors\". A recipient of every major theatrical award in the UK, McKellen is regarded as a British cultural icon. He started his professional career in 1961 at the Belgrade Theatre as a member of their highly regarded repertory company. In 1965, McKellen made his first West End appearance. In 1969, he was invited to join the Prospect Theatre Company to play the lead parts in Shakespeare's \"Richard II\" and Marlowe's \"Edward II\", and he firmly established himself as one of the country's foremost classical actors. In the 1970s, McKellen became a stalwart of the Royal Shakespeare Company and the National Theatre of Great Britain.\n\nMcKellen was appointed Commander of the Order of the British Empire in the 1979 Birthday Honours, was knighted in the 1991 New Year Honours for services to the performing arts, and made a Companion of Honour for services to drama and to equality in the 2008 New Year Honours. He has been openly gay since 1988, and continues to be a champion for LGBT social movements worldwide. He was awarded Freedom of the City of London in October 2014.\n\nMcKellen was born on 25 May 1939 in Burnley, Lancashire, the son of Margery Lois (née Sutcliffe) and Denis Murray McKellen. He was their second child, with a sister, Jean, five years his senior. Shortly before the outbreak of the Second World War in September 1939, his family moved to Wigan. They lived there until Ian was twelve years old, before relocating to Bolton in 1951, after his father had been promoted. The experience of living through the war as a young child had a lasting impact on him, and he later said that \"only after peace resumed ... did I realise that war wasn't normal.\" When an interviewer remarked that he seemed quite calm in the aftermath of the 11 September attacks, McKellen said: \"Well, darling, you forget—I slept under a steel plate until I was four years old.”\n\nMcKellen's father was a civil engineer and lay preacher, and was of Protestant Irish and Scottish descent. Both of McKellen's grandfathers were preachers, and his great-great-grandfather, James McKellen, was a \"strict, evangelical Protestant minister\" in Ballymena, County Antrim. His home environment was strongly Christian, but non-orthodox. \"My upbringing was of low nonconformist Christians who felt that you led the Christian life in part by behaving in a Christian manner to everybody you met.\" When he was 12, his mother died of breast cancer; his father died when he was 24. After his coming out as gay to his stepmother, Gladys McKellen, who was a member of the Religious Society of Friends, he said, \"Not only was she not fazed, but as a member of a society which declared its indifference to people's sexuality years back, I think she was just glad for my sake that I wasn't lying anymore.\" His great-great-grandfather Robert J. Lowes was an activist and campaigner in the ultimately successful campaign for a Saturday half-holiday in Manchester, the forerunner to the modern five-day work week, thus making Lowes a \"grandfather of the modern weekend\".\n\nMcKellen attended Bolton School (Boys' Division), of which he is still a supporter, attending regularly to talk to pupils. McKellen's acting career started at Bolton Little Theatre, of which he is now the patron. An early fascination with the theatre was encouraged by his parents, who took him on a family outing to \"Peter Pan\" at the Opera House in Manchester when he was three. When he was nine, his main Christmas present was a fold-away wood and bakelite Victorian theatre from Pollocks Toy Theatres, with cardboard scenery and wires to push on the cut-outs of Cinderella and of Laurence Olivier's Hamlet.\n\nHis sister took him to his first Shakespeare play, \"Twelfth Night\", by the amateurs of Wigan's Little Theatre, shortly followed by their \"Macbeth\" and Wigan High School for Girls' production of \"A Midsummer Night's Dream\", with music by Mendelssohn, with the role of Bottom played by Jean McKellen, who continued to act, direct, and produce amateur theatre until her death.\n\nIn 1958, McKellen, at the age of 18, won a scholarship to St Catharine's College, Cambridge, where he read English literature. He has since been made an Honorary Fellow of the College. While at Cambridge, McKellen was a member of the Marlowe Society, where he appeared in 23 plays over the course of 3 years. At that young age he was already giving performances that have since become legendary such as his Justice Shallow in \"Henry IV\" alongside Trevor Nunn and Derek Jacobi (March 1959), \"Cymbeline\" (as Posthumus, opposite Margaret Drabble as Imogen) and \"Doctor Faustus\". During this period McKellen had already been directed by Peter Hall, John Barton and Dadie Rylands, all of whom would have a huge impact on McKellen's future career.\n\nMcKellen made his first professional appearance in 1961 at the Belgrade Theatre, as Roper in \"A Man for All Seasons\", although an audio recording of the Marlowe Society's \"Cymbeline\" had gone on commercial sale as part of the Argo Shakespeare series.\n\nAfter four years in regional repertory theatres he made his first West End appearance, in \"A Scent of Flowers\", regarded as a \"notable success\". In 1965 he was a member of Laurence Olivier's National Theatre Company at the Old Vic, which led to roles at the Chichester Festival. With the Prospect Theatre Company, McKellen made his breakthrough performances of Richard II (directed by Richard Cottrell) and Marlowe's Edward II (directed by Toby Robertson) at the Edinburgh festival in 1969, the latter causing a storm of protest over the enactment of the homosexual Edward's lurid death.\n\nIn the 1970s and 1980s McKellen became a well-known figure in British theatre, performing frequently at the Royal Shakespeare Company and the Royal National Theatre, where he played several leading Shakespearean roles, including the title role in \"Macbeth\" (which he had first played for Trevor Nunn in a \"gripping...out of the ordinary\" production, with Judi Dench, at Stratford in 1976), and Iago in \"Othello\", in award-winning productions directed by Nunn. Both of these productions were adapted into television films, also directed by Nunn.\n\nIn 2007 he returned to the Royal Shakespeare Company, in productions of \"King Lear\" and \"The Seagull\", both directed by Trevor Nunn. In 2009 he appeared in a very popular revival of \"Waiting for Godot\" at London's Haymarket Theatre, directed by Sean Mathias, and playing opposite Patrick Stewart. He is Patron of English Touring Theatre and also President and Patron of the Little Theatre Guild of Great Britain, an association of amateur theatre organisations throughout the UK. In late August 2012, he took part in the opening ceremony of the London Paralympics, portraying Prospero from \"The Tempest\".\n\nIn October 2017, McKellen played King Lear at Chichester Festival Theatre, a role which he said was likely to be his \"last big Shakespearean part\". He performed the play at the Duke of York's Theatre in London's West End during the summer of 2018.\n\nMcKellen had taken film roles throughout his career—beginning in 1969 with his role of George Matthews in \"A Touch of Love\", and his first leading role was in 1980 as D. H. Lawrence in \"Priest of Love\", but it was not until the 1990s that he became more widely recognised in this medium after several roles in blockbuster Hollywood films. In 1993, he had a supporting role as a South African tycoon in the critically acclaimed \"Six Degrees of Separation\", in which he starred with Stockard Channing, Donald Sutherland, and Will Smith. In the same year, he appeared in minor roles in the television miniseries \"Tales of the City\", based on the novel by his friend Armistead Maupin, and the film \"Last Action Hero\", in which he briefly played Death opposite Arnold Schwarzenegger and Charles Dance.\n\nLater in 1993, McKellen appeared in the television film \"And the Band Played On\" about the discovery of the AIDS virus for which McKellen won a CableACE Award for Supporting Actor in a Movie or Miniseries and was nominated for the Emmy Award for Outstanding Supporting Actor in a Miniseries or a Movie. In 1995, he played the title role in \"Richard III\", which transported the setting into an alternative 1930s in which England is ruled by fascists. The film was a critical success. McKellen co-produced and co-wrote the film, adapting the play for the screen based on a stage production of Shakespeare's play directed by Richard Eyre for the Royal National Theatre in which McKellen had appeared. As executive producer he returned his £50,000 fee to complete the filming of the final battle. In his review of the film, \"The Washington Post\" film critic Hal Hinson called McKellen's performance a \"lethally flamboyant incarnation\" and said his \"florid mastery ... dominates everything\". His performance in the title role garnered BAFTA and Golden Globe nominations for Best Actor and won the European Film Award for Best Actor. His screenplay was nominated for the BAFTA Award for Best Adapted Screenplay.\nHe appeared in the modestly acclaimed film \"Apt Pupil\", which was directed by Bryan Singer and based on a story by Stephen King. McKellen portrayed a fugitive Nazi officer living under a false name in the US who is befriended by a curious teenager (Brad Renfro) who threatens to expose him unless he tells his story in detail. He was subsequently nominated for the Academy Award for Best Actor for his role in the 1998 film \"Gods and Monsters\", wherein he played James Whale, the director of \"Show Boat\" (1936) and \"Frankenstein\".\n\nIn 1999 McKellen was cast, again under the direction of Bryan Singer, to play the comic book supervillain Magneto in the 2000 film \"X-Men\" and its sequels \"X2: X-Men United\" (2003) and \"\" (2006). He later made a short appearance as an older Magneto in 2014's \"\", sharing the role with Michael Fassbender, who played a younger version of the character in 2011's \"\".\n\nWhile filming the first \"X-Men\" film in 1999, McKellen was cast as the wizard Gandalf in Peter Jackson's three-film adaptation of \"The Lord of the Rings\" (consisting of \"\" (2001), \"\" (2002), and \"\" (2003) ). He received honors from the Screen Actors Guild for Best Supporting Actor in a Motion Picture for his work in \"The Fellowship of the Ring\" and was nominated for the Academy Award for Best Supporting Actor for the same role. He provided the voice of Gandalf for several video game adaptations of the \"Lord of the Rings\" films, then reprised the role on screen in Jackson's film adaptation of \"The Hobbit\", which was released in three parts from 2012 to 2014.\n\nOn 16 March 2002, he hosted \"Saturday Night Live\". In 2003, McKellen made a guest appearance as himself on the American cartoon show \"The Simpsons\" in a special British-themed episode entitled \"The Regina Monologues\", along with the then UK Prime Minister Tony Blair and author J. K. Rowling. In April and May 2005, he played the role of Mel Hutchwright in Granada Television's long running British soap opera, \"Coronation Street\", fulfilling a lifelong ambition. He narrated Richard Bell's film \"Eighteen\" as a grandfather who leaves his World War II memoirs on audio-cassette for his teenage grandson.\n\nMcKellen has appeared in limited release films, such as \"Emile\" (which was shot in three weeks following the \"X2\" shoot), \"Neverwas\" and \"Asylum\". He appeared as Sir Leigh Teabing in \"The Da Vinci Code\". During a 17 May 2006 interview on \"The Today Show\" with the \"Da Vinci Code\" cast and director, Matt Lauer posed a question to the group about how they would have felt if the film had borne a prominent disclaimer that it is a work of fiction, as some religious groups wanted. McKellen responded, \"I've often thought the Bible should have a disclaimer in the front saying 'This is fiction.' I mean, walking on water? It takes... an act of faith. And I have faith in this movie—not that it's true, not that it's factual, but that it's a jolly good story.\" He continued, \"And I think audiences are clever enough and bright enough to separate out fact and fiction, and discuss the thing when they've seen it\". McKellen appeared in the 2006 BBC series of Ricky Gervais' comedy series \"Extras\", where he played himself directing Gervais' character Andy Millman in a play about gay lovers. McKellen received a 2007 Primetime Emmy Award for Outstanding Guest Actor – Comedy Series nomination for his performance. In 2009 he portrayed Number Two in \"The Prisoner\", a remake of the 1967 cult series \"The Prisoner\". In 2013, McKellen co-starred in the ITV sitcom \"Vicious\" as Freddie Thornhill, alongside Derek Jacobi. The series revolves around an elderly gay couple who have been together for 50 years. On 23 August 2013 the show was renewed for a six-episode second series which began airing in June 2015.\n\nIn November 2013, McKellen appeared in the \"Doctor Who\" 50th anniversary comedy homage \"The Five(ish) Doctors Reboot\". In October 2015, McKellen appeared as Norman to Anthony Hopkins' Sir in a BBC Two production of Ronald Harwood's \"The Dresser\", alongside Edward Fox and Emily Watson. In 2017, McKellen portrayed Cogsworth in the live-action adaptation of Disney's \"Beauty and the Beast\", directed by Bill Condon (which marked the third collaboration between Condon and McKellen, after \"Gods and Monsters\" and \"Mr. Holmes\") and co-starred alongside Emma Watson and Dan Stevens. Also that year, McKellen appeared in the documentary \"McKellen: Playing the Part\", directed by director Joe Stephenson. The documentary explores McKellen's life and career as an actor.\n\nIn 2019, McKellen starred in \"The Good Liar\" with Helen Mirren, and will play Gus the Theatre Cat in \"Cats\", an adaptation of Andrew Lloyd Webber's musical, directed by Tom Hooper, and also featuring Jennifer Hudson, James Corden, Idris Elba, and Judi Dench.\n\nMcKellen and his first partner, Brian Taylor, a history teacher from Bolton, began their relationship in 1964. Their relationship lasted for eight years, ending in 1972. They lived in London, where McKellen continued to pursue his career as an actor. For over a decade, he has lived in a five-storey Victorian conversion in Narrow Street, Limehouse. In 1978 he met his second partner, Sean Mathias, at the Edinburgh Festival. This relationship lasted until 1988, and according to Mathias, was tempestuous, with conflicts over McKellen's success in acting versus Mathias's somewhat less-successful career. The two remained friends with Mathias later directing McKellen in \"Waiting for Godot\" at the Theatre Royal Haymarket in 2009. The pair entered into a business partnership with Evgeny Lebedev, purchasing the lease of The Grapes public house in Narrow Street.\n\nMcKellen is an atheist. In the late 1980s, McKellen lost his appetite for meat except for fish, and has since followed a mainly pescetarian diet. In 2001, Ian McKellen received the Artist Citizen of the World Award (France).\n\nHe has a tattoo of the Elvish number nine, written using J. R. R. Tolkien's constructed script of Tengwar, on his shoulder in reference to his involvement in the \"Lord of the Rings\" and the fact that his character was one of the original nine companions of the Fellowship of the Ring. The other actors of \"The Fellowship\" (Elijah Wood, Sean Astin, Orlando Bloom, Billy Boyd, Sean Bean, Dominic Monaghan and Viggo Mortensen) have the same tattoo. John Rhys-Davies, whose character was also one of the original nine companions, arranged for his stunt double to get the tattoo instead.\n\nHe was diagnosed with prostate cancer in 2006. In 2012, McKellen stated on his blog that \"There is no cause for alarm. I am examined regularly and the cancer is contained. I've not needed any treatment.\"\n\nHe became an ordained minister of the Universal Life Church in early 2013 in order to preside over the marriage of his friend and \"X-Men\" co-star Patrick Stewart to the singer Sunny Ozell.\n\nMcKellen was awarded an honorary Doctorate of Letters by Cambridge University on 18 June 2014. He was made a Freeman of the city of London on Thursday 30 October 2014. The ceremony took place at Guildhall in London. McKellen was nominated by London's Lord Mayor Fiona Woolf, who said he was chosen as he was an \"exceptional actor\" and \"tireless campaigner for equality\". He is also an Emeritus Fellow of St Catherine's College, Oxford.\n\nWhile McKellen had made his sexual orientation known to fellow actors early on in his stage career, it was not until 1988 that he came out to the general public, in a programme on BBC Radio. The context that prompted McKellen's decision—overriding any concerns about a possible negative effect on his career—was that the controversial Section 28 of the Local Government Bill, known simply as Section 28, was then under consideration in the British Parliament. Section 28 proposed prohibiting local authorities from promoting homosexuality \"... as a kind of pretended family relationship\". McKellen became active in fighting the proposed law, and, during a BBC Radio 3 programme where he debated Section 28 with the conservative journalist Peregrine Worsthorne, declared himself gay. McKellen has stated that he was influenced in his decision by the advice and support of his friends, among them noted gay author Armistead Maupin. In a 1998 interview that discusses the 29th anniversary of the Stonewall riots, McKellen commented, I have many regrets about not having come out earlier, but one of them might be that I didn't engage myself in the politicking. He has said of this period: My own participating in that campaign was a focus for people [to] take comfort that if Ian McKellen was on board for this, perhaps it would be all right for other people to be as well, gay and straight. Section 28 was, however, enacted and remained on the statute books until 2000 in Scotland and 2003 in England and Wales. Section 28 never applied in Northern Ireland.\n\nIn 2003, during an appearance on \"Have I Got News For You\", McKellen claimed when he visited Michael Howard, then Environment Secretary (responsible for local government), in 1988 to lobby against Section 28, Howard refused to change his position but did ask him to leave an autograph for his children. McKellen agreed, but wrote, \"Fuck off, I'm gay.\" McKellen described Howard's junior ministers, Conservatives David Wilshire and Dame Jill Knight, who were the architects of Section 28, as the 'ugly sisters' of a political pantomime.\n\nMcKellen has continued to be very active in LGBT rights efforts. In a statement on his website regarding his activism, the actor commented that:\nMcKellen is a co-founder of Stonewall, an LGBT rights lobby group in the United Kingdom, named after the Stonewall riots. McKellen is also patron of LGBT History Month, Pride London, Oxford Pride, GAY-GLOS, LGBT Foundation, and FFLAG where he appears in their video \"Parents Talking\".\n\nIn 1994, at the closing ceremony of the Gay Games, he briefly took the stage to address the crowd, saying, \"I'm Sir Ian McKellen, but you can call me Serena\": This nickname, given to him by Stephen Fry, had been circulating within the gay community since McKellen's knighthood was conferred. In 2002, he was the Celebrity Grand Marshal of the San Francisco Pride Parade and he attended the Academy Awards with his then-boyfriend, New Zealander Nick Cuthell. In 2006, McKellen spoke at the pre-launch of the 2007 LGBT History Month in the UK, lending his support to the organisation and its founder, Sue Sanders. In 2007, he became a patron of The Albert Kennedy Trust, an organisation that provides support to young, homeless and troubled LGBT people.\n\nIn 2006, he became a patron of Oxford Pride, stating:I send my love to all members of Oxford Pride, their sponsors and supporters, of which I am proud to be one... Onlookers can be impressed by our confidence and determination to be ourselves and gay people, of whatever age, can be comforted by the occasion to take the first steps towards coming out and leaving the closet forever behind.\n\nMcKellen has taken his activism internationally, and caused a major stir in Singapore, where he was invited to do an interview on a morning show and shocked the interviewer by asking if they could recommend him a gay bar; the programme immediately ended. In December 2008, he was named in \"Out\" annual Out 100 list.\n\nIn 2010, McKellen extended his support for Liverpool's Homotopia festival in which a group of gay and lesbian Merseyside teenagers helped to produce an anti-homophobia campaign pack for schools and youth centres across the city. In May 2011, he called Sergey Sobyanin, Moscow's mayor, a \"coward\" for refusing to allow gay parades in the city.\n\nIn 2014, he was named in the top 10 on the World Pride Power list.\n\nIn April 2010, along with actors Brian Cox and Eleanor Bron, McKellen appeared in a series of TV advertisements to support Age UK, the charity recently formed from the merger of Age Concern and Help the Aged. All three actors gave their time free of charge.\n\nA cricket fan since childhood, McKellen umpired in March 2011 for a charity cricket match in New Zealand to support earthquake victims of the February 2011 Christchurch earthquake.\n\nMcKellen is an honorary board member for the New York and Washington, DC based organization Only Make Believe. Only Make Believe creates and performs interactive plays in children's hospitals and care facilities. He was honoured by the organisation in 2012 and hosted their annual Make Believe on Broadway Gala in November 2013. He garnered publicity for the organisation by stripping down to his Lord of the Rings underwear on stage.\n\nMcKellen also has a history of supporting individual theatres. While in New Zealand filming \"The Hobbit\" in 2012, he announced a special New Zealand tour \"Shakespeare, Tolkien, and You!\", with proceeds going to help save the Isaac Theatre Royal, which suffered extensive damage during the 2011 Christchurch earthquake. McKellen said he opted to help save the building as it was the last theatre he played in New Zealand (\"Waiting for Godot\" in 2010) and the locals' love for it made it a place worth supporting. In July 2017, he performed a new one-man show for a week at Park Theatre (London), donating the proceeds to the theatre.\n\nA friend of Ian Charleson and an admirer of his work, McKellen contributed an entire chapter to \"For Ian Charleson: A Tribute\". A recording of McKellen's voice is heard before performances at the Royal Festival Hall, reminding patrons to ensure their mobile phones and watch alarms are switched off and to keep coughing to a minimum. He also took part in the 2012 Summer Paralympics opening ceremony in London as Prospero from Shakespeare's \"The Tempest\".\n\nBULLET::::- In 1987, McKellen appeared reciting Shakespeare while rock group The Fleshtones improvised behind him on \"Andy Warhol's Fifteen Minutes\" which ran on MTV.\nBULLET::::- Vampire in the music video \"Heart\" by Pet Shop Boys\nBULLET::::- The man who's \"falling out of reach\" in the music video \"Falling Out of Reach\" by Guillemots\nBULLET::::- Appears on the Scissor Sisters track \"Invisible Light\" from their 2010 album \"Night Work\", reciting a passage regarding the \"Invisible Light\" of the title.\nBULLET::::- Appeared as himself alongside George Ezra in the latter's music video for \"Listen to the Man\". Whilst Ezra is singing his song, McKellen joins in and lip-syncs Ezra's voice.\n\nBULLET::::- Audiobook narrator of Michelle Paver's series \"Wolf Brother\", \"Spirit Walker\", \"Soul Eater\", \"Outcast\", \"Oath Breaker\", and \"Ghost Hunter\", as well as a version of Homer's \"Odyssey\".\n\nBULLET::::- The papers of Sir Ian McKellen, actor are held by the Victoria and Albert Museum Theatre and Performance Department.\nBULLET::::- Biography of Sir Ian McKellen, CH, CBE, Debrett's\n"}
{"id": "15309", "url": "https://en.wikipedia.org/wiki?curid=15309", "title": "Intellivision", "text": "Intellivision\n\nThe Intellivision is a home video game console released by Mattel Electronics in 1979. The name \"Intellivision\" is a portmanteau of \"intelligent television\". Development of the console began in 1977, the same year as the introduction of its main competitor, the Atari 2600. In 1984 Mattel sold their video game assets to a former Mattel Electronics executive and investors that would become INTV Corporation. Games development started in 1978 and continued until 1990 when the Intellivision was discontinued. From 1980 to 1983 over 3 million Intellivision units were sold.\n\nIn 2009, video game website IGN named the Intellivision the No. 14 greatest video game console of all time. It remained Mattel's only video game console until the release of the HyperScan in 2006.\n\nThe Intellivision was developed at Mattel in Hawthorne, California along with their Mattel Electronics line of handheld electronic games. Mattel's Design and Development group began investigating a home video game system in 1977. It was to have rich graphics and long lasting gameplay to distinguish itself from its competitors. Mattel identified a new but expensive chipset from National Semiconductor and negotiated better pricing for a simpler design. Their consultant, APh Technological Consulting, suggested a General Instrument chipset, listed as the Gimini programmable set in the GI 1977 catalog. The GI chipset lacked reprogrammable graphics and Mattel worked with GI to implement changes. GI published an updated chipset in its 1978 catalog. After initially choosing National in August 1977, Mattel waited for two months before ultimately going with the proposed GI chipset in the fall of 1977. A team at Mattel, headed by David Chandler, began engineering the hardware, including the famous hand controllers. In 1978, David Rolfe of APh developed the executive control software (Exec) and, with a group of Caltech summer student hires, programmed the first games. Graphics were designed by a group of artists at Mattel led by Dave James.\n\nThe Intellivision was test marketed in Fresno, California in 1979 with a total of four games available. It was released nationwide in 1980 with a price tag of US$299, a pack-in game (\"Las Vegas Poker & Blackjack\"), and a library of ten cartridges. Mattel Electronics would become a subsidiary in 1981.\n\nThough the Intellivision was not the first system to challenge Warner Communications's Atari, it was the first to pose a serious threat to the market leader. A series of advertisements featuring George Plimpton were produced that demonstrated the superiority of the Intellivision's graphics and sound to those of the Atari 2600, using side-by-side game comparisons. One of the slogans of the television advertisements stated that Intellivision was \"the closest thing to the real thing\"; one example in an advertisement compared golf games. The other console's games had a blip sound and cruder graphics, while the Intellivision featured a realistic swing sound and striking of the ball, and graphics that suggested a more 3D look. There was also an advertisement comparing the Atari 2600 to it, featuring the slogan \"I didn't know\". In its first year, Mattel sold out its initial 175,000 production run of Intellivision \"Master Components\". In 1981, over one million Intellivision consoles were sold, five times as many as in 1980.\nThe Intellivision Master Component was branded and distributed by various companies. Before Mattel shifted manufacturing to Hong Kong, Mattel Intellivisions were manufactured by GTE Sylvania. \"GTE Sylvania\" Intellivisions were produced along with Mattel's, with the brand name the only differentiation. The Sears \"Super Video Arcade\", manufactured by Mattel in Hong Kong, has a restyled beige top cover and detachable controllers. The Sears Intellivision modified the default title screen by removing the \"Mattel Electronics\" captioning. In 1982 Radio Shack marketed the \"Tandyvision One\", similar to the original Intellivision but with the gold plates replaced with more wood trim. In Japan Intellivisions were branded by Bandai in 1982, and in Brazil there were Digimed and Digiplay Intellivisions manufactured by Sharp in 1983.\n\nInside every Intellivision is 4K of ROM containing the Exec software. It provides two benefits: reusable code that can effectively make a 4K cartridge an 8K game, and a software framework for new programmers to develop games more easily and quickly. It also allows other programmers to more easily review and continue another's project. Under the supervision of David Rolfe (APh) and graphics supplied by Mattel artist Dave James, APh was able to quickly create the Intellivision launch title library using mostly summer students. The drawback is that to be flexible and handle many different types of games the Exec runs less efficiently than a dedicated program. Intellivision games that leverage the Exec run at a 20 Hz frame rate instead of the 60 Hz frame rate for which the Intellivision was designed. Using the Exec framework is optional, but almost all Intellivision games released by Mattel Electronics are 20 Hz. The limited ROM space also meant there was no room for computer artificial intelligence and many early games required two players.\n\nInitially, all Intellivision games were programmed by an outside firm, APh Technological Consulting, with 19 cartridges produced before Christmas 1980. Once the Intellivision project became successful, software development was brought in-house. Mattel formed its own software development group and began hiring programmers. The original five members of that Intellivision team were Mike Minkoff, Rick Levine, John Sohl, Don Daglow, and manager Gabriel Baum. Levine and Minkoff, a long-time Mattel Toys veteran, both came over from the hand-held Mattel games engineering team. During 1981 Mattel hired programmers as fast it could. Early in 1982 Mattel Electronics relocated from Mattel headquarters to an unused industrial building. Office renovation work happened as new staff moved in. To keep these programmers from being hired away by rival Atari, their identity and work location was kept a closely guarded secret. In public, the programmers were referred to collectively as the Blue Sky Rangers.\n\nMost of the early games were based on traditional real-world concepts such as sports, with an emphasis on realism and depth of play within the technology of the day. The Intellivision was not marketed as a toy; as such, games such as \"Sea Battle\" and \"B-17 Bomber\" are not made in a pick-up-and-play format which arcade style games are. Reading the instructions is often a prerequisite to play. Every cartridge produced by Mattel Electronics included two plastic controller \"overlays\" to help navigate the 12 keypad buttons, although not every game made use of the keypad. Mattel organized its games into networks: \"Major League Sports, Action, Strategy, Gaming, Children's Learning\" and later \"Space Action\" and \"Arcade\". The network concept was dropped in 1983, as were the convenient gate-fold style boxes for storing the cartridge, instructions, and overlays.\n\nStarting in 1981 programmers looking for credit and royalties on sales began leaving both APh and Mattel Electronics to create Intellivision cartridges for third-party publishers. They helped form Imagic in 1981 and in 1982 others joined Activision and Atari. Cheshire Engineering was formed by a few senior APh programmers including David Rolfe (author of the Exec) and Tom Loughry, who had created one of the most popular Intellivision games \"\"; Cheshire created Intellivision games for Activision. Third-party developers Activision, Imagic, and Coleco started producing Intellivision cartridges in 1982, and Atari, Parker Brothers, Sega, and Interphase followed in 1983. The third-party developers, not having legal access to Exec knowledge, often bypassed the Exec framework to create smooth 30 Hz and 60 Hz Intellivision games such as \"The Dreadnaught Factor\". Cheaper ROM prices also allowed for larger games as 8K, 12K, and then 16K cartridges became common. The first Mattel Electronics Intellivision game to run at 60 Hz was \"Masters of the Universe\" in 1983. Marketing dubbed the term \"Super Graphics\" on the game's packaging and marketing.\n\nMattel Electronics' team of programmers was diverse in experience and talent, which proved to be an advantage. As competitors often depended on licensing well known trademarks to sell video games, Mattel focused on original ideas. Don Daglow was a key early programmer at Mattel and became director of Intellivision game development. Daglow created \"Utopia\", a precursor to the sim genre and, with Eddie Dombrower, the ground breaking sports simulation \"World Series Major League Baseball\". Daglow was also involved with the popular Intellivision games \"Tron Deadly Discs\" and \"Shark! Shark!\". After Mattel Electronics closed in 1984, their programmers would go on to make significant contributions to the video game industry. Don Daglow and Eddie Dombrower went on to Electronic Arts to create \"Earl Weaver Baseball\", and Don Daglow founded Stormfront Studios. Bill Fisher, Steve Roney and Mike Breen founded Quicksilver Software and David Warhol founded Realtime Associates.\n\nFrom the beginning, Intellivision's packaging and promotional materials, as well as television commercials, promised the addition of a soon-to-be-available accessory called the \"Keyboard Component\". The Intellivision was designed as a modular home computer. The \"Master Component\" could be purchased as a stand-alone video game system and the \"Keyboard Component\" could be added, providing the computer keyboard and tape drive. Not meant to be a hobbyist or business computer, the Intellivision home computer was meant to run pre-programmed software and bring \"data flow\" (Videotex) into the home.\n\nThe Keyboard Component added an 8-bit 6502 processor making the Intellivision a dual processor computer. It had 16K 10-bit shared RAM that could load and execute both Intellivision CP1610 and 6502 program code from tape; a large amount as typical cartridges of the day were 4K. The cassettes have two tracks of digital data and two tracks of analog audio completely controlled by the computer. Two tracks are read only for the software, and two tracks for user data. The tape-drive was block addressed with high speed indexing. A high resolution 40x24 monochrome text display could overlay regular Intellivision graphics. There was an input for a microphone and two additional expansion ports for peripherals and RAM expansion. The Microsoft BASIC programming cartridge used one of these ports. Expanded memory cartridges could support 1000 8KB pages. A third pass-through cartridge port was for regular Intellivision cartridges. It uses the Intellivision's power supply. A 40-column thermal printer was available, and a telephone modem was planned along with voice synthesis and voice recognition.\n\nDavid Rolfe of APh wrote a control program for the Keyboard Component called \"PicSe\" (Picture Sequencer) specifically for the development of multimedia applications. PicSe synchronized the graphics and analog audio while concurrently saving or loading data to tape. Productivity software for home finances, personal improvement, and self education were planned. Subject experts were consulted and their voices recorded and used in the software.\n\nThree applications using the PicSe system were released on cassette tape: \nBULLET::::- \"Conversational French\"\nBULLET::::- \"Jack Lalanne's Physical Conditioning\"\nBULLET::::- \"Spelling Challenge\"\n\nFive BASIC applications were released on tape: \"Programs written in BASIC did not have access to Intellivision graphics and were sold at a lower price.\"\nBULLET::::- \"Family Budgeting\"\nBULLET::::- \"Geography Challenge\"\nBULLET::::- \"Crosswords I, II, and III\"\n\nWhile the Keyboard Component was an ambitious piece of engineering for its time it was repeatedly delayed as the engineers tried to reduce manufacturing costs. In August 1979 the Intellivision Keyboard Component, in breadboard form, was successfully entered into the Sears Market Research Program. In December 1979 Mattel had production design working units but decided on a significant internal design change to consolidate circuit boards. In September 1980 it was test marketed in Fresno, California but without software, except for the BASIC programming cartridge. In the fall of 1981 design changes were finally implemented and the \"Keyboard Component\" was released at $600 in Seattle and New Orleans only. Those that complained in writing could buy a Keyboard Component directly from Mattel. The printer, a rebadged Alphacom Sprinter 40, was only available by mail order.\n\nThe keyboard component's repeated delays became so notorious around Mattel headquarters that comedian Jay Leno, when performing at Mattel's 1981 Christmas party, got his biggest titter of the evening with the line: \"You know what the three big lies are, don't you? 'The check is in the mail,' 'I'll still respect you in the morning,' and 'The keyboard will be out in spring.'\"\n\nComplaints from consumers who had chosen to buy the Intellivision specifically on the promise of a \"coming soon\" personal-computer upgrade, eventually caught the attention of the Federal Trade Commission (FTC), who started investigating Mattel Electronics for fraud and false advertising. In mid-1982 the FTC ordered Mattel to pay a monthly fine (said to be $10,000) until the promised computer upgrade was in full retail distribution. To protect themselves from the ongoing fines, the Keyboard Component was officially canceled in August 1982 and the Entertainment Computer System (ECS) module offered up in its place. Part of Mattel's settlement with the FTC involved offering to buy back all of the existing Keyboard Components from customers. Mattel provided a full refund but without a receipt paid $550 for the Keyboard Component, $60 for the BASIC cartridge, and $30 for each cassette software. Any customer who opted to keep theirs was required to sign a waiver with the understanding that no more software would be written for the system and absolved Mattel of any future responsibility for technical support. They were also compensated with $1000 worth of Mattel Electronics products.\n\nWhile approximately 4,000 Keyboard Components were manufactured, it is not clear how many of them actually found their way into the hands of Intellivision customers. Today, very few of them still exist. Many of the units were dismantled for parts. Others were used by Mattel Electronics programmers as part of their development system. A Keyboard Component could be interfaced with an Intellivision development system in place of the hand-built Magus board RAM cartridge. Data transfer to the Keyboard Component RAM had to be done serially and was slower compared with the Magus board parallel interface.\n\nThe keyboard component debacle was ranked as No. 11 on \"GameSpy\"s \"25 dumbest moments in gaming\".\n\nIn mid-1981, Mattel's upper management was becoming concerned that the keyboard component division would never be able to produce a sellable product. As a result, Mattel Electronics set up a competing internal engineering team whose stated mission was to produce an inexpensive add-on called the \"Basic Development System\", or BDS, to be sold as an educational device to introduce kids to the concepts of computer programming.\n\nThe rival BDS engineering group, who had to keep the project's real purpose a secret among themselves, fearing that if David Chandler, the head of the keyboard component team, found out about it he would use his influence to end the project, eventually came up with a much less expensive alternative. Originally dubbed the \"Lucky\", from LUCKI: Low User-Cost Keyboard Interface, it lacked many of the sophisticated features envisioned for the original keyboard component. Gone, for example, was the 16K (8MB max) of RAM, the secondary CPU, and high resolution text; instead, the ECS offered a mere 2KB RAM expansion, a built-in BASIC that was marginally functional, plus a much-simplified cassette and printer interface.\n\nUltimately, this fulfilled the original promises of turning the Intellivision into a computer, making it possible to write programs and store them to tape, and interfacing with a printer well enough to allow Mattel to claim that they had delivered the promised computer upgrade and stop the FTC's mounting fines. It even offered, via an additional sound chip (AY-3-8917) inside the ECS module and an optional 49-key music synthesizer keyboard, the possibility of turning the Intellivision into a multi-voice synthesizer which could be used to play or learn music.\n\nIn the fall of 1982, the LUCKI, now renamed the Entertainment Computer System (ECS), was presented at the annual sales meeting, officially ending the ill-fated keyboard component project. A new advertising campaign was aired in time for the 1982 Christmas season, and the ECS itself was shown to the public at the January 1983 Consumer Electronics Show (CES) in Las Vegas. A few months later, the ECS hit the market, and the FTC agreed to drop the $10K per day fines.\n\nBy the time the ECS made its retail debut as the Intellivision Computer Module, an internal shake-up at the top levels of Mattel Electronics' management had caused the company's focus to shift away from hardware add-ons in favor of software, and the ECS received very little in terms of furthering the marketing push. Further hardware developments, including a planned Program Expander that would have added another 16K of RAM and a more intricate, fully featured Extended-BASIC to the system, were halted. In the end a half-dozen software titles were released for the ECS; a few more were completed but not released.\n\nThe ECS also offered four player game-play with the optional addition of two extra hand controllers. Four player games were in development when Mattel Electronics closed in 1984. \"World Cup Soccer\" was later completed and released in 1985 by Dextel in Europe and then INTV Corporation in North America. The documentation does not mention it but when the ECS Computer Adapter is used, \"World Cup Soccer\" can be played with one to four players, or two players cooperatively against the computer.\n\nIn 1982 Mattel introduced a new peripheral for the Intellivision: the \"Intellivoice Voice Synthesis Module\". A speech synthesizer which produces speech with compatible cartridges. The Intellivoice was original in two respects: human sounding male and female voices with distinct accents, and the speech-supporting games were designed with speech being an integral part of the game-play.\n\nLike the Intellivision chip-set, the Intellivoice chip-set was developed by General Instrument. The SP0256-012 orator chip has 2KB ROM inside, and is used to store the speech for numerical digits, some common words, and the phrase \"Mattel Electronics presents\". Speech can also be processed from the Intellivoice's SP650 buffer chip, stored and loaded from cartridge memory. That buffer chip has its own I/O and the Intellivoice has a 30-pin expansion port under a removable top plate. Mattel Electronics planned to use that connector for wireless hand controllers.\n\nMattel Electronics built a state of the art voice processing lab to produce the phrases used in Intellivoice games. However, the amount of speech that could be compressed into an 8K or 12K cartridge and still leave room for a game was limited. Intellivoice cartridges \"Space Spartans\" and \"B-17 Bomber\" did sell about 300,000 copies each, priced a few dollars more than regular Intellivision cartridges. However, at $79 the Intellivoice did not sell as well as Mattel expected, and Intellivoices were later offered free with the purchase of a Master Component. In August 1983 the Intellivoice system was quietly phased out. A children's title called \"Magic Carousel\", and foreign language versions of \"Space Spartans\" were completed but shelved. Additional games \"Woody Woodpecker\" and \"Space Shuttle\" went unfinished with the voice recordings unused.\n\nThe four titles available for the Intellivoice system, in order of their release, were:\n\nBULLET::::- \"Space Spartans\"\nBULLET::::- \"B-17 Bomber\"\nBULLET::::- \"Bomb Squad\"\n\nA fifth title, \"Intellivision World Series Major League Baseball\", developed as part of the Entertainment Computer System series, also supports the Intellivoice if both the ECS and Intellivoice are connected concurrently. Unlike the Intellivoice-specific games, however, \"World Series Major League Baseball\" is also playable without the Intellivoice module (but not without the ECS).\n\nIn the spring of 1983, Mattel introduced the \"Intellivision II\". It was not the technology upgrade that was expected, but a cheaper, compact replacement to the original. The Intellivision II was designed to be inexpensive to manufacture and service, with updated styling. It also had longer controller cords. The Intellivision II was initially released without a pack-in game but was later packaged with BurgerTime in the United States and Lock'N'Chase in Canada. In 1984 the Digiplay Intellivision II was introduced in Brazil. Brazil was the only country outside North America to have the redesigned Intellivision II.\n\nUsing an external AC Adapter (16.2VAC), consolidating some ICs, and taking advantage of relaxed FCC emission standards, the Intellivision II has a significantly smaller footprint than the original. The controllers, now detachable, have a different feel, with plastic rather than rubber side buttons and a flat membrane keypad. Users of the original Intellivision missed the ability to find keypad buttons by the tactile feel of the original controller bubble keypad.\n\nOne functional difference was the addition of a video input to the cartridge port, added specifically to support the System Changer. The System Changer, also released in 1983 by Mattel, is an Intellivision peripheral that plays Atari 2600 cartridges through the Intellivision. The Intellivision hand controllers can be used to play Atari 2600 games. The System Changer also has two controller ports compatible with Atari joysticks. The original Intellivision requires a hardware modification in order to work with the \"System Changer\"; a service provided by Mattel. Otherwise the Intellivision II was promoted to be compatible with the original.\n\nIt was discovered that a few Coleco Intellivision games did not work on the Intellivision II. Mattel secretly changed the Intellivision's internal ROM program (Exec) in an attempt to lock out 3rd party titles. A few of Coleco's early games were affected but the 3rd party developers quickly figured out how to get around it. Mattel's own \"Electric Company Word Fun\", however, will not run on the Intellivision II due to this change. In an unrelated issue but also due to Exec changes, Super Pro Football experiences a minor glitch where the quarterback does not appear until after the ball is hiked. There were also some minor changes to the sound chip (AY-3-8914A/AY-3-8916) affecting sound effects in some games. Programmers at Mattel discovered the audio differences and avoided the problem in future games.\n\nDave Chandler's group began designing Mattel's next generation console in 1981 codenamed \"Decade\", now referred to as the \"Intellivision IV\". It was based on the 32-bit MC68000 processor and a 16-bit custom designed advanced graphic interface chip. Specifications called for dual display support, 240x192 bitmap resolution, 16 programmable 12-bit colors (4096 colors), antialiasing, 40x24 tiled graphics modes, four colors per tile (16 with shading), text layer and indepdendent scrolling, 16 multicolored 16x16 sprites per scan-line, 32 level hardware sprite scaling. Line interrupts for reprogramming sprite and color registers allow for many more sprites and colors on screen at the same time.. A machine that could lead Mattel Electronics into the 1990s, however on August 4, 1983 most hardware people at Mattel Electronics had been laid off.\n\nIn 1982, with new machines introduced by competitors, Mattel marketing wanted to bring an upgraded system to market sooner. The \"Intellivision III\" was to be an upgraded but backward compatible system; based on a similar CP1610 processor and with an improved graphics STIC chip producing double the resolution with more sprites and colors. The Intellivision III existed in the lab and a new EXEC was written for it but little else. It was cancelled in mid-1983. A Mattel document called \"Target Specification Intellivision III\" has the following.\n\nBULLET::::- CPU: CP1610-2 at 3.56 MHz (2x original CPU speed)\nBULLET::::- separate 16-bit data bus and address bus\nBULLET::::- multiplexed data/address mode for backward compatibility with existing cartridges\nBULLET::::- Graphics: STIC 1B\nBULLET::::- tiled graphics, 20 cards by 24 rows\nBULLET::::- 2-color 16x8 pixel cards for a resolution of 320x192\nBULLET::::- 4-color 8x8 pixel cards for a resolution of 160x192\nBULLET::::- 40 x 24 alphanumerics\nBULLET::::- 16 programmable colors\nBULLET::::- color palette selectable per card\nBULLET::::- 12-bit RGB definition for 4096 possible colors\nBULLET::::- 8 sprites per scanline\nBULLET::::- reusable on different scanlines\nBULLET::::- 16 pixels wide in 1 color, 8 pixels wide in 3 colors\nBULLET::::- up-to 255 lines high\nBULLET::::- overlap detect of individual colors\nBULLET::::- fine pixel horizontal and vertical scrolling (backward compatible)\nBULLET::::- single data bus allows graphics rom/ram storage on cartridges\nBULLET::::- STIC 1 backwards compatible mode\nBULLET::::- RAM: 4K words, 16-bit, DRAM (upgradable to 65K words)\nBULLET::::- five channel sound with improved frequency range (backward compatible)\nBULLET::::- integrated Intellivoice\n\nAccording to the company's 1982 Form 10-K, Mattel had almost 20% of the domestic video-game market. Mattel Electronics provided 25% of revenue and 50% of operating income in fiscal 1982. Although the Atari 2600 had more third-party development, \"Creative Computing Video & Arcade Games\" reported after visiting the summer 1982 Consumer Electronics Show that \"The momentum is tremendous\". Activision and Imagic began releasing games for the Intellivision, as did hardware rival Coleco. Mattel created \"M Network\" branded games for Atari's system. The company's advertisement budget increased to over $20 million for the year. In its October 1982 stockholders' report Mattel announced that \"Electronics\" had, so far that year, posted a nearly $100 million profit on nearly $500 million sales; a threefold increase over October 1981.\n\nHowever, the same report predicted a loss for the upcoming quarter. Still hiring continued, and optimism that the investment in software and hardware development will payoff. The \"M Network\" brand expanded to personal computers. An office in Taiwan was opened to handle Apple II programming. The original five-person Mattel game development team had grown to 110 people under new vice president Baum, while Daglow led Intellivision development and top engineer Minkoff directed all work on all other platforms. In February 1983, Mattel Electronics opened an office in the south of France to provide European input to Intellivision games and develop games for the ColecoVision. At its peak Mattel Electronics employed 1800 people.\n\nAmid the flurry of new hardware and software development, there was trouble for the Intellivision. New game systems (ColecoVision and Atari 5200) introduced in 1982 took advantage of falling RAM prices to offer graphics closer to arcade quality. In 1983 the price of home computers, particularly the Commodore 64, came down drastically to compete with video game system sales. The market became flooded with hardware and software, and retailers were ill-equipped to cope. In spring 1983 hiring at Mattel Electronics came to a halt.\n\nAt the June 1983 Consumer Electronics Show in Chicago, Mattel Electronics had the opportunity to show off all their new products. The response was underwhelming. Amidst massive losses, top management was replaced. On July 12, 1983, Mattel Electronics President Josh Denham was replaced with outsider Mack Morris. Morris brought in former Mattel Electronics president and marketing director Jeff Rochlis as a consultant and all projects were under review. The Intellivision III was cancelled and then all new hardware development was stopped when 660 jobs were cut on August 4. The price of the Intellivision II (which launched at $150 earlier that year) was lowered to $69, Mattel Electronics was to be a software company. However, by October 1983 \"Electronics\"' losses were over $280 million for the year and one third of the programming staff were laid off. In November another third were gone, and on January 20, 1984 the remaining programming staff were laid-off. The Taiwan and French offices continued a little while longer due to contract and legal obligations. On February 4, 1984 Mattel sold the Intellivision business for $20 million. In 1983, 750,000 Intellivision Master Components were sold, more than three million units from 1980 to 1983.\n\nFormer Mattel Electronics Senior Vice President of Marketing, Terrence Valeski, understood that although losses were huge, the demand for video games increased in 1983. Valeski found investors and purchased the rights to Intellivision, the games, and inventory from Mattel. A new company, Intellivision Inc, was formed and by the end of 1984 Valeski bought out the other investors and changed the name to INTV Corporation. They continued to supply the large toy stores and sold games through direct mail order. At first they sold the existing inventory of games and Intellivision II systems. When the inventory of games sold out they produced more, but without the Mattel name or unnecessary licenses on the printed materials. To lower costs, the boxes, instructions, and overlays were produced at lower quality compared to Mattel.\n\nIn France, the Mattel Electronics office found investors and became Nice Ideas in April 1984. They continued to work on Intellivision, Colecovision, and other computer games. They produced Intellivision \"World Cup Soccer\" and \"Championship Tennis\", both released in 1985 by European publisher Dextel.\n\nIn 1985 INTV Corporation introduced the \"INTV System III\", also branded as the \"Intellivision Super Pro System\", using the same design as the original Intellivision model but in black and silver. That same year INTV Corp introduced two new games that were completed at Mattel but not released: \"Thunder Castle\" and \"World Championship Baseball\". With their early success INTV Corp decided to produce new games and in 1986 introduced \"Super Pro Football\", an update of Mattel \"NFL Football\". INTV Corp continued a relationship that Mattel had with Data East and produced all new titles such as \"Commando\" in 1987 and \"Body Slam Wrestling\" in 1988. Also in 1987 INTV Corp released \"Dig Dug\", purchased from Atari where the game was completed but not released in 1984. They also got into producing next generation games with the production of \"Monster Truck Rally\" for Nintendo Entertainment System (NES) in 1991, also released as \"Stadium Mud Buggies\" for Intellivision in 1989.\n\nLicensing agreements with Nintendo and Sega required INTV Corporation to discontinue the Intellivision in 1990. INTV Corporation did publish 21 new Intellivision cartridges bringing the Intellivision library to a total of 124 cartridges plus one compilation cartridge.\n\nIn 1989 INTV Corp and World Book Encyclopedia entered into an agreement to manufacture an educational video game system called Tutorvision. It is a modified Intellivision, the case molded in light beige with gold and blue trim. The Exec ROM expanded, system RAM increased to 1.75K, and graphics RAM increased to 2KB. That is enough graphics RAM to define unique graphic tiles for the entire screen.\n\nGames were designed by World Book, \"J. Hakansson Associates\", and programmed by Realtime Associates. Sixteen titles were in production, plus one Canadian variation. However, the cartridges and the Tutorvision were never released; instead World Book and INTV Corporation sued each other. In 1990 INTV Corporation filed for bankruptcy protection and closed in 1991.\n\nAn unknown number of later Intellivision SuperPro systems have Tutorvision hardware inside. A subset of these units contain the full Tutorvision EXEC and can play Tutorvision games.\n\nIntellivision games became readily available again when Keith Robinson and Stephen Roney, both former Intellivision programmers at Mattel Electronics, obtained exclusive rights to the Intellivision and games in 1997. That year they formed \"Intellivision Productions\" and made \"Intellivision for PC Volume 1\" available as a free download. Intellivision games could be played on a modern computer for the first time. That download includes three Intellivision games and an MS-DOS Intellivision emulator that plays original game code. It was followed by \"Volume 2\" and another three games including \"Deep Pockets Super Pro Pool & Billiards\"; a game completed in 1990 but never released until this download in 1997. In 2000 the \"Intellipack 3\" download was available with another four Intellivision games and emulators for Windows or Macintosh.\n\nIntellivision Productions released \"Intellivision Lives!\" and \"Intellivision Rocks\" on compact disc in 1998 and 2001. These compilation CDs play the original game code through emulators for MS-DOS, Windows, and Macintosh computers. Together they have over 100 Intellivision games including never before released \"King of the Mountain, Takeover, Robot Rubble\", \"League of Light\", and others. Intellivision Rocks includes Intellivision games made by Activision and Imagic. Some games could not be included due to licensing, others simply used different titles to avoid trademarked names. The CDs are also a resource for development history, box art, hidden features, programmer biographies, video interviews, and original commercials.\n\nAlso in 1997 Intellivision Productions announced they would sell development tools allowing customers to program their own Intellivision games. They were to provide documentation, PC compatible cross-assemblers, and the \"Magus II\" PC Intellivision cartridge interface. Unfortunately, the project was cancelled but they did provide copies of \"Your Friend the EXEC\", the programmers guide to the Intellivision Executive control software. By 2000 Intellivision hobbyists ultimately created their own development tools, including Intellivision memory cartridges.\n\nIn 2005 Intellivision Productions announced that new Intellivision cartridges were to be produced. \"Deep Pockets and Illusions will be the first two releases in a series of new cartridges for the Intellivision. The printed circuit boards, the cartridge casings, the boxes are all being custom manufactured for this special series.\" \"Illusions\" was completed at Mattel Electronics' French office in 1983 but never released. \"Deep Pockets Super Pro Pool & Billiards\" was programmed for INTV Corporation in 1990 and only released as a ROM file in 1998. However, no cartridges were produced. Previously, in 2000, Intellivision Productions did release new cartridges for the Atari 2600 and Colecovision. \"Sea Battle\" and \"Swordfight\" were Atari 2600 games created by Mattel Electronics in the early 1980s but not previously released. \"Steamroller\" (Colecovision) was developed for Activision in 1984 and not previously released.\n\nAlso in 1999, Activision released \"A Collection of Intellivision Classic Games\" for PlayStation. Also known as \"Intellivision Classics\", it has 30 emulated Intellivision games as well as video interviews of some of the original programmers. All of the games were licensed from Intellivision Productions and none of the Activision or Imagic Intellivision games were included. In 2003, Crave Entertainment released a PlayStation 2 version of Intellivision Lives! and then Xbox and GameCube version in 2004. In 2010 Virtual Play Games released Intellivision Lives! for the Nintendo DS including one never before released game, \"Blow Out\". In 2008 Microsoft made Intellivision Lives! an available download on the Xbox Live Marketplace as an Xbox Original and playable on the Xbox 360.\n\nIn 2003, the Intellivision 25 and Intellivision 15 direct-to-TV systems were released by Techno Source Ltd. These are an all-in-one single controller design that plugs directly into a television. One includes 25 games the other ten. These Intellivision games were not emulated but rewritten for the native processor (Nintendo NES compatible) and adapted to a contemporary controller. As such they look and play differently than Intellivision. In 2005 they were updated for two-player play as the Intellivision X2 with 15 games. They were commercially very successful altogether selling about 4 million units by end of 2006.\n\nSeveral licensed Intellivision games became available to Windows computers through the GameTap subscription gaming service in 2005 including \"Astrosmash, Buzz Bombers, Hover Force, Night Stalker, Pinball, Shark! Shark!, Skiing and Snafu\". Installation of the GameTap Player software was required to access the emulator and games. The VH1 Online Arcade made nine Intellivision games available in 2007. Using a Shockwave emulator these Intellivision games could be played directly through a web browser with Shockwave Player. In 2010 VH1 Classic and MTV Networks released 6 Intellivision games to iOS. Intellivision games were first adapted to mobile phones and published by THQ Wireless in 2001. On March 24, 2010, Microsoft launched the Game Room service for Xbox Live and Games for Windows Live. This service includes support for Intellivision titles and allows players to compete against one another for high scores via online leaderboards. At the 2011 Consumer Electronics Show, Microsoft announced a version of Game Room for Windows Phone, promising a catalog of 44 Intellivision titles. AtGames and their Direct2Drive digital store has Windows compatible Intellivision compilations available for download purchase.\n\nThe number of Intellivision games that can be played effectively with contemporary game controllers is limited. On October 1, 2014, AtGames Digital Media, Inc., under license from Intellivision Productions, Inc., released the Intellivision Flashback classic game console. It is a miniature sized Intellivision console with two original sized Intellivision controllers. While adapters have been available to interface original Intellivision controllers to personal computers, the Intellivision Flashback includes two new Intellivision controllers identical in layout and function to the originals. It comes with 60 emulated Intellivision games built into ROM and a sample set of plastic overlays for 10 games. The Advanced Dungeons & Dragons games were included as \"Crown of Kings\" and \"Minotaur\". As with many of the other Intellivision compilations, no games requiring third party licensing were included.\n\nIn May 2018, Tommy Tallarico announced that he plans to launch a new Intellivision console system, and formed a new company \"Intellivision Entertainment\", serving as president. \"Intellivision Productions\" has been renamed \"Blue Sky Rangers Inc.\" and their video game intellectual property has been transferred to \"Intellivision Entertainment\". At the Portland Retro Gaming Expo, in October 2018, the Intellivision Amico was officially revealed.\n\nKen Uston published \"Ken Uston's Guide to Buying and Beating the Home Video Games\" in 1982 as a guide to potential buyers of console systems/cartridges, as well as a brief strategy guide to numerous cartridge games then in existence. He described Intellivision as \"the most mechanically reliable of the systems… The controller (used during \"many hours of experimentation\") worked with perfect consistency. The unit never had overheating problems, nor were loose wires or other connections encountered.\" However, Uston rated the controls and control system as \"below average\" and the worst of the consoles he tested (including Atari 2600, Magnavox Odyssey², Astrovision, and Fairchild Channel F).\n\nJeff Rovin lists \"Intellivision\" as one of the seven major suppliers of videogames in 1982, and mentions it as \"the unchallenged king of graphics\", however stating that the controllers can be \"difficult to operate\", the fact that if a controller breaks the entire unit must be shipped off for repairs (since they did not detach at first), and that the overlays \"are sometimes so stubborn as to tempt one's patience\" .\n\nA 1996 article in \"Next Generation\" said the Intellivision \"had greater graphics power than the dominant Atari 2600. It was slower than the 2600 and had less software available, but it was known for its superior sports titles.\" A year later \"Electronic Gaming Monthly\" assessed the Intellivision in an overview of older gaming consoles, remarking that the controllers \"were as comfortable as they were practical. The unique disk-shaped directional pad provided unprecedented control for the time, and the numeric keypad opened up new options previously unavailable in console gaming.\" They praised the breadth of the software library but said there was a lack of genuinely stand-out games.\n\nBULLET::::- Intellivision can be considered the first 16-bit game console, as it has a 16-bit microprocessor.\nBULLET::::- The first home console and one of the first video games to use a tile based playfield. It allowed for the display of detailed graphics and colour with very little RAM.\nBULLET::::- The Intellivision was also the first system to feature downloadable games with PlayCable in 1981.\nBULLET::::- Intellivision was the first game console to provide real-time human voices in the middle of gameplay, courtesy of the Intellivoice module.\nBULLET::::- The first game controller with a directional thumb pad.\nBULLET::::- The Intellivision was also the first game console or home computer to offer a musical synthesizer keyboard.\nBULLET::::- Intellivision was also the first console to have a complete built-in character font. While Odyssey² had a limited character font (uppercase alphabet, numerals, and some other characters), Intellivision's system font had complete upper- and lowercase alphabets, numerals, and almost all of the punctuation and symbols found on standard computer keyboards.\nBULLET::::- \"Utopia\" (1982) is credited as the game that spawned the construction and management simulation genre.\nBULLET::::- World Series Major League Baseball (1983) is considered to be the first sports simulation video game with a number of innovations: multiple views of a 3D calculated virtual play-field, statistical based game-play using real historical baseball player statistics, manager player substitutions, play-by-play speech, and save games or lineups to tape storage.\n\n\"Intellivision, Super Video Arcade, Tandyvision One, Intellivision II, INTV System III, Super Pro System\"\nBULLET::::- General Instrument CP1610 16-bit microprocessor CPU\nBULLET::::- 1 microsecond cycle time, 2 MHz 2-phase clock (1.117 µs and 1.7897725 MHz NTSC)\nBULLET::::- 16-bit multiplexed data/address bus\nBULLET::::- 1456 bytes of RAM (SRAM):\nBULLET::::- 240 × 8-bit scratchpad memory\nBULLET::::- 352 × 16-bit (704 bytes) system memory, General Instrument RA-3-9600 dual ported, bridges CPU and STIC buses, 240 words used for graphics\nBULLET::::- 512 × 8-bit graphics RAM\nBULLET::::- 7168 bytes of ROM:\nBULLET::::- 4096 × 10-bit (5120 bytes) executive ROM (4352 x 10-bit Intellivision II)\nBULLET::::- 2048 × 8-bit graphics ROM (344 bytes used by Exec program)\nBULLET::::- Standard Television Interface Chip (STIC): General Instrument AY-3-8900/AY-3-8900-1\nBULLET::::- operates at 4 MHz or 3.579545 Mhz (NTSC)\nBULLET::::- 14-bit multiplexed data/address bus shared with CPU\nBULLET::::- 20x12 tiled playfield, tiles are 8x8 pixels for a resolution of 159x96 (right pixel not displayed)\nBULLET::::- 16 color palette, two colors per tile\nBULLET::::- \"Foreground/Background\" mode; all 16 colors available for background and colors 1-8 available for foreground per tile; grom cards limited to the first 64\nBULLET::::- \"Color Stack\" mode; all 16 colors available for foreground per tile; background colour from a four colour rotating stack of any four colors, all 277 grom and gram cards available\nBULLET::::- \"Colored Squares\" mode allows each tile to have four different colored 4x4 blocks as in \"Snafu\"); first seven colors available for foreground blocks; background colour from the color stack\nBULLET::::- 8 sprites (all visible on the same scanline). Hardware supports the following features per-sprite:\nBULLET::::- coordinate addressable off screen for smooth edge entries and exits\nBULLET::::- Size selection: 8x16 or 8 pixels wide by 8 half-pixels high\nBULLET::::- Stretching: horizontal (1× or 2×) and vertical (1×, 2×, 4× or 8×)\nBULLET::::- Mirroring: horizontal and vertical\nBULLET::::- Collision detection: sprite to sprite, sprite to background, and sprite to screen border\nBULLET::::- Priority: selects whether sprite appears in front of or behind background.\nBULLET::::- fine horizontal and vertical pixel scrolling\nBULLET::::- all STIC attributes and GRAM re-programmable at VBLANK, 60 times a second\nBULLET::::- Three-channel sound, with one noise generator, audio chip: General Instrument AY-3-8914 (AY-3-8914A/AY-3-8916 Intellivision II)\nBULLET::::- Connections:\nBULLET::::- 44-pin cartridge/expansion port\nBULLET::::- 64K addressable (approx 50K available), more with memory bank switching\nBULLET::::- typical cartridges: 4K, 6K, 8K, 12K, 16K, 24K (10-bit ROMs)\nBULLET::::- 2 x 9-pin controller connectors\nBULLET::::- \"inline pin connectors internally accessible on original Intellivision and INTV systems\"\nBULLET::::- \"DE-9 connectors externally accessible on Super Video Arcade and Intellivision II\"\nBULLET::::- RF/RCA audio/video connector; RGB/scart/péritel in France\nBULLET::::- Intellivision II only: external power adapter 16.7Vac 1amp or 16.2Vac 955mA\n\nThe Intellivision controller features:\n\nBULLET::::- 12-button numeric keypad (0-9, \"clear\", and \"enter\")\nBULLET::::- Four side-located action buttons (two for left handed players, two for right handed players)\nBULLET::::- \"top two side buttons are electronically the same, giving three distinct buttons\"\nBULLET::::- A directional pad, capable of detecting 16 directions of movement\nBULLET::::- Plastic overlays that slide into place as an extra layer on the keypad to show game-specific key functions\n\nThe directional pad was called a \"control disc\" and marketed as having the \"functionality of both a joystick and a paddle\". The controller was ranked the fourth worst video game controller by IGN editor Craig Harris.\n\nBULLET::::- Keyboard Component \"(limited availability)\"\nBULLET::::- 6502 CPU, 16K x 10-bit SRAM, 40x24 text overlay, tape-drive, microphone input, two expansion ports\nBULLET::::- PlayCable \"(availability through cable TV provider 1981-1983)\"\nBULLET::::- \"Mattel and General Instrument joint venture, manufactured by GI/Jerrold\"\nBULLET::::- 8K x 10bit RAM\nBULLET::::- Intellivoice Voice Synthesis Module\nBULLET::::- General Instrument SP0256-012\nBULLET::::- Computer Module \"(includes the following)\"\nBULLET::::- Computer Adapter\nBULLET::::- 2K x 8-bit SRAM, 12K ECS Exec/BASIC ROM, memory expansion port (discontinued)\nBULLET::::- AY-3-8917 sound generator\nBULLET::::- two DE-9 hand controller connectors\nBULLET::::- audio tape recorder data storage interface, two 3.5mm mono jacks and one 2.5mm jack for optional tape control\nBULLET::::- auxiliary jack for a serial printer connection (Mattel Aquarius compatible), 3.5mm stereo jack that is RS-232C compatible, where tip is data transmit, ring is DSR/DCD, sleeve is ground, 1200 baud, 8 data bits, 2 stop bits, and no parity\nBULLET::::- external power adapter 10Vac 1amp\nBULLET::::- Computer Keyboard\nBULLET::::- Music Synthesizer \"(requires Computer Adapter)\"\nBULLET::::- 49 key piano keyboard\nBULLET::::- System Changer\nBULLET::::- Atari 2600 compatible cartridge slot\nBULLET::::- two DE-9 Atari 2600 compatible controller connectors\nBULLET::::- Videoplexer (from Compro Electronics)\nBULLET::::- cartridge switching accessory with eight cartridge slots\n\nBULLET::::- List of Intellivision games\nBULLET::::- PlayCable\nBULLET::::- Entertainment Computer System\nBULLET::::- Intellivoice\nBULLET::::- Intellivision Lives!\nBULLET::::- TV POWWW (interactive TV game show that used Intellivision)\n\nBULLET::::- Intellivision retrogaming company homepage, run by Keith Robinson and The Blue Sky Rangers (the Intellivision game programmers)\nBULLET::::- The history of the Intellivision, at The Dot Eaters\nBULLET::::- Video Game Console Library entry\nBULLET::::- TheGameConsole.com entry\nBULLET::::- Old-Computers.com entry\nBULLET::::- 8-bit Central.com entry & images\nBULLET::::- Science Museum Group entry\nBULLET::::- Games Database.org entry.\nBULLET::::- Console Passion UK entry & games catalog\nBULLET::::- Gamasutra - A History of Gaming Platforms: Mattel Intellivision, by Bill Loguidice and Matt Barton (Backup copy)\nBULLET::::- 1980 ad of Atari 2600 & Intellivision comparison at MSN\n"}
{"id": "15316", "url": "https://en.wikipedia.org/wiki?curid=15316", "title": "Imperialism", "text": "Imperialism\n\nImperialism is a policy or ideology of extending a country's rule over foreign nations, often by military force or by gaining political and economic control of other areas. Imperialism was both normal and common \"worldwide\" throughout recorded history, the earliest examples dating from the mid-third millennium BC. In recent times, it has been considered morally reprehensible and prohibited by international law. Therefore, the term is used in international propaganda to denounce an opponent's foreign policy.\n\nThe term can be applied to the colonization of the Americas between the 16th and 19th centuries, as opposed to New Imperialism, which describes the expansion of Western Powers and Japan during the late 19th and early 20th centuries. However, both are examples of imperialism.\n\nThe word imperialism originated from the Latin word \"imperium\", which means supreme power. It first became common with its current sense in Great Britain, during the 1870s and was used with a negative connotation. Previously the word imperialism had been used to describe to what was perceived as Napoleon III's attempts of obtaining political support through foreign military interventions. The term was and is mainly applied to Western (and Japanese) political and economic dominance especially in Asia and Africa, in the 19th and 20th centuries. Its precise meaning continues to be debated by scholars. Some writers, such as Edward Said, use the term more broadly to describe any system of domination and subordination organised with an imperial center and a periphery. This definition encompasses both nominal empires and neocolonialism.\n\n\"The word 'empire' comes from the Latin word imperium; for which the closest modern English equivalent would perhaps be 'sovereignty', or simply 'rule'\". The greatest distinction of an empire is through the amount of land that a nation has conquered and expanded. Political power grows from conquering land; however, cultural and economic aspects flourish through sea and trade routes. A distinction about empires is \"that although political empires were built mostly by expansion overland, economic and cultural influences spread at least as much by sea\". Some of the main aspects of trade that went overseas consisted of animals and plant products. European empires in Asia and Africa \"have come to be seen as the classic forms of imperialism: and indeed most books on the subject confine themselves to the European seaborne empires\". European expansion caused the world to be divided by how developed and developing nation are portrayed through the world systems theory. The two main regions are the core and the periphery. The core consists of areas of high income and profit; the periphery is on the opposing side of the spectrum consisting of areas of low income and profit. These critical theories of geo-politics have led to increased discussion of the meaning and impact of imperialism on the modern post-colonial world. The Russian leader Lenin suggested that \"imperialism was the highest form of capitalism, claiming that imperialism developed after colonialism, and was distinguished from colonialism by monopoly capitalism\". This idea from Lenin stresses how important new political world order has become in the modern era. Geopolitics now focuses on states becoming major economic players in the market; some states today are viewed as empires due to their political and economic authority over other nations.\nThe term \"imperialism\" is often conflated with \"colonialism\"; however, many scholars have argued that each have their own distinct definition. Imperialism and colonialism have been used in order to describe one's perceived superiority, domination and influence upon a person or group of people. Robert Young writes that while imperialism operates from the center, is a state policy and is developed for ideological as well as financial reasons, colonialism is simply the development for settlement or commercial intentions. However, colonialism still includes invasion. Colonialism in modern usage also tends to imply a degree of geographic separation between the colony and the imperial power. Particularly, Edward Said distinguishes the difference between imperialism and colonialism by stating; \"imperialism involved 'the practice, the theory and the attitudes of a dominating metropolitan center ruling a distant territory', while colonialism refers to the 'implanting of settlements on a distant territory.' Contiguous land empires such as the Russian or Ottoman have traditionally been excluded from discussions of colonialism, though this is beginning to change, since it is accepted that they also sent populations into the territories they ruled.\n\nImperialism and colonialism both dictate the political and economic advantage over a land and the indigenous populations they control, yet scholars sometimes find it difficult to illustrate the difference between the two. Although imperialism and colonialism focus on the suppression of \"an other\", if colonialism refers to the process of a country taking physical control of another, imperialism refers to the political and monetary dominance, either formally or informally. Colonialism is seen to be the architect deciding how to start dominating areas and then imperialism can be seen as creating the idea behind conquest cooperating with colonialism. Colonialism is when the imperial nation begins a conquest over an area and then eventually is able to rule over the areas the previous nation had controlled. Colonialism's core meaning is the exploitation of the valuable assets and supplies of the nation that was conquered and the conquering nation then gaining the benefits from the spoils of the war. The meaning of imperialism is to create an empire, by conquering the other state's lands and therefore increasing its own dominance. Colonialism is the builder and preserver of the colonial possessions in an area by a population coming from a foreign region. Colonialism can completely change the existing social structure, physical structure and economics of an area; it is not unusual that the characteristics of the conquering peoples are inherited by the conquered indigenous populations. Few colonies remain remote from their mother country. Thus, most will eventually establish a separate nationality or remain under complete control of their mother colony.\n\nStephen Howe has summarized his view on the beneficial effects of the colonial empires:\nA controversial aspect of imperialism is the defense and justification of empire-building based on seemingly rational grounds. In ancient China, Tianxia denoted the lands, space, and area divinely appointed to the Emperor by universal and well-defined principles of order. The center of this land was directly apportioned to the Imperial court, forming the center of a world view that centered on the Imperial court and went concentrically outward to major and minor officials and then the common citizens, tributary states, and finally ending with the fringe \"barbarians\". Tianxia's idea of hierarchy gave Chinese a privileged position and was justified through the promise of order and peace. J. A. Hobson identifies this justification on general grounds as: \"It is desirable that the earth should be peopled, governed, and developed, as far as possible, by the races which can do this work best, i.e. by the races of highest 'social efficiency'\". Many others argued that imperialism is justified for several different reasons. Friedrich Ratzel believed that in order for a state to survive, imperialism was needed. Halford Mackinder felt that Great Britain needed to be one of the greatest imperialists and therefore justified imperialism. The purportedly scientific nature of \"Social Darwinism\" and a theory of races formed a supposedly rational justification for imperialism. Under this doctrine, the French politician Jules Ferry could declare in 1883 that \"Superior races have a right, because they have a duty. They have the duty to civilize the inferior races.\" The rhetoric of colonizers being racially superior appears to have achieved its purpose, for example throughout Latin America \"whiteness\" is still prized today and various forms of blanqueamiento (whitening) are common.\n\nThe Royal Geographical Society of London and other geographical societies in Europe had great influence and were able to fund travelers who would come back with tales of their discoveries. These societies also served as a space for travellers to share these stories. Political geographers such as Friedrich Ratzel of Germany and Halford Mackinder of Britain also supported imperialism. Ratzel believed expansion was necessary for a state's survival while Mackinder supported Britain's imperial expansion; these two arguments dominated the discipline for decades.\n\nGeographical theories such as environmental determinism also suggested that tropical environments created uncivilized people in need of European guidance. For instance, American geographer Ellen Churchill Semple argued that even though human beings originated in the tropics they were only able to become fully human in the temperate zone. Tropicality can be paralleled with Edward Said's Orientalism as the west's construction of the east as the \"other\". According to Said, orientalism allowed Europe to establish itself as the superior and the norm, which justified its dominance over the essentialized Orient.\n\nTechnology and economic efficiency were often improved in territories subjected to imperialism through the building of roads, other infrastructure and introduction of new technologies.\n\nThe principles of imperialism are often generalizable to the policies and practices of the British Empire \"during the last generation, and proceeds rather by diagnosis than by historical description\". British imperialism in some sparsely-inhabited regions appears to have applied a principle now termed Terra nullius (Latin expression which stems from Roman law meaning 'no man's land'). The country of Australia serves as a case study in relation to British settlement and colonial rule of the continent in the 18th century, that was arguably premised on \"terra nullius\", as its settlers considered it unused by its original inhabitants.\n\nImperial control, territorial and cultural, is justified through discourses about the imperialists' understanding of different spaces. Conceptually, imagined geographies explain the limitations of the imperialist understanding of the societies (human reality) of the different spaces inhabited by the non–European Other.\n\nIn \"Orientalism\" (1978), Edward Said said that the West developed the concept of The Orient—an imagined geography of the Eastern world—which functions as an essentializing discourse that represents neither the ethnic diversity nor the social reality of the Eastern world. That by reducing the East into cultural essences, the imperial discourse uses place-based identities to create cultural difference and psychologic distance between \"We, the West\" and \"They, the East\" and between \"Here, in the West\" and \"There, in the East\".\n\nThat cultural differentiation was especially noticeable in the books and paintings of early Oriental studies, the European examinations of the Orient, which misrepresented the East as irrational and backward, the opposite of the rational and progressive West. Defining the East as a negative vision of the Western world, as its inferior, not only increased the sense-of-self of the West, but also was a way of ordering the East, and making it known to the West, so that it could be dominated and controlled. Therefore, Orientalism was the ideological justification of early Western imperialism—a body of knowledge and ideas that rationalized social, cultural, political, and economic control of other, non-white peoples.\n\nOne of the main tools used by imperialists was cartography. Cartography is \"the art, science and technology of making maps\" but this definition is problematic. It implies that maps are objective representations of the world when in reality they serve very political means. For Harley, maps serve as an example of Foucault's power and knowledge concept.\n\nTo better illustrate this idea, Bassett focuses his analysis of the role of 19th-century maps during the \"scramble for Africa\". He states that maps \"contributed to empire by promoting, assisting, and legitimizing the extension of French and British power into West Africa\". During his analysis of 19th-century cartographic techniques, he highlights the use of blank space to denote unknown or unexplored territory. This provided incentives for imperial and colonial powers to obtain \"information to fill in blank spaces on contemporary maps\".\n\nAlthough cartographic processes advanced through imperialism, further analysis of their progress reveals many biases linked to eurocentrism. According to Bassett, \"[n]ineteenth-century explorers commonly requested Africans to sketch maps of unknown areas on the ground. Many of those maps were highly regarded for their accuracy\" but were not printed in Europe unless Europeans verified them.\nImperialism in ancient times is clear in the history of China and in the history of western Asia and the Mediterranean—an unending succession of empires. The tyrannical empire of the Assyrians was replaced (6th–4th century BCE) by that of the Persians, in strong contrast to the Assyrian in its liberal treatment of subjected peoples, assuring it long duration. It eventually gave way to the imperialism of Greece. When Greek imperialism reached an apex under Alexander the Great (356–323 BCE), a union of the eastern Mediterranean with western Asia was achieved. But the cosmopolis, in which all citizens of the world would live harmoniously together in equality, remained a dream of Alexander. It was partially realized when the Romans built their empire from Britain to Egypt.\n\nCultural imperialism is an extremely fuzzy concept, pointing to the supposed influence of one dominant culture over others, i.e. a form of soft power, which changes the moral, cultural, and societal worldview of the subordinate country. In some ways, this is such an expansion of the concept of imperialism as to be meaningless. This is more than just \"foreign\" music, television or film becoming popular with young people, but that popular culture changing their own expectations of life and their desire for their own country to become more like the foreign country depicted. For example, depictions of opulent American lifestyles in the soap opera Dallas during the Cold War changed the expectations of Romanians; a more recent example is the influence of smuggled South Korean drama series in North Korea. The importance of soft power is not lost on authoritarian regimes, fighting such influence with bans on foreign popular culture, control of the internet and unauthorised satellite dishes etc. Nor is such a usage of culture recent, as part of Roman imperialism local elites would be exposed to the benefits and luxuries of Roman culture and lifestyle, with the aim that they would then become willing participants.\n\nImperialism has been subject to moral or immoral censure by its critics, and thus the term is frequently used in international propaganda as a pejorative for expansionist and aggressive foreign policy.\n\nThe Age of Imperialism, a time period beginning around 1760, saw European industrializing nations, engaging in the process of colonizing, influencing, and annexing other parts of the world. 19th century episodes included the \"Scramble for Africa.\"\n\nIn the 1970s British historians John Gallagher (1919–1980) and Ronald Robinson (1920–1999) argued that European leaders rejected the notion that \"imperialism\" required formal, legal control by one government over a colonial region. Much more important was informal control of independent areas. According to Wm. Roger Louis, \"In their view, historians have been mesmerized by formal empire and maps of the world with regions colored red. The bulk of British emigration, trade, and capital went to areas outside the formal British Empire. Key to their thinking is the idea of empire 'informally if possible and formally if necessary.'\" Oron Hale says that Gallagher and Robinson looked at the British involvement in Africa where they \"found few capitalists, less capital, and not much pressure from the alleged traditional promoters of colonial expansion. Cabinet decisions to annex or not to annex were made, usually on the basis of political or geopolitical considerations.\"\n\nLooking at the main empires from 1875–1914, historians estimate a mixed record in terms of profitability. At first planners expected that colonies would provide an excellent captive market for manufactured items. Apart from the Indian subcontinent, this was seldom true. By the 1890s, imperialists saw the economic benefit primarily in the production of inexpensive raw materials to feed the domestic manufacturing sector. Overall, Great Britain did very well in terms of profits from India, especially Mughal Bengal, but not from most of the rest of its empire. The Netherlands did very well in the East Indies. Germany and Italy got very little trade or raw materials from their empires. France did slightly better. The Belgian Congo was notoriously profitable when it was a capitalistic rubber plantation owned and operated by King Leopold II as a private enterprise. However, scandal after scandal regarding very badly mistreated labour led the international community to force the government of Belgium to take it over in 1908, and it became much less profitable. The Philippines cost the United States much more than expected because of military action against rebels.\n\nBecause of the resources made available by imperialism, the world's economy grew significantly and became much more interconnected in the decades before World War I, making the many imperial powers rich and prosperous.\n\nEurope's expansion into territorial imperialism was largely focused on economic growth by collecting resources from colonies, in combination with assuming political control by military and political means. The colonization of India in the mid-18th century offers an example of this focus: there, the \"British exploited the political weakness of the Mughal state, and, while military activity was important at various times, the economic and administrative incorporation of local elites was also of crucial significance\" for the establishment of control over the subcontinent's resources, markets, and manpower. Although a substantial number of colonies had been designed to provide economic profit and to ship resources to home ports in the 17th and 18th centuries, Fieldhouse suggests that in the 19th and 20th centuries in places such as Africa and Asia, this idea is not necessarily valid:\n\nDuring this time, European merchants had the ability to \"roam the high seas and appropriate surpluses from around the world (sometimes peaceably, sometimes violently) and to concentrate them in Europe\".\n\nEuropean expansion greatly accelerated in the 19th century. To obtain raw materials, Europe expanded imports from other countries and from the colonies. European industrialists sought raw materials such as dyes, cotton, vegetable oils, and metal ores from overseas. Concurrently, industrialization was quickly making Europe the center of manufacturing and economic growth, driving resource needs.\n\nCommunication became much more advanced during European expansion. With the invention of railroads and telegraphs, it became easier to communicate with other countries and to extend the administrative control of a home nation over its colonies. Steam railroads and steam-driven ocean shipping made possible the fast, cheap transport of massive amounts of goods to and from colonies.\n\nAlong with advancements in communication, Europe also continued to advance in military technology. European chemists made new explosives that made artillery much more deadly. By the 1880s, the machine gun had become a reliable battlefield weapon. This technology gave European armies an advantage over their opponents, as armies in less-developed countries were still fighting with arrows, swords, and leather shields (e.g. the Zulus in Southern Africa during the Anglo-Zulu War of 1879).. Some exceptions of armies that managed to get nearly on par with the European expeditions and standards include the Ethiopian armies at the Battle of Adwa, the Chinese Ever Victorious Army and the Japanese Imperial Army of Japan, but these still relied heavily on weapon imports from Europe and often on European military advisors and adventurers.\n\nAnglophone academic studies often base their theories regarding imperialism on the British experience of Empire. The term \"imperialism\" was originally introduced into English in its present sense in the late 1870s by opponents of the allegedly aggressive and ostentatious imperial policies of British Prime Minister Benjamin Disraeli. Supporters of \"imperialism\" such as Joseph Chamberlain quickly appropriated the concept. For some, imperialism designated a policy of idealism and philanthropy; others alleged that it was characterized by political self-interest, and a growing number associated it with capitalist greed.\n\nJohn A. Hobson, A leading English Liberal, developed a highly influential interpretation of \"Imperialism: A Study\" (1902) that expanded on his belief that free enterprise capitalism had a negative impact on the majority of the population. In \"Imperialism\" he argued that the financing of overseas empires drained money that was needed at home. It was invested abroad because lower wages paid the workers overseas made for higher profits and higher rates of return, compared to domestic wages. So although domestic wages remained higher, they did not grow nearly as fast as they might have otherwise. Exporting capital, he concluded, put a lid on the growth of domestic wages in the domestic standard of living. . By the 1970s, historians such as David K. Fieldhouse and Oron Hale could argue that \"the Hobsonian foundation has been almost completely demolished.\" The British experience failed to support it. However, European Socialists picked up Hobson's ideas and made it into their own theory of imperialism, most notably in Lenin's \"Imperialism, the Highest Stage of Capitalism\" (1916). Lenin portrayed Imperialism as the closure of the world market and the end of capitalist free-competition that arose from the need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion. Later Marxist theoreticians echo this conception of imperialism as a structural feature of capitalism, which explained the World War as the battle between imperialists for control of external markets. Lenin's treatise became a standard textbook that flourished until the collapse of communism in 1989–91.\n\nSome theoreticians on the non-Communist left have emphasized the structural or systemic character of \"imperialism\". Such writers have expanded the period associated with the term so that it now designates neither a policy, nor a short space of decades in the late 19th century, but a world system extending over a period of centuries, often going back to Christopher Columbus and, in some accounts, to the Crusades. As the application of the term has expanded, its meaning has shifted along five distinct but often parallel axes: the moral, the economic, the systemic, the cultural, and the temporal. Those changes reflect—among other shifts in sensibility—a growing unease, even great distaste, with the pervasiveness of such power, specifically, Western power.\n\nHistorians and political theorists have long debated the correlation between capitalism, class and imperialism. Much of the debate was pioneered by such theorists as J. A. Hobson (1858–1940), Joseph Schumpeter (1883–1950), Thorstein Veblen (1857–1929), and Norman Angell (1872–1967). While these non-Marxist writers were at their most prolific before World War I, they remained active in the interwar years. Their combined work informed the study of imperialism and its impact on Europe, as well as contributing to reflections on the rise of the military-political complex in the United States from the 1950s. Hobson argued that domestic social reforms could cure the international disease of imperialism by removing its economic foundation. Hobson theorized that state intervention through taxation could boost broader consumption, create wealth, and encourage a peaceful, tolerant, multipolar world order.\n\nWalter Rodney, in his 1972 classic How Europe Underdeveloped Africa, proposes the idea that imperialism is a phase of capitalism \"in which Western European capitalist countries, the US, and Japan established political, economic, military and cultural hegemony over other parts of the world which were initially at a lower level and therefore could not resist domination.\" As a result, Imperialism \"for many years embraced the whole world – one part being the exploiters and the other the exploited, one part being dominated and the other acting as overlords, one part making policy and the other being dependent.\"\n\nThe concept of environmental determinism served as a moral justification for the domination of certain territories and peoples. The environmental determinist school of thought held that the environment in which certain people lived determined those persons' behaviours; and this validated their domination. For example, the Western world saw people living in tropical environments as \"less civilized\", therefore justifying colonial control as a civilizing mission. Across the three major waves of European colonialism (the first in the Americas, the second in Asia and the last in Africa), environmental determinism served to place categorically indigenous people in a racial hierarchy. This takes two forms, orientalism and tropicality.\n\nSome geographic scholars under colonizing empires divided the world into climatic zones. These scholars believed that Northern Europe and the Mid-Atlantic temperate climate produced a hard-working, moral, and upstanding human being. In contrast, tropical climates allegedly yielded lazy attitudes, sexual promiscuity, exotic culture, and moral degeneracy. The people of these climates were believed to be in need of guidance and intervention from a European empire to aid in the governing of a more evolved social structure; they were seen as incapable of such a feat. Similarly, orientalism could promote a view of a people based on their geographical location.\n\nBritain's imperialist ambitions can be seen as early as the 16th century as the Tudor conquest of Ireland began in the 1530s. In 1599 the British East India Company was established and was chartered by Queen Elizabeth in the following year. With the establishment of trading posts in India, the British were able to maintain strength relative to other empires such as the Portuguese who already had set up trading posts in India. In 1767, the Anglo-Mysore Wars and other political activity caused exploitation of the East India Company causing the plundering of the local economy, almost bringing the company into bankruptcy. By the year 1670 Britain's imperialist ambitions were well off as she had colonies in Virginia, Massachusetts, Bermuda, Honduras, Antigua, Barbados, Jamaica and Nova Scotia.\n\nDue to the vast imperialist ambitions of European countries, Britain had several clashes with France. This competition was evident in the colonization of what is now known as Canada. John Cabot claimed Newfoundland for the British while the French established colonies along the St. Lawrence River and claiming it as \"New France\". Britain continued to expand by colonizing countries such as New Zealand and Australia, both of which were not empty land as they had their own locals and cultures. Britain's nationalistic movements were evident with the creation of the commonwealth countries where there was a shared nature of national identity.\n\nFollowing the proto-industrialization, the \"First\" British Empire was based on mercantilism, and involved colonies and holdings primarily in North America, the Caribbean, and India. Its growth was reversed by the loss of the American colonies in 1776. Britain made compensating gains in India, Australia, and in constructing an informal economic empire through control of trade and finance in Latin America after the independence of Spanish and Portuguese colonies in about 1820. By the 1840s, Britain had adopted a highly successful policy of free trade that gave it dominance in the trade of much of the world. After losing its first Empire to the Americans, Britain then turned its attention towards Asia, Africa, and the Pacific. Following the defeat of Napoleonic France in 1815, Britain enjoyed a century of almost unchallenged dominance and expanded its imperial holdings around the globe. Unchallenged at sea, British dominance was later described as \"Pax Britannica\" (\"British Peace\"), a period of relative peace in Europe and the world (1815–1914) during which the British Empire became the global hegemon and adopted the role of global policeman. However, this peace was mostly a perceived one from Europe, and the period was still an almost uninterrupted series of colonial wars and disputes. The British Conquest of India, its intervention against Mehemet Ali, the Anglo-Burmese Wars, the Crimean War, the Opium Wars and the Scramble for Africa to name the most notable conflicts mobilised ample military means to press Britain's lead in the global conquest Europe led across the century.\n\nIn the early 19th century, the Industrial Revolution began to transform Britain; by the time of the Great Exhibition in 1851 the country was described as the \"workshop of the world\". The British Empire expanded to include India, large parts of Africa and many other territories throughout the world. Alongside the formal control it exerted over its own colonies, British dominance of much of world trade meant that it effectively controlled the economies of many regions, such as Asia and Latin America. Domestically, political attitudes favoured free trade and laissez-faire policies and a gradual widening of the voting franchise. During this century, the population increased at a dramatic rate, accompanied by rapid urbanisation, causing significant social and economic stresses. To seek new markets and sources of raw materials, the Conservative Party under Disraeli launched a period of imperialist expansion in Egypt, South Africa, and elsewhere. Canada, Australia, and New Zealand became self-governing dominions.\n\nA resurgence came in the late 19th century with the Scramble for Africa and major additions in Asia and the Middle East. The British spirit of imperialism was expressed by Joseph Chamberlain and Lord Rosebury, and implemented in Africa by Cecil Rhodes. The pseudo-sciences of Social Darwinism and theories of race formed an ideological underpinning and legitimation during this time. Other influential spokesmen included Lord Cromer, Lord Curzon, General Kitchener, Lord Milner, and the writer Rudyard Kipling. The British Empire was the largest Empire that the world has ever seen both in terms of landmass and population. Its power, both military and economic, remained unmatched for a few decades. After the First Boer War, the South African Republic and Orange Free State were recognised by Britain but eventually re-annexed after the Second Boer War. But British power was fading, as the reunited German state founded by the Kingdom of Prussia posed a growing threat to Britain's dominance. As of 1913, Britain was the world's fourth economy, behind the U.S, Russia and Germany. \n\nIrish War of Independence in 1919-1921 led to the сreation of the Irish Free State. But Britain gained control of former German and Ottoman colonies with the League of Nations mandate. Britain now had a practically continuous line of controlled territories from Egypt to Burma and another one from Cairo to Cape Town. However, this period was also the one of the emergence of independence movements based on nationalism and new experiences the colonists had gained in the war.\n\nWorld War II decisively weakened Britain's position in the world, especially financially. Decolonization movements arose nearly everywhere in the Empire, resulting in Indian independence and partition in 1947 and the establishment of independent states in the 1950s. British imperialism showed its frailty in Egypt during the Suez Crisis in 1956. However, with the United States and Soviet Union emerging from World War II as the sole superpowers, Britain's role as a worldwide power declined significantly and rapidly.\n\nAncient China was one of the world's oldest empires. Due to its long history of imperialist expansion, China has been seen by its neighboring countries as a threat due to its large population, giant economy, large military force as well as its territorial evolution throughout history. Starting with the unification of China under the Qin dynasty, later Chinese dynasties continued to follow its form of expansions. \n\nThe most successful Chinese imperial dynasties are Tang and Qing dynasty, due to its expansions. According to historian Eric Setzekorn examining the 1850-1877 period, China's imperialism was brutal, and \"resulted in the deaths of millions...[ Chinese leaders] radically shifted the ethnic balance in favor of Han colonists. This was accomplished through the mass expulsion of ethnic communities and, more directly, the killing of unwanted minority groups, i.e. ethnic cleansing.\"\n\nDuring the 16th century, the French colonization of the Americas began with the creation of New France. It was followed by French East India Company's trading posts in Africa and Asia in the 17th century. France had its \"First colonial empire\" from 1534 until 1814, including New France (Canada, Acadia, Newfoundland and Louisiana), French West Indies (Saint-Domingue, Guadeloupe, Martinique), French Guiana, Senegal (Gorée), Mascarene Islands (Mauritius Island, Réunion) and French India.\n\nIts \"Second colonial empire\" began with the conquest of Algiers in 1830 and came for the most part to an end with the granting of independence to Algeria in 1962. The French imperial history was marked by numerous wars, large and small, and also by significant help to France itself from the colonials in the world wars. France took control of Algeria in 1830 but began in earnest to rebuild its worldwide empire after 1850, concentrating chiefly in North and West Africa (French North Africa, French West Africa, French Equatorial Africa), as well as South-East Asia (French Indochina), with other conquests in the South Pacific (New Caledonia, French Polynesia). France also twice attempted to make Mexico a colony in 1838–39 and in 1861-67 (see Pastry War and Second French intervention in Mexico).\n\nFrench Republicans, at first hostile to empire, only became supportive when Germany started to build her own colonial empire. As it developed, the new empire took on roles of trade with France, supplying raw materials and purchasing manufactured items, as well as lending prestige to the motherland and spreading French civilization and language as well as Catholicism. It also provided crucial manpower in both World Wars. It became a moral justification to lift the world up to French standards by bringing Christianity and French culture. In 1884 the leading exponent of colonialism, Jules Ferry declared France had a civilising mission: \"The higher races have a right over the lower races, they have a duty to civilize the inferior\". Full citizenship rights – \"assimilation\" – were offered, although in reality assimilation was always on the distant horizon. Contrasting from Britain, France sent small numbers of settlers to its colonies, with the only notable exception of Algeria, where French settlers nevertheless always remained a small minority.\n\nIn the 19th and 20th centuries, the French colonial empire was the second-largest colonial empire in the world behind the British Empire, extending over 12,347,000 km (4,767,000 sq. miles) at its height in the 1920s and 1930s. France controlled nearly 1/10th of the Earth's land area, with a population of 110 million people on the eve of World War II (5% of the world's population at the time).\n\nIn World War II, Charles de Gaulle and the Free French used the overseas colonies as bases from which they fought to liberate France. However, after 1945 anti-colonial movements began to challenge the Empire. France fought and lost a bitter war in Vietnam in the 1950s. Whereas they won the war in Algeria, de Gaulle decided to grant Algeria independence anyway in 1962. French settlers and many local supporters relocated to France. Nearly all of France's colonies gained independence by 1960, but France retained great financial and diplomatic influence. It has repeatedly sent troops to assist its former colonies in Africa in suppressing insurrections and coups d'état.\n\nGerman expansion into Slavic lands begins in 12th-13th-century (see Drang nach Osten). The concept of Drang nach Osten was a core element of German nationalism and a major element of Nazi ideology. However the German involvement in the seizure of overseas territories was negligible until the end of the 19th century. Prussia unified the other states into the second German Empire in 1871. Its Chancellor, Otto von Bismarck (1862–90), long opposed colonial acquisitions, arguing that the burden of obtaining, maintaining, and defending such possessions would outweigh any potential benefits. He felt that colonies did not pay for themselves, that the German bureaucratic system would not work well in the tropics and the diplomatic disputes over colonies would distract Germany from its central interest, Europe itself.\n\nHowever, public opinion and elite opinion in Germany demanded colonies for reasons of international prestige, so Bismarck was forced to oblige. In 1883–84 Germany began to build a colonial empire in Africa and the South Pacific. The establishment of the German colonial empire started with German New Guinea in 1884.\n\nGerman colonies included the present territories of in Africa: Tanzania, Rwanda, Burundi, Namibia, Cameroon, Ghana and Togo; in Oceania: New Guinea, Solomon islands, Nauru, Marshall Islands, Mariana Islands, Caroline Islands and Samoa; and in Asia: Tsingtao, Chefoo and the Jiaozhou Bay. The Treaty of Versailles made them mandates temporarily operated by the Allied victors.\n\nFor over 200 years, Japan maintained a feudal society during a period of relative isolation from the rest of the world. However, in the 1850s, military pressure from the United States and other world powers coerced Japan to open itself to the global market, resulting in an end to the country's isolation. A period of conflicts and political revolutions followed due to socioeconomic uncertainty, ending in 1868 with the reunification of political power under the Japanese Emperor during the Meiji Restoration. This sparked a period of rapid industrialization driven in part by a Japanese desire for self-sufficiency. By the early 1900s, Japan was a naval power that could hold its own against an established European power as it defeated Russia.\n\nDespite its rising population and increasingly industrialized economy, Japan had relatively little territory and lacked significant natural resources. As a result, the country turned to imperialism and expansionism in part as a means of compensating for these shortcomings, adopting the national motto \"\"Fukoku kyōhei\"\" (富国強兵, \"Enrich the state, strengthen the military\").\n\nAnd Japan was eager to take every opportunity. In 1869 they took advantage of the defeat of the rebels of the Republic of Ezo to incorporate definitely the island of Hokkaido to Japan. For centuries, Japan viewed the Ryukyu Islands as one of its provinces. In 1871 the Mudan incident happened: cannibal Taiwanese aborigines murdered 54 Ryūkyūan sailors that had their ship shipwrecked. At that time the Ryukyu Islands were claimed by both Qing China and Japan, and the Japanese interpreted the incident as an attack on their citizens. They took steps to bring the islands in their jurisdiction: in 1872 the Japanese Ryukyu Domain was declared, and in 1874 a retaliatory incursion to Taiwan was sent, which was a success. The success of this expedition emboldened the Japanese: not even the Americans could defeat the Taiwanese cannibals in the Formosa Expedition of 1867. Very few gave it much thought at the time, but this was the first move in the Japanese expansionism series. Japan occupied Taiwan for the rest of 1874 and then left owing to Chinese pressures, but in 1879 it finally annexed the Ryukyu Islands. In 1875 Qing China sent a 300-men force to subdue the Taiwanese cannibals, but unlike the Japanese the Chinese were routed, ambushed and 250 of their men were killed; the failure of this expedition exposed once more the failure of Qing China to exert effective control in Taiwan, and acted as another incentive for the Japanese to annex Taiwan. Eventually, the spoils for winning the First Sino-Japanese War in 1894 included Taiwan.\n\nIn 1875 Japan took its first operation against Joseon Korea, another territory that for centuries it coveted; the Ganghwa Island incident made Korea open to international trade. Korea was annexed in 1910. As a result of winning the Russo-Japanese War in 1905, Japan took part of Sakhalin Island from Russia. Precisely, the victory against the Russian Empire shook the world: never before an Asian nation defeated a European power, and in Japan it was seen as a feat. Japan's victory against Russia would act as an antecedent for Asian countries in the fight against the Western powers for Decolonization. During World War I, Japan took German-leased territories in China's Shandong Province, as well as the Mariana, Caroline, and Marshall Islands, and kept the islands as League of nations mandates. At first, Japan was in good standing with the victorious Allied powers of World War I, but different discrepancies and dissatisfaction with the rewards of the treaties cooled the relations with them, for example American pressure forced it to return the Shandong area. By the '30s, economic depression, urgency of resources and a growing distrust in the Allied powers made Japan lean to a hardened militaristic stance. Through the decade, it would grow closer to Germany and Italy, forming together the Axis alliance. In 1931 Japan took Manchuria from China. International reactions condemned this move, but Japan's already strong skepticism against Allied nations meant that it nevertheless carried on.\nDuring the Second Sino-Japanese War in 1937, Japan's military invaded central China. Also, in 1938-1939 Japan made an attempt to seize the territory of Soviet Russia and Mongolia, but suffered a serious defeats (see Battle of Lake Khasan, Battles of Khalkhin Gol). By now, relations with the Allied powers were at the bottom, and an international boycott against Japan to deprive it of natural resources was enforced. Thus a military move to gain access to them was needed, and so Japan attacked Pearl Harbor, bringing the United States to World War II. Using its superior technological advances in naval aviation and its modern doctrines of amphibious and naval warfare, Japan achieved one of the fastest maritime expansions in history. By 1942 Japan had conquered much of East Asia and the Pacific, including the east of China, Hong Kong, Thailand, Vietnam, Cambodia, Burma (Myanmar), Malaysia, the Philippines, Indonesia, part of New Guinea and many islands of the Pacific Ocean. Just as Japan's late industrialization success and victory against the Russian Empire was seen as an example among underdeveloped Asia-Pacific nations, the Japanese took advantage of this and promoted among its conquered the goal to jointly create an anti-European \"Greater East Asia Co-Prosperity Sphere\". This plan helped the Japanese gain support from native populations during its conquests, especially in Indonesia. However, the United States had a vastly stronger military and industrial base and defeated Japan, stripping it of conquests and returning its settlers back to Japan.\n\nThe Ottoman Empire was an imperial state that lasted from 1299 to 1922. In 1453, Mehmed the Conqueror besieged the capital of the Byzantine Empire, resulting in the Fall of Constantinople after 1,500 years of Roman rule, thereafter making it the capital of the empire. During the 16th and 17th centuries, in particular at the height of its power under the reign of Suleiman the Magnificent, the Ottoman Empire was a powerful multinational, multilingual empire, which invaded and colonized much of Southeast Europe, Western Asia, the Caucasus, North Africa, and the Horn of Africa. Its repeated invasions, and brutal treatment of Slavs led to the Great Migrations of the Serbs to escape persecution. At the beginning of the 17th century the empire contained 32 provinces and numerous vassal states. Some of these were later absorbed into the empire, while others were granted various types of autonomy during the course of centuries.\n\nWith Constantinople as its capital and control of lands around the Mediterranean basin, the Ottoman Empire was at the center of interactions between the Eastern and Western worlds for six centuries. Following a long period of military setbacks against European powers, the Ottoman Empire gradually declined in its ability to remain sovereign against competing powers in the late 19th century. \n\nThe collapse of the Ottoman Empire was accelerated by the intervention of the great powers. In 1821-1829 the Greeks in their struggle for independence were assisted by the Russian Empire, Great Britain, and the Kingdom of France (see Greek War of Independence). \nLater in fact, the Ottoman Empire could exist only in the conditions of acute rivalry of the great powers. Russia's attempt to negotiate with Britain on the partition of the Ottoman Empire failed. Britain after the conclusion of Treaty of Balta Liman in 1838 was interested in preserving the Ottoman Empire and in Crimean war 1853-1856, the great powers of Britain and France opposed Russia, as a result of the Ottoman Empire existed until 1922. As result of the Russo-Turkish War (1877–1878), Bulgaria, Serbia and Montenegro gained independence in the European part of the Empire.\n\nThe empire allied with Germany in the early 20th century, with the imperial ambition of recovering its lost territories, but it dissolved in the aftermath of its defeat in the First World War. At the same time, Turkey itself could barely avoid the fate of being divided into colonies of great powers, see Treaty of Sèvres. The result was the Turkish War of Independence, when Kemalist forces backed by Soviet Russia established the Republic of Turkey. The residue was the new state of Turkey in the Ottoman Anatolian heartland, as well as the creation of modern Balkan and Middle Eastern states, thus ending Turkish colonial ambitions.\n\nBy the 18th century, the Russian Empire extended its control to the Pacific, peacefully forming a common border with the Qing Empire and Empire of Japan. This took place in a large number of military invasions of the lands east, west, and south of it. The Polish–Russian War of 1792 took place after Polish nobility from the Polish–Lithuanian Commonwealth wrote the Constitution of 3 May 1791. The war resulted in eastern Poland being conquered by Imperial Russia as a colony until 1918. The southern campaigns involved a series of Russo-Persian Wars, which began with the Persian Expedition of 1796, resulting in the acquisition of Georgia (country) as a protectorate. Between 1800 and 1864, Imperial armies invaded south in the Russian conquest of the Caucasus, the Murid War, and the Russo-Circassian War. This last conflict led to the ethnic cleansing of Circassians from their lands. The Russian conquest of Siberia over the Khanate of Sibir took place in the 16th and 17th centuries, and resulted in the slaughter of various indigenous tribes by Russians, including the Daur, the Koryaks, the Itelmens, Mansi people and the Chukchi. The Russian colonization of Central and Eastern Europe and Siberia and treatment of the resident indigenous peoples has been compared to European colonization of the Americas, with similar negative impacts on the indigenous Siberians as upon the indigenous peoples of the Americas. The extermination of indigenous Siberian tribes was so complete that a relatively small population of only 180,000 are said to exist today. The Russian Empire exploited and suppressed Cossacks hosts during this period, before turning them into the special military estate Sosloviye in the late 18th century. Cossacks were then used in Imperial Russian campaigns against other tribes.\n\nBut it would be a strong simplification to reduce expansion of Russia only to military conquests. The reunification of Ukraine with Russia took place in 1654, when Polish rule brought the population of Ukraine to revolts (see Pereyaslav Council). Another example is Georgia's accession to Russia in 1783. Given Georgia's history of invasions from the south, an alliance with Russia may have been seen as the only way to discourage or resist Persian and Ottoman aggression, while also establishing a link to Western Europe (see Treaty of Georgievsk). Russia's support helped establish independent Mongolia (independent from China) (see Mongolian Revolution of 1911).\n\nBolshevik leaders had effectively reestablished a polity with roughly the same extent as that empire by 1921, however with an internationalist ideology: Lenin in particular asserted the right to limited self-determination for national minorities within the new territory. Beginning in 1923, the policy of \"Indigenization\" [korenizatsiya] was intended to support non-Russians develop their national cultures within a socialist framework. Never formally revoked, it stopped being implemented after 1932. After World War II, the Soviet Union installed socialist regimes modeled on those it had installed in 1919–20 in the old Russian Empire, in areas its forces occupied in Eastern Europe. The Soviet Union and later the People's Republic of China supported revolutionary and communist movements in foreign nations and colonies to advance their own interests, but were not always successful. The USSR provided great assistance to Kuomintang in 1926-1928 in the formation of a unified Chinese government (see Northern Expedition). Although then relations with the USSR deteriorated, but the USSR was the only world power that provided military assistance to China against Japanese aggression in 1937-1941 (see Sino-Soviet Non-Aggression Pact). It should be pointed out that the victory of the Chinese Communists in the civil war of 1946-1949 relied on the great help of the USSR (see Chinese Civil War).\n\nTrotsky, and others, believed that the revolution could only succeed in Russia as part of a world revolution. Lenin wrote extensively on the matter and famously declared that Imperialism was the highest stage of capitalism. However, after Lenin's death, Joseph Stalin established 'socialism in one country' for the Soviet Union, creating the model for subsequent inward looking Stalinist states and purging the early Internationalist elements. The internationalist tendencies of the early revolution would be abandoned until they returned in the framework of a client state in competition with the Americans during the Cold War. In the post-Stalin period in the late 1950s, the new political leader Nikita Khrushchev put pressure on the Soviet-American relations starting a new wave of anti-imperialist propaganda. In his speech on the UN conference in 1960, he announced the continuation of the war on imperialism, stating that soon the people of different countries will come together and overthrow their imperialist leaders. Although the Soviet Union declared itself anti-imperialist, critics argue that it exhibited traits common to historic empires. Some scholars hold that the Soviet Union was a hybrid entity containing elements common to both multinational empires and nation states. Some also argued that the USSR practiced colonialism as did other imperial powers and was carrying on the old Russian tradition of expansion and control. Mao Zedong once argued that the Soviet Union had itself become an imperialist power while maintaining a socialist façade. Moreover, the ideas of imperialism were widely spread in action on the higher levels of government. Some Marxists within the Russian Empire and later the USSR, like Sultan Galiev and Vasyl Shakhrai, considered the Soviet regime a renewed version of the Russian imperialism and colonialism.\n\nSoviet imperialism involved invasion of Hungary in 1956 to destroy democratic forces. Soviet imperialism was roundly condemned In 1979 when the USSR invaded Afghanistan to keep a friendly government in power. The invasion \"alerted the Third World, as no earlier Soviet in intervention a done, to the nature of Soviet imperialism. It must be said that the USSR never called itself an \"Empire\" unlike other world powers and the use of such a name carries a negative connotation.\n\nMade up of former colonies itself, the early United States expressed its opposition to Imperialism, at least in a form distinct from its own Manifest Destiny, through policies such as the Monroe Doctrine. However the US may have unsuccessfully attempted to capture Canada in the War of 1812. The United States achieved very significant territorial concessions from Mexico during the Mexican-American War. Beginning in the late 19th and early 20th century, policies such as Theodore Roosevelt’s interventionism in Central America and Woodrow Wilson’s mission to \"make the world safe for democracy\" changed all this. They were often backed by military force, but were more often affected from behind the scenes. This is consistent with the general notion of hegemony and imperium of historical empires. In 1898, Americans who opposed imperialism created the Anti-Imperialist League to oppose the US annexation of the Philippines and Cuba. One year later, a war erupted in the Philippines causing business, labor and government leaders in the US to condemn America's occupation in the Philippines as they also denounced them for causing the deaths of many Filipinos. American foreign policy was denounced as a \"racket\" by Smedley Butler, a former American general who had become a spokesman for the far left.\n\nAt the start of World War II, President Franklin D. Roosevelt was opposed to European colonialism, especially in India. He pulled back when Britain's Winston Churchill demanded that victory in the war be the first priority. Roosevelt expected that the United Nations would take up the problem of decolonization.\n\nSome have described the internal strife between various people groups as a form of imperialism or colonialism. This internal form is distinct from informal U.S. imperialism in the form of political and financial hegemony. This internal form of imperialism is also distinct from the United States' formation of \"colonies\" abroad. Through the treatment of its indigenous peoples during westward expansion, the United States took on the form of an imperial power prior to any attempts at external imperialism. This internal form of empire has been referred to as \"internal colonialism\". Participation in the African slave trade and the subsequent treatment of its 12 to 15 million Africans is viewed by some to be a more modern extension of America's \"internal colonialism\". However, this internal colonialism faced resistance, as external colonialism did, but the anti-colonial presence was far less prominent due to the nearly complete dominance that the United States was able to assert over both indigenous peoples and African-Americans. In his lecture on April 16, 2003, Edward Said made a bold statement on modern imperialism in the United States, whom he described as using aggressive means of attack towards the contemporary Orient, \"due to their backward living, lack of democracy and the violation of women’s rights. The western world forgets during this process of converting the other that enlightenment and democracy are concepts that not all will agree upon\".\n\nSpanish imperialism in the colonial era corresponds with the rise and decline of the Spanish Empire, conventionally recognized as emerging in 1402 with the conquest of the Canary Islands. Following the successes of exploratory maritime voyages conducted during the Age of Discovery, such as those undertaken by Christopher Columbus, Spain committed considerable financial and military resources towards developing a robust navy capable of conducting large-scale, transatlantic expeditionary operations in order to establish and solidify a firm imperial presence across portions of North America, South America, and the geographic regions comprising the Caribbean basin. Concomitant with Spanish endorsement and sponsorship of transatlantic expeditionary voyages was the deployment of \"Conquistadors\", which further expanded Spanish imperial boundaries through the acquisition and development of territories and colonies.\n\nIn congruence with the colonialist activities of competing European imperial powers throughout the 15th – 19th centuries, the Spanish were equally engrossed in extending geopolitical power. The Caribbean basin functioned as a key geographic focal point for advancing Spanish imperialism. Similar to the strategic prioritization Spain placed towards achieving victory in the conquests of the Aztec Empire and Inca Empire, Spain placed equal strategic emphasis on expanding the nation's imperial footprint within the Caribbean basin.\n\nEchoing the prevailing ideological perspectives regarding colonialism and imperialism embraced by Spain's European rivals during the colonial era, including the English, French, and the Dutch, the Spanish utilized colonialism as a means of expanding imperial geopolitical borders and securing the defense of maritime trade routes in the Caribbean basin.\n\nWhile leveraging colonialism in the same geographic operating theater as its imperial rivals, Spain maintained distinct imperial objectives and instituted a unique form of colonialism in support of its imperial agenda. Spain placed significant strategic emphasis on the acquisition, extraction, and exportation of precious metals (primarily gold and silver). A second objective was the evangelization of subjugated indigenous populations residing in mineral-rich and strategically favorable locations. Notable examples of these indigenous groups include the Taίno populations inhabiting Puerto Rico and segments of Cuba. Compulsory labor and slavery were widely institutionalized across Spanish-occupied territories and colonies, with an initial emphasis on directing labor towards mining activity and related methods of procuring semi-precious metals. The emergence of the \"Encomienda\" system during the 16th–17th centuries in occupied colonies within the Caribbean basin reflects a gradual shift in imperial prioritization, increasingly focusing on large-scale production and exportation of agricultural commodities.\n\nThe scope and scale of Spanish participation in imperialism within the Caribbean basin remains a subject of scholarly debate among historians. A fundamental source of contention stems from the inadvertent conflation of theoretical conceptions of imperialism and colonialism. Furthermore, significant variation exists in the definition and interpretation of these terms as expounded by historians, anthropologists, philosophers, and political scientists.\n\nAmong historians, there is substantial support in favor of approaching imperialism as a conceptual theory emerging during the 18th–19th centuries, particularly within Britain, propagated by key exponents such as Joseph Chamberlain and Benjamin Disraeli. In accordance with this theoretical perspective, the activities of the Spanish in the Caribbean are not components of a preeminent, ideologically-driven form of imperialism. Rather, these activities are more accurately classified as representing a form of colonialism.\n\nFurther divergence among historians can be attributed to varying theoretical perspectives regarding imperialism that are proposed by emerging academic schools of thought. Noteworthy examples include cultural imperialism, whereby proponents such as John Downing and Annabelle Sreberny-Modammadi define imperialism as \"\"...the conquest and control of one country by a more powerful one.\"\" Cultural imperialism signifies the dimensions of the process that go beyond economic exploitation or military force.\" Moreover, colonialism is understood as \"\"...the form of imperialism in which the government of the colony is run directly by foreigners.\"\"\n\nIn spite of diverging perspectives and the absence of a unilateral scholarly consensus regarding imperialism among historians, within the context of Spanish expansion in the Caribbean basin during the colonial era, imperialism can be interpreted as an overarching ideological agenda that is perpetuated through the institution of colonialism. In this context, colonialism functions as an instrument designed to achieve specific imperialist objectives.\n\nBULLET::::- Globalization\nBULLET::::- Hegemony\nBULLET::::- Historiography of the British Empire\nBULLET::::- \"Imperialism, the Highest Stage of Capitalism\" 1917 book by Lenin\nBULLET::::- International relations of the Great Powers (1814–1919)\nBULLET::::- International relations, 1648–1814\nBULLET::::- List of empires\nBULLET::::- List of largest empires\nBULLET::::- Pluricontinentalism\nBULLET::::- Postcolonialism\nBULLET::::- Super-imperialism\nBULLET::::- Suzerainty\nBULLET::::- Ultra-imperialism\nBULLET::::- Uneven and combined development\nBULLET::::- Western European colonialism and colonization\n\nBULLET::::- Abernethy, David P. \"The Dynamics of Global Dominance: European Overseas Empires, 1425–1980\" (Yale UP, 2000), political science approach. online review\nBULLET::::- Ankerl, Guy. \"Coexisting Contemporary Civilizations: Arabo-Muslim, Bharatai, Chinese, and Western,\" Geneva, INU Press, 2000, .\nBULLET::::- Bayly, C.A. ed. \"Atlas of the British Empire\" (1989). survey by scholars; heavily illustrated\nBULLET::::- Brendon, Piers. \"A Moral Audit of the British Empire\". \"History Today\", (Oct 2007), Vol. 57 Issue 10, pp. 44–47, online at EBSCO\nBULLET::::- Brendon, Piers. \"The Decline and Fall of the British Empire, 1781–1997\" (2008), , wide-ranging survey\nBULLET::::- Bickers, Robert and Christian Henriot, \"New Frontiers: Imperialism's New Communities in East Asia, 1842–1953\", Manchester, Manchester University Press, 2000,\nBULLET::::- Blanken, Leo. \"Rational Empires: Institutional Incentives and Imperial Expansion,\" University Of Chicago Press, 2012\nBULLET::::- Bush, Barbara. \"Imperialism and Postcolonialism (History: Concepts, Theories and Practice),\" Longmans, 2006,\nBULLET::::- Comer, Earl of. \"Ancient and Modern Imperialism,\" John Murray, 1910.\nBULLET::::- Cotterell, Arthur. \"Western Power in Asia: Its Slow Rise and Swift Fall, 1415 - 1999\" (2009) popular history excerpts\nBULLET::::- Darwin, John. \" After Tamerlane: The Rise and Fall of Global Empires, 1400–2000,\" (Penguin Books, 2008), 576 pp\nBULLET::::- Darwin, John. \"The Empire Project\" (2011) 811pp free viewing\nBULLET::::- Fay, Richard B. and Daniel Gaido (ed. and trans.), \"Discovering Imperialism: Social Democracy to World War I.\" Chicago: Haymarket Books, 2012.\nBULLET::::- Niall Ferguson, \"Empire: How Britain Made the Modern World,\" Penguin Books, 2004,\nBULLET::::- Gotteland, Mathieu. What Is Informal Imperialism?, The Middle Ground Journal (2017).\nBULLET::::- Michael Hardt and Toni Negri, \"Empire,\" Harvard University Press, 2000,\nBULLET::::- E.J. Hobsbawm, \"The Age of Empire, 1875–1914,\" Abacus Books, 1989,\nBULLET::::- E.J. Hobsbawm, \"On Empire: America, War, and Global Supremacy,\" Pantheon Books, 2008,\nBULLET::::- J.A. Hobson, \"Imperialism: A Study,\" Cosimo Classics, 2005,\nBULLET::::- Hodge, Carl Cavanagh. \"Encyclopedia of the Age of Imperialism, 1800–1914\" (2 vol. 2007), online\nBULLET::::- Howe, Stephen Howe, ed., \"The New Imperial Histories Reader\" (2009) online review.\nBULLET::::- Kumar, Krishan. \"Visions of Empire: How Five Imperial Regimes Shaped the World\" (2017).\nBULLET::::- Gabriel Kuhn, \"Oppressor and Oppressed Nations: Sketching a Taxonomy of Imperialism\", Kersplebedeb, June 2017.\nBULLET::::- Lawrence, Adria K. \"Imperial Rule and the Politics of Nationalism: Anti-Colonial Protest in the French Empire\" (Cambridge UP, 2013) online reviews\nBULLET::::- Jackson Lears, \"Imperial Exceptionalism\" (review of Victor Bulmer-Thomas, \"Empire in Retreat: The Past, Present, and Future of the United States\", Yale University Press, 2018, , 459 pp.; and David C. Hendrickson, \"Republic in Peril: American Empire and the Liberal Tradition\", Oxford University Press, 2017, , 287 pp.), \"The New York Review of Books\", vol. LXVI, no. 2 (February 7, 2019), pp. 8–10. Bulmer-Thomas writes: \"Imperial retreat is not the same as national decline, as many other countries can attest. Indeed, imperial retreat can strengthen the nation-state just as imperial expansion can weaken it.\" (\"NYRB\", cited on p. 10.)\nBULLET::::- Moon, Parker T. \"Imperialism and world politics\" (1926); 583 pp; Wide-ranging historical survey; online\nBULLET::::- Ness, Immanuel and Zak Cope, eds. \"The Palgrave Encyclopedia of Imperialism and Anti-Imperialism\" (2 vol 2015), 1456 pp\nBULLET::::- Page, Melvin E. et al. eds. \"Colonialism: An International Social, Cultural, and Political Encyclopedia\" (2 vol 2003)\nBULLET::::- Thomas Pakenham. \"The Scramble for Africa: White Man's Conquest of the Dark Continent from 1876–1912\" (1992),\nBULLET::::- Petringa, Maria, \"Brazza, A Life for Africa\", Bloomington, IN: AuthorHouse, 2006.\nBULLET::::- Rothermund, Dietmar. \"Memories of Post-Imperial Nations: The Aftermath of Decolonization, 1945–2013\" (2015), ; Compares the impact on Great Britain, the Netherlands, Belgium, France, Portugal, Italy and Japan\nBULLET::::- Edward Said, \"Culture and Imperialism,\" Vintage Books, 1998,\nBULLET::::- Simms, Brendan. \"Three victories and a defeat: the rise and fall of the first British Empire\" (Hachette UK, 2008). to 1783.\nBULLET::::- Smith, Simon C. \"British Imperialism 1750–1970,\" Cambridge University Press, 1998,\nBULLET::::- Stuchtey, Benedikt. \"Colonialism and Imperialism, 1450–1950\", European History Online, Mainz: Institute of European History, 2011.\nBULLET::::- U.S. Tariff Commission. \"Colonial tariff policies\" (1922), worldwide; 922 pp\nBULLET::::- Winslow, E.M. \"Marxian, Liberal, and Sociological Theories of Imperialism,\" \"Journal of Political Economy,\" vol. 39, no. 6 (Dec. 1931), pp. 713–58. In JSTOR\n\nPrimary sources\nBULLET::::- V. I. Lenin, \",\" International Publishers, New York, 1997,\nBULLET::::- Rosa Luxemburg, \"\"\n\nBULLET::::- J.A Hobson, Imperialism a Study 1902.\nBULLET::::- The Paradox of Imperialism by Hans-Hermann Hoppe. November 2006.\nBULLET::::- Imperialism Quotations\nBULLET::::- State, Imperialism and Capitalism by Joseph Schumpeter\nBULLET::::- Economic Imperialism by A.J.P. Taylor\nBULLET::::- Imperialism Entry in the Columbia Encyclopedia (Bartleby)\nBULLET::::- Imperialism by Emile Perreau-Saussine\nBULLET::::- The Nation-State, Core and Periphery: A Brief sketch of Imperialism in the 20th century.\nBULLET::::- Mehmet Akif Okur, :Rethinking Empire After 9/11: Towards A New Ontological Image of World Order\", \"Perceptions, Journal of International Affairs\", Volume XII, Winter 2007, pp. 61–93\nBULLET::::- \"Imperialism 101, Against Empire\" By Michael Parenti Published by City Lights Books, 1995, , 217 pages\n"}
{"id": "15317", "url": "https://en.wikipedia.org/wiki?curid=15317", "title": "IPv4", "text": "IPv4\n\nInternet Protocol version 4 (IPv4) is the fourth version of the Internet Protocol (IP). It is one of the core protocols of standards-based internetworking methods in the Internet and other packet-switched networks. IPv4 was the first version deployed for production in the ARPANET in 1983. It still routes most Internet traffic today, despite the ongoing deployment of a successor protocol, IPv6. IPv4 is described in IETF publication RFC 791 (September 1981), replacing an earlier definition (RFC 760, January 1980).\n\nIPv4 uses a 32-bit address space, which limits the number of unique hosts to 4,294,967,296 (2), but large blocks are reserved for special networking methods.\n\nThe Internet Protocol is the protocol that defines and enables internetworking at the internet layer of the Internet Protocol Suite. In essence it forms the Internet. It uses a logical addressing system and performs \"routing\", which is the forwarding of packets from a source host to the next router that is one hop closer to the intended destination host on another network.\n\nIPv4 is a connectionless protocol, and operates on a best effort delivery model, in that it does not guarantee delivery, nor does it assure proper sequencing or avoidance of duplicate delivery. These aspects, including data integrity, are addressed by an upper layer transport protocol, such as the Transmission Control Protocol (TCP).\n\nIPv4 uses 32-bit addresses which limits the address space to (2) addresses.\n\nIPv4 reserves special address blocks for private networks (~18 million addresses) and multicast addresses (~270 million addresses).\n\nIPv4 addresses may be represented in any notation expressing a 32-bit integer value. They are most often written in dot-decimal notation, which consists of four octets of the address expressed individually in decimal numbers and separated by periods.\n\nFor example, the quad-dotted IP address \"192.0.2.235\" represents the 32-bit decimal number 3221226219, which in hexadecimal format is 0xC00002EB. This may also be expressed in dotted hex format as 0xC0.0x00.0x02.0xEB, or with octal byte values as 0300.0000.0002.0353.\n\nCIDR notation combines the address with its routing prefix in a compact format, in which the address is followed by a slash character (/) and the count of consecutive \"1\" bits in the routing prefix (subnet mask).\n\nOther address representations were in common use when classful networking was practiced. For example, the loopback address \"127.0.0.1\" was commonly written as \"127.1\", given that it belonged to a class-A network with eight bits for the network mask and 24 bits for the host number. When fewer than four numbers are specified in the address in dotted notation, the last value is treated as an integer of as many bytes as are required to fill out the address to four octets. Thus, the address \"127.65530\" is equivalent to \"127.0.255.250\".\n\nIn the original design of IPv4, an IP address was divided into two parts: the network identifier was the most significant octet of the address, and the host identifier was the rest of the address. The latter was also called the \"rest field\". This structure permitted a maximum of 256 network identifiers, which was quickly found to be inadequate.\n\nTo overcome this limit, the most-significant address octet was redefined in 1981 to create \"network classes\", in a system which later became known as classful networking. The revised system defined five classes. Classes A, B, and C had different bit lengths for network identification. The rest of the address was used as previously to identify a host within a network. Because of the different sizes of fields in different classes, each network class had a different capacity for addressing hosts. In addition to the three classes for addressing hosts, Class D was defined for multicast addressing and Class E was reserved for future applications.\n\nDividing existing classful networks into subnets began in 1985 with the publication of . This division was made more flexible with the introduction of variable-length subnet masks (VLSM) in in 1987. In 1993, based on this work, introduced Classless Inter-Domain Routing (CIDR), which expressed the number of bits (from the most significant) as, for instance, /24, and the class-based scheme was dubbed \"classful\", by contrast. CIDR was designed to permit repartitioning of any address space so that smaller or larger blocks of addresses could be allocated to users. The hierarchical structure created by CIDR is managed by the Internet Assigned Numbers Authority (IANA) and the regional Internet registries (RIRs). Each RIR maintains a publicly searchable WHOIS database that provides information about IP address assignments.\n\nThe Internet Engineering Task Force (IETF) and the Internet Assigned Numbers Authority (IANA) have restricted from general use various reserved IP addresses for special purposes. Notably these addresses are used for multicast traffic and to provide addressing space for unrestricted uses on private networks.\n<section begin=IPv4-special-address-blocks/>\n+ Special address blocks\n!Address block\n!Address range\n!Number of addresses\n!Scope\n!Description\n0.0.0.0/8\n0.0.0.0–0.255.255.255\nalign=\"right\"\nSoftware\nCurrent network (only valid as source address).\n10.0.0.0/8\n10.0.0.0–10.255.255.255\nalign=\"right\"\nPrivate network\nUsed for local communications within a private network.\n\n100.64.0.0/10\n100.64.0.0–100.127.255.255\nalign=\"right\"\nPrivate network\nShared address space for communications between a service provider and its subscribers when using a carrier-grade NAT.\n127.0.0.0/8\n127.0.0.0–127.255.255.255\nalign=\"right\"\nHost\nUsed for loopback addresses to the local host.\n\n169.254.0.0/16\n169.254.0.0–169.254.255.255\nalign=\"right\"\nSubnet\nUsed for link-local addresses between two hosts on a single link when no IP address is otherwise specified, such as would have normally been retrieved from a DHCP server.\n172.16.0.0/12\n172.16.0.0–172.31.255.255\nalign=\"right\"\nPrivate network\nUsed for local communications within a private network.\n\n192.0.0.0/24\n192.0.0.0–192.0.0.255\nalign=\"right\"\nPrivate network\nIETF Protocol Assignments.\n192.0.2.0/24\n192.0.2.0–192.0.2.255\nalign=\"right\"\nDocumentation\nAssigned as TEST-NET-1, documentation and examples.\n192.88.99.0/24\n192.88.99.0–192.88.99.255\nalign=\"right\"\nInternet\nReserved. Formerly used for IPv6 to IPv4 relay (included IPv6 address block 2002::/16).\n192.168.0.0/16\n192.168.0.0–192.168.255.255\nalign=\"right\"\nPrivate network\nUsed for local communications within a private network.\n198.18.0.0/15\n198.18.0.0–198.19.255.255\nalign=\"right\"\nPrivate network\nUsed for benchmark testing of inter-network communications between two separate subnets.\n198.51.100.0/24\n198.51.100.0–198.51.100.255\nalign=\"right\"\nDocumentation\nAssigned as TEST-NET-2, documentation and examples.\n203.0.113.0/24\n203.0.113.0–203.0.113.255\nalign=\"right\"\nDocumentation\nAssigned as TEST-NET-3, documentation and examples.\n\n224.0.0.0/4\n224.0.0.0–239.255.255.255\nalign=\"right\"\nInternet\nIn use for IP multicast. (Former Class D network).\n240.0.0.0/4\n240.0.0.0–255.255.255.254\nalign=\"right\"\nInternet\nReserved for future use. (Former Class E network).\n255.255.255.255/32\n255.255.255.255\nalign=\"right\"\nSubnet\nReserved for the \"limited broadcast\" destination address.\n}<section end=IPv4-special-address-blocks/>\n\nOf the approximately four billion addresses defined in IPv4, about 18 million addresses in three ranges are reserved for use in private networks. Packets addresses in these ranges are not routable in the public Internet; they are ignored by all public routers. Therefore, private hosts cannot directly communicate with public networks, but require network address translation at a routing gateway for this purpose.\n\n<section begin=IPv4-private-networks/>\n+ Reserved private IPv4 network ranges\n!Name!!CIDR block!!Address range!!Number of addresses!!\"Classful\" description\n24-bit block10.0.0.0/810.0.0.0 – 10.255.255.255align=\"right\"Single Class A. \n20-bit block172.16.0.0/12172.16.0.0 – 172.31.255.255align=\"right\"Contiguous range of 16 Class B blocks. \n16-bit block192.168.0.0/16192.168.0.0 – 192.168.255.255align=\"right\"Contiguous range of 256 Class C blocks. \n}<section end=IPv4-private-networks/>\n\nSince two private networks, e.g., two branch offices, cannot directly interoperate via the public Internet, the two networks must be bridged across the Internet via a virtual private network (VPN) or an IP tunnel, which encapsulates packets, including their headers containing the private addresses, in a protocol layer during transmission across the public network. Additionally, encapsulated packets may be encrypted for the transmission across public networks to secure the data.\n\nRFC 3927 defines the special address block 169.254.0.0/16 for link-local addressing. These addresses are only valid on the link (such as a local network segment or point-to-point connection) directly connected to a host that uses them. These addresses are not routable. Like private addresses, these addresses cannot be the source or destination of packets traversing the internet. These addresses are primarily used for address autoconfiguration (Zeroconf) when a host cannot obtain an IP address from a DHCP server or other internal configuration methods.\n\nWhen the address block was reserved, no standards existed for address autoconfiguration. Microsoft created an implementation called Automatic Private IP Addressing (APIPA), which was deployed on millions of machines and became a de facto standard. Many years later, in May 2005, the IETF defined a formal standard in RFC 3927, entitled \"Dynamic Configuration of IPv4 Link-Local Addresses\".\n\nThe class A network 127.0.0.0 (classless network 127.0.0.0/8) is reserved for loopback. IP packets whose source addresses belong to this network should never appear outside a host. Packets received on a non-loopback interface with a loopback source or destination address must be dropped.\n\nThe first address in a subnet is used to identify the subnet itself. The last address is used as a local broadcast address for all devices on the subnet.\n\nFor example, in the subnet 192.168.5.0/255.255.255.0 (192.168.5.0/24) the identifier 192.168.5.0 commonly is used to refer to the entire subnet. To avoid ambiguity in representation, the address ending in the octet \"0\" is reserved.\n\nA broadcast address is an address that allows information to be sent to all interfaces in a given subnet, rather than a specific machine. The broadcast address is the last address in the address range of the subnet. For example, the broadcast address for the network 192.168.5.0 is 192.168.5.255. For networks of size /24 or larger, the broadcast address always ends in 255.\n\n! !! Binary form !! Dot-decimal notation\n\nHowever, this does not mean that every address ending in 0 or 255 cannot be used as a host address. For example, in the /16 subnet 192.168.0.0/255.255.0.0, which is equivalent to the address range 192.168.0.0–192.168.255.255, the broadcast address is 192.168.255.255. One can use the following addresses for hosts, even though they end with 255: 192.168.1.255, 192.168.2.255, etc. Also, 192.168.0.0 is the network identifier and must not be assigned to an interface. The addresses 192.168.1.0, 192.168.2.0, etc., may be assigned, despite ending with 0.\n\nIn the past, conflict between network addresses and broadcast addresses arose because some software used non-standard broadcast addresses with zeros instead of ones.\n\nIn networks smaller than /24, broadcast addresses do not necessarily end with 255. For example, a CIDR subnet 203.0.113.16/28 has the broadcast address 203.0.113.31.\n\n! !! Binary form !! Dot-decimal notation\n\nAs a special case, a /31 network has capacity for just two hosts. These networks are typically used for point-to-point connections. There is no network identifier or broadcast address for these networks.\n\nHosts on the Internet are usually known by names, e.g., www.example.com, not primarily by their IP address, which is used for routing and network interface identification. The use of domain names requires translating, called \"resolving\", them to addresses and vice versa. This is analogous to looking up a phone number in a phone book using the recipient's name.\n\nThe translation between addresses and domain names is performed by the Domain Name System (DNS), a hierarchical, distributed naming system which allows for subdelegation of name spaces to other DNS servers.\n\nSince the 1980s, it was apparent that the pool of available IPv4 addresses was being depleted at a rate that was not initially anticipated in the original design of the network address system. The main market forces that accelerated IPv4 address depletion included the rapidly growing number of Internet users, the need for always-on devices, and the proliferation of mobile computing devices, such as laptop computers, PDAs, and mobile phones.\n\nThe threat of exhaustion motivated the introduction of a number of remedial technologies, such as classful networks, Classless Inter-Domain Routing (CIDR) methods, network address translation (NAT) and strict usage-based allocation policies.\n\nThe primary address pool of the Internet, maintained by IANA, was exhausted on 3 February 2011, when the last five blocks were allocated to the five RIRs. APNIC was the first RIR to exhaust its regional pool on 15 April 2011, except for a small amount of address space reserved for the transition technologies to IPv6, which is to be allocated under a restricted policy.\n\nThe long-term solution to the impending address exhaustion was the 1998 definition of a new version of the Internet Protocol, IPv6, which increased the address size to 128 bits. IPv6 provides a vastly increased address space, but also allows improved route aggregation across the Internet, and offers large subnetwork allocations of a minimum of 2 host addresses to end-users. However, IPv4 is not directly interoperable with IPv6, so that IPv4-only hosts cannot directly communicate with IPv6-only hosts. As migration to IPv6 is in progress, completion is however expected to take considerable time, so that intermediate transition technologies are necessary to permit hosts to participate in the Internet using both versions of the protocol.\n\nAn IP packet consists of a header section and a data section.\n\nAn IP packet has no data checksum or any other footer after the data section.\nTypically the link layer encapsulates IP packets in frames with a CRC footer that detects most errors,\nand typically the end-to-end TCP layer checksum detects most other errors.\n\nThe IPv4 packet header consists of 14 fields, of which 13 are required. The 14th field is optional and aptly named: options. The fields in the header are packed with the most significant byte first (big endian), and for the diagram and discussion, the most significant bits are considered to come first (MSB 0 bit numbering). The most significant bit is numbered 0, so the version field is actually found in the four most significant bits of the first byte, for example.\n\n+ IPv4 Header Format\n! \"Offsets\"\n! Octet\n! colspan=\"8\"  0\n! colspan=\"8\"  1\n! colspan=\"8\"  2\n! colspan=\"8\"  3\n!  Octet\n! Bit\n! style=\"width:2.6%;\" 0\n! style=\"width:2.6%;\" 1\n! style=\"width:2.6%;\" 2\n! style=\"width:2.6%;\" 3\n! style=\"width:2.6%;\" 4\n! style=\"width:2.6%;\" 5\n! style=\"width:2.6%;\" 6\n! style=\"width:2.6%;\" 7\n! style=\"width:2.6%;\" 8\n! style=\"width:2.6%;\" 9\n! style=\"width:2.6%;\" 10\n! style=\"width:2.6%;\" 11\n! style=\"width:2.6%;\" 12\n! style=\"width:2.6%;\" 13\n! style=\"width:2.6%;\" 14\n! style=\"width:2.6%;\" 15\n! style=\"width:2.6%;\" 16\n! style=\"width:2.6%;\" 17\n! style=\"width:2.6%;\" 18\n! style=\"width:2.6%;\" 19\n! style=\"width:2.6%;\" 20\n! style=\"width:2.6%;\" 21\n! style=\"width:2.6%;\" 22\n! style=\"width:2.6%;\" 23\n! style=\"width:2.6%;\" 24\n! style=\"width:2.6%;\" 25\n! style=\"width:2.6%;\" 26\n! style=\"width:2.6%;\" 27\n! style=\"width:2.6%;\" 28\n! style=\"width:2.6%;\" 29\n! style=\"width:2.6%;\" 30\n! style=\"width:2.6%;\" 31\n! 0\n! 0\n! 4\n! 32\n! 8\n! 64\n! 12\n! 96\n! 16\n! 128\n! 20\n! 160\n! 24\n! 192\n! 28\n! 224\n! 32\n! 256\n\nThe IPv4 header is variable in size due to the optional 14th field (options). The IHL field contains the size of the IPv4 header, it has 4 bits that specify the number of 32-bit words in the header. The minimum value for this field is 5, which indicates a length of 5 × 32 bits = 160 bits = 20 bytes. As a 4-bit field, the maximum value is 15, this means that the maximum size of the IPv4 header is 15 × 32 bits, or 480 bits = 60 bytes.\n\n\nThe fragment offset field is measured in units of eight-byte blocks. It is 13 bits long and specifies the offset of a particular fragment relative to the beginning of the original unfragmented IP datagram. The first fragment has an offset of zero. This allows a maximum offset of (2 – 1) × 8 = 65,528 bytes, which would exceed the maximum IP packet length of 65,535 bytes with the header length included (65,528 + 20 = 65,548 bytes).\n\n\nThe options field is not often used. Note that the value in the IHL field must include enough extra 32-bit words to hold all the options (plus any padding needed to ensure that the header contains an integer number of 32-bit words). The list of options may be terminated with an EOL (End of Options List, 0x00) option; this is only necessary if the end of the options would not otherwise coincide with the end of the header. The possible options that can be put in the header are as follows:\n\n! Field !! Size (bits) !! Description\n\nBULLET::::- Note: If the header length is greater than 5 (i.e., it is from 6 to 15) it means that the options field is present and must be considered.\nBULLET::::- Note: Copied, Option Class, and Option Number are sometimes referred to as a single eight-bit field, the \"Option Type\".\n\nPackets containing some options may be considered as dangerous by some routers and be blocked.\n\nThe packet payload is not included in the checksum. Its contents are interpreted based on the value of the Protocol header field.\n\nSome of the common payload protocols are:\n! Protocol Number !! Protocol Name !! Abbreviation\nSee List of IP protocol numbers for a complete list.\n\nThe Internet Protocol enables traffic between networks. The design accommodates networks of diverse physical nature; it is independent of the underlying transmission technology used in the link layer. Networks with different hardware usually vary not only in transmission speed, but also in the maximum transmission unit (MTU). When one network wants to transmit datagrams to a network with a smaller MTU, it may fragment its datagrams. In IPv4, this function was placed at the Internet Layer, and is performed in IPv4 routers, which thus require no implementation of any higher layers for the function of routing IP packets.\n\nIn contrast, IPv6, the next generation of the Internet Protocol, does not allow routers to perform fragmentation; hosts must determine the path MTU before sending datagrams.\n\nWhen a router receives a packet, it examines the destination address and determines the outgoing interface to use and that interface's MTU. If the packet size is bigger than the MTU, and the Do not Fragment (DF) bit in the packet's header is set to 0, then the router may fragment the packet.\n\nThe router divides the packet into fragments. The max size of each fragment is the MTU minus the IP header size (20 bytes minimum; 60 bytes maximum). The router puts each fragment into its own packet, each fragment packet having following changes:\nBULLET::::- The \"total length\" field is the fragment size.\nBULLET::::- The \"more fragments\" (MF) flag is set for all fragments except the last one, which is set to 0.\nBULLET::::- The \"fragment offset\" field is set, based on the offset of the fragment in the original data payload. This is measured in units of eight-byte blocks.\nBULLET::::- The \"header checksum\" field is recomputed.\n\nFor example, for an MTU of 1,500 bytes and a header size of 20 bytes, the fragment offsets would be multiples of\nformula_1.\nThese multiples are 0, 185, 370, 555, 740, ...\n\nIt is possible that a packet is fragmented at one router, and that the fragments are further fragmented at another router. For example, a packet of 4,520 bytes, including the 20 bytes of the IP header (without options) is fragmented to two packets on a link with an MTU of 2,500 bytes:\n\n!Fragment\n!Size\n!Header size\n!Data size\n!Flag\"More fragments\"\n!Fragment offset\n1\n2500\n20\n2480\n1\n0\n2\n2040\n20\n2020\n0\n310\n\nThe total data size is preserved: 2480 bytes + 2020 bytes = 4500 bytes.\nThe offsets are\nformula_2\nand\nformula_3.\n\nOn a link with an MTU of 1,500 bytes, each fragment results in two fragments:\n\n!Fragment\n!Size\n!Header size\n!Data size\n!Flag\"More fragments\"\n!Fragment offset\n1\n1500\n20\n1480\n1\n0\n2\n1020\n20\n1000\n1\n185\n3\n1500\n20\n1480\n1\n310\n4\n560\n20\n540\n0\n495\n\nAgain, the data size is preserved: 1480 + 1000 = 2480, and 1480 + 540 = 2020.\n\nAlso in this case, the \"More Fragments\" bit remains 1 for all the fragments that came with 1 in them and for the last fragment that arrives, it works as usual, that is the MF bit is set to 0 only in the last one. And of course, the Identification field continues to have the same value in all re-fragmented fragments. This way, even if fragments are re-fragmented, the receiver knows they have initially all started from the same packet.\n\nThe last offset and last data size are used to calculate the total data size:\nformula_4.\n\nA receiver knows that a packet is a fragment, if at least one of the following conditions is true:\nBULLET::::- The flag \"more fragments\" is set, which is true for all fragments except the last.\nBULLET::::- The field \"fragment offset\" is nonzero, which is true for all fragments except the first.\n\nThe receiver identifies matching fragments using the foreign and local address, the protocol ID, and the identification field. The receiver reassembles the data from fragments with the same ID using both the fragment offset and the more fragments flag. When the receiver receives the last fragment, which has the \"more fragments\" flag set to 0, it can calculate the size of the original data payload, by multiplying the last fragment's offset by eight, and adding the last fragment's data size. In the given example, this calculation was 495*8 + 540 = 4500 bytes.\n\nWhen the receiver has all fragments, they can be reassembled in the correct sequence according to the offsets, to form the original datagram.\n\nIP addresses are not tied in any permanent manner to hardware identifications and, indeed, a network interface can have multiple IP addresses in modern operating systems. Hosts and routers need additional mechanisms to identify the relationship between device interfaces and IP addresses, in order to properly deliver an IP packet to the destination host on a link. The Address Resolution Protocol (ARP) performs this IP-address-to-hardware-address translation for IPv4. (A hardware address is also called a MAC address.) In addition, the reverse correlation is often necessary. For example, when an IP host is booted or connected to a network it needs to determine its IP address, unless an address is preconfigured by an administrator. Protocols for such inverse correlations exist in the Internet Protocol Suite. Currently used methods are Dynamic Host Configuration Protocol (DHCP), Bootstrap Protocol (BOOTP) and, infrequently, reverse ARP.\n\nBULLET::::- History of the Internet\nBULLET::::- List of assigned /8 IPv4 address blocks\nBULLET::::- List of IP protocol numbers\n\nBULLET::::- https://www.iana.org — Internet Assigned Numbers Authority (IANA)\nBULLET::::- http://www.networksorcery.com/enp/protocol/ip.htm — IP Header Breakdown, including specific options\nBULLET::::- RFC 3344 — IPv4 Mobility\nBULLET::::- IPv6 vs. carrier-grade NAT/squeezing more out of IPv4\nBULLET::::- RIPE report on address consumption as of October 2003\nBULLET::::- Official current state of IPv4 /8 allocations, as maintained by IANA\nBULLET::::- Dynamically generated graphs of IPv4 address consumption with predictions of exhaustion dates—Geoff Huston\nBULLET::::- IP addressing in China and the myth of address shortage\nBULLET::::- Countdown of remaining IPv4 available addresses (estimated)\n"}
{"id": "15318", "url": "https://en.wikipedia.org/wiki?curid=15318", "title": "IPv6", "text": "IPv6\n\nInternet Protocol version 6 (IPv6) is the most recent version of the Internet Protocol (IP), the communications protocol that provides an identification and location system for computers on networks and routes traffic across the Internet. IPv6 was developed by the Internet Engineering Task Force (IETF) to deal with the long-anticipated problem of IPv4 address exhaustion. IPv6 is intended to replace IPv4. In December 1998, IPv6 became a Draft Standard for the IETF, who subsequently ratified it as an Internet Standard on 14 July 2017.\n\nDevices on the Internet are assigned a unique IP address for identification and location definition. With the rapid growth of the Internet after commercialization in the 1990s, it became evident that far more addresses would be needed to connect devices than the IPv4 address space had available. By 1998, the Internet Engineering Task Force (IETF) had formalized the successor protocol. IPv6 uses a 128-bit address, theoretically allowing 2, or approximately addresses. The actual number is slightly smaller, as multiple ranges are reserved for special use or completely excluded from use. The total number of possible IPv6 addresses is more than times as many as IPv4, which uses 32-bit addresses and provides approximately 4.3 billion addresses. The two protocols are not designed to be interoperable, and thus direct communication between them is impossible, complicating the move to IPv6. However, several transition mechanisms have been devised to rectify this.\n\nIPv6 provides other technical benefits in addition to a larger addressing space. In particular, it permits hierarchical address allocation methods that facilitate route aggregation across the Internet, and thus limit the expansion of routing tables. The use of multicast addressing is expanded and simplified, and provides additional optimization for the delivery of services. Device mobility, security, and configuration aspects have been considered in the design of the protocol.\n\nIPv6 addresses are represented as eight groups, separated by colons, of four hexadecimal digits. The full representation may be simplified by several methods of notation; for example, \"2001:0db8:0000:0000:0000:8a2e:0370:7334\" becomes \"2001:db8::8a2e:370:7334\".\n\nIPv6 is an Internet Layer protocol for packet-switched internetworking and provides end-to-end datagram transmission across multiple IP networks, closely adhering to the design principles developed in the previous version of the protocol, Internet Protocol Version 4 (IPv4).\n\nIn addition to offering more addresses, IPv6 also implements features not present in IPv4. It simplifies aspects of address configuration, network renumbering, and router announcements when changing network connectivity providers. It simplifies processing of packets in routers by placing the responsibility for packet fragmentation into the end points. The IPv6 subnet size is standardized by fixing the size of the host identifier portion of an address to 64 bits.\n\nThe addressing architecture of IPv6 is defined in and allows three different types of transmission: unicast, anycast and multicast.\n\nInternet Protocol Version 4 (IPv4) was the first publicly used version of the Internet Protocol. IPv4 was developed as a research project by the Defense Advanced Research Projects Agency (DARPA), a United States Department of Defense agency, before becoming the foundation for the Internet and the World Wide Web. IPv4 includes an addressing system that uses numerical identifiers consisting of 32 bits. These addresses are typically displayed in quad-dotted notation as decimal values of four octets, each in the range 0 to 255, or 8 bits per number. Thus, IPv4 provides an addressing capability of 2 or approximately 4.3 billion addresses. Address exhaustion was not initially a concern in IPv4 as this version was originally presumed to be a test of DARPA's networking concepts. During the first decade of operation of the Internet, it became apparent that methods had to be developed to conserve address space. In the early 1990s, even after the redesign of the addressing system using a classless network model, it became clear that this would not suffice to prevent IPv4 address exhaustion, and that further changes to the Internet infrastructure were needed.\n\nThe last unassigned top-level address blocks of 16 million IPv4 addresses were allocated in February 2011 by the Internet Assigned Numbers Authority (IANA) to the five regional Internet registries (RIRs). However, each RIR still has available address pools and is expected to continue with standard address allocation policies until one /8 Classless Inter-Domain Routing (CIDR) block remains. After that, only blocks of 1024 addresses (/22) will be provided from the RIRs to a local Internet registry (LIR). As of September 2015, all of Asia-Pacific Network Information Centre (APNIC), the Réseaux IP Européens Network Coordination Centre (RIPE_NCC), Latin America and Caribbean Network Information Centre (LACNIC), and American Registry for Internet Numbers (ARIN) have reached this stage. This leaves African Network Information Center (AFRINIC) as the sole regional internet registry that is still using the normal protocol for distributing IPv4 addresses. As of November 2018, AFRINIC's minimum allocation is /22 or 1024 IPv4 addresses. A LIR may receive additional allocation when about 80% of all the address space has been utilized.\n\nRIPE NCC announced that it had fully run out of IPv4 addresses on November 25, 2019, and called for greater progress on the adoption of IPv6.\n\nIt is widely expected that the Internet will use IPv4 alongside IPv6 for the foreseeable future.\n\nOn the Internet, data is transmitted in the form of network packets. IPv6 specifies a new packet format, designed to minimize packet header processing by routers. Because the headers of IPv4 packets and IPv6 packets are significantly different, the two protocols are not interoperable. However, most transport and application-layer protocols need little or no change to operate over IPv6; exceptions are application protocols that embed Internet-layer addresses, such as File Transfer Protocol (FTP) and Network Time Protocol (NTP), where the new address format may cause conflicts with existing protocol syntax.\n\nThe main advantage of IPv6 over IPv4 is its larger address space. The length of an IPv6 address is 128 bits, compared with 32 bits in IPv4. The address space therefore has 2 or approximately addresses (340,282,366,920,938,463,463,374,607,431,768,211,456, which is approximately 340 undecillion, or 340 billion billion billion billion, addresses). As with IPv4, some of these addresses are reserved for special uses.\n\nIn addition, the IPv4 address space is poorly allocated; in 2011, approximately 14% of all available addresses were utilized. While these numbers are large, it was not the intent of the designers of the IPv6 address space to assure geographical saturation with usable addresses. Rather, the longer addresses simplify allocation of addresses, enable efficient route aggregation, and allow implementation of special addressing features. In IPv4, complex Classless Inter-Domain Routing (CIDR) methods were developed to make the best use of the small address space. The standard size of a subnet in IPv6 is 2 addresses, more than 4 billion times the size of the entire IPv4 address space. Thus, actual address space utilization rates will be small in IPv6, but network management and routing efficiency are improved by the large subnet space and hierarchical route aggregation.\n\nMulticasting, the transmission of a packet to multiple destinations in a single send operation, is part of the base specification in IPv6. In IPv4 this is an optional (although commonly implemented) feature. IPv6 multicast addressing has features and protocols in common with IPv4 multicast, but also provides changes and improvements by eliminating the need for certain protocols. IPv6 does not implement traditional IP broadcast, i.e. the transmission of a packet to all hosts on the attached link using a special \"broadcast address\", and therefore does not define broadcast addresses. In IPv6, the same result is achieved by sending a packet to the link-local \"all nodes\" multicast group at address ff02::1, which is analogous to IPv4 multicasting to address 224.0.0.1. IPv6 also provides for new multicast implementations, including embedding rendezvous point addresses in an IPv6 multicast group address, which simplifies the deployment of inter-domain solutions.\n\nIn IPv4 it is very difficult for an organization to get even one globally routable multicast group assignment, and the implementation of inter-domain solutions is arcane. Unicast address assignments by a local Internet registry for IPv6 have at least a 64-bit routing prefix, yielding the smallest subnet size available in IPv6 (also 64 bits). With such an assignment it is possible to embed the unicast address prefix into the IPv6 multicast address format, while still providing a 32-bit block, the least significant bits of the address, or approximately 4.2 billion multicast group identifiers. Thus each user of an IPv6 subnet automatically has available a set of globally routable source-specific multicast groups for multicast applications.\n\nIPv6 hosts can configure themselves automatically when connected to an IPv6 network using the Neighbor Discovery Protocol via Internet Control Message Protocol version 6 (ICMPv6) router discovery messages. When first connected to a network, a host sends a link-local router solicitation multicast request for its configuration parameters; routers respond to such a request with a router advertisement packet that contains Internet Layer configuration parameters. Routers present a special case of requirements for address configuration, as they often are sources of autoconfiguration information, such as router and prefix advertisements. Stateless configuration of routers can be achieved with a special router renumbering protocol.\n\nRenumbering an existing network for a new connectivity provider with different routing prefixes is a major effort with IPv4. With IPv6, however, changing the prefix announced by a few routers can in principle renumber an entire network, since the host identifiers (the least-significant 64 bits of an address) can be independently self-configured by a host.\n\nIf IPv6 stateless address auto-configuration is unsuitable, IPv6 just like IPv4 allows for stateful configuration with the Dynamic Host Configuration Protocol version 6 (DHCPv6) or manual static configuration of hosts.\n\nLike IPv4, IPv6 supports globally unique IP addresses. The design of IPv6 intended to re-emphasize the end-to-end principle of network design that was originally conceived during the establishment of the early Internet. In this approach, each device on the network has a unique address globally reachable directly from any other location on the Internet.\n\nA unique IP address can potentially be used to track the network activity of a device. Moreover, when using IPv6 address auto-configuration, the Interface Identifier (MAC address) of a network card is used to make its public IPv6 interface identifier unique, exposing the type of hardware used and providing a unique handle for a user's online activity. Autoconfiguration on the basis of the network card MAC address is, therefore, a particular privacy concern for mobile devices, such as laptops, because when they access the Internet from different local area networks, their MAC based interface identifier would always stay the same. Thus the MAC address based interface identifier can be used to track the movement and usage of a particular mobile device.\n\nWhen IPv6 was developed in the mid-90s, the Internet was not accessed by a large number of mobile devices and privacy was not the priority it has become today. To address these privacy concerns, the SLAAC protocol was updated with mechanisms that were termed “Privacy Extensions for Stateless Address Autoconfiguration in IPv6”, codified in RFC 4941, which introduced what are typically called \"privacy addresses\" or, more correctly, \"temporary addresses\". Temporary addresses employ randomized interface identifiers, and are generated in addition to stable addresses, and are to be employed for client-like outgoing communications, thus preventing IPv6 addresses from leaking the MAC address of the device when performing client-like operations. As the name implies, and as opposed to stable addresses, the Preferred Lifetime and Valid Lifetime of temporary addresses are not refreshed upon receipt of ICMPv6 RA packets advertising the corresponding SLAAC prefix. Instead, old addresses are phased out as new temporary addresses are configured. Typically the Preferred Lifetime of temporary addresses defaults to 1 day, while the Valid Lifetime defaults to 1 week. This means that IPv6 autoconfiguration will generate and set a new IPv6 host temporary every day, which will be valid for one week. As a result, a host that has had an uptime of at least one week may employ up to seven temporary addresses. As of late 2014 the SLAAC privacy extensions functionality was implemented by the following operating systems: all Microsoft Windows after Windows XP, all versions of Mac OS X from 10.7 onward, all versions of iOS since 4.3, all versions of Android since 4.0 (Ice Cream Sandwich). The privacy extension is now enabled by default in Windows (since XP SP1), OS X (since 10.7), and iOS (since version 4.3). Some Linux distributions have enabled privacy extensions as well.\n\nSince temporary addresses do not eliminate the security and privacy implications of the traditional SLAAC stable addresses (that embed the underlying MAC address), the traditional scheme to generate stable addresses has been replaced by RFC 8064 with the method codified in RFC 7217 (sometimes known as \"stable-privacy addresses\", due to the filename of the IETF internet-draft that introduced the idea). RFC7217 addresses have been implemented and enabled by default in most recent versions of Ubuntu, Fedora, FreeBSD, and OpenBSD.\n\nInternet Protocol Security (IPsec) was originally developed for IPv6, but found widespread deployment first in IPv4, for which it was re-engineered. IPsec was a mandatory part of all IPv6 protocol implementations, and Internet Key Exchange (IKE) was recommended, but with RFC 6434 the inclusion of IPsec in IPv6 implementations was downgraded to a recommendation because it was considered impractical to require full IPsec implementation for all types of devices that may use IPv6. However, as of RFC 4301 IPv6 protocol implementations that do implement IPsec need to implement IKEv2 and need to support a minimum set of cryptographic algorithms. This requirement will help to make IPsec implementations more interoperable between devices from different vendors. The IPsec Authentication Header (AH) and the Encapsulating Security Payload header (ESP) are implemented as IPv6 extension headers.\n\nThe packet header in IPv6 is simpler than the IPv4 header. Many rarely used fields have been moved to optional header extensions. With the simplified IPv6 packet header the process of packet forwarding by routers has been simplified. Although IPv6 packet headers are at least twice the size of IPv4 packet headers, processing of packets that only contain the base IPv6 header by routers may, in some case, be more efficient, because less processing is required in routers due to the headers being aligned to match common word sizes. However, many devices implement IPv6 support in software (as opposed to hardware), thus resulting in very bad packet processing performance. Additionally, for many implementations, the use of Extension Headers causes packets to be processed by a router's CPU, leading to poor performance or even security issues.\n\nMoreover, an IPv6 header does not include a checksum. The IPv4 header checksum is calculated for the IPv4 header, and has to be recalculated by routers every time the time to live (called hop limit in the IPv6 protocol) is reduced by one. The absence of a checksum in the IPv6 header furthers the end-to-end principle of Internet design, which envisioned that most processing in the network occurs in the leaf nodes. Integrity protection for the data that is encapsulated in the IPv6 packet is assumed to be assured by both the link layer or error detection in higher-layer protocols, namely the Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) on the transport layer. Thus, while IPv4 allowed UDP datagram headers to have no checksum (indicated by 0 in the header field), IPv6 requires a checksum in UDP headers.\n\nIPv6 routers do not perform IP fragmentation. IPv6 hosts are required to either perform path MTU discovery, perform end-to-end fragmentation, or to send packets no larger than the default Maximum transmission unit (MTU), which is 1280 octets.\n\nUnlike mobile IPv4, mobile IPv6 avoids triangular routing and is therefore as efficient as native IPv6. IPv6 routers may also allow entire subnets to move to a new router connection point without renumbering.\n\nThe IPv6 packet header has a minimum size of 40 octets (320 bits). Options are implemented as extensions. This provides the opportunity to extend the protocol in the future without affecting the core packet structure. However, RFC 7872 notes that some network operators drop IPv6 packets with extension headers when they traverse transit autonomous systems.\n\nIPv4 limits packets to 65,535 (2−1) octets of payload. An IPv6 node can optionally handle packets over this limit, referred to as jumbograms, which can be as large as 4,294,967,295 (2−1) octets. The use of jumbograms may improve performance over high-MTU links. The use of jumbograms is indicated by the Jumbo Payload Option extension header.\n\nAn IPv6 packet has two parts: a header and payload.\n\nThe header consists of a fixed portion with minimal functionality required for all packets and may be followed by optional extensions to implement special features.\n\nThe fixed header occupies the first 40 octets (320 bits) of the IPv6 packet. It contains the source and destination addresses, traffic classification options, a hop counter, and the type of the optional extension or payload which follows the header. This \"Next Header\" field tells the receiver how to interpret the data which follows the header. If the packet contains options, this field contains the option type of the next option. The \"Next Header\" field of the last option, points to the upper-layer protocol that is carried in the packet's payload.\n\nExtension headers carry options that are used for special treatment of a packet in the network, e.g., for routing, fragmentation, and for security using the IPsec framework.\n\nWithout special options, a payload must be less than . With a Jumbo Payload option (in a \"Hop-By-Hop Options\" extension header), the payload must be less than 4 GB.\n\nUnlike with IPv4, routers never fragment a packet. Hosts are expected to use Path MTU Discovery to make their packets small enough to reach the destination without needing to be fragmented. See IPv6 packet fragmentation.\n\nIPv6 addresses have 128 bits. The design of the IPv6 address space implements a different design philosophy than in IPv4, in which subnetting was used to improve the efficiency of utilization of the small address space. In IPv6, the address space is deemed large enough for the foreseeable future, and a local area subnet always uses 64 bits for the host portion of the address, designated as the interface identifier, while the most-significant 64 bits are used as the routing prefix. While the myth has existed regarding IPv6 subnets being impossible to scan, RFC 7707 notes that patterns resulting from some IPv6 address configuration techniques and algorithms allow for address scanning in many real-world scenarios.\n\nThe identifier is only unique within the subnet to which a host is connected. IPv6 has a mechanism for automatic duplicate address detection, so that address autoconfiguration always produces unique assignments.\n\nThe 128 bits of an IPv6 address are represented in 8 groups of 16 bits each. Each group is written as four hexadecimal digits (sometimes called hextets or more formally hexadectets and informally a quibble or quad-nibble ) and the groups are separated by colons (:). An example of this representation is .\n\nFor convenience, an IPv6 address may be abbreviated to shorter notations by application of the following rules.\nBULLET::::- One or more leading zeros from any groups of hexadecimal digits are removed; this is usually done to either all or none of the leading zeros. For example, the group is converted to .\nBULLET::::- Consecutive sections of zeros are replaced with a double colon (::). The double colon may only be used once in an address, as multiple use would render the address indeterminate. requires that a double colon not be used to denote an omitted single section of zeros.\n\nAn example of application of these rules:\n\nThe loopback address is defined in and may be abbreviated to by using both rules.\n\nAs an IPv6 address may have more than one representation, the IETF has issued a proposed standard for representing them in text.\n\nAll interfaces of IPv6 hosts require a link-local address. IPv6 link-local addresses have the prefix . This prefix is combined with a 64 bit suffix, which the host can compute and/or assign by itself—without configuration and without the presence or cooperation of an external network component like a DHCP server.\n\nThe lower 64 bits of the link local address (the suffix) were originally derived from the MAC address of the underlying network interface card. As this method of assigning addresses would cause undesirable address changes when faulty network cards were replaced, and as it also suffered from a number of security and privacy issues, RFC 8064 has replaced the original MAC-based method with the hash-based method specified in RFC 7217.\n\nIPv6 uses a new mechanism for mapping IP addresses to link layer addresses (MAC addresses), because it does not support the broadcast addressing method, on which the functionality of the Address Resolution Protocol (ARP) in IPv4 is based. IPv6 implements the Neighbor Discovery Protocol (NDP, ND) in the link layer, which relies on ICMPv6 and multicast transmission. IPv6 hosts verify the uniqueness of their IPv6 addresses in a local area network (LAN) by sending a neighbor solicitation message asking for the link layer address of the IP address. If any other host in the LAN is using that address, it responds. In a LAN, MAC addresses are designed to be unique, which minimizes chances of duplication.\n\nAfter having generated a link-local address, the IPv6 host determines if the LAN is connected to any router network card with IPv6 implementation by sending out an ICMPv6 router solicitation message to the all-routers multicast group with its link-local address as source. If there is no answer after a predetermined number of attempts, the host concludes that no routers are connected. If it does get a response from a router, there will be network information inside that is needed to create a globally unique address. There are also two flag bits that tell the host whether it should use DHCP to get further information and addresses:\nBULLET::::- The Manage bit, that indicates whether or not the host should use DHCP to obtain additional addresses\nBULLET::::- The Other bit, that indicates whether or not the host should obtain other information through DHCP. The other information consists of one or more prefix information options for the subnets that the host is attached to, a lifetime for the prefix, and two flags:\nBULLET::::- On-link: If this flag is set, the host will treat all addresses on the specific subnet as being on-link, and send packets directly to them instead of sending them to a router for the duration of the given lifetime.\nBULLET::::- Address: This is the flag that tells the host to actually create a global address.\n\nThe assignment procedure for global addresses is similar to local address construction. The prefix is supplied from router advertisements on the network. Multiple prefix announcements cause multiple addresses to be configured.\n\nStateless address autoconfiguration (SLAAC) requires a address block, as defined in . Local Internet registries are assigned at least blocks, which they divide among subordinate networks. The initial recommendation stated assignment of a subnet to end-consumer sites (). This was replaced by , which \"recommends giving home sites significantly more than a single , but does not recommend that every home site be given a either\". s are specifically considered. It remains to be seen if ISPs will honor this recommendation. For example, during initial trials, Comcast customers were given a single network.\n\nIn the Domain Name System (DNS), hostnames are mapped to IPv6 addresses by AAAA (\"quad-A\") resource records. For reverse resolution, the IETF reserved the domain ip6.arpa, where the name space is hierarchically divided by the 1-digit hexadecimal representation of nibble units (4 bits) of the IPv6 address. This scheme is defined in .\n\nWhen a dual-stack host queries a DNS server to resolve a fully qualified domain name (FQDN), the DNS client of the host sends two DNS requests, one querying A records and the other querying AAAA records. The host operating system may be configured with a preference for address selection rules .\nAn alternate record type was used in early DNS implementations for IPv6, designed to facilitate network renumbering, the \"A6\" records for the forward lookup and a number of other innovations such as \"bit-string labels\" and \"DNAME\" records. It is defined in and its references (with further discussion of the pros and cons of both schemes in ), but has been deprecated to experimental status ().\n\nIPv6 is not foreseen to supplant IPv4 instantaneously. Both protocols will continue to operate simultaneously for some time. Therefore, IPv6 transition mechanisms are needed to enable IPv6 hosts to reach IPv4 services and to allow isolated IPv6 hosts and networks to reach each other over IPv4 infrastructure.\n\nAccording to Silvia Hagen, a dual-stack implementation of the IPv4 and IPv6 on devices is the easiest way to migrate to IPv6. Many other transition mechanisms use tunneling to encapsulate IPv6 traffic within IPv4 networks and vice versa. This is an imperfect solution, which reduces the maximum transmission unit (MTU) of a link and therefore complicates Path MTU Discovery, and may increase latency.\n\nDual-stack IP implementations provide complete IPv4 and IPv6 protocol stacks in the operating system of a computer or network device on top of the common physical layer implementation, such as Ethernet. This permits dual-stack hosts to participate in IPv6 and IPv4 networks simultaneously. The method is defined in .\n\nA device with dual-stack implementation in the operating system has an IPv4 and IPv6 address, and can communicate with other nodes in the LAN or the Internet using either IPv4 or IPv6. The Domain Name System (DNS) protocol is used by both IP protocols to resolve fully qualified domain names (FQDN) and IP addresses, but dual stack requires that the resolving DNS server can resolve both types of addresses. Such a dual stack DNS server would hold IPv4 addresses in the A records, and IPv6 addresses in the AAAA records. Depending on the destination that is to be resolved, a DNS name server may return an IPv4 or IPv6 IP address, or both. A default address selection mechanism, or preferred protocol, needs to be configured either on hosts or the DNS server. The IETF has published Happy Eyeballs to assist dual stack applications, so that they can connect using both IPv4 and IPv6, but prefer an IPv6 connection if it is available. However, dual-stack also needs to be implemented on all routers between the host and the service for which the DNS server has returned an IPv6 address. Dual-stack clients should only be configured to prefer IPv6, if the network is able to forward IPv6 packets using the IPv6 versions of routing protocols. When dual stack networks protocols are in place the application layer can be migrated to IPv6.\n\nWhile dual-stack is supported by major operating system and network device vendors, legacy networking hardware and servers don't support IPv6.\n\nInternet service providers (ISPs) are increasingly providing their business and private customers with public-facing IPv6 global unicast addresses. However, if in the local area network (LAN) IPv4 is still used, and the ISP can only provide a public facing IPv6, the IPv4 LAN addresses are translated into the public facing IPv6 address using NAT64, a network address translation (NAT) mechanism. Some ISPs cannot provide their customers with public-facing IPv4 and IPv6 addresses, thus supporting dual stack networking, because some ISPs have exhausted their globally routable IPv4 address pool. Meanwhile, ISP customers are still trying to reach IPv4 web servers and other destinations.\n\nA significant percentage of ISPs in all regional Internet registry (RIR) zones have obtained IPv6 address space. This includes many of the world's major ISPs and mobile network operators, such as Verizon Wireless, StarHub Cable, Chubu Telecommunications, Kabel Deutschland, Swisscom, T-Mobile, Internode and Telefonica.\n\nWhile some ISPs still allocate customers only IPv4 addresses, many ISPs allocate their customers only an IPv6 or dual stack IPv4 and IPv6. ISPs report the share of IPv6 traffic from customers over their network to be anything between 20% and 40%, but by mid-2017 IPv6 traffic still only accounted for a fraction of total traffic at several large Internet exchange points (IXPs). AMS-IX reported it to be 2% and SeattleIX reported 7%. A 2017 survey found that many DSL customers that were served by a dual stack ISP did not request DNS servers to resolve fully qualified domain names into IPv6 addresses. The survey also found that the majority of traffic from IPv6-ready webserver resources were still requested and served over IPv4, mostly due to ISP customers that did not use the dual stack facility provided by their ISP and to a lesser extent due to customers of IPv4-only ISPs.\n\nThe technical basis for tunneling, or encapsulating IPv6 packets in IPv4 packets, is outlined in RFC 4213. When the Internet backbone was IPv4-only, one of the frequently used tunneling protocols was 6to4. Teredo tunneling was also frequently used for integrating IPv6 LANs with the IPv4 Internet backbone. Teredo is outlined in RFC 4380 and allows IPv6 local area networks to tunnel over IPv4 networks, by encapsulating IPv6 packets within UDP. The Teredo relay is an IPv6 router that mediates between a Teredo server and the native IPv6 network. It was expected that 6to4 and Teredo would be widely deployed until ISP networks would switch to native IPv6, but by 2014 Google Statistics showed that the use of both mechanisms had dropped to almost 0.\n\nHybrid dual-stack IPv6/IPv4 implementations recognize a special class of addresses, the IPv4-mapped IPv6 addresses. These addresses are typically written with a 96-bit prefix in the standard IPv6 format, and the remaining 32 bits written in the customary dot-decimal notation of IPv4.\n\nAddresses in this group consist of an 80-bit prefix of zeros, the next 16 bits are ones, and the remaining, least-significant 32 bits contain the IPv4 address. For example, ::ffff:192.0.2.128 represents the IPv4 address 192.0.2.128. Another format, called \"IPv4-compatible IPv6 address\", is ::192.0.2.128; however, this method is deprecated.\n\nBecause of the significant internal differences between IPv4 and IPv6 protocol stacks, some of the lower-level functionality available to programmers in the IPv6 stack does not work the same when used with IPv4-mapped addresses. Some common IPv6 stacks do not implement the IPv4-mapped address feature, either because the IPv6 and IPv4 stacks are separate implementations (e.g., Microsoft Windows 2000, XP, and Server 2003), or because of security concerns (OpenBSD). On these operating systems, a program must open a separate socket for each IP protocol it uses. On some systems, e.g., the Linux kernel, NetBSD, and FreeBSD, this feature is controlled by the socket option IPV6_V6ONLY, as specified in .\n\nCompatibility with IPv6 networking is mainly a software or firmware issue. However, much of the older hardware that could in principle be upgraded is likely to be replaced instead. In 2010, the American Registry for Internet Numbers (ARIN) suggested that all Internet servers be prepared to serve IPv6-only clients by January 2012.\n\nHost software may have only IPv4 or only IPv6 networking software, or it may support dual-stack, or hybrid dual-stack operation. Many popular applications with networking capabilities are compliant. Some software transitioning mechanisms are outlined in , , and .\n\nIPv6 has been implemented on all major operating systems in use in commercial, business, and home consumer environments. All personal computers and smartphones running recent major operating system versions support IPv6.\n\nThe CableLabs consortium published the 160 Mbit/s DOCSIS 3.0 IPv6-ready specification for cable modems in August 2006. DOCSIS 2.0 was updated as \"DOCSIS 2.0 + IPv6\" to provide IPv6 support, which may be available with a firmware upgrade.\n\nA number of security implications may arise from the use of IPv6. Some of them may be related with the IPv6 protocols themselves, while others may be related with implementations flaws.\n\nThe addition of nodes having IPv6 enabled by default by the software manufacturer, may result in the inadvertent creation of \"shadow networks\", causing IPv6 traffic flowing into networks having only IPv4 security management in place. This may also occur with operating system upgrades, when the newer operating system enables IPv6 by default, while the older one did not. Failing to update the security infrastructure to accommodate IPv6 can lead to IPv6 traffic bypassing it. Shadow networks have occurred on business networks in which enterprises are replacing Windows XP systems that do not have an IPv6 stack enabled by default, with Windows 7 systems, that do. Some IPv6 stack implementors have therefore recommended disabling IPv4 mapped addresses and instead using a dual-stack network where supporting both IPv4 and IPv6 is necessary.\n\nResearch has shown that the use of fragmentation can be leveraged to evade network security controls, similar to IPv4. As a result, requires that the first fragment of an IPv6 packet contains the entire IPv6 header chain, such that some very pathological fragmentation cases are forbidden. Additionally, as a result of research on the evasion of RA-Guard in , has deprecated the use of fragmentation with Neighbor Discovery, and discouraged the use of fragmentation with Secure Neighbor Discovery (SEND).\n\nDue to the anticipated global growth of the Internet, the Internet Engineering Task Force (IETF) in the early 1990s started an effort to develop a next generation IP protocol. By the beginning of 1992, several proposals appeared for an expanded Internet addressing system and by the end of 1992 the IETF announced a call for white papers. In September 1993, the IETF created a temporary, ad-hoc \"IP Next Generation\" (IPng) area to deal specifically with such issues. The new area was led by Allison Mankin and Scott Bradner, and had a directorate with 15 engineers from diverse backgrounds for direction-setting and preliminary document review: The working-group members were J. Allard (Microsoft), Steve Bellovin (AT&T), Jim Bound (Digital Equipment Corporation), Ross Callon (Wellfleet), Brian Carpenter (CERN), Dave Clark (MIT), John Curran (NEARNET), Steve Deering (Xerox), Dino Farinacci (Cisco), Paul Francis (NTT), Eric Fleischmann (Boeing), Mark Knopper (Ameritech), Greg Minshall (Novell), Rob Ullmann (Lotus), and Lixia Zhang (Xerox).\n\nThe Internet Engineering Task Force adopted the IPng model on 25 July 1994, with the formation of several IPng working groups. By 1996, a series of RFCs was released defining Internet Protocol version 6 (IPv6), starting with . (Version 5 was used by the experimental Internet Stream Protocol.)\n\nThe first RFC to standardize IPv6 was the in 1995, which became obsoleted by in 1998. In July 2017 this RFC was obsoleted by , which elevated IPv6 to \"Internet Standard\" (the highest maturity level for IETF protocols).\n\nThe 1993 introduction of Classless Inter-Domain Routing (CIDR) in the routing and IP address allocation for the Internet, and the extensive use of network address translation (NAT), delayed IPv4 address exhaustion. The final phase of exhaustion started on 3 February 2011. Universities were among the early adopters of IPv6. Virginia Tech deployed IPv6 at a trial location in 2004 and has since expanded IPv6 deployment across the campus network. In 2016 82% of the traffic on their network used IPv6. Imperial College London has been experimenting with IPv6 deployment since 2003 and in 2016 the IPv6 traffic on their networks averaged between 20% and 40%. A significant portion of this IPv6 traffic was generated through their high energy physics collaboration with CERN, which relies entirely on IPv6.\n\nSince 2008, the Domain Name System (DNS) supports IPv6. In the same year, IPv6 was first used in a major world event during the Beijing 2008 Summer Olympics. , about 4% of domain names and 16.2% of the networks in the Internet had IPv6 protocol support. In 2014, IPv4 still carried more than 99% of worldwide Internet traffic.\n\nThe deployment of IPv6 in the Internet backbone is in progress. In 2018 only 25.3% of the about 54,000 autonomous systems advertised both IPv4 and IPv6 prefixes in the global Border Gateway Protocol (BGP) routing database. A further 243 networks advertised only an IPv6 prefix. Internet backbone transit networks offering IPv6 support exist in every country globally, except in parts of Africa, the Middle East and China. By mid-2018 some major European broadband ISPs had deployed IPv6 for the majority of their customers. British Sky Broadcasting provided over 86% of its customers with IPv6, Deutsche Telekom had 56% deployment of IPv6, XS4ALL in the Netherlands had 73% deployment and in Belgium the broadband ISPs VOO and Telenet had 73% and 63% IPv6 deployment respectively. In the United States the broadband ISP Comcast had an IPv6 deployment of about 66%. In 2018 Comcast reported an estimated 36.1 million IPv6 users, while AT&T reported 22.3 million IPv6 users.\n\nThe Internet exchanges in Amsterdam and Seattle are the only large exchanges that publicly show IPv6 traffic statistics, which as of October 2018 are tracking at about 2.9% and 7.7%, growing at about 1.9% and -2.6% per year, respectively. , the percentage of users reaching Google services with IPv6 is about 29% and about 26% of Alexa Top 1000 web servers support IPv6. According to the Internet Society's report \"State of IPv6 Deployment 2018\" major mobile network providers drove the IPv6 adoption. In Japan the mobile network providers Nippon Telegraph and Telephone (NTT), KDDI and SoftBank pushed forward on IPv6 deployment, while in India IPv6 adoption was advanced by Jio, which has a LTE network which covers India's 29 states and reaches 80% of the country's population. In 2018 Jio had an estimated 237.6 million IPv6 users. In the United States IPv6 adoption was pioneered by Verizon Wireless. In 2009 Verizon mandated IPv6 operation and reduced IPv4 to an optional capability for LTE cellular hardware. Verizon productively deployed IPv6 across its existing IPv4 network to avoid the network complexity that arose from networks using the same private network IPv4 address space. As of 2018 80% of the traffic from Verizon Wireless to major content providers was using IPv6.\n\nIn the United States, some data centers are transitioned to IPv6 networking. Since 2018, Facebook has been eliminating IPv4 in data centers, while the network-facing load balancers accept IPv4 and IPv6 traffic. LinkedIn and Microsoft have stated intentions to move their networks to IPv6. Google, LinkedIn, and Akamai are as of 2018 deploying IPv6 in data center networks and are connecting natively with IPv6 end users.\n\nSome governments, including the United States and China, have issued guidelines and requirements for IPv6 capability.\n\nBULLET::::- China Next Generation Internet\nBULLET::::- Comparison of IPv6 support in operating systems\nBULLET::::- Comparison of IPv6 support in common applications\nBULLET::::- DoD IPv6 product certification\nBULLET::::- Happy Eyeballs\nBULLET::::- List of IPv6 tunnel brokers\nBULLET::::- University of New Hampshire InterOperability Laboratory\n\nBULLET::::- IPv6 in the Linux Kernel by Rami Rosen.\nBULLET::::- Free Pool of IPv4 Address Space Depleted\nBULLET::::- An Introduction and Statistics about IPV6\n"}
{"id": "15319", "url": "https://en.wikipedia.org/wiki?curid=15319", "title": "Inca Empire", "text": "Inca Empire\n\nThe Inca Empire (,  \"The Four Regions\"), also known as the Incan Empire and the Inka Empire, was the largest empire in pre-Columbian America. Its political and administrative structure is considered by most scholars to have been the most developed in the Americas before Columbus' arrival. The administrative, political and military center of the empire was located in the city of Cusco. The Inca civilization arose from the Peruvian highlands sometime in the early 13th century. Its last stronghold was conquered by the Spanish in 1572.\n\nFrom 1438 to 1533, the Incas incorporated a large portion of western South America, centered on the Andean Mountains, using conquest and peaceful assimilation, among other methods. At its largest, the empire joined Peru, southwest Ecuador, western and south central Bolivia, northwest Argentina, a large portion of what is today Chile, and a small part of southwest Colombia into a state comparable to the historical empires of Eurasia. Its official language was Quechua. Many local forms of worship persisted in the empire, most of them concerning local sacred \"Huacas\", but the Inca leadership encouraged the sun worship of Inti – their sun god – and imposed its sovereignty above other cults such as that of Pachamama. The Incas considered their king, the Sapa Inca, to be the \"son of the sun.\"\n\nThe Inca Empire was unusual in that it lacked many features associated with civilization in the Old World. Anthropologist Gordon McEwan wrote that:\n\nThe Incan economy has been described in contradictory ways by scholars:\n\nThe Inca empire functioned largely without money and without markets. Instead, exchange of goods and services was based on reciprocity between individuals and among individuals, groups, and Inca rulers. \"Taxes\" consisted of a labour obligation of a person to the Empire. The Inca rulers (who theoretically owned all the means of production) reciprocated by granting access to land and goods and providing food and drink in celebratory feasts for their subjects.\n\nThe Inca referred to their empire as \"Tawantinsuyu\", \"the four \"suyu\"\". In Quechua, \"tawa\" is four and \"-ntin\" is a suffix naming a group, so that a \"tawantin\" is a quartet, a group of four things taken together, in this case representing the four \"suyu\" (\"regions\" or \"provinces\") whose corners met at the capital. The four \"suyu\" were: Chinchaysuyu (north), Antisuyu (east; the Amazon jungle), Qullasuyu (south) and Kuntisuyu (west). The name \"Tawantinsuyu\" was, therefore, a descriptive term indicating a union of provinces. The Spanish transliterated the name as \"Tahuatinsuyo\" or \"Tahuatinsuyu\".\n\nThe term \"Inka\" means \"ruler\" or \"lord\" in Quechua and was used to refer to the ruling class or the ruling family. The Incas were a very small percentage of the total population of the empire, probably numbering only 15,000 to 40,000, but ruling a population of around 10 million people. The Spanish adopted the term (transliterated as \"Inca\" in Spanish) as an ethnic term referring to all subjects of the empire rather than simply the ruling class. As such, the name \"Imperio inca\" (\"Inca Empire\") referred to the nation that they encountered and subsequently conquered.\n\nThe Inca Empire was the last chapter of thousands of years of Andean civilizations. The Andean civilization was one of five civilizations in the world deemed by scholars to be \"pristine\", that is indigenous and not derivative from other civilizations.\n\nThe Inca Empire was preceded by two large-scale empires in the Andes: the Tiwanaku (c. 300–1100 AD), based around Lake Titicaca and the Wari or Huari (c. 600–1100 AD) centered near the city of Ayacucho. The Wari occupied the Cuzco area for about 400 years. Thus, many of the characteristics of the Inca Empire derived from earlier multi-ethnic and expansive Andean cultures.\n\nCarl Troll has argued that the development of the Inca state in the central Andes was aided by conditions that allow for the elaboration of the staple food chuño. Chuño, which can be stored for long periods, is made of potato dried at the freezing temperatures that are common at nighttime in the southern Peruvian highlands. Such a link between the Inca state and chuño may be questioned, as potatoes and other crops such as maize can also be dried with only sunlight. Troll did also argue that llamas, the Inca's pack animal, can be found in its largest numbers in this very same region. It is worth considering the maximum extent of the Inca Empire roughly coincided with the greatest distribution of llamas and alpacas in Pre-Hispanic America. The link between the Andean biomes of puna and páramo, pastoralism and the Inca state is a matter of research. As a third point Troll pointed out irrigation technology as advantageous to the Inca state-building. While Troll theorized environmental influences on the Inca Empire, he opposed environmental determinism, arguing that culture lay at the core of the Inca civilization.\n\nThe Inca people were a pastoral tribe in the Cusco area around the 12th century. Incan oral history tells an origin story of three caves. The center cave at Tampu T'uqu \"(Tambo Tocco)\" was named Qhapaq T'uqu (\"principal niche\", also spelled \"Capac Tocco\"). The other caves were Maras T'uqu \"(Maras Tocco)\" and Sutiq T'uqu \"(Sutic Tocco)\". Four brothers and four sisters stepped out of the middle cave. They were: Ayar Manco, Ayar Cachi, Ayar Awqa \"(Ayar Auca)\" and Ayar Uchu; and Mama Ocllo, Mama Raua, Mama Huaco and Mama Qura \"(Mama Cora)\". Out of the side caves came the people who were to be the ancestors of all the Inca clans.\n\nAyar Manco carried a magic staff made of the finest gold. Where this staff landed, the people would live. They traveled for a long time. On the way, Ayar Cachi boasted about his strength and power. His siblings tricked him into returning to the cave to get a sacred llama. When he went into the cave, they trapped him inside to get rid of him.\n\nAyar Uchu decided to stay on the top of the cave to look over the Inca people. The minute he proclaimed that, he turned to stone. They built a shrine around the stone and it became a sacred object. Ayar Auca grew tired of all this and decided to travel alone. Only Ayar Manco and his four sisters remained.\n\nFinally, they reached Cusco. The staff sank into the ground. Before they arrived, Mama Ocllo had already borne Ayar Manco a child, Sinchi Roca. The people who were already living in Cusco fought hard to keep their land, but Mama Huaca was a good fighter. When the enemy attacked, she threw her bolas (several stones tied together that spun through the air when thrown) at a soldier (gualla) and killed him instantly. The other people became afraid and ran away.\n\nAfter that, Ayar Manco became known as Manco Cápac, the founder of the Inca. It is said that he and his sisters built the first Inca homes in the valley with their own hands. When the time came, Manco Cápac turned to stone like his brothers before him. His son, Sinchi Roca, became the second emperor of the Inca.\n\nUnder the leadership of Manco Cápac, the Inca formed the small city-state Kingdom of Cusco (Quechua \"Qusqu', Qosqo\"). In 1438, they began a far-reaching expansion under the command of Sapa Inca (paramount leader) Pachacuti-Cusi Yupanqui, whose name literally meant \"earth-shaker\". The name of Pachacuti was given to him after he conquered the Tribe of Chancas (modern Apurímac). During his reign, he and his son Tupac Yupanqui brought much of the modern-day territory of Peru under Inca control.\n\nPachacuti reorganized the kingdom of Cusco into the Tahuantinsuyu, which consisted of a central government with the Inca at its head and four provincial governments with strong leaders: Chinchasuyu (NW), Antisuyu (NE), Kuntisuyu (SW) and Qullasuyu (SE). Pachacuti is thought to have built Machu Picchu, either as a family home or summer retreat, although it may have been an agricultural station.\n\nPachacuti sent spies to regions he wanted in his empire and they brought to him reports on political organization, military strength and wealth. He then sent messages to their leaders extolling the benefits of joining his empire, offering them presents of luxury goods such as high quality textiles and promising that they would be materially richer as his subjects.\n\nMost accepted the rule of the Inca as a \"fait accompli\" and acquiesced peacefully. Refusal to accept Inca rule resulted in military conquest. Following conquest the local rulers were executed. The ruler's children were brought to Cusco to learn about Inca administration systems, then return to rule their native lands. This allowed the Inca to indoctrinate them into the Inca nobility and, with luck, marry their daughters into families at various corners of the empire.\n\nTraditionally the son of the Inca ruler led the army. Pachacuti's son Túpac Inca Yupanqui began conquests to the north in 1463 and continued them as Inca ruler after Pachacuti's death in 1471. Túpac Inca's most important conquest was the Kingdom of Chimor, the Inca's only serious rival for the Peruvian coast. Túpac Inca's empire then stretched north into modern-day Ecuador and Colombia.\n\nTúpac Inca's son Huayna Cápac added a small portion of land to the north in modern-day Ecuador. At its height, the Inca Empire included Peru, western and south central Bolivia, southwest Ecuador and a large portion of what is today Chile, north of the Maule River. Traditional historiography claims the advance south halted after the Battle of the Maule where they met determined resistance from the Mapuche. This view is challenged by historian Osvaldo Silva who argues instead that it was the social and political framework of the Mapuche that posed the main difficulty in imposing imperial rule. Silva does also add that accepting the battle of the Maule as a statemale, the Incas lacked incentives for conquest they had had when fighting more complex societies such as the Chimú Empire. Silva also disputes the date given by traditional historiography for the battle: the late 15th century during the reign of Topa Inca Yupanqui (1471–93). Instead, he places it in 1532 during the Inca Civil War. Nevertheless, Silva agrees on the claim that the bulk of the Incan conquests were made during the late 15th century. At the time of the Incan Civil War an Inca army was, according to Diego de Rosales, subduing a revolt among the Diaguitas of Copiapó and Coquimbo.\n\nThe empire's push into the Amazon Basin near the Chinchipe River was stopped by the Shuar in 1527. The empire extended into corners of Argentina and Colombia. However, most of the southern portion of the Inca empire, the portion denominated as Qullasuyu, was located in the Altiplano.\n\nThe Inca Empire was an amalgamation of languages, cultures and peoples. The components of the empire were not all uniformly loyal, nor were the local cultures all fully integrated. The Inca empire as a whole had an economy based on exchange and taxation of luxury goods and labour. The following quote describes a method of taxation:\n\nFor as is well known to all, not a single village of the highlands or the plains failed to pay the tribute levied on it by those who were in charge of these matters. There were even provinces where, when the natives alleged that they were unable to pay their tribute, the Inca ordered that each inhabitant should be obliged to turn in every four months a large quill full of live lice, which was the Inca's way of teaching and accustoming them to pay tribute.\nSpanish conquistadors led by Francisco Pizarro and his brothers explored south from what is today Panama, reaching Inca territory by 1526. It was clear that they had reached a wealthy land with prospects of great treasure, and after another expedition in 1529 Pizarro traveled to Spain and received royal approval to conquer the region and be its viceroy. This approval was received as detailed in the following quote: \"In July 1529 the Queen of Spain signed a charter allowing Pizarro to conquer the Incas. Pizarro was named governor and captain of all conquests in Peru, or New Castile, as the Spanish now called the land.\"\n\nWhen the conquistadors returned to Peru in 1532, a war of succession between the sons of Sapa Inca Huayna Capac, Huáscar and Atahualpa, and unrest among newly conquered territories weakened the empire. Perhaps more importantly, smallpox, influenza, typhus and measles had spread from Central America.\n\nThe forces led by Pizarro consisted of 168 men, one cannon, and 27 horses. Conquistadors ported lances, arquebuses, steel armor and long swords. In contrast, the Inca used weapons made out of wood, stone, copper and bronze, while using an Alpaca fiber based armor, putting them at significant technological disadvantage - none of their weapons could pierce the Spanish steel armor. In addition, due to the absence of horses in the Americas, the Inca did not develop tactics to fight cavalry. However, the Inca were still effective warriors, being able to successfully fight the Mapuche, which later would strategically defeat the Spanish as they expanded further south.\n\nThe first engagement between the Inca and the Spanish was the Battle of Puná, near present-day Guayaquil, Ecuador, on the Pacific Coast; Pizarro then founded the city of Piura in July 1532. Hernando de Soto was sent inland to explore the interior and returned with an invitation to meet the Inca, Atahualpa, who had defeated his brother in the civil war and was resting at Cajamarca with his army of 80,000 troops, that were at the moment armed only with hunting tools (knives and lassos for hunting llamas).\n\nPizarro and some of his men, most notably a friar named Vincente de Valverde, met with the Inca, who had brought only a small retinue. The Inca offered them ceremonial chicha in a golden cup, which the Spanish rejected. The Spanish interpreter, Friar Vincente, read the \"Requerimiento\" that demanded that he and his empire accept the rule of King Charles I of Spain and convert to Christianity. Atahualpa dismissed the message and asked them to leave. After this, the Spanish began their attack against the mostly unarmed Inca, captured Atahualpa as hostage, and forced the Inca to collaborate.\n\nAtahualpa offered the Spaniards enough gold to fill the room he was imprisoned in and twice that amount of silver. The Inca fulfilled this ransom, but Pizarro deceived them, refusing to release the Inca afterwards. During Atahualpa's imprisonment Huáscar was assassinated elsewhere. The Spaniards maintained that this was at Atahualpa's orders; this was used as one of the charges against Atahualpa when the Spaniards finally executed him, in August 1533.\n\nAlthough \"defeat\" often implies an unwanted loss in battle, much of the Inca elite \"actually welcomed the Spanish invaders as liberators and willingly settled down with them to share rule of Andean farmers and miners.\"\n\nThe Spanish installed Atahualpa's brother Manco Inca Yupanqui in power; for some time Manco cooperated with the Spanish while they fought to put down resistance in the north. Meanwhile, an associate of Pizarro, Diego de Almagro, attempted to claim Cusco. Manco tried to use this intra-Spanish feud to his advantage, recapturing Cusco in 1536, but the Spanish retook the city afterwards. Manco Inca then retreated to the mountains of Vilcabamba and established the small Neo-Inca State, where he and his successors ruled for another 36 years, sometimes raiding the Spanish or inciting revolts against them. In 1572 the last Inca stronghold was conquered and the last ruler, Túpac Amaru, Manco's son, was captured and executed. This ended resistance to the Spanish conquest under the political authority of the Inca state.\n\nAfter the fall of the Inca Empire many aspects of Inca culture were systematically destroyed, including their sophisticated farming system, known as the vertical archipelago model of agriculture. Spanish colonial officials used the Inca mita corvée labor system for colonial aims, sometimes brutally. One member of each family was forced to work in the gold and silver mines, the foremost of which was the titanic silver mine at Potosí. When a family member died, which would usually happen within a year or two, the family was required to send a replacement.\n\nThe effects of smallpox on the Inca empire were even more devastating. Beginning in Colombia, smallpox spread rapidly before the Spanish invaders first arrived in the empire. The spread was probably aided by the efficient Inca road system. Smallpox was only the first epidemic. Other diseases, including a probable Typhus outbreak in 1546, influenza and smallpox together in 1558, smallpox again in 1589, diphtheria in 1614, and measles in 1618, all ravaged the Inca people.\n\nThe number of people inhabiting Tawantinsuyu at its peak is uncertain, with estimates ranging from 4–37 million. Most population estimates are in the range of 6 to 14 million. In spite of the fact that the Inca kept excellent census records using their quipus, knowledge of how to read them was lost as almost all fell into disuse and disintegrated over time or were destroyed by the Spaniards.\n\nThe main form of communication and record-keeping in the empire were quipus, ceramics, textiles and various dialects of Quechua, the language the Incas imposed upon the peoples within the empire. While Quechua had been spoken in the Andean region, including central Peru, for several centuries prior to the expansion of the Inca civilization, the dialect of Quechua the Incas imposed was an adaptation from the Kingdom of Cusco (an early form of \"Southern Quechua\" originally named Qhapaq Runasimi, or 'the great language of the people'), or what some historians define as the Cusco dialect.\n\nThe language imposed by the Incas diverted from its original phonetics as some societies formed their own regional varieties. The diversity of Quechua at that point and even today does not come directly from the Incas, who were just a part of the reason for Quechua's diversity. The civilizations within the empire that had previously spoken Quechua kept their own variety distinct from the Quechua the Incas spread. Although these dialects of Quechua had a similar linguistic structure, they differed according to the region in which they were spoken.\n\nAlthough many of the societies within the empire spoke or learned to speak Quechua, others continued to speak their original languages, such as Aymara, which remains in use in contemporary Bolivia, where it is the primary indigenous language and in various regions surrounding Bolivia. The linguistic body of the Inca Empire was thus varied. The Inca's impact outlasted their empire, as the Spanish continued the use of Quechua.\n\nThe Incas were not known to develop a written form of communication; however, they visually recorded narratives through paintings on vases and cups (qirus). These paintings are usually accompanied by geometric patterns known as toqapu, which are also found in textiles. Researchers have speculated that toqapu patterns could have served as a form of written communication (e.g.: heraldry, or glyphs), however this remains unclear.\n\nThe high infant mortality rates that plagued the Inca Empire caused all newborn infants to be given the term ‘wawa’ when they were born. Most families did not invest very much into their child until they reached the age of two or three years old. Once the child reached the age of three, a \"coming of age\" ceremony occurred, called the \"rutuchikuy\". For the Incas, this ceremony indicated that the child had entered the stage of \"ignorance\". During this ceremony, the family would invite all relatives to their house for food and dance, and then each member of the family would receive a lock of hair from the child. After each family member had received a lock, the father would shave the child's head. This stage of life was categorized by a stage of \"ignorance, inexperience, and lack of reason, a condition that the child would overcome with time.\" For Incan society, in order to advance from the stage of ignorance to development the child must learn the roles associated with their gender.\n\nThe next important ritual was to celebrate the maturity of a child. Unlike the coming of age ceremony, the celebration of maturity signified the child's sexual potency. This celebration of puberty was called \"warachikuy\" for boys and \"qikuchikuy\" for girls. The \"warachikuy\" ceremony included dancing, fasting, tasks to display strength, and family ceremonies. The boy would also be given new clothes and taught how to act as an unmarried man. The \"qikuchikuy\" signified the onset of menstruation, upon which the girl would go into the forest alone and return only once the bleeding had ended. In the forest she would fast, and, once returned, the girl would be given a new name, adult clothing, and advice. This \"folly\" stage of life was the time young adults were allowed to have sex without being a parent.\n\nBetween the ages of 20 and 30, people were considered young adults, \"ripe for serious thought and labor.\" Young adults were able to retain their youthful status by living at home and assisting in their home community. Young adults only reached full maturity and independence once they had married.\n\nAt the end of life, the terms for men and women denote loss of sexual vitality and humanity. Specifically, the \"decrepitude\" stage signifies the loss of mental well-being and further physical decline.\nAge\nSocial Value of Life Stage\nFemale Term\nMale Term\n< 3\nConception\nWawa\nWawa\n3–7\nIgnorance (not speaking)\nWarma\nWarma\n7–14\nDevelopment\nThaski (or P'asña)\nMaqt'a\n14–20\nFolly (sexually active)\nSipas (unmarried)\nWayna (unmarried)\n20+\nMaturity (body and mind)\nWarmi\nQhari\n70\nInfirmity\nPaya\nMachu\n90\nDecrepitude\nRuku\nRuku\n\nIn the Incan Empire, the age of marriage differed for men and women: men typically married at the age of 20, while women usually got married about four years earlier at the age of 16. Men who were highly ranked in society could have multiple wives, but those lower in the ranks could only take a single wife. Marriages were typically within classes and resembled a more business-like agreement. Once married, the women were expected to cook, collect food and watch over the children and livestock. Girls and mothers would also work around the house to keep it orderly to please the public inspectors. These duties remained the same even after wives became pregnant and with the added responsibility of praying and making offerings to Kanopa, who was the god of pregnancy. It was typical for marriages to begin on a trial basis with both men and women having a say in the longevity of the marriage. If the man felt that it wouldn't work out or if the woman wanted to return to her parents’ home the marriage would end. Once the marriage was final, the only way the two could be divorced was if they did not have a child together. Marriage within the Empire was crucial for survival. A family was considered disadvantaged if there was not a married couple at the center because everyday life centered around the balance of male and female tasks.\n\nIn the eyes of the Inca, male and female roles were considered equal. The \"indigenous cultures saw the two genders as complementary parts of a whole.\" In other words, there was not a hierarchical structure in the domestic sphere for the Incas. Within the domestic sphere, women were known as the weavers. Women's everyday tasks included: spinning, watching the children, weaving cloth, cooking, brewing chichi, preparing fields for cultivation, planting seeds, bearing children, harvesting, weeding, hoeing, herding, and carrying water. Men on the other hand, \"weeded, plowed, participated in combat, helped in the harvest, carried firewood, built houses, herded llama and alpaca, and spun and wove when necessary\". On looking Spaniards did not understand the complementary nature of men and women roles within the Inca culture and believed women were treated like slaves. However, Inca women did not view themselves as slaves, nor did they do their job for the man. The women completed their daily tasks for the improvement of her household and community, to ensure her family would survive. Furthermore, women were allowed to own land and herds because inheritance was passed down from both the mother's and father's side of the family. Kinship within the Inca society followed a parallel line of descent. In other words, women ascended from women and men ascended from men. Due to the parallel descent, women had access to land and other necessities through her mother, and communities flourished because of the environmental social ties among women.\n\nInca myths were transmitted orally until early Spanish colonists recorded them; however, some scholars claim that they were recorded on quipus, Andean knotted string records.\n\nThe Inca believed in reincarnation. After death, the passage to the next world was fraught with difficulties. The spirit of the dead, \"camaquen,\" would need to follow a long road and during the trip the assistance of a black dog that could see in the dark was required. Most Incas imagined the after world to be like an earthly paradise with flower-covered fields and snow-capped mountains.\n\nIt was important to the Inca that they not die as a result of burning or that the body of the deceased not be incinerated. Burning would cause their vital force to disappear and threaten their passage to the after world. Those who obeyed the Inca moral code – \"ama suwa, ama llulla, ama quella\" (do not steal, do not lie, do not be lazy) – \"went to live in the Sun's warmth while others spent their eternal days in the cold earth\". The Inca nobility practiced cranial deformation. They wrapped tight cloth straps around the heads of newborns to shape their soft skulls into a more conical form, thus distinguishing the nobility from other social classes.\n\nThe Incas made human sacrifices. As many as 4,000 servants, court officials, favorites and concubines were killed upon the death of the Inca Huayna Capac in 1527. The Incas performed child sacrifices around important events, such as the death of the Sapa Inca or during a famine. These sacrifices were known as \"qhapaq hucha\".\n\nThe Incas were polytheists who worshipped many gods. These included:\nBULLET::::- Viracocha (also Pachacamac) – Created all living things\nBULLET::::- Apu Illapu – Rain God, prayed to when they need rain\nBULLET::::- Ayar Cachi – Hot-tempered God, causes earthquakes\nBULLET::::- Illapa – Goddess of lightning and thunder (also Yakumama water goddess)\nBULLET::::- Inti – sun god and patron deity of the holy city of Cusco (home of the sun)\nBULLET::::- Kuychi – Rainbow God, connected with fertility\nBULLET::::- Mama Killa – Wife of Inti, called Moon Mother\nBULLET::::- Mama Occlo – Wisdom to civilize the people, taught women to weave cloth and build houses\nBULLET::::- Manco Cápac – known for his courage and sent to earth to become first king of the Incas. Taught people how to grow plants, make weapons, work together, share resources and worship the Gods\nBULLET::::- Pachamama – The Goddess of earth and wife of Viracocha. People give her offerings of coca leaves and beer and pray to her for major agricultural occasions\nBULLET::::- Quchamama – Goddess of the sea\nBULLET::::- Sachamama – Means Mother Tree, goddess in the shape of a snake with two heads\nBULLET::::- Yakumama – Means mother Water. Represented as a snake. When she came to earth she transformed into a great river (also Illapa).\n\nThe Inca Empire employed central planning. The Inca Empire traded with outside regions, although they did not operate a substantial internal market economy. While axe-monies were used along the northern coast, presumably by the provincial \"mindaláe\" trading class, most households in the empire lived in a traditional economy in which households were required to pay taxes, usually in the form of the \"mit'a\" corvée labor, and military obligations, though barter (or \"trueque\") was present in some areas. In return, the state provided security, food in times of hardship through the supply of emergency resources, agricultural projects (e.g. aqueducts and terraces) to increase productivity and occasional feasts. While \"mit'a\" was used by the state to obtain labor, individual villages had a pre-inca system of communal work, known as mink'a, established. This system survives to the modern day, known as \"mink'a\" or \"faena\". The economy rested on the material foundations of the vertical archipelago, a system of ecological complementarity in accessing resources and the cultural foundation of \"ayni\", or reciprocal exchange.\n\nThe Sapa Inca was conceptualized as divine and was effectively head of the state religion. The \"Willaq Umu\" (or Chief Priest) was second to the emperor. Local religious traditions continued and in some cases such as the Oracle at Pachacamac on the Peruvian coast, were officially venerated. Following Pachacuti, the Sapa Inca claimed descent from Inti, who placed a high value on imperial blood; by the end of the empire, it was common to incestuously wed brother and sister. He was \"son of the sun,\" and his people the \"intip churin\", or \"children of the sun,\" and both his right to rule and mission to conquer derived from his holy ancestor. The Sapa Inca also presided over ideologically important festivals, notably during the \"Inti Raymi\", or \"Sunfest\" attended by soldiers, mummified rulers, nobles, clerics and the general population of Cusco beginning on the June solstice and culminating nine days later with the ritual breaking of the earth using a foot plow by the Inca. Moreover, Cusco was considered cosmologically central, loaded as it was with \"huacas\" and radiating \"ceque\" lines and geographic center of the Four-Quarters; Inca Garcilaso de la Vega called it \"the navel of the universe\".\n\nThe Inca Empire was a federalist system consisting of a central government with the Inca at its head and four-quarters, or \"suyu\": Chinchay Suyu (NW), Anti Suyu (NE), Kunti Suyu (SW) and Qulla Suyu (SE). The four corners of these quarters met at the center, Cusco. These \"suyu\" were likely created around 1460 during the reign of Pachacuti before the empire reached its largest territorial extent. At the time the \"suyu\" were established they were roughly of equal size and only later changed their proportions as the empire expanded north and south along the Andes.\n\nCusco was likely not organized as a \"wamani\", or province. Rather, it was probably somewhat akin to a modern federal district, like Washington, DC or Mexico City. The city sat at the center of the four \"suyu\" and served as the preeminent center of politics and religion. While Cusco was essentially governed by the Sapa Inca, his relatives and the royal \"panaqa\" lineages, each \"suyu\" was governed by an \"Apu\", a term of esteem used for men of high status and for venerated mountains. Both Cusco as a district and the four \"suyu\" as administrative regions were grouped into upper \"hanan\" and lower \"hurin\" divisions. As the Inca did not have written records, it is impossible to exhaustively list the constituent \"wamani\". However, colonial records allow us to reconstruct a partial list. There were likely more than 86 \"wamani\", with more than 48 in the highlands and more than 38 on the coast.\n\nThe most populous \"suyu\" was Chinchaysuyu, which encompassed the former Chimu empire and much of the northern Andes. At its largest extent, it extended through much of modern Ecuador and into modern Colombia.\n\nThe largest \"suyu\" by area was Qullasuyu, named after the Aymara-speaking Qulla people. It encompassed the Bolivian Altiplano and much of the southern Andes, reaching Argentina and as far south as the Maipo or Maule river in Central Chile. Historian José Bengoa singled out Quillota as likely being the foremost Inca settlement in Chile.\n\nThe second smallest \"suyu\", Antisuyu, was northwest of Cusco in the high Andes. Its name is the root of the word \"Andes.\"\n\nKuntisuyu was the smallest \"suyu\", located along the southern coast of modern Peru, extending into the highlands towards Cusco.\n\nThe Inca state had no separate judiciary or codified laws. Customs, expectations and traditional local power holders governed behavior. The state had legal force, such as through \"tokoyrikoq\" (lit. \"he who sees all\"), or inspectors. The highest such inspector, typically a blood relative to the Sapa Inca, acted independently of the conventional hierarchy, providing a point of view for the Sapa Inca free of bureaucratic influence.\n\nThe Inca had three moral precepts that governed their behavior:\nBULLET::::- \"Ama sua\": Do not steal\nBULLET::::- \"Ama llulla\": Do not lie\nBULLET::::- \"Ama quella\": Do not be lazy\n\nColonial sources are not entirely clear or in agreement about Inca government structure, such as exact duties and functions of government positions. But the basic structure can be broadly described. The top was the \"Sapa Inca\". Below that may have been the \"Willaq Umu\", literally the \"priest who recounts\", the High Priest of the Sun. However, beneath the \"Sapa Inca\" also sat the \"Inkap rantin\", who was a confidant and assistant to the \"Sapa Inca\", perhaps similar to a Prime Minister. Starting with Topa Inca Yupanqui, a \"Council of the Realm\" was composed of 16 nobles: 2 from \"hanan\" Cusco; 2 from \"hurin\" Cusco; 4 from Chinchaysuyu; 2 from Cuntisuyu; 4 from Collasuyu; and 2 from Antisuyu. This weighting of representation balanced the \"hanan\" and \"hurin\" divisions of the empire, both within Cusco and within the Quarters (\"hanan suyukuna\" and \"hurin suyukuna\").\n\nWhile provincial bureaucracy and government varied greatly, the basic organization was decimal. Taxpayers – male heads of household of a certain age range – were organized into corvée labor units (often doubling as military units) that formed the state's muscle as part of mit'a service. Each unit of more than 100 tax-payers were headed by a \"kuraka\", while smaller units were headed by a \"kamayuq\", a lower, non-hereditary status. However, while \"kuraka\" status was hereditary and typically served for life, the position of a \"kuraka\" in the hierarchy was subject to change based on the privileges of superiors in the hierarchy; a \"pachaka kuraka\" could be appointed to the position by a \"waranqa kuraka\". Furthermore, one \"kuraka\" in each decimal level could serve as the head of one of the nine groups at a lower level, so that a \"pachaka kuraka\" might also be a \"waranqa kuraka\", in effect directly responsible for one unit of 100 tax-payers and less directly responsible for nine other such units.\n\n! Kuraka in Charge !! Number of Taxpayers\n\nArchitecture was the most important of the Incan arts, with textiles reflecting architectural motifs. The most notable example is Machu Picchu, which was constructed by Inca engineers. The prime Inca structures were made of stone blocks that fit together so well that a knife could not be fitted through the stonework. These constructs have survived for centuries, with no use of mortar to sustain them.\n\nThis process was first used on a large scale by the Pucara (c. 300 BC–AD 300) peoples to the south in Lake Titicaca and later in the city of Tiwanaku (c. AD 400–1100) in present-day Bolivia. The rocks were sculpted to fit together exactly by repeatedly lowering a rock onto another and carving away any sections on the lower rock where the dust was compressed. The tight fit and the concavity on the lower rocks made them extraordinarily stable, despite the ongoing challenge of earthquakes and volcanic activity.\n\nPhysical measures used by the Inca were based on human body parts. Units included fingers, the distance from thumb to forefinger, palms, cubits and wingspans. The most basic distance unit was \"thatkiy\" or \"thatki\", or one pace. The next largest unit was reported by Cobo to be the \"topo\" or \"tupu\", measuring 6,000 \"thatkiy\"s, or about ; careful study has shown that a range of is likely. Next was the \"wamani\", composed of 30 \"topo\"s (roughly ). To measure area, 25 by 50 wingspans were used, reckoned in \"topo\"s (roughly ). It seems likely that distance was often interpreted as one day's walk; the distance between \"tambo\" way-stations varies widely in terms of distance, but far less in terms of time to walk that distance.\n\nInca calendars were strongly tied to astronomy. Inca astronomers understood equinoxes, solstices and zenith passages, along with the Venus cycle. They could not, however, predict eclipses. The Inca calendar was essentially lunisolar, as two calendars were maintained in parallel, one solar and one lunar. As 12 lunar months fall 11 days short of a full 365-day solar year, those in charge of the calendar had to adjust every winter solstice. Each lunar month was marked with festivals and rituals. Apparently, the days of the week were not named and days were not grouped into weeks. Similarly, months were not grouped into seasons. Time during a day was not measured in hours or minutes, but in terms of how far the sun had travelled or in how long it had taken to perform a task.\n\nThe sophistication of Inca administration, calendrics and engineering required facility with numbers. Numerical information was stored in the knots of \"quipu\" strings, allowing for compact storage of large numbers. These numbers were stored in base-10 digits, the same base used by the Quechua language and in administrative and military units. These numbers, stored in \"quipu\", could be calculated on \"yupanas\", grids with squares of positionally varying mathematical values, perhaps functioning as an abacus. Calculation was facilitated by moving piles of tokens, seeds or pebbles between compartments of the \"yupana\". It is likely that Inca mathematics at least allowed division of integers into integers or fractions and multiplication of integers and fractions.\n\nAccording to mid-17th-century Jesuit chronicler Bernabé Cobo, the Inca designated officials to perform accounting-related tasks. These officials were called quipo camayos. Study of khipu sample VA 42527 (Museum für Völkerkunde, Berlin) revealed that the numbers arranged in calendrically significant patterns were used for agricultural purposes in the \"farm account books\" kept by the khipukamayuq (accountant or warehouse keeper) to facilitate the closing of accounting books.\n\nCeramics were painted using the polychrome technique portraying numerous motifs including animals, birds, waves, felines (popular in the Chavin culture) and geometric patterns found in the Nazca style of ceramics. In a culture without a written language, ceramics portrayed the basic scenes of everyday life, including the smelting of metals, relationships and scenes of tribal warfare. The most distinctive Inca ceramic objects are the Cusco bottles or \"aryballos\". Many of these pieces are on display in Lima in the Larco Archaeological Museum and the National Museum of Archaeology, Anthropology and History.\n\nAlmost all of the gold and silver work of the Incan empire was melted down by the conquistadors, and shipped back to Spain.\n\nThe Inca recorded information on assemblages of knotted strings, known as Quipu, although they can no longer be decoded. Originally it was thought that Quipu were used only as mnemonic devices or to record numerical data. Quipus are also believed to record history and literature.\n\nThe Inca made many discoveries in medicine. They performed successful skull surgery, by cutting holes in the skull to alleviate fluid buildup and inflammation caused by head wounds. Many skull surgeries performed by Inca surgeons were successful. Survival rates were 80–90%, compared to about 30% before Inca times.\n\nThe Incas revered the coca plant as sacred/magical. Its leaves were used in moderate amounts to lessen hunger and pain during work, but were mostly used for religious and health purposes. The Spaniards took advantage of the effects of chewing coca leaves. The Chasqui, messengers who ran throughout the empire to deliver messages, chewed coca leaves for extra energy. Coca leaves were also used as an anaesthetic during surgeries.\n\nThe Inca army was the most powerful at that time, because any ordinary villager or farmer could be recruited as a soldier as part of the \"mit'a\" system of mandatory public service. Every able bodied male Inca of fighting age had to take part in war in some capacity at least once and to prepare for warfare again when needed. By the time the empire reached its largest size, every section of the empire contributed in setting up an army for war.\n\nThe Incas had no iron or steel and their weapons were not much more effective than those of their opponents so they often defeated opponents by sheer force of numbers, or else by persuading them to surrender beforehand by offering generous terms. Inca weaponry included \"hardwood spears launched using throwers, arrows, javelins, slings, the bolas, clubs, and maces with star-shaped heads made of copper or bronze.\" Rolling rocks downhill onto the enemy was a common strategy, taking advantage of the hilly terrain. Fighting was sometimes accompanied by drums and trumpets made of wood, shell or bone. Armor included:\nBULLET::::- Helmets made of wood, cane, or animal skin, often lined with copper or bronze; some were adorned with feathers\nBULLET::::- Round or square shields made from wood or hide\nBULLET::::- Cloth tunics padded with cotton and small wooden planks to protect the spine\nBULLET::::- Ceremonial metal breastplates, of copper, silver, and gold, have been found in burial sites, some of which may have also been used in battle.\n\nRoads allowed quick movement (on foot) for the Inca army and shelters called \"tambo\" and storage silos called qullqas were built one day's travelling distance from each other, so that an army on campaign could always be fed and rested. This can be seen in names of ruins such as \"Ollantay Tambo\", or My Lord's Storehouse. These were set up so the Inca and his entourage would always have supplies (and possibly shelter) ready as they traveled.\n\nChronicles and references from the 16th and 17th centuries support the idea of a banner. However, it represented the Inca (emperor), not the empire.\n\nFrancisco López de Jerez wrote in 1534:\n\nChronicler Bernabé Cobo wrote:\n\n<br>()<br>-\n\nGuaman Poma's 1615 book, \"El primer nueva corónica y buen gobierno\", shows numerous line drawings of Inca flags. In his 1847 book \"A History of the Conquest of Peru\", \"William H. Prescott ... says that in the Inca army each company had its particular banner and that the imperial standard, high above all, displayed the glittering device of the rainbow, the armorial ensign of the Incas.\" A 1917 world flags book says the Inca \"heir-apparent ... was entitled to display the royal standard of the rainbow in his military campaigns.\"\n\nIn modern times the rainbow flag has been wrongly associated with the Tawantinsuyu and displayed as a symbol of Inca heritage by some groups in Peru and Bolivia. The city of Cusco also flies the Rainbow Flag, but as an official flag of the city. The Peruvian president Alejandro Toledo (2001–2006) flew the Rainbow Flag in Lima's presidential palace. However, according to Peruvian historiography, the Inca Empire never had a flag. Peruvian historian María Rostworowski said, \"I bet my life, the Inca never had that flag, it never existed, no chronicler mentioned it\". Also, to the Peruvian newspaper \"El Comercio\", the flag dates to the first decades of the 20th century, and even the Congress of the Republic of Peru has determined that flag is a fake by citing the conclusion of National Academy of Peruvian History:\n\n\"The official use of the wrongly called 'Tawantinsuyu flag' is a mistake. In the Pre-Hispanic Andean World there did not exist the concept of a flag, it did not belong to their historic context\".\n<br>National Academy of Peruvian History\n\nIncas were able to adapt to their high-altitude living through successful acclimatization, which is characterized by increasing oxygen supply to the blood tissues. For the native Inca living in the Andean highlands, this was achieved through the development of a larger lung capacity, and an increase in red blood cell counts, hemoglobin concentration, and capillary beds.\n\nCompared to other humans, the Incas had slower heart rates, almost one-third larger lung capacity, about 2 L (4 pints) more blood volume and double the amount of hemoglobin, which transfers oxygen from the lungs to the rest of the body. While the Conquistadors may have been slightly taller, the Inca had the advantage of coping with the extraordinary altitude.\n\nBULLET::::- Muisca Confederation\nBULLET::::- Choquequirao\nBULLET::::- Cojitambo\nBULLET::::- Cusco\nBULLET::::- El Fuerte de Samaipata\nBULLET::::- Huánuco Pampa\nBULLET::::- Huchuy Qosqo\nBULLET::::- Inca-Caranqui\nBULLET::::- Llaqtapata\nBULLET::::- Machu Picchu\nBULLET::::- Moray\nBULLET::::- Ollantaytambo\nBULLET::::- Oroncota\nBULLET::::- Pambamarca Fortress Complex\nBULLET::::- Písac\nBULLET::::- Pukara of La Compañia\nBULLET::::- Quispiguanca\nBULLET::::- Rumicucho\nBULLET::::- Sacsayhuamán\nBULLET::::- Tumebamba\nBULLET::::- Vilcabamba\nBULLET::::- Vitcos\n\nBULLET::::- Aclla, the \"chosen women\"\nBULLET::::- Amauta, Inca teachers\nBULLET::::- Amazonas before the Inca Empire\nBULLET::::- Anden, agricultural terrace\nBULLET::::- Chincha culture\nBULLET::::- Inca Civil War\nBULLET::::- Inca cuisine\nBULLET::::- Incan agriculture\nBULLET::::- Incan aqueducts\nBULLET::::- Incas in Central Chile\nBULLET::::- Felipe Guaman Poma de Ayala\nBULLET::::- Garcilaso de la Vega (chronicler)\nBULLET::::- Paria, Bolivia\nBULLET::::- Quipu, knotted cords\nBULLET::::- Qullqa, Inca storehouse\nBULLET::::- Religion in the Inca Empire\nBULLET::::- Spanish conquest of Peru\nBULLET::::- Tambo\nBULLET::::- Tampukancha, Inca religious site\nBULLET::::- Society of the Spanish-Americans in the Spanish Colonial Americas\n\nBULLET::::- Ancient Peru\nBULLET::::- Cultural periods of Peru\nBULLET::::- Demographic history of the indigenous peoples of the Americas\nBULLET::::- History of Peru\nBULLET::::- History of smallpox\nBULLET::::- Muisca Confederation\n\nBULLET::::- \"Guaman Poma – El Primer Nueva Corónica Y Buen Gobierno\" – A high-quality digital version of the Corónica, scanned from the original manuscript.\nBULLET::::- Conquest nts.html Inca Land by Hiram Bingham (published 1912–1922).\nBULLET::::- Inca Artifacts, Peru and Machu Picchu 360-degree movies of inca artifacts and Peruvian landscapes.\nBULLET::::- Ancient Civilizations – Inca\nBULLET::::- \"Ice Treasures of the Inca\" National Geographic site.\nBULLET::::- \"The Sacred Hymns of Pachacutec,\" poetry of an Inca emperor.\nBULLET::::- Incan Religion\nBULLET::::- Engineering in the Andes Mountains, lecture on Inca suspension bridges\nBULLET::::- A Map and Timeline of Inca Empire events\nBULLET::::- Ancient Peruvian art: contributions to the archaeology of the empire of the Incas, a four volume work from 1902 (fully available online as PDF)\n"}
{"id": "15321", "url": "https://en.wikipedia.org/wiki?curid=15321", "title": "Inca (disambiguation)", "text": "Inca (disambiguation)\n\nThe Inca Empire was the largest empire in pre-Columbian America.\n\nInca, Inka, or İncə may also refer to:\nBULLET::::- Inca civilization, centered in what is now Peru\nBULLET::::- Sapa Inca or Inka, the main ruler of the Inca Empire\n\nBULLET::::- Glaucineis Martins or \"Inca\" (born 1973), Brazilian footballer\nBULLET::::- Edwin Valero or \"El Inca\" (1981-2010), Venezuela boxer\nBULLET::::- Garcilaso de la Vega (chronicler) or \"El Inca\" (1539–1616), Spanish Peruvian writer\nBULLET::::- INCA (singer) (born 1985), French singer\n\nBULLET::::- Inka (La Paz), a mountain in the La Paz Department, Bolivia\nBULLET::::- İncə, Goychay, Azerbaijan\nBULLET::::- İncə, Shaki, Azerbaijan\nBULLET::::- Inca, Spain, a town on the island of Majorca in the Mediterranean Sea\n\nBULLET::::- \"Los Incas - Parque Chas\" (Buenos Aires Underground), metro subway station\nBULLET::::- SEAT Inca, a panel van\nBULLET::::- Industri Kereta Api (INKA), a rolling stock manufacturer in Indonesia\n\nBULLET::::- \"Inca\" (schooner), the first five-masted schooner built on the United States western coast, in 1896\nBULLET::::- , U.S. Navy shipname\nBULLET::::- USS \"Inca\" (1898), a screw steamer\nBULLET::::- USS \"Inca\" (1911), a steam ferry\nBULLET::::- USS \"Inca\" (SP-1212), a motor boat built in 1917\nBULLET::::- USS \"Inca\" (ID-3219), an iron tugboat built in 1879\nBULLET::::- USS \"Inca\" (IX-229), an unclassified miscellaneous vessel\n\nBULLET::::- \"Inca\" (genus), a genus of beetles in the subfamily Cetoniinae\nBULLET::::- Inca (hummingbird), the common name for several hummingbirds in the genus \"Coeligena\"\n\nBULLET::::- \"Inca\" (video game), a 1992 adventure game by Coktel Vision\nBULLET::::- INCA (software), measurement, calibration and diagnostic software published by ETAS\nBULLET::::- INCA Internet, South Korean company\n\nBULLET::::- Inka (drink), a Polish roasted grain drink\nBULLET::::- Inca Kola, a carbonated soft drink from Peru\n\nBULLET::::- \"El Inca\" (film), 2016 Venezuelan drama film directed by Ignacio Castillo Cottin\nBULLET::::- \"Los Incas\", Andean folk music group\nBULLET::::- Inka shōmei, a form of dharma transmission in Zen Buddhism\nBULLET::::- Ion and Neutral Camera (INCA), an instrument aboard the \"Cassini–Huygens\" spacecraft\n\nBULLET::::- Incan (disambiguation)\nBULLET::::- INKAS, Canadian armoured transport, strongbox, security services company\n"}
{"id": "15323", "url": "https://en.wikipedia.org/wiki?curid=15323", "title": "Internet Protocol", "text": "Internet Protocol\n\nThe Internet Protocol (IP) is the principal communications protocol in the Internet protocol suite for relaying datagrams across network boundaries. Its routing function enables internetworking, and essentially establishes the Internet.\n\nIP has the task of delivering packets from the source host to the destination host solely based on the IP addresses in the packet headers. For this purpose, IP defines packet structures that encapsulate the data to be delivered. It also defines addressing methods that are used to label the datagram with source and destination information.\n\nHistorically, IP was the connectionless datagram service in the original Transmission Control Program introduced by Vint Cerf and Bob Kahn in 1974, which was complemented by a connection-oriented service that became the basis for the Transmission Control Protocol (TCP). The Internet protocol suite is therefore often referred to as \"TCP/IP\".\n\nThe first major version of IP, Internet Protocol Version 4 (IPv4), is the dominant protocol of the Internet. Its successor is Internet Protocol Version 6 (IPv6), which has been in increasing deployment on the public Internet since c. 2006.\n\nThe Internet Protocol is responsible for addressing host interfaces, encapsulating data into datagrams (including fragmentation and reassembly) and routing datagrams from a source host interface to a destination host interface across one or more IP networks. For these purposes, the Internet Protocol defines the format of packets and provides an addressing system.\n\nEach datagram has two components: a header and a payload. The IP header includes source IP address, destination IP address, and other metadata needed to route and deliver the datagram. The payload is the data that is transported. This method of nesting the data payload in a packet with a header is called encapsulation.\n\nIP addressing entails the assignment of IP addresses and associated parameters to host interfaces. The address space is divided into subnetworks, involving the designation of network prefixes. IP routing is performed by all hosts, as well as routers, whose main function is to transport packets across network boundaries. Routers communicate with one another via specially designed routing protocols, either interior gateway protocols or exterior gateway protocols, as needed for the topology of the network.\n\nIn May 1974, the Institute of Electrical and Electronics Engineers (IEEE) published a paper entitled \"A Protocol for Packet Network Intercommunication\". The paper's authors, Vint Cerf and Bob Kahn, described an internetworking protocol for sharing resources using packet switching among network nodes. A central control component of this model was the \"Transmission Control Program\" that incorporated both connection-oriented links and datagram services between hosts. The monolithic Transmission Control Program was later divided into a modular architecture consisting of the Transmission Control Protocol and User Datagram Protocol at the transport layer and the Internet Protocol at the internet layer. The model became known as the \"Department of Defense (DoD) Internet Model\" and \"Internet protocol suite\", and informally as \"TCP/IP\".\n\nIP versions 0 to 3 were experimental versions, used between 1977 and 1979. The following Internet Experiment Note (IEN) documents describe versions of the Internet Protocol prior to the modern version of IPv4:\nBULLET::::- IEN 2 (\"Comments on Internet Protocol and TCP\"), dated August 1977 describes the need to separate the TCP and Internet Protocol functionalities (which were previously combined.) It proposes the first version of the IP header, using 0 for the version field.\nBULLET::::- IEN 26 (\"A Proposed New Internet Header Format\"), dated February 1978 describes a version of the IP header that uses a 1-bit version field.\nBULLET::::- IEN 28 (\"Draft Internetwork Protocol Description Version 2\"), dated February 1978 describes IPv2.\nBULLET::::- IEN 41 (\"Internetwork Protocol Specification Version 4\"), dated June 1978 describes the first protocol to be called IPv4. The IP header is different from the modern IPv4 header.\nBULLET::::- IEN 44 (\"Latest Header Formats\"), dated June 1978 describes another version of IPv4, also with a header different from the modern IPv4 header.\nBULLET::::- IEN 54 (\"Internetwork Protocol Specification Version 4\"), dated September 1978 is the first description of IPv4 using the header that would be standardized in .\n\nThe dominant internetworking protocol in the Internet Layer in use is IPv4; the number 4 is the protocol version number carried in every IP datagram. IPv4 is described in (1981).\n\nVersion number 5 was used by the Internet Stream Protocol, an experimental streaming protocol.\n\nThe successor to IPv4 is IPv6. IPv6 was a result of several years of experimentation and dialog during which various protocol models were proposed, such as TP/IX (), PIP () and TUBA (TCP and UDP with Bigger Addresses, ). Its most prominent difference from version 4 is the size of the addresses. While IPv4 uses 32 bits for addressing, yielding c. 4.3 billion () addresses, IPv6 uses 128-bit addresses providing ca. 340 undecillion, or addresses. Although adoption of IPv6 has been slow, , all United States government systems have demonstrated basic infrastructure support for IPv6.\n\nThe assignment of the new protocol as IPv6 was uncertain until due diligence revealed that IPv6 had not yet been used previously. Other Internet Layer protocols have been assigned version numbers, such as 7 (\"IP/TX\"), 8 and 9 (\"historic\"). Notably, on April 1, 1994, the IETF published an April Fools' Day joke about IPv9.\n\nThe design of the Internet protocol suite adheres to the end-to-end principle, a concept adapted from the CYCLADES project. Under the end-to-end principle, the network infrastructure is considered inherently unreliable at any single network element or transmission medium and is dynamic in terms of availability of links and nodes. No central monitoring or performance measurement facility exists that tracks or maintains the state of the network. For the benefit of reducing network complexity, the intelligence in the network is purposely located in the end nodes.\n\nAs a consequence of this design, the Internet Protocol only provides best-effort delivery and its service is characterized as unreliable. In network architectural language, it is a connectionless protocol, in contrast to connection-oriented communication. Various error conditions may occur, such as data corruption, packet loss and duplication. Because routing is dynamic, meaning every packet is treated independently, and because the network maintains no state based on the path of prior packets, different packets may be routed to the same destination via different paths, resulting in out-of-order delivery to the receiver.\n\nAll error conditions in the network must be detected and compensated by the participating end nodes. The upper layer protocols of the Internet protocol suite are responsible for resolving reliability issues. For example, a host may buffer network data to ensure correct ordering before the data is delivered to an application.\n\nIPv4 provides safeguards to ensure that the header of an IP packet is error-free. A routing node discards packets that fail a header checksum test. Although the Internet Control Message Protocol (ICMP) provides notification of errors, a routing node is not required to notify either end node of errors. IPv6, by contrast, operates without header checksums, since current link layer technology is assumed to provide sufficient error detection.\n\nThe dynamic nature of the Internet and the diversity of its components provide no guarantee that any particular path is actually capable of, or suitable for, performing the data transmission requested. One of the technical constraints is the size of data packets allowed on a given link. Facilities exist to examine the maximum transmission unit (MTU) size of the local link and Path MTU Discovery can be used for the entire intended path to the destination.\n\nThe IPv4 internetworking layer has the ability to automatically fragment the original datagram into smaller units for transmission. In this case, IP provides re-ordering of fragments delivered out of order. An IPv6 network does not perform fragmentation or reassembly, and as per the end-to-end principle, requires end stations and higher-layer protocols to avoid exceeding the network's MTU.\n\nThe Transmission Control Protocol (TCP) is an example of a protocol that adjusts its segment size to be smaller than the MTU. The User Datagram Protocol (UDP) and ICMP disregard MTU size, thereby forcing IP to fragment oversized datagrams.\n\nDuring the design phase of the ARPANET and the early Internet, the security aspects and needs of a public, international network could not be adequately anticipated. Consequently, many Internet protocols exhibited vulnerabilities highlighted by network attacks and later security assessments. In 2008, a thorough security assessment and proposed mitigation of problems was published. The IETF has been pursuing further studies.\n\nBULLET::::- ICANN\nBULLET::::- IP forwarding algorithm\nBULLET::::- List of IP protocol numbers\nBULLET::::- Next-generation network\n\n"}
{"id": "15328", "url": "https://en.wikipedia.org/wiki?curid=15328", "title": "Impeachment", "text": "Impeachment\n\nImpeachment is the process by which a legislative body levels charges against a government official. Impeachment does not in itself remove the official definitively from office; it is similar to an indictment in criminal law, and thus it is essentially the statement of charges against the official. Whereas in some countries the individual is provisionally removed, in others they can remain in office during the trial. Once an individual is impeached, they must then face the possibility of conviction on the charges by a legislative vote, which is separate from the impeachment, but flows from it, and a judgment which convicts the official on the articles of impeachment entails the official's definitive removal from office.\n\nBecause impeachment and conviction of officials involve an overturning of the normal constitutional procedures by which individuals achieve high office (election, ratification, or appointment) and because it generally requires a supermajority, they are usually reserved for those deemed to have committed serious abuses of their office. In the United States, for example, impeachment at the federal level is limited to those who may have committed \"Treason, Bribery, or other high crimes and misdemeanors\".\n\nImpeachment exists under constitutional law in many countries around the world, including Brazil, France, India, Ireland, the Philippines, Russia, South Korea, and the United States.\n\nThe word \"impeachment\" likely derives from Old French \"empeechier\" from Latin word \"impedīre\" expressing the idea of catching or ensnaring by the 'foot' (\"pes, pedis\"), and has analogues in the modern French verb \"empêcher\" (to prevent) and the modern English \"impede\". Medieval popular etymology also associated it (wrongly) with derivations from the Latin \"impetere\" (to attack). Some contend that the word comes from the Latin \"impicare\" (through the late-Latin \"impiciare\", \"impiciamentum\"), that is the punishment that in Latin antiquity they gave to parricides, consisting in throwing them into the sea confined in a \"culleus\", namely a sac made of esparto or hide and covered with pitch or bitumen on the outside, so that the water delayed in entering; they sometimes confined some aggressive beasts with the convict so to increase his last torments (\"\"Culleus, tunica ex sparto im modum crumenae facta, quae liniebatur a populo pice et bitumine, in qua imcludebantur parricidae cum simia, serpente, et gallo; insuta mittebatur in mare et, contendentibus inter se animantibus, homo maioribus poenis afficiebatur\"\").\n\nThe process was first used by the English \"Good Parliament\" against Baron Latimer in the second half of the 14th century. Following the British example, the constitutions of Virginia (1776), Massachusetts (1780) and other states thereafter adopted the impeachment mechanism, but they restricted the punishment to removal of the official from office.\n\nThe Austrian Federal President can be impeached by the Federal Assembly (\"Bundesversammlung\") before the Constitutional Court. The constitution also provides for the recall of the president by a referendum. Neither of these courses has ever been taken. This is likely because while Austrian Presidents are vested with considerable powers on paper, they act as a largely ceremonial figurehead in practice, and are thus unlikely to abuse their powers.\n\nThe President of the Federative Republic of Brazil may be impeached by the Chamber of Deputies and tried and removed from office by the Federal Senate. The Brazilian Constitution requires that two-thirds of the Deputies vote in favor of the impeachment of the President and two-thirds of the Senators vote for conviction in the subsequent trial for removal from office. State governors and municipal mayors can also be impeached, tried and removed by the respective legislative bodies. Upon conviction, the officeholder has their political rights revoked for eight years—which bars them from running for any office during that time.\n\nFernando Collor de Mello, the 32nd President of Brazil, resigned in 1992 amidst impeachment proceedings. Despite his resignation, the Senate nonetheless voted to convict him and bar him from holding any office for eight years, due to evidence of bribery and misappropriation.\n\nIn 2016, the Chamber of Deputies initiated an impeachment case against President Dilma Rousseff on allegations of budgetary mismanagement. Following her impeachment by the Chamber of Deputies and her conviction by trial in the Senate, she was definitively replaced by Vice President Michel Temer, who had served as acting president while Rousseff's case was pending in the Senate.\n\nThe President of Bulgaria can be removed only for high treason or violation of the constitution. The process is started by a two-thirds majority vote of the Parliament to impeach the President, whereupon the Constitutional Court decides whether the President is guilty of the crime of which he is charged. If he is found guilty, he is removed from power. No Bulgarian President has ever been impeached. The same procedure can be used to remove the Vice President of Bulgaria, which has also never happened.\n\nThe process of impeaching the President of Croatia can be initiated by a two-thirds majority vote in favor in the Sabor and is thereafter referred to the Constitutional Court, which must accept such a proposal with a two-thirds majority vote in favor in order for the president to be removed from office. This has never occurred in the history of the Republic of Croatia. In case of a successful impeachment motion a president's constitutional term of five years would be terminated and an election called within 60 days of the vacancy occurring. During the period of vacancy the presidential powers and duties would be carried out by the Speaker of the Croatian Parliament in his/her capacity as Acting President of the Republic.\n\nIn 2013, the constitution was changed. Since 2013, the process can be started by at least three-fifths of present senators, and must be approved by at least \nthree-fifths of all members of Parliament. Also, the President can be impeached for high treason (newly defined in the Constitution) or any serious infringement of the Constitution. \n\nThe process starts in the Senate of the Czech Republic which has the right to only impeach the president, and the Senate passes the case to the Constitutional Court of the Czech Republic, which has to decide the verdict against the President. If the Court finds the President guilty, then the President is removed from office and is permanently barred from being elected President of the Czech Republic again. \n\nNo Czech president has ever been impeached, though members of the Senate sought to impeach President Vaclav Klaus in 2013. This case was dismissed by the court, which reasoned that his mandate had expired.\n\nIn France the comparable procedure is called \"la destitution\". The President of France can be impeached by the French Parliament for willfully violating the Constitution or the national laws. The process of impeachment is written in the 68th article of the French Constitution. A group of senators or a group of members of the National Assembly can begin the process. Then, both the French National Assembly and the French Senate have to acknowledge the impeachment. After the upper and lower houses' agreement, they unite to form the High Court. Finally, the High Court must decide to declare the impeachment of the President of France—or not.\n\nThe Federal President of Germany can be impeached both by the Bundestag and by the Bundesrat for willfully violating federal law. Once the Bundestag or the Bundesrat impeaches the president, the Federal Constitutional Court decides whether the President is guilty as charged and, if this is the case, whether to remove him or her from office. The Federal Constitutional Court also has the power to remove federal judges from office for willfully violating core principles of the federal constitution or a state constitution. The impeachment procedure is regulated in Article 61 of the Basic Law for the Federal Republic of Germany.\n\nThere is no formal impeachment process for the Chancellor of Germany, however the Bundestag can replace the chancellor at any time by voting for a new chancellor (constructive vote of no confidence, Article 67 of the Basic Law).\n\nThere has never been an impeachment against the President so far. Constructive votes of no confidence against the Chancellor occurred in 1972 and 1982, with only the second one being successful.\n\nThe Chief Executive of Hong Kong can be impeached by the Legislative Council. A motion for investigation, initiated jointly by at least one-fourth of all the legislators charging the Chief Executive with \"serious breach of law or dereliction of duty\" and refusing to resign, shall first be passed by the Council. An independent investigation committee, chaired by the Chief Justice of the Court of Final Appeal, will then carry out the investigation and report back to the Council. If the Council find the evidence sufficient to substantiate the charges, it may pass a motion of impeachment by a two-thirds majority.\n\nHowever, the Legislative Council does not have the power to actually remove the Chief Executive from office, as the Chief Executive is appointed by the Central People's Government (State Council of China). The Council can only report the result to the Central People's Government for its decision.\n\nArticle 13 of Hungary's Fundamental Law (constitution) provides for the process of impeaching and removing the President. The President enjoys immunity from criminal prosecution while in office, but may be charged with crimes committed during his term afterwards. Should the President violate the constitution while discharging his duties or commit a willful criminal offense, he may be removed from office. Removal proceedings may be proposed by the concurring recommendation of one-fifth of the 199 members of the country's unicameral Parliament. Parliament votes on the proposal by secret ballot, and if two thirds of all representatives agree, the President is impeached. Once impeached, the President's powers are suspended, and the Constitutional Court decides whether or not the President should be removed from office.\n\nThe Constitution of Iceland does not provide a process to impeach the President of Iceland. The President can be removed from office by a three-fourths majority in Parliament and a subsequent majority in a referendum. Cabinet ministers can be impeached by Parliament and their cases are adjudicated by the National Court. Since cabinet ministers can be relieved of duty only by the President, a guilty verdict can result in only a fine or imprisonment.\n\nThe president and judges, including the chief justice of the supreme court and high courts, can be impeached by the parliament before the expiry of the term for violation of the Constitution. Other than impeachment, no other penalty can be given to a president in position for the violation of the Constitution under of the constitution. However a president after his/her term/removal can be punished for his already proven unlawful activity under disrespecting the constitution, etc. No president has faced impeachment proceedings. Hence, the provisions for impeachment have never been tested. The sitting president cannot be charged and needs to step down in order for that to happen.\n\nThe Assembly of Experts can impeach the Supreme Leader of Iran and appoint a new one.\n\nThe President of Iran can be impeached jointly by the members of the Assembly (Majlis) and the Supreme Leader. A new presidential election is then triggered. Abolhassan Banisadr, Iran's first president, was impeached in June 1981 and removed from the office. Mohammad-Ali Rajai was elected as the new president.\n\nCabinet ministers can be impeached by the members of the Assembly. Presidential appointment of a new minister is subject to a parliamentary vote of confidence. Impeachment of ministers has been a fairly commonly-used tactic in the power struggle between the president and the assembly during the last several governments.\n\nIn the Republic of Ireland formal impeachment applies only to the Irish president. Article 12 of the Irish Constitution provides that, unless judged to be \"permanently incapacitated\" by the Supreme Court, the president can be removed from office only by the houses of the Oireachtas (parliament) and only for the commission of \"stated misbehaviour\". Either house of the Oireachtas may impeach the president, but only by a resolution approved by a majority of at least two thirds of its total number of members; and a house may not consider a proposal for impeachment unless requested to do so by at least thirty of its number.\n\nWhere one house impeaches the president, the remaining house either investigates the charge or commissions another body or committee to do so. The investigating house can remove the president if it decides, by at least a two-thirds majority of its members, both that the president is guilty of the charge and that the charge is sufficiently serious as to warrant the president's removal. To date no impeachment of an Irish president has ever taken place. The president holds a largely ceremonial office, the dignity of which is considered important, so it is likely that a president would resign from office long before undergoing formal conviction or impeachment.\n\nThe Republic's Constitution and law also provide that only a joint resolution of both houses of the Oireachtas may remove a judge. Although often referred to as the \"impeachment\" of a judge, this procedure does not technically involve impeachment.\n\nIn Italy, according to Article 90 of the Constitution, the President of the Republic can be impeached through a majority vote of the Parliament in joint session for high treason and for attempting to overthrow the Constitution. If impeached, the President of the Republic is then tried by the Constitutional Court integrated with sixteen citizens older than forty chosen by lot from a list compiled by the Parliament every nine years.\n\nItalian press and political forces made use of the term \"impeachment\" for the attempt by some members of parliamentary opposition to initiate the procedure provided for in Article 90 against Presidents Francesco Cossiga (1991), Giorgio Napolitano (2014) and Sergio Mattarella (2018).\n\nMembers of the Liechtenstein Government can be impeached before the State Court for breaches of the Constitution or of other laws. As a hereditary monarchy the Sovereign Prince can not be impeached as he \"is not subject to the jurisdiction of the courts and does not have legal responsibility\". The same is true of any member of the Princely House who exercises the function of head of state should the Prince be temporarily prevented or in preparation for the Succession.\n\nIn the Republic of Lithuania, the President may be impeached by a three-fifths majority in the Seimas. President Rolandas Paksas was removed from office by impeachment on April 6, 2004 after the Constitutional Court of Lithuania found him guilty of having violated his oath and the constitution. He was the first European head of state to have been impeached.\n\nMembers of government, representatives of the national assembly (Stortinget) and Supreme Court judges can be impeached for criminal offenses tied to their duties and committed in office, according to the Constitution of 1814, §§ 86 and 87. The procedural rules were modeled after the U.S. rules and are quite similar to them. Impeachment has been used eight times since 1814, last in 1927. Many argue that impeachment has fallen into desuetude. In cases of impeachment, an appointed court (Riksrett) takes effect.\n\nThe country's ruling coalition said on August 7, 2008, that it would seek the impeachment of President Pervez Musharraf, alleging the U.S.-backed former general had \"eroded the trust of the nation\" and increasing pressure on him to resign. He resigned on August 18, 2008. Another kind of impeachment in Pakistan is known as the vote of less-confidence or vote of mis-understanding and has been practiced by provincial assemblies to weaken the national assembly.\n\nImpeaching a president requires a two-thirds majority support of lawmakers in a joint session of both houses of Parliament.\n\nImpeachment in the Philippines follows procedures similar to the United States. Under Sections2 and 3, Article XI, Constitution of the Philippines, the House of Representatives of the Philippines has the exclusive power to initiate all cases of impeachment against the President, Vice President, members of the Supreme Court, members of the Constitutional Commissions (Commission on Elections, Civil Service Commission and the Commission on Audit), and the Ombudsman. When a third of its membership has endorsed the impeachment articles, it is then transmitted to the Senate of the Philippines which tries and decide, as impeachment tribunal, the impeachment case.\n\nA main difference from U.S. proceedings however is that only one third of House members are required to approve the motion to impeach the President (as opposed to a simple majority of those present and voting in their U.S. counterpart). In the Senate, selected members of the House of Representatives act as the prosecutors and the Senators act as judges with the Senate President presiding over the proceedings (the Chief Justice jointly presides with the Senate President if the President is on trial). Like the United States, to convict the official in question requires that a minimum of two thirds (i.e. 16 of 24 members) of all the Members of the Senate vote in favor of conviction. If an impeachment attempt is unsuccessful or the official is acquitted, no new cases can be filed against that impeachable official for at least one full year.\n\nThe 1987 Philippine Constitution says the grounds for impeachment include culpable violation of the Constitution, bribery, graft and corruption, and betrayal of public trust. These offenses are considered \"high crimes and misdemeanors\" under the Philippine Constitution.\n\nThe President, Vice President, Supreme Court justices, and members of the Constitutional Commission and Ombudsman are all considered impeachable officials under the Constitution.\n\nPresident Joseph Estrada was the first official impeached by the House in 2000, but the trial ended prematurely due to outrage over a vote to open an envelope where that motion was narrowly defeated by his allies. Estrada was deposed days later during the 2001 EDSA Revolution.\n\nIn 2005, 2006, 2007 and 2008, impeachment complaints were filed against President Gloria Macapagal-Arroyo, but none of the cases reached the required endorsement of of the members for transmittal to, and trial by, the Senate.\n\nIn March 2011, the House of Representatives impeached Ombudsman Merceditas Gutierrez, becoming the second person to be impeached. In April, Gutierrez resigned prior to the Senate's convening as an impeachment court.\n\nIn December 2011, in what was described as \"blitzkrieg fashion\", 188 of the 285 members of the House of Representatives voted to transmit the 56-page Articles of Impeachment against Supreme Court Chief Justice Renato Corona.\n\nTo date, three officials had been successfully impeached by the House of Representatives, and two were not convicted. The latter, Chief Justice Renato C. Corona, was convicted on May 29, 2012, by the Senate under Article II of the Articles of Impeachment (for betraying public trust), with 20–3 votes from the Senator Judges.\n\nIn Polish law there is no impeachment procedure defined, as it is present in the other countries. Infringements of the law can be investigated only by special Parliament's Committee or (if accusations involve people holding the highest offices of state) by the State Tribunal. The State Tribunal is empowered to rule for the removal of individuals from public office but it is not a common practice.\n\nThe President can be impeached by Parliament and is then suspended. A referendum then follows to determine whether the suspended President should be removed from office. President Traian Băsescu was impeached twice by the Parliament: in 2007 and more recently in July 2012. A referendum was held on May 19, 2007 and a large majority of the electorate voted against removing the president from office. For the most recent suspension a referendum was held on July 29, 2012; the results were heavily against the president, but the referendum was invalidated due to low turnout.\n\nThe President of Russia can be impeached if both the State Duma (which initiates the impeachment process through the formation of a special investigation committee) and the Federation Council of Russia vote by a two-thirds majority in favor of impeachment and, additionally, the Supreme Court finds the President guilty of treason or a similarly heavy crime against the nation and the Constitutional Court confirms that the constitutional procedure of the impeachment process was correctly observed. In 1995–1999, the Duma made several attempts to impeach then-President Boris Yeltsin, but they never had a sufficient number of votes for the process to reach the Federation Council.\n\nThe Constitution of Singapore allows the impeachment of a sitting President on charges of treason, violation of the Constitution, corruption, or attempting to mislead the Presidential Elections Committee for the purpose of demonstrating eligibility to be elected as President. The Prime Minister or at least one-quarter of all Members of Parliament (MPs) can pass an impeachment motion, which can succeed only if at least half of all MPs (excluding nominated Members) vote in favor, whereupon the Chief Justice of the Supreme Court will appoint a tribunal to investigate allegations against the President. If the tribunal finds the President guilty, or otherwise declares that the President is \"permanently incapable of discharging the functions of his office by reason of mental or physical infirmity\", Parliament will hold a vote on a resolution to remove the President from office, which requires a three-quarters majority to succeed. No President has ever been removed from office in this fashion.\n\nAccording to the Article 65 Clause 1 of Constitution of South Korea, if President, Prime Minister, or other state council members including Supreme Court and Constitutional court members, violate the Constitution or other laws of official duty, the National Assembly can impeach them. Clause2 states the impeachment bill may be proposed by one third or more of the total members of the National Assembly, and shall require majority voting and approved by two thirds or more of the total members of the National Assembly. This article also states that any person against whom a motion for impeachment has been passed shall be suspended from exercising his power until the impeachment has been adjudicated and shall not extend further than removal from public office. Provided, that it shall not exempt the person impeached from civil or criminal liability.\n\nTwo presidents have been impeached since the foundation of the Sixth Republic of Korea and adoption of the new Constitution of South Korea in 1987. Roh Moo-hyun in 2004 was impeached by the National Assembly but was overturned by the Constitutional Court. Park Geun-hye in 2016 was impeached by the National Assembly, and the impeachment was confirmed by the Constitutional Court on March 10, 2017.\n\nIn Taiwan, according to the Additional Articles of the Constitution of the Republic of China, impeachment of the president or the vice president by the Legislative Yuan shall be initiated upon the proposal of more than one-half of the total members of the Legislative Yuan and passed by more than two-thirds of the total members of the Legislative Yuan, whereupon it shall be presented to the grand justices of the Judicial Yuan for adjudication.\n\nIn Turkey, according to the Constitution, the Grand National Assembly may initiate an investigation of the President, the Vice President or any member of the Cabinet upon the proposal of simple majority of its total members, and within a period less than a month, the approval of three-fifths of the total members. The investigation would be carried out by a commission of fifteen members of the Assembly, each nominated by the political parties in proportion to their representation therein. The Commission would submit its report indicating the outcome of the investigation to the Speaker within two months. If the investigation is not completed within this period, the Commission's time renewed for another month. Within ten days of its submission to the Speaker, the report would be distributed to all members of the Assembly, and ten days after its distribution, the report would be discussed on the floor. Upon the approval of two thirds of the total number of the Assembly by secret vote, the person or persons, about whom the investigation was conducted, may be tried before the Constitutional Court. The trial would be finalized within three months, and if not, a one-time additional period of three months shall be granted.\nThe President, about whom an investigation has been initiated, may not call for an election. The President, who is convicted by the Court, would be removed from office.\n\nThe provision of this article shall also apply to the offenses for which the President allegedly worked during his term of office.\n\nDuring the crisis which started in November 2013, the increasing political stress of the face-down between the protestors occupying Independence Square in Kiev and the State Security forces under the control of President Yanukovych led to deadly armed force being used on the protestors. Following the negotiated return of Kiev's City Hall on February 16, 2014, occupied by the protesters since November 2013, the security forces thought they could also retake \"Maidan\", Independence Square. The ensuing fighting from 17 through 21 February 2014 resulted in a considerable number of deaths and a more generalised alienation of the population, and the withdrawal of President Yanukovych to his support area in the East of Ukraine.\nIn the wake of the President's departure, Parliament convened on February 22; it reinstated the 2004 Constitution, which reduced Presidential authority, and voted impeachment of President Yanukovych as \"de facto\" recognition of his departure from office as President of an integrated Ukraine. The President riposted that Parliament's acts were illegal as they could pass into law only by Presidential signature.\n\nIn the United Kingdom, in principle anybody may be prosecuted and tried by the two Houses of Parliament for any crime. The first recorded impeachment is that of William Latimer, 4th Baron Latimer during the Good Parliament of 1376. The last was that of Henry Dundas, 1st Viscount Melville in 1806. Over the centuries, the procedure has been supplemented by other forms of oversight including select committees, confidence motions, and judicial review, while the privilege of peers to trial only in the House of Lords was abolished in 1948, and thus impeachment, which has not kept up with modern norms of democracy or procedural fairness, is generally considered obsolete.\n\nArticle One of the United States Constitution gives the House of Representatives the sole power of impeachment and the Senate the sole power to try impeachments of officers of the U.S. federal government. (Various state constitutions include similar measures, allowing the state legislature to impeach the governor or other officials of the state government.) In the United States, impeachment is only the first of two stages, and conviction during the second stage requires \"the concurrence of two thirds of the members present\". Impeachment does not necessarily result in removal from office; it is only a legal statement of charges, parallel to an indictment in criminal law. An official who is impeached faces a second legislative vote (whether by the same body or another), which determines conviction, or failure to convict, on the charges embodied by the impeachment. Most constitutions require a supermajority to convict. Although the subject of the charge is criminal action, it does not constitute a criminal trial; the only question under consideration is the removal of the individual from office, and the possibilities of a subsequent vote preventing the removed official from ever again holding political office in the jurisdiction where they were removed.\n\nThe article on Impeachment in the United States discusses the following topics:\nBULLET::::- Procedure\nBULLET::::- Federal impeachment investigations formally commenced and officials impeached\nBULLET::::- History of federal constitutional impeachment\nBULLET::::- Impeachment in the states\n\nThree United States Presidents have been impeached: Andrew Johnson in 1868, Bill Clinton in 1998 and Donald Trump in 2019. Neither Johnson nor Clinton were convicted by the Senate, while Trump still awaits a Senate trial. Additionally, there were efforts to impeach John Tyler and Richard Nixon (Nixon resigned before proceedings began).\n\nBULLET::::- List of presidential impeachments\n"}
{"id": "15334", "url": "https://en.wikipedia.org/wiki?curid=15334", "title": "Ibizan Hound", "text": "Ibizan Hound\n\nThe Ibizan Hound (, ) is a lean, agile dog of the hound family. There are two hair types of the breed: smooth and wire. The more commonly seen type is the smooth. Some consider there to be a third type, long, but the longhair is most likely a variation of the wire.\n\nThe Ibizan Hound is an elegant and agile breed, with an athletic and attractive outline and a ground-covering springy trot. Though graceful in appearance, it has good bone girth and is a rugged/hardy breed. Its large upright ears - a hallmark of the breed - are broad at the base and frame a long and elegant headpiece. The neck is long and lean. It has a unique front assembly with well laid-back shoulders and relatively straight upper arm. Coming in both smooth and wire-coated varieties, their coat is a combination of red and white with the nose, ears, eye rims, and pads of feet being a light tan color. Its eyes are a striking amber color and have an alert and intelligent expression. The Ibizan may range in height, depending on which Standard you follow, from and weigh from , males being larger than females.\n\nIbizan Hounds are intelligent, active, and engaging by nature. They rank 53rd in Stanley Coren's The Intelligence of Dogs, being of average working/obedience intelligence, but many Ibizan owners will enjoy recounting a multitude of examples of their problem-solving abilities. They are true \"clowns\" of the dog world, delighting in entertaining their people with their antics. Though somewhat independent and stubborn at times, they do take well to training if positive methods are used, but will balk at punitive training methods. They are generally quiet, but will alarm bark if necessary, so they make good watch dogs. They are sensitive hounds, and very good around children and other dogs alike. They generally make good house dogs, but are active and athletic, therefore need a lot of daily exercise. They do not make good kennel dogs. Ibizan hounds are sweet, but they are very stubborn and independent.\n\nIbizan Hounds are \"escapologists\": they are able to jump incredible heights from a standstill, so they need very tall fences. They also have been known to climb, and many can escape from crates, open baby gates and even locks. They have a strong prey drive, therefore they cannot be trusted off leash unless in a safely enclosed area. Once off the leash, they might not come back for a long time. A hound that knows where its home is and the surrounding area will usually return unscathed.\n\nThe Ibizan Hound is typical of the Hound Group in that it rarely suffers from hereditary illness. Minor health concerns for the breed include seizures and allergies; very rarely, one will see axonal dystrophy, cataract, retinal dysplasia and deafness in the breed. Ibizan Hound owners should have their dogs' eyes tested by a veterinarian before breeding. CERF and BAER testing is recommended for the breed. Ibizan Hounds are sensitive to barbiturate anesthesia, and typically live between 12 and 14 years.\n\nThis breed originates in the island of Eivissa and has been traditionally used in the Catalan-speaking areas of Spain, and France where it was known under the name of \"le charnigue\", to hunt rabbits and other small game. The Ibizan Hound is a fast dog that can hunt on all types of terrain, working by scent, sound and sight. Hunters run these dogs in mostly female packs, with perhaps a male or two, as the female is considered the better hunter.\n\nTraditionally a farmer may have one dog and a very well off farmer two dogs to catch rabbits for food. However in the last twenty years it is seen as a sport where between five and fifteen dogs can be seen in the chase of one rabbit.\n\nThe Ibizan Hound authority Miquel Rosselló has provided a detailed description of a working trial which characterises their typical hunting technique and action, strikingly illustrated with action photos by Charles Camberoque which demonstrate hunt behaviour and typical hunt terrain. \nWhile local hunters will at times use one dog or a brace, and frequently packs of six to eight or as many as fifteen, the working trial requires an evaluation of one or two braces. A brace is called a \"colla\". The couples should be tested on at least two to five rabbits (not hares), without the use of any other hunting aid. An inspection and evaluation of the exterior, fitness, character and obedience of the dogs is recommended prior to the hunt. \nThe trial is qualified as having 5 parts. The dogs should show: (1) careful tracking and scenting of the rabbit, without being distracted in the least, 0-30 points; (2) correct signalling of the game, patient stand, strong jump into the air, obedience 0-10 points; (3) chase, giving tongue, speed, sureness, anticipation 0-30 points; (4) putting the game to cover at close quarters, listening, waiting, obedience, correct attack 0-10 point; and (5) good catch, or correct indication of the game’s location, retrieval, obedience 0-20 points.\n\nIndividual dogs are expected to show a great degree of discipline, obedience and co-operation. They should be extremely agile, have good speed and a powerful vertical jump from a stationary position in rough and often heavily covered ground. They should have excellent scent-tracking abilities, give tongue at the right time when approaching the game closely, and otherwise be silent so that they can locate the game by sound.\n\nThe Ibizan Hound is similar in function and type to several breeds, such as the Pharaoh Hound, the Cirneco dell'Etna, the Portuguese Podengo, and the Podenco Canario. The Ibizan Hound is the largest of these breeds, classified by the Fédération Cynologique Internationale as primitive types.\n\nIt is believed the Ibizan Hound evolves from the \"tesem\", the ancient Egyptian hunting dog. Representations of this dog on the walls of ancient tombs show a striking similarity to the modern Ibizan Hound. These dogs would have been brought to the island of Eivissa by the Phoenicians, who founded settlements there as early as the 8th century BC. A recent DNA analysis found that the breed was formed recently from other breeds. \nA more recent article \nargues that continued trait selective breeding may be behind this lack of support.\n\nIn the United States, the Ibizan Hound is frequently competed in lure coursing through the AKC and ASFA, and also competes in LGRA straight racing and NOTRA oval track racing. Some parts of the country also use them for coursing live prey, generally jackrabbits.\n\nThe Ibizan Hound breed is recognized by the Fédération Cynologique Internationale, Continental Kennel Club, American Kennel Club, United Kennel Club, Kennel Club of Great Britain, Canadian Kennel Club, National Kennel Club, New Zealand Kennel Club, Australian National Kennel Council, America's Pet Registry, and American Canine Registry. It was fully recognized by the American Kennel Club in 1979.\n\nAccording to journalist Norman Lewis, when an owner no longer wants to own one of these dogs (having too much of an appetite, for instance), it is considered very bad luck to kill the dog. Instead, they release the dog on the other side of the island, so that someone else might 'adopt' the animal.\n\nBULLET::::- Sighthound Sanctuary & Animal Services\nBULLET::::- Ibizan Hound Photos\nBULLET::::- Charles Camberoque: photos of Ibizans at work\nBULLET::::- Video: How Ibizans hunt\nBULLET::::- Ibizan Hound Club (Eivissa)\nBULLET::::- Norwegian Ibizan Hound Club\nBULLET::::- Swiss Ibizan Hound Club\nBULLET::::- German Ibizan Hound Club\nBULLET::::- Ibizan Hound Rescue in Spain\nBULLET::::- Ibizan Hounds in the UK\nBULLET::::- Additional information on the German language Wikipedia.(In German: \"Podenco Ibicenco\")\n"}
{"id": "15335", "url": "https://en.wikipedia.org/wiki?curid=15335", "title": "Irish wolfhound", "text": "Irish wolfhound\n\nThe Irish Wolfhound is a historic sighthound dog breed from Ireland that has by its presence and substantial size inspired literature, poetry and mythology. Like all sighthounds, it was used to pursue game by speed; it was also famed as a guardian dog, specializing in protection against and for the hunting of wolves. The original dog-type was presumed extinct by most knowledgeable authors but recreated specifically for the canine fancy mainly by Captain George A. Graham in the late 19th century The modern breed, classified by recent genetic research into the \"Sighthound United Kingdom Rural Clade\", has been used by coursing hunters who have prized it for its ability to dispatch game caught by swifter sighthounds.\n\nIn 391 AD there is a reference to large dogs by Quintus Aurelius Symmachus, a Roman Consul who received seven \"canes Scotici\" as a gift to be used for fighting lions and bears, and who wrote \"all Rome viewed (them) with wonder\". Scoti is a Latin name for the Gaels (ancient Irish). Dansey, the early 19th century translator of the first complete version of Arrian's work in English, \"On Coursing\", suggested the Irish and Scottish \"greyhounds\" were derived from the same ancestor, the \"vertragus\", and had expanded with the Scoti from Ireland across the Western Isles and into what is today Scotland.\n\nThe dog-type is imagined by some to be very old. Wolfhounds were used as hunting dogs by the Gaels, who called them \"Cú Faol\" (, \"hound\" \"wolf\" or wolfhound). Dogs are mentioned, as cú in Irish laws and in Irish literature which dates from the 6th century or, in the case of the Sagas, from the old Irish period - AD 600-900. The word \"Cú\" often became an added prefix of respect on the names of warriors as well as kings denoting that they were worthy of the respect and loyalty of a Cú. CúChulainn, the name of a legend, which translates literally as \"hound of Culann\", gained his name as a child, known then as Sétanta, he slew the ferocious guard dog of Culann, forcing him to offer himself as a replacement. In discussing the systematic evidence of historic dog sizes in Ireland, the Irish zooarchaeologist Finbar McCormick stressed that no dogs of Irish Wolfhound size are known from sites of the Iron Age period of 1000 BC through to the early Christian period to 1200 AD, and on the basis of the historic dog bones available, dogs of current Irish Wolfhound size seem to be a relatively modern development; \"[...] it must be concluded that the dog of CúChulainn was no larger than an alsatian and not the calf-sized beast of the popular imagination [...].\"\n\nHunting dogs were coveted and were frequently given as gifts to important personages and foreign nobles. King John of England, in about 1210 presented an Irish hound , Gelert, to Llywelyn, the Prince of Wales. The poet The Hon William Robert Spencer immortalized this hound in a poem.\n\nIn his Historie of Ireland completed 1571, Edmund Campion gives a description of the hounds used for hunting wolves in the Dublin and Wicklow mountains. He says: \"They (the Irish) are not without wolves and greyhounds to hunt them, bigger of bone and limb than a colt\". Due to their popularity overseas many were exported to European royal houses leaving numbers in Ireland depleted. This led to a declaration by Oliver Cromwell himself being published in Kilkenny on 27 April 1652 to ensure that sufficient numbers remained to control the wolf population.\n\nThe early 18th century engraving from \"Entwurf einiger Thiere\" by Johann Elias Ridinger is the oldest known image of the original wolfdog. References to the Irish Wolfhound in the 18th century tell of its great size, strength and greyhound shape as well as its scarcity. Writing in 1790, Bewick described it as the largest and most beautiful of the dog kind; about 36 inches high, generally of a white or cinnamon colour, somewhat like the Greyhound but more robust. He said that their aspect was mild, disposition peaceful, and strength so great that in combat the Mastiff or Bulldog was far from being an equal to them.\n\nThe last wolf in Ireland was killed in Co. Carlow in 1786. It is thought to have been killed at Myshall, on the slopes of Mount Leinster by a pack of wolfdogs kept by a Mr Watson of Ballydarton. The wolfhounds that remained in the hands of a few families who were mainly descendants of the old Irish chieftains were now symbols of status rather than used as hunters, and these were said to be the last of their race.\n\nThomas Pennant (1726-1798) reported that he could find no more than three wolfdogs when he visited Ireland. During the 1836 meeting of the Geological Society of Dublin, Dr. Scouler presented the \"\"Notices of Animals which have disappeared from Ireland\"\", with the wolfdog mentioned.\n\nCaptain George Augustus Graham (1833-1909) of Rednock House, Dursley, Gloucestershire was responsible for creating the modern Irish wolfhound breed. He stated that he could not find the breed \"in its original integrity\" to work with:\n\nBased on the writings of others, Graham had formed the opinion that a dog resembling the original wolfhound could be recreated through using the biggest and best examples of the Scottish Deerhound and the Great Dane, two breeds which he believed had been derived earlier from the wolfhound. Into the mix went the Scottish Deerhound, the Great Dane, and Kathleen Pelham-Clinton, Duchess of Newcastle's Borzoi \"Korotai\", who had proved his wolf hunting abilities earlier in his native Russia. For an outbreed a \"huge shaggy dog\" was added, which may have possibly been a Tibetan Mastiff.\n\nThe famous English Mastiff \"Garnier's Lion\" was bred to the Deerhound \"Lufra\", and their offspring \"Marquis\" entered wolfhound pedigrees through his granddaughter \"Young Donagh\". Graham included \"a single outcross of Tibetan Wolf Dog\". This was long assumed to have been a Tibetan Mastiff. However, a photograph of \"Wolf\" shows a bearded, long-coated dog—what would now be called a Tibetan kyi apso. In 1885 Captain Graham with other breeders founded the Irish Wolfhound Club, and the Breed Standard of Points to establish and agree the ideal to which breeders should aspire.\n\nThe Wolfhound has been adopted as a symbol by both rugby codes. The national rugby league team is nicknamed the Wolfhounds, and the Irish Rugby Football Union, which governs rugby union, changed the name of the country's A (second-level) national team in that code to the Ireland Wolfhounds in 2010.\n\nIn the video game Skyrim, the Irish Wolfhound is the breed of dog for all dogs in the base game.\n\nGenomic analysis indicates that although there has been some DNA sharing between the Irish wolfhound with the Deerhound, Whippet, and Greyhound, there has been significant sharing of DNA between the Irish Wolfhound with the Great Dane. One writer has stated that for the Irish Wolfhound, \"the Great Dane appearance is strongly marked too prominently before the 20th Century\".\n\nGeorge Augustus Graham created the modern Irish wolfhound breed that retained the appearance of the original form but not its genetic ancestry.\n\nConsidered by the American Kennel Club to be the tallest of all dog breeds, describing the breed as, \"Of great size and commanding appearance, the Irish Wolfhound is remarkable in combining power and swiftness with keen sight. The largest and tallest of the galloping hounds, in general type he is a rough-coated, Greyhound-like breed; very muscular, strong though gracefully built; movements easy and active; head and neck carried high, the tail carried with an upward sweep with a slight curve towards the extremity\". The average height of an Irish Wolfhound should be taller than that of a Great Dane. However, the wolfhound is not to be confused with being the heaviest, as its structure should be similar to that of a Greyhound, with a very broad and deep chest that tucks up.\n\nIts colour may be grey, brindle, red, black, white, fawn, and wheaten.\n\nThe Irish Wolfhound was bred for long solitary hunts based solely on the dog's ability to visualize its landscape and perceive, unlike scent hounds (such as Bloodhounds and Beagles) who rely on scent rather than sight. For this reason, the neck of an Irish Wolfhound should be long with the head held high the majority of the time. The Irish Wolfhound should also appear to be longer than it is tall.\nOnce used to hunt wolves, an Irish Wolfhound’s structure should appear as if it is “fast enough to catch a wolf, and strong enough to kill it”.\n\nThe AKC specifies the minimum height as for mature males, for females; the minimum weight: for males, for females. It is not rare to see modern day female hounds reaching the minimal height requirements of those of male hounds; most females are well over and in most AKC conformation shows a wolfhound’s height is looked at with as much importance as the hound’s head and face structure. Per the AKC, great size, including height of shoulder and proportionate length of body is to be aimed at, to firmly establish a breed averaging in males. The height/weight standards in Ireland and England are slightly different: males /, females /.\n\nIrish Wolfhounds have a varied range of personalities and are most often noted for their personal quirks and individualism. An Irish Wolfhound, however, is rarely mindless, and despite its large size is rarely found to be destructive in the house or boisterous. This is because the breed is generally introverted, intelligent, and reserved in character. An easygoing animal, the Irish Wolfhound is quiet by nature. Wolfhounds often create a strong bond with their family and can become quite destructive or morose if left alone for long periods of time. An Irish Wolfhound is not a guard dog and will protect individuals rather than the house or the owner’s possessions. However independent the wolfhound is, the breed becomes attached to both owners and other dogs they are raised with and is therefore not the most adaptable of breeds. Bred for independence, an Irish Wolfhound is not necessarily keen on defending spaces. A wolfhound is most easily described by its historical motto, “gentle when stroked, fierce when provoked”. They should not be territorially aggressive to other domestic dogs but are born with specialized skills and it is common for hounds at play to course another dog. This is a specific hunting behavior, not a fighting or territorial domination behavior. Most Wolfhounds are very gentle with children. The Irish Wolfhound is relatively easy to train. They respond well to firm, but gentle, consistent leadership. However, historically these dogs were required to work at great distances from their masters and think independently when hunting rather than waiting for detailed commands and this can still be seen in the breed.\n\nIrish Wolfhounds are often favored for their loyalty, affection, patience and devotion. Although at some points in history they have been used as watchdogs, unlike some breeds, the Irish Wolfhound is usually unreliable in this role as they are often friendly toward strangers, although their size can be a natural deterrent. However, when protection is required this dog is never found wanting. When they or their family are in any perceived danger they display a fearless nature. Author and Irish Wolfhound breeder Linda Glover believes the dogs' close affinity with humans makes them acutely aware and sensitive to ill will or malicious intentions leading to their excelling as a guardian rather than guard dog.\n\nLike many large dog breeds, Irish Wolfhounds have a relatively short lifespan. Published lifespan estimations vary between 6 and 10 years with 7 years being the average. Dilated cardiomyopathy and bone cancer are the leading cause of death and like all deep-chested dogs, gastric torsion (bloat) is common; the breed is affected by hereditary intrahepatic portosystemic shunt. \n\nIn a privately funded study conducted under the auspices of the Irish Wolfhound Club of America and based on an owner survey, Irish Wolfhounds in the United States from 1966 to 1986 lived to a mean age of 6.47 and died most frequently of bone cancer. A more recent study by the UK Kennel Club puts the average age of death at 7 years.\n\nStudies have shown that neutering is associated with a higher risk of bone cancer in various breeds, with one study suggesting that castration of male Irish Wolfhounds should be avoided at least until the dog is fully grown.\n\nIrish Wolfhounds should not receive additional supplements when a good dog food is used. It is generally accepted that they should be fed a low protein adult dog food (19 to 21% protein) from puppyhood onward. Most breeders today recommend that they not be supplemented to slow their rapid growth.\n\nIrish Wolfhounds are the tallest of all dog breeds, sometimes reaching 7 feet tall on their hind legs. They are well suited to rural life, but their medium energy profile allows them to adjust fairly well to suburban and urban life as well, provided they receive appropriate exercise.\n\n\n"}
{"id": "15336", "url": "https://en.wikipedia.org/wiki?curid=15336", "title": "Italian Greyhound", "text": "Italian Greyhound\n\nThe Italian Greyhound (in Italian: \"piccolo levriero italiano\") is a small breed of dog; of the sighthound type, sometimes called the Italian for short, and nicknamed the \"IG\" or \"Iggy\".\n\nThe Italian Greyhound is the smallest of the sighthounds, typically weighing about and standing about tall at the shoulder. They are in the toy group in the UK and US but in the sighthound group in the Fédération Cynologique Internationale (FCI).\n\nThe Italian Greyhound's chest is deep, with a tucked up abdomen, long slender legs and a long neck that tapers down to a small head. The head is long and pointed, like a full sized Greyhound. Overall, they look like \"miniature\" Greyhounds. Though many Italian Greyhound owners dispute the use of the term \"miniature greyhound\" in reference to the breed itself, by definition of the American Kennel Club they are true genetic Greyhounds, with a bloodline extending back over 2,000 years. Their current small stature is a function of selective breeding. Their gait is distinctive and should be high stepping and free, rather like that of a horse. They are able to run at top speed with a double suspension gallop, and can achieve a top speed of up to .\n\nRecognised coat colours in the UK are Black, Blue (grey), Red and Fawn. For The Kennel Club (UK), all colours except brindle are accepted. For the American Kennel Club, and the Australian National Kennel Council, parti colored Italian Greyhounds are accepted, while the FCI standard for international shows allows white only on the chest and feet. Coat colours of Black, Blue and Isabelle (Fawn) exist in all nuances.\n\nThe modern Italian Greyhound's appearance is a result of breeders throughout Europe, particularly Austrian, German, Italian, French and British, making great contributions to the forming of this breed. The Italian Greyhound should resemble a small Greyhound, or rather a Sloughi.\n\nThe Italian Greyhound makes a good companion dog and enjoys the company of people. However, the breed's slim build and short coat make them somewhat fragile, and injury can result from rough or careless play with children. They are fast, agile and athletic, and love to run. Due to their size, and in some lineages poor bone density, they are prone to broken legs. Italian Greyhounds make reasonably good watchdogs, as they bark at unfamiliar sounds. They may also bark at passers-by and other animals. However, they should not be considered \"true\" guard dogs as they are often aloof with strangers and easily spooked to run.\n\nAs sighthounds, Italian Greyhounds instinctively hunt by sight and have an extremely high predator drive. As with most sighthounds, martingale collars are often used with Italian greyhounds since their necks are nearly the same width as their skulls. Some Italian Greyhounds take part in dog agility. The breed's lithe body and its love of action provide potential to do well at this sport, although their natural inclination is for straight-out racing rather than for working tightly as a team with a handler on a technical course. Lure coursing is well-suited to the Italian Greyhound. They are fast dogs, and while they are not as well suited to racing as their larger cousins, many Italian Greyhounds participate in amateur straight-track and oval-track racing.\n\nDogs of this breed have an extremely short and almost odorless coat that requires little more than an occasional bath about once a month (though many veterinarians suggest that even bathing once per month is too frequent for this breed), but a wipe-down with a damp cloth is recommended after walks as seeds, burrs and floating dust in the air can get into the coat and irritate the skin. This breed sheds medium to little hair.\n\nThe Italian Greyhound has a median lifespan of 13.5 in a 2004 UK Kennel Club survey. A 1993 US breed club survey gives an average lifespan of 9 years but more than a quarter of the dogs had \"accidents\" recorded as cause of death. \n\nHealth problems that can be found in the breed:\nBULLET::::- Epilepsy\nBULLET::::- Legg-Perthes disease (degeneration of the hip)\nBULLET::::- Patellar Luxation (slipped stifles)\nBULLET::::- von Willebrand disease (vWD) (Bleeding disorder)\nBULLET::::- Progressive retinal atrophy (PRA)\nBULLET::::- Color dilution alopecia (hair loss in dilute pigmented dogs, i.e.: blues, blue fawns, etc.)\nBULLET::::- Leg Breaks (most common under the age of 2)\nBULLET::::- Cataracts\nBULLET::::- Vitreous degeneration\nBULLET::::- Liver shunts\nBULLET::::- Autoimmune hemolytic anemia\nBULLET::::- Periodontal disease, gum recession, early tooth loss, bad tooth enamel\nBULLET::::- Hypothyroidism, Autoimmune Thyroid Disease (Hashimoto's disease)\nTheir scissor-bite and thin jaw bones make them susceptible to periodontal disease, which can be avoided with good dental care. Daily brushing has been shown to be very beneficial as well as regular dental cleanings from the vet.\n\nResponsible breeders will routinely check their dogs for the onset of various inherited disorders, these commonly include (but are not limited to): CERF examinations on eyes, OFA patellar examinations, OFA thyroid function panels, von Willebrand's factor, OFA hip and Legg-Perthes disease x-rays, and others. In research by the Ortheopedic Foundation for Animals, the Italian Greyhound was found to be the least affected by hip dysplasia out of 157 breeds. Tests were conducted on 169 individual Italian Greyhounds, of which none were found to have hip dysplasia and 59.2% scored excellent on their hip evaluations.\n\nBy the Middle Ages, the breed had become distributed throughout Southern Europe and was later a favorite of the Italians of the sixteenth century, among whom miniature dogs were in great demand. Sadly, though, 'designer' breeders tried, and failed, to make the breed even smaller by crossbreeding it with other breeds of dogs. This only led to mutations with deformed skulls, bulging eyes and dental problems. The original Italian Greyhound had almost disappeared when groups of breeders got together and managed to return the breed to normal. From this period onward the history of the breed can be fairly well traced as it spread through Europe, arriving in England in the seventeenth century.\n\nThe grace of the breed has prompted several artists to include the dogs in paintings, among others Velázquez, Pisanello, and Giotto.\n\nThe breed has been popular with royalty. Among the royal aficionados are Queen Anne, Queen Victoria, Catherine the Great, Frederick the Great. YouTube personality Jenna Marbles also has an interest in the breed.\n\nBULLET::::- Companion group\n"}
{"id": "15341", "url": "https://en.wikipedia.org/wiki?curid=15341", "title": "Into the Woods", "text": "Into the Woods\n\nInto the Woods is a musical with music and lyrics by Stephen Sondheim and book by James Lapine. The musical intertwines the plots of several Brothers Grimm and Charles Perrault fairy tales, exploring the consequences of the characters' wishes and quests. The main characters are taken from \"Little Red Riding Hood\", \"Jack and the Beanstalk\", \"Rapunzel\", and \"Cinderella\", as well as several others. The musical is tied together by a story involving a childless baker and his wife and their quest to begin a family (the original beginning of The Grimm Brothers' \"Rapunzel\"), their interaction with a witch who has placed a curse on them, and their interaction with other storybook characters during their journey.\n\nThe musical debuted in San Diego at the Old Globe Theatre in 1986 and premiered on Broadway on November 5, 1987, where it won several Tony Awards, including Best Score, Best Book, and Best Actress in a Musical (Joanna Gleason), in a year dominated by \"The Phantom of the Opera\" (1988). The musical has since been produced many times, with a 1988 US national tour, a 1990 West End production, a 1997 tenth anniversary concert, a 2002 Broadway revival, a 2010 London revival, and in 2012 as part of New York City's outdoor Shakespeare in the Park series.\n\nA Disney film adaptation directed by Rob Marshall and starring Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Tracey Ullman, Christine Baranski and Johnny Depp was released in 2014. The film grossed over $213 million worldwide, and received three Academy Award nominations and three Golden Globe Award nominations.\n\nThe Narrator introduces four characters: Cinderella, who wishes to attend the King's festival; Jack wishes his cow, Milky White, would give milk; a baker and his wife wish to have a child; Little Red Riding Hood wishes for bread to bring her grandmother\n\nThe Baker's neighbor, an ugly old witch, reveals the couple is infertile from a curse she cast on his father for stealing her vegetables, including magic beans. The Witch took the father of the baker's child Rapunzel. She explains the curse will be lifted if she is brought four ingredients – \"the cow as white as milk, the cape as red as blood, the hair as yellow as corn, and the slipper as pure as gold\" – in three days' time. All begin the journey into the woods: Jack to sell his beloved cow; Cinderella to her mother's grave; Little Red to her grandmother's house; and the Baker, refusing his Wife's help, to find the ingredients (\"Prologue\").\n\nCinderella receives a gown and golden slippers from her mother's spirit (\"Cinderella at the Grave\"). A Mysterious Man mocks Jack for valuing his cow more than a \"sack of beans\". Little Red meets a hungry Wolf (\"Hello, Little Girl\"), who persuades her to take a longer path and admire the beauty, with his own ulterior motives in mind. The Baker, followed by his Wife, meets Jack. They convince Jack that the beans found in the Baker's father's jacket are magic and trade them for the cow; Jack bids Milky White a tearful farewell (\"I Guess This Is Goodbye\"). The Baker has qualms about their deceit, but his wife reassures him (\"Maybe They're Magic\").\n\nThe Witch has raised Rapunzel in a tall tower accessible only by climbing Rapunzel's long, golden hair (\"Our Little World\"); a Prince spies Rapunzel. The Baker, in pursuit of the red cape, slays the Wolf and rescues Little Red and her grandmother. Little Red rewards him with her cape, and reflects on her experiences (\"I Know Things Now\"). Jack's Mother tosses his beans aside, which grow into an enormous stalk. Cinderella flees the Festival, pursued by another Prince, and the Baker's Wife hides her; asked about the ball, Cinderella is nonplussed (\"A Very Nice Prince\"). Spotting Cinderella's gold slippers, the Baker's Wife chases her and loses Milky White. The characters recite morals as the day ends (\"First Midnight\").\n\nJack describes his adventure climbing the beanstalk (\"Giants in the Sky\"). He gives the Baker gold stolen from the giants to buy back his cow, and returns up the beanstalk to find more; the Mysterious Man steals the money. Cinderella's Prince and Rapunzel's Prince, who are brothers, compare their unobtainable amours (\"Agony\"). The Baker's Wife overhears their talk of a girl with golden hair. She fools Rapunzel and takes a piece of her hair. The Mysterious Man returns Milky White to the Baker.\n\nThe Baker's Wife again fails to seize Cinderella's slippers. The Baker admits they must work together (\"It Takes Two\"). Jack arrives with a hen that lays golden eggs, but Milky White keels over dead as midnight chimes (\"Second Midnight\"). The Witch discovers the Prince's visits and demands Rapunzel stay sheltered from the world (\"Stay with Me\"). She refuses, and the Witch cuts off Rapunzel's hair and banishes her. The Mysterious Man gives the Baker money for another cow. Jack meets Little Red, now sporting a wolf skin cape and knife. She goads him into returning to the Giant's home to retrieve the Giant's harp.\n\nCinderella, torn between staying with her Prince or escaping, leaves him a slipper as a clue (\"On the Steps of the Palace\"), and trades shoes with the Baker's Wife. The Baker arrives with another cow; they now have all four items. A great crash is heard, and Jack's mother reports a dead Giant in her backyard, which no one seems to care about. Jack returns with a magic harp. The Witch discovers the new cow is useless, and resurrects Milky White, who is fed the ingredients but fails to give milk. The Witch explains Rapunzel's hair will not work, and the Mysterious Man offers corn silk instead; Milky White produces the potion. The Witch reveals the Mysterious Man is the Baker's father, and she drinks – he falls dead, the curse is broken, and the Witch regains her youth and beauty.\n\nCinderella's Prince seeks the girl who fits the slipper; the desperate stepsisters mutilate their feet (\"Careful My Toe\"). Cinderella succeeds and becomes his bride. Rapunzel bears twins and is found by her Prince. The Witch finds her, and attempts to claim her back, but the Witch's powers are gone. At Cinderella's wedding, her stepsisters are blinded by birds, and the Baker's Wife, very pregnant, thanks Cinderella for her help. Congratulating themselves on living happily \"Ever After,\" no one notices another beanstalk growing...\n\nThe Narrator continues, \"Once Upon a Time... Later.\" Everyone still has wishes: The Baker and his Wife face new frustrations with their infant son; newly rich Jack misses the kingdom in the sky; Cinderella is bored with life in the palace (\"So Happy\"), but are still relatively content.\n\nWith a tremendous crash, a Giant's foot destroys the Witch's garden, and damages the Baker's home. The Baker travels to the palace, but his warning is ignored by the Prince's Steward, and by Jack's Mother. Returning home, he finds Little Red on her way to Granny's; he and his Wife escort her. Jack decides to slay the Giant and Cinderella investigates her mother's disturbed grave. Everyone returns to the woods, but now \"the skies are strange, the winds are strong\" (\"Into the Woods\" Reprise).\n\nRapunzel, driven mad, also flees to the woods. Her Prince follows and meets his brother; they confess their lust for two new women, Snow White and Sleeping Beauty.\n\nThe Baker, his Wife, and Little Red find Cinderella's family and the Steward, who reveal the castle was set upon by the Giant. The Witch brings news that the Giant destroyed the village and the Baker's house. The Giantess – widow of the Giant Jack killed – appears, seeking revenge. As a sacrifice, the group offer up the Narrator, who is killed. Jack's mother defends her son, angering the Giantess, and the Steward silences Jack's mother, inadvertently killing her. As the Giantess leaves in search of Jack, Rapunzel is trampled (\"Witch's Lament\").\n\nThe Royal Family flee despite the Baker's pleas to stay and fight. The Witch vows to find Jack and give him to the Giant, and the Baker and his Wife split up to find him first. Cinderella's Prince seduces the Baker's Wife (\"Any Moment\"). The Baker finds and convinces Cinderella to join their group. The Baker's Wife reflects on her adventure and tryst with the Prince (\"Moments in the Woods\"), but stumbles into the path of the Giant and is killed.\n\nThe Baker, Little Red, and Cinderella await the return of the Baker's Wife when the Witch arrives with Jack, found weeping over the Baker's Wife's body. The Baker turns against Jack, and the two, along with Cinderella and Little Red start to blame each other before the four turn on the Witch (\"Your Fault\"). Chastising their inability to accept the consequences of their own actions, the Witch is struck by another curse and vanishes (\"Last Midnight\").\n\nGrief-stricken, the Baker flees, but is convinced by his father's un-dead spirit to face his responsibilities (\"No More\"). He returns and lays out a plan to kill the Giantess. Cinderella stays behind with the Baker's child and confronts her Prince over his infidelity; he explains his feelings of unfulfillment and that he wasn't raised to be sincere, and she asks him to leave.\n\nLittle Red discovers her grandmother has been killed by the Giantess, as the Baker tells Jack that his mother is dead. Jack vows to kill the Steward but the Baker dissuades him, while Cinderella comforts Little Red. The Baker and Cinderella explain that choices have consequences, and everyone is connected (\"No One Is Alone\").\n\nThe four together slay the Giant, and the other characters – including the Royal Family, who have starved to death, and the Princes with their new paramours (Sleeping Beauty and Snow White) – return to share one last set of morals. The survivors band together, and the spirit of the Baker's Wife comforts her mourning husband, encouraging him to tell their child their story. The Baker begins to tell his son the tale, while the Witch offers a final lesson: \"Careful the things you say, Children Will Listen\" (\"Finale\").\n\nBULLET::::- Act I\nBULLET::::- Prologue: \"Into the Woods\" –\nBULLET::::- \"Hello, Little Girl\" –\nBULLET::::- \"I Guess This Is Goodbye\" –\nBULLET::::- \"Maybe They're Magic\" –\nBULLET::::- \"I Know Things Now\" –\nBULLET::::- \"A Very Nice Prince\" –\nBULLET::::- \"First Midnight\" -\nBULLET::::- \"Giants in the Sky\" –\nBULLET::::- \"Agony\" –\nBULLET::::- \"It Takes Two\" –\nBULLET::::- \"Stay with Me\" –\nBULLET::::- \"On the Steps of the Palace\" –\nBULLET::::- \"Ever After\" –\nBULLET::::- Act II\nBULLET::::- Prologue: \"So Happy\" –\nBULLET::::- \"Agony\" (Reprise) –\nBULLET::::- \"Lament\" –\nBULLET::::- \"Any Moment\" –\nBULLET::::- \"Moments in the Woods\" –\nBULLET::::- \"Your Fault\" –\nBULLET::::- \"Last Midnight\" –\nBULLET::::- \"No More\" –\nBULLET::::- \"No One Is Alone\" –\nBULLET::::- Finale: \"Children Will Listen\" –\n\n\"Into the Woods\" premiered at the Old Globe Theatre in San Diego, California, on December 4, 1986 and ran for 50 performances under the direction of James Lapine. Many of the performers from that production appeared in the Broadway cast but John Cunningham, who played the Narrator, Wolf and Steward, and George Coe, as the Mysterious Man and Cinderella's Father, were replaced by Tom Aldredge among others. Kenneth Marshall as Cinderella's Prince was replaced by Robert Westenberg (who also played the Wolf), LuAnne Ponce, who played Little Red Ridinghood, was replaced by Danielle Ferland, Ellen Foley, the Witch, was replaced by Bernadette Peters. Kay McClelland, who played both Rapunzel and the Stepsister Florinda, stayed with the cast but only played Florinda, Rapunzel being played by Pamela Winslow.\n\nThe show evolved, and the most notable change was the addition of the song \"No One Is Alone\" in the middle of the run.\n\n\"Into The Woods\" opened on Broadway at the Martin Beck Theatre on November 5, 1987, and closed on September 3, 1989 after 765 performances. It starred Bernadette Peters, Joanna Gleason, Chip Zien, Kim Crosby, Ben Wright, Danielle Ferland, Chuck Wagner, Merle Louise, Tom Aldredge, and Robert Westenberg. The musical was directed by James Lapine, with musical staging by Lar Lubovitch, settings by Tony Straiges, lighting by Richard Nelson, costumes by Ann Hould-Ward (based on original concepts by Patricia Zipprodt and Ann Hould-Ward), and makeup by Jeff Raum. The original production won the 1988 New York Drama Critics' Circle Award and the Drama Desk Award for Best Musical, and the original cast recording won a Grammy Award. The show was nominated for ten Tony Awards, and won three: Best Score (Stephen Sondheim), Best Book (James Lapine) and Best Actress in a Musical (Joanna Gleason).\n\nPeters left the show after almost five months due to a prior commitment to film the movie \"Slaves of New York\". The Witch was then played by: Betsy Joslyn (from March 30, 1988); Phylicia Rashad (from April 14, 1988); Betsy Joslyn (from July 5, 1988); Nancy Dussault (from December 13, 1988); and Ellen Foley (from August 1, 1989 until the closing).\n\nOther cast replacements included Dick Cavett as the Narrator (as of July 19, 1988) (for a temporary engagement after which Tom Aldredge returned), Edmund Lyndeck as the Mysterious Man, Patricia Ben Peterson as Cinderella, LuAnne Ponce returning to the role of Little Red Ridinghood, Jeff Blumenkrantz as Jack, Marin Mazzie as Rapunzel (as of March 7, 1989) and Kay McClelland, Lauren Mitchell, Cynthia Sikes and Mary Gordon Murray as the Baker's Wife.\n\nIn 1989, from May 23 to May 25 the full original cast (with the exception of Cindy Robinson as Snow White instead of Jean Kelly) reunited for three performances to tape the musical in its entirety for the Season 10 premiere episode of PBS’s \"American Playhouse\", which first aired on March 15, 1991. The show was filmed professionally with seven cameras on the set of the Martin Beck Theater in front of an audience with certain elements changed from its standard production only slightly for the recording in order to better fit the screen rather than the stage such as the lighting, minor costume differences, and others. There were also pick up shots not filmed in front of an audience for various purposes. This video has since been released on Tape and DVD and on occasion, remastered and re-released.\n\nTenth Anniversary benefit performances were held on November 9, 1997 at The Broadway Theatre (New York), with most of the original cast. Original cast understudies Chuck Wagner and Jeff Blumenkrantz played Cinderella's Prince/Wolf and The Steward in place of Robert Westenberg and Philip Hoffmann, while Jonathan Dokuchitz (who joined the Broadway production as an understudy in 1989) played Rapunzel's Prince in place of Wagner. This concert featured the duet \"Our Little World,\" written for the first London production of the show.\n\nOn November 9, 2014, most of the original cast reunited for two reunion concerts and discussion in Costa Mesa, California. Mo Rocca hosted the reunion and interviewed Stephen Sondheim and James Lapine as well as each cast member. Appearing were Bernadette Peters, Joanna Gleason, Chip Zien, Danielle Ferland, Ben Wright and real life husband and wife, Robert Westenberg and Kim Crosby. The same group presented this discussion/concert on June 21, 2015 at the Brooklyn Academy of Music, New York City.\n\nA United States tour began on November 22, 1988 with Cleo Laine playing the Witch, replaced by Betsy Joslyn in May 1989. Rex Robbins played the Narrator and Mysterious Man, Charlotte Rae played Jack's Mother, and the Princes were played by Chuck Wagner and Douglas Sills. The set was almost completely reconstructed, and there were certain changes to the script, changing certain story elements. The 10-month tour played cities around the country, such as Fort Lauderdale, Florida, Los Angeles, and Atlanta. The tour ran at the John F. Kennedy Center for the Performing Arts from June 1989 to July 16, 1989, with the reviewer for \"The Washington Post\" writing: \"his lovely score -- poised between melody and dissonance -- is the perfect measure of our tenuous condition. The songs invariably follow the characters' thinking patterns, as they weigh their options and digest their experience. Needless to say, that doesn't make for traditional show-stoppers. But it does make for vivacity of another kind. And Sondheim's lyrics...are brilliant... I think you'll find these cast members alert and engaging.\"\n\nThe original West End production opened on September 25, 1990 at the Phoenix Theatre and closed on February 23, 1991 after 197 performances. It was directed by Richard Jones, and produced by David Mirvish, with choreography by Anthony Van Laast, costumes by Sue Blane and orchestrations by Jonathan Tunick. The cast featured Julia McKenzie as the Witch, Ian Bartholomew as the Baker, Imelda Staunton as the Baker's Wife and Clive Carter as the Wolf/Cinderella's Prince. The show received seven Olivier Award nominations in 1991, winning for Best Actress in a Musical (Staunton) and Best Director of a Musical (Jones).\n\nThe song \"Our Little World\" was added. This song was a duet sung between the Witch and Rapunzel giving further insight into the care the Witch has for her self-proclaimed daughter and the desire Rapunzel has to see the world outside of her tower. The overall feel of the show was a lot darker than that of the original Broadway production. Critic Michael Billington wrote, \"But the evening's triumph belongs also to director Richard Jones, set designer Richard Hudson and costume designer Sue Blane who evoke exactly the right mood of haunted theatricality. Old-fashioned footlights give the faces a sinister glow. The woods themselves are a semi-circular, black-and-silver screen punctuated with nine doors and a crazy clock: they achieve exactly the 'agreeable terror' of Gustave Dore's children's illustrations. And the effects are terrific: doors open to reveal the rotating magnified eyeball or the admonitory finger of the predatory giant.\"\n\nA new intimate production of the show opened (billed as the first London revival) at the Donmar Warehouse on 16 November 1998, closing on 13 February 1999. This revival was directed by John Crowley and designed by his brother, Bob Crowley. The cast included Clare Burt as the Witch, Nick Holder as the Baker, Sophie Thompson as the Baker's Wife, Jenna Russell as Cinderella, Sheridan Smith as Little Red Ridinghood and Frank Middlemass as the Narrator/Mysterious Man. Russell later appeared as the Baker's Wife in the 2010 Regent's Park production. Thompson won the 1999 Olivier Award for Best Actress in a Musical for her performance, while the production itself was nominated for Outstanding Musical Production.\n\nA revival opened at the Ahmanson Theatre in Los Angeles, running from February 1, 2002 to March 24, 2002. This production was directed and choreographed with the same principal cast that later ran on Broadway.\n\nThe 2002 Broadway revival, directed by James Lapine and choreographed by John Carrafa, began previews on April 13, 2002 and opened April 30, 2002 at the Broadhurst Theatre, closing on December 29 after a run of 18 previews and 279 regular performances. It starred Vanessa L. Williams as the Witch, John McMartin as the Narrator, Stephen DeRosa as the Baker, Kerry O'Malley as the Baker's Wife, Gregg Edelman as Cinderella's Prince/Wolf, Christopher Sieber as Rapunzel's Prince/Wolf, Molly Ephraim as Little Red Ridinghood, Adam Wylie as Jack, and Laura Benanti as Cinderella. Judi Dench provided the pre-recorded voice of the Giant.\n\nLapine revised the script slightly for this production, with a cameo appearance of the \"Three Little Pigs\" restored from the earlier San Diego production. Other changes, apart from numerous small dialogue changes, included the addition of the song \"Our Little World,\" a duet for the Witch and Rapunzel written for the first London production, the addition of a second wolf in the song \"Hello Little Girl\" who competes for Little Red's attention with the first Wolf, the portrayal of Jack's cow by a live performer (Chad Kimball) in an intricate costume and new lyrics were written for \"The Last Midnight,\" now sung by the Witch as a menacing lullaby to the Baker's baby.\n\nThis production featured scenic design by Douglas W. Schmidt, costume design by Susan Hilferty, lighting design by Brian MacDevitt, sound design by Dan Moses Schreier and projection design by Elaine J. McCarthy. The revival won the Tony Awards for the Best Revival of a Musical and Best Lighting Design. This Broadway revival wardrobe is on display at the Costume World in South Florida.\n\nA revival at the Royal Opera House's Linbury Studio in Covent Garden had a limited run from June 14 through June 30, 2007 followed by a short stint at The Lowry theatre, Salford Quays, Manchester between 4–7 July. The production mixed Opera singers, Musical Theatre actors as well as Film and television actors; including Anne Reid as Jack's Mother and Gary Waldhorn as the Narrator. The production itself, directed by Will Tuckett, was met with mixed reviews; although there were clear stand out performances.\n\nThe production completely sold out three weeks before opening. As this was an 'opera' production, the show and its performers were overlooked for the 'musical' nominations in the 2008 Olivier Awards. This production featured Suzie Toase (Little Red), Peter Caulfield (Jack), Beverley Klein (Witch), Anna Francolini (Baker's Wife), Clive Rowe (Baker), Nicholas Garrett (Wolf), and Lara Pulver (Lucinda). This was the second Sondheim musical to be staged by the Opera House, following 2003's \"Sweeney Todd\".\n\nThe Olivier Award-winning Regent's Park Open Air Theatre production, directed by Timothy Sheader and choreographed by Liam Steel, ran for a six-week limited season from 6 August to 11 September 2010. The cast included Hannah Waddingham as the Witch, Mark Hadfield as the Baker, Jenna Russell as the Baker's wife, Helen Dallimore as Cinderella, and Judi Dench as the recorded voice of the Giant. Gareth Valentine was the Musical Director. The musical was performed outdoors in a wooded area. Whilst the book remained mostly unchanged, the subtext of the plot was dramatically altered by casting the role of the Narrator as a young school boy lost in the woods following a family argument – a device used to further illustrate the musical's themes of parenting and adolescence.\n\nThe production opened to wide critical acclaim, much of the press commenting on the effectiveness of the open air setting. The \"Telegraph\" reviewer, for example, wrote: \"It is an inspired idea to stage this show in the magical, sylvan surroundings of Regent's Park, and designer Soutra Gilmour has come up with a marvellously rickety, adventure playground of a set, all ladders, stairs and elevated walkways, with Rapunzel discovered high up in a tree.\" \"The New York Times\" reviewer commented: \"The natural environment makes for something genuinely haunting and mysterious as night falls on the audience...\" Stephen Sondheim attended twice, reportedly extremely pleased with the production. The production also won the Laurence Olivier Award for Best Musical Revival and Michael Xavier, who played Cinderella's Prince and the Wolf, was nominated for the Laurence Olivier Award for Best Performance in a Supporting Role in a Musical.\n\nThe production was recorded in its entirety, available to download and watch from Digital Theatre.\n\nThe Regent's Park Open Air Theatre production transferred to the Public Theater's 2012 summer series of free performances Shakespeare in the Park at the Delacorte Theater in Central Park, New York, with an American cast as well as new designers. Sheader again was the director and Steel served as co-director and choreographer. Performances were originally to run from July 24 (delayed from July 23 due to the weather) to August 25, 2012, but the show was extended till September 1, 2012. The cast included Amy Adams as The Baker's Wife, Donna Murphy as The Witch, Denis O'Hare as The Baker, Chip Zien as the Mysterious Man/Cinderella's Father, Jack Broderick as the young Narrator, Gideon Glick as Jack, Cooper Grodin as Rapunzel's Prince, Ivan Hernandez as Cinderella's Prince/Wolf, Tina Johnson as Granny, Josh Lamon as the Steward, Jessie Mueller as Cinderella, Laura Shoop as Cinderella's Mother, Tess Soltau as Rapunzel, and Glenn Close as the Voice of the Giant. The set was a \"collaboration between original Open Air Theatre designer Soutra Gilmour and...John Lee Beatty, [and] rises over 50 feet in the air, with a series of tree-covered catwalks and pathways.\" The production was dedicated to Nora Ephron, who died earlier in 2012. In February 2012 and in May 2012, reports of a possible Broadway transfer surfaced with the production's principal actors in negotiations to reprise their roles. In January 2013, it was announced that the production will not transfer to Broadway due to scheduling conflicts.\n\nFor its annual fully staged musical event, the Hollywood Bowl produced a limited run of \"Into the Woods\" from July 26–28, 2019, directed and choreographed by Robert Longbottom. The cast included Skylar Astin as The Baker, Sierra Boggess as Cinderella, Chris Carmack as Rapunzel's Prince, Anthony Crivello as The Mysterious Man, Sutton Foster as The Baker's Wife, Edward Hibbert as The Narrator, Cheyenne Jackson as Cinderella's Prince and The Wolf, Hailey Kilgore as Rapunzel, Gaten Matarazzo as Jack, Patina Miller as The Witch, Rebecca Spencer as Jack's Mother, Shanice Williams as Little Red Riding Hood, and Whoopi Goldberg as the voice of The Giant.\n\nA production played in Sydney from 19 March 1993 to 5 June 1993 at the Drama Theatre, Sydney Opera House. It starred Judi Connelli, Geraldine Turner, Tony Sheldon, Philip Quast, Pippa Grandison, and DJ Foster. A Melbourne Theatre Company played from 17 January 1998 to 21 February 1998 at the Playhouse, Victorian Arts Centre. It starred Rhonda Burchmore, John McTernan, Gina Riley, Lisa McCune, Peter Carroll, Tamsin Carroll and Robert Grubb.\n\nThe first professional Spanish language production, \"Dentro del Bosque\", was produced by University of Puerto Rico Repertory Theatre and premiered in San Juan at Teatro de la Universidad (University Theatre) on March 14, 2013. The cast included Víctor Santiago as Baker, Ana Isabelle as Baker's Wife and Lourdes Robles as the Witch\n\nThe Roundabout Theatre production, directed by Noah Brody and Ben Steinfeld, began performances Off-Broadway at the Laura Pels Theatre on December 19, 2014 in previews, officially on January 22, 2015, and closed on April 12, 2015. Like the original Broadway production 28 years prior, this production had a try-out run at the Old Globe Theatre in San Diego, California from July 12, 2014 – August 17, 2014 with the opening night taking place on July 17. This new version is completely minimalistically reimagined by the Fiasco Theater Company, featuring only ten actors playing multiple parts, and one piano accompanist.\n\nThe DreamCatcher Theatre production opened in January 2015 and played a sold-out run at the Adrienne Arsht Center in Miami, Florida. Tituss Burgess starred as The Witch, the first male actor to do so. The cast also included Arielle Jacobs as The Bakers Wife. The musical had a production at The Muny in Forest Park, St. Louis, Missouri running from July 21 through 28 2015. The cast included Heather Headley (Witch), Erin Dilly (Baker's Wife), Rob McClure (Baker), Ken Page (Narrator), Elena Shaddow (Cinderella). The Hart House Theatre production in Toronto, Ontario from January 15, 2016 to January 30, 2016. A production ran at the West Yorkshire Playhouse in Leeds in a collaboration with Opera North from 2 June 2016 to 25 June 2016.\n\nThe Israeli premiere, אל תוך היער (El Toch Ha-ya-ar), opened in Tel Aviv on August 2016 for a limited run produced by The Tramp Productions and Stuff Like That, starring Roi Dolev as The Witch, the second male actor to do so.\n\nThe principal original casts of notable stage productions of \"Into the Woods.\"\n\n! width=\"11%\" rowspan=\"2\" Role\n! width=\"11%\" Broadway\n! width=\"11%\" First National Tour\n! width=\"11%\" West End\n! width=\"11%\" Broadway Revival\n! width=\"11%\" West End Revival\n! width=\"11%\" Regent's Park Production\n! width=\"11%\" Central Park Production\n! width=\"11%\" Australian Production\n! width=\"11%\" Hollywood Bowl\n! \n! \n! \n! \n! \n! Witch\n! Baker\n! Baker's Wife\n! Narrator\n! Mysterious Man\n! Wolf\n! Cinderella's Prince\n! Cinderella\n! Little Red Ridinghood\n! Jack\n! Jack's Mother\n! Rapunzel\n! Rapunzel's Prince\n! Grandmother\n! Cinderella's Mother\n! Giant \n! Steward\n! Florinda\n! Lucinda\n! Cinderella's Stepmother\n! Cinderella's Father\n! Snow White\n! Sleeping Beauty\n! Milky White\n\nThe musical has been adapted into a child-friendly version for use by schools and young companies, with the second act completely removed, as well as almost half the material from the first. The show is shortened from the original 2 and a half hours to fit in a 50-minute range, and the music transposed into keys that more easily fit young voices. It is licensed through Music Theatre International Broadway Junior musicals. \n\nA theatrical film adaptation of the musical was produced by Walt Disney Pictures, directed by Rob Marshall, and starring Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Tracey Ullman, Christine Baranski, Lilla Crawford, Daniel Huttlestone, MacKenzie Mauzy, Billy Magnussen, and Johnny Depp. The film was released on December 25, 2014. It was a critical and commercial hit, grossing over $213 million worldwide. For her performance as the Witch, Streep was nominated for the Academy Award for Best Supporting Actress. The film also received Academy Award nominations for Best Production Design and Best Costume Design.\n\nIn most productions of \"Into the Woods\", including the original Broadway production, several parts are doubled. Cinderella's Prince and the Wolf, who share the characteristic of being unable to control their appetites, are usually played by the same actor. Similarly, the Narrator and the Mysterious Man, who share the characteristic of commenting on the story while avoiding any personal involvement or responsibility. Granny and Cinderella's Mother, who are both matriarchal characters in the story, are also typically played by the same person, who also gives voice to the nurturing but later murderous Giant's Wife.\n\nThe show covers multiple themes: growing up, parents and children, accepting responsibility, morality, and finally, wish fulfillment and its consequences. The \"Time Magazine\" reviewers wrote that the play's \"basic insight... is at heart, most fairy tales are about the loving yet embattled relationship between parents and children. Almost everything that goes wrong—which is to say, almost everything that can—arises from a failure of parental or filial duty, despite the best intentions.\" Stephen Holden wrote that the themes of the show include parent-child relationships and the individual's responsibility to the community. The witch isn't just a scowling old hag, but a key symbol of moral ambivalence. James Lapine said that the most unpleasant person (the Witch) would have the truest things to say and the \"nicer\" people would be less honest. In the Witch's words: \"I'm not good; I'm not nice; I'm just right.\"\n\nGiven the show's debut during the 1980s, the height of the US AIDS crisis, the work has been interpreted to be a parable about AIDS. In this interpretation, the Giant's Wife serves as a metaphor for HIV/AIDS, killing good and bad characters indiscriminately and forcing the survivors to band together to stop the threat and move on from the devastation, reflecting the devastation to many communities during the AIDS crisis. When asked about the thematic connection, Sondheim acknowledged that initial audiences interpreted it as an AIDS metaphor, but stated that the work was not intended to be specific.\n\nThe score is also notable in Sondheim's output, because of its intricate reworking and development of small musical motifs. In particular, the opening words, \"I wish\", are set to the interval of a rising major second and this small unit is both repeated and developed throughout the show, just as Lapine's book explores the consequences of self-interest and \"wishing.\" The dialogue in the show is characterized by the heavy use of syncopated speech. In many instances, the characters' lines are delivered with a fixed beat that follows natural speech rhythms, but is also purposely composed in eighth, sixteenth, and quarter note rhythms as part of a spoken song. Like many Sondheim/Lapine productions, the songs contain thought-process narrative, where characters converse or think aloud.\n\nSondheim drew on parts of his troubled childhood when writing the show. In 1987, he told \"Time Magazine\" that the \"father uncomfortable with babies [was] his father, and [the] mother who regrets having had children [was] his mother.\" \n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"20%\" Nominee\n! width=\"10%\" Result\n\nBest Direction of a Musical\nStuart Maunder\n\n! width=\"5%\" Year\n! width=\"20%\" Award\n! width=\"45%\" Category\n! width=\"10%\" Result\n\nBULLET::::- \"Into the Woods\" 2012 lortel.org\nBULLET::::- \"Into the Woods\" 2015 lortel.org\nBULLET::::- Libretto for Into the Woods\nBULLET::::- \"Into the Woods\" on The Stephen Sondheim Reference Guide\nBULLET::::- Illustrated Book of \"Into the Woods\" article, Sondheim.com (2004)\nBULLET::::- \"Into the Woods\" at the Music Theatre International website\nBULLET::::- \"Into the Woods JR.\" at the Music Theatre International website\nBULLET::::- \"Profile: Into the Woods\", \"Ovrtur: International Database of Musicals\"\n"}
{"id": "15342", "url": "https://en.wikipedia.org/wiki?curid=15342", "title": "Isaac Klein", "text": "Isaac Klein\n\nIsaac Klein (September 5, 1905 – January 23, 1979) was a prominent rabbi and halakhic authority within Conservative Judaism.\n\nKlein was born in the small village of Várpalánka, today part of Mukachevo, in what was then Hungary. He emigrated with his family to the United States in 1921. He earned a BA from City College of New York in 1931. Although nearing ordination at the Yeshiva University's Rabbi Isaac Elchanan Theological Seminary, he transferred to the Jewish Theological Seminary of America (JTSA), where he was ordained in 1934 and received the advanced Jewish legal degree of \"Hattarat Hora’ah\" under the great talmudic scholar Rabbi Professor Louis Ginzberg. He was one of only three people, along with Boaz Cohen and Louis Finkelstein, to ever to receive this degree from JTSA. Klein subsequently earned a PhD from Harvard under the pioneering academic of Judaic studies Harry Wolfson. \n\nHe married the former Henriette Levine in 1932 and had three daughters, Hannah, Miriam, and Rivke. Devoted to his family, he dedicated his major work, \"A Guide to Jewish Religious Practice\" to his children, sons-in-law and 13 grandchildren listing each by name. \n\nKlein served as rabbi at Kadimoh Congregation in Springfield, Massachusetts from 1934–1953; Temple Emanu-El, Buffalo, New York, 1953–1968; Temple Shaarey Zedek, Buffalo, (which was created from the merger of Emanu-El with Temple Beth David in 1968), 1968-1972. A beloved Rabbi, he influenced generations of congregants and visiting students and, together with his wife who was an educator, founded Jewish day schools in both Springfield and Buffalo.\n\nDespite the difficulties facing a congregational Rabbi raising a family, Klein volunteered for the U.S. Army during World War II as a chaplain, motivated by a cause he saw as clearly right with important implications for the Jewish People. He served over 4 years, rising to the rank of Major and was an advisor to the high commissioner of the Occupation government. He also served on special assignments for Jewish soldiers in the U.S. Army in the 1950s, receiving the simulated rank of Brigadier General for these missions. His experiences in the war are described in his book \"The Anguish and the Ecstasy of a Jewish Chaplain\".\n\nKlein was a leader of the right-wing of the Conservative movement. He was president of the Rabbinical Assembly, 1958–1960, and a member of its Committee on Jewish Law and Standards, 1948-1979. He was the author of several books, notably, \"A Guide to Jewish Religious Practice\". One of the outstanding halakhists of the movement, he served as a leading member of the Committee on Jewish Law and Standards from 1948 until his death in 1979.\n\nAs a leading authority on halakha he authored many important teshuvot (responsa), many of which were published in his influential \"Responsa and Halakhic Studies\". From the 1950s to 1970s, he wrote a comprehensive guide to Jewish law that was used to teach halakha at the JTSA. In 1979 he assembled this into \"A Guide to Jewish Religious Practice\", which is used widely by laypeople and rabbis within Conservative Judaism.\n\nThe philosophy upon which \"A Guide to Jewish Religious Practice\" is written is stated in the foreword: \"The premise on which Torah is based is that all aspects of life - leisure no less than business, worship or rites of passage (birth, bar mitzvah, marriage, divorce, death) - are part of the covenant and mandate under which every Jew is to serve God in everything he does. In the eyes of Torah there is, strictly speaking, no such thing as the purely private domain, for even in solitude - be it the privacy of the bath or the unconsciousness of sleep - one has the capacity and the duty to serve God.\" This message, of life seen in consonance with the dictates of Judaism, permeates many pages of the book. Rabbi Louis Finkelstein, scholar of the JTSA, wrote: \"There are those who would think that we have but two alternatives, to reject or to accept the law, but in either case to treat it as a dead letter. Both of these alternatives are repugnant to the whole tradition of Judaism. Jewish law must be preserved but it is subject to interpretation by those who have mastered it, and the interpretation placed upon it by duly authorized masters in every generation must be accepted with as much reverence as those which were given in previous generations.\" \n\nThis understanding of traditional preservation of the law through its continuous interpretation lies at the heart of Klein's extensive study of Jewish law. \n\nKlein's papers are located at the University Archives, State University of New York at Buffalo (see finding aid). The archives include fifteen reels of microfilm. The collection consists of extensive writings by Klein on traditional Jewish practice and law. This includes manuscript material for his books \"Guide to Jewish Religious Practice\" (1979), \"The Ten Commandments in a Changing World \" (1963), \"The Anguish and the Ecstasy of a Jewish Chaplain\" (1974), and his translation of \"The Code of Maimonides (Mishneh Torah): Book 7, The Book of Agriculture\" (1979). The collection also contains speeches, sermons, articles, and remarks from the Conservative Jewish viewpoint on subjects such as Jewish medical ethics, dietary laws, adoption, and marriage and divorce. Meeting minutes, annual reports, bulletins, and sermons relating to Klein's rabbinical vocations in Springfield, Massachusetts and Buffalo, New York are also included. The papers contain photographs, wartime letters, and military records of Klein documenting his service in World War II as a director of Jewish religious affairs in Germany.\n\nBULLET::::- About Klein's \"A Guide to Jewish Religious Practice\"\nBULLET::::- Excerpts from \"A Guide to Jewish Religious Practice\"\nBULLET::::- Isaac Klein\nBULLET::::- Finding Aid for the Rabbi Isaac Klein Papers, 1925-1979. University Archives, The State University of New York at Buffalo.\nBULLET::::- Images of Rabbi Isaac Klein on New York Heritage\n"}
{"id": "15343", "url": "https://en.wikipedia.org/wiki?curid=15343", "title": "Intron", "text": "Intron\n\nAn intron is any nucleotide sequence within a gene that is removed by RNA splicing during maturation of the final RNA product. In other words, Introns are noncoding regions of an RNA transcript, or the DNA encoding it, which are eliminated by splicing before translation. The word \"intron\" is derived from the term \"intragenic region\", i.e. a region inside a gene. The term \"intron\" refers to both the DNA sequence within a gene and the corresponding sequence in RNA transcripts. Sequences that are joined together in the final mature RNA after RNA splicing are exons. Introns are found in the genes of most organisms and many viruses, and can be located in a wide range of genes, including those that generate proteins, ribosomal RNA (rRNA), and transfer RNA (tRNA). When proteins are generated from intron-containing genes, RNA splicing takes place as part of the RNA processing pathway that follows transcription and precedes translation.\n\nIntrons were first discovered in protein-coding genes of adenovirus, and were subsequently identified in genes encoding transfer RNA and ribosomal RNA genes. Introns are now known to occur within a wide variety of genes throughout organisms and viruses within all of the biological kingdoms.\n\nThe fact that genes were split or interrupted by introns was discovered independently in 1977 by Phillip Allen Sharp and Richard J. Roberts, for which they shared the Nobel Prize in Physiology or Medicine in 1993. The term \"intron\" was introduced by American biochemist Walter Gilbert:\n\n\"The notion of the cistron [i.e., gene] ... must be replaced by that of a transcription unit containing regions which will be lost from the mature messenger – which I suggest we call introns (for intragenic regions) – alternating with regions which will be expressed – exons.\" (Gilbert 1978)\n\nThe term \"intron\" also refers to \"intracistron\", i.e., an additional piece of DNA that arises within a cistron.\n\nAlthough introns are sometimes called \"intervening sequences\", the term \"intervening sequence\" can refer to any of several families of internal nucleic acid sequences that are not present in the final gene product, including inteins, untranslated sequences (UTR), and nucleotides removed by RNA editing, in addition to introns.\n\nThe frequency of introns within different genomes is observed to vary widely across the spectrum of biological organisms. For example, introns are extremely common within the nuclear genome of jawed vertebrates (e.g. humans and mice), where protein-coding genes almost always contain multiple introns, while introns are rare within the nuclear genes of some eukaryotic microorganisms, for example baker's/brewer's yeast (\"Saccharomyces cerevisiae\"). In contrast, the mitochondrial genomes of vertebrates are entirely devoid of introns, while those of eukaryotic microorganisms may contain many introns.\n\nA particularly extreme case is the \"Drosophila dhc7\" gene containing a ≥3.6 megabase (Mb) intron, which takes roughly three days to transcribe. On the other extreme, a recent study suggests that the shortest known eukaryotic intron length is 30 base pairs (bp) belonging to the human \"MST1L\" gene.\n\nSplicing of all intron-containing RNA molecules is superficially similar, as described above. However, different types of introns were identified through the examination of intron structure by DNA sequence analysis, together with genetic and biochemical analysis of RNA splicing reactions.\n\nAt least four distinct classes of introns have been identified:\nBULLET::::- Introns in nuclear protein-coding genes that are removed by spliceosomes (spliceosomal introns)\nBULLET::::- Introns in nuclear and archaeal transfer RNA genes that are removed by proteins (tRNA introns)\nBULLET::::- Self-splicing group I introns that are removed by RNA catalysis\nBULLET::::- Self-splicing group II introns that are removed by RNA catalysis\nGroup III introns are proposed to be a fifth family, but little is known about the biochemical apparatus that mediates their splicing. They appear to be related to group II introns, and possibly to spliceosomal introns.\n\nNuclear pre-mRNA introns (spliceosomal introns) are characterized by specific intron sequences located at the boundaries between introns and exons. These sequences are recognized by spliceosomal RNA molecules when the splicing reactions are initiated. In addition, they contain a branch point, a particular nucleotide sequence near the 3' end of the intron that becomes covalently linked to the 5' end of the intron during the splicing process, generating a branched (\"lariat\") intron. Apart from these three short conserved elements, nuclear pre-mRNA intron sequences are highly variable. Nuclear pre-mRNA introns are often much longer than their surrounding exons.\n\nTransfer RNA introns that depend upon proteins for removal occur at a specific location within the anticodon loop of unspliced tRNA precursors, and are removed by a tRNA splicing endonuclease. The exons are then linked together by a second protein, the tRNA splicing ligase. Note that self-splicing introns are also sometimes found within tRNA genes.\n\nGroup I and group II introns are found in genes encoding proteins (messenger RNA), transfer RNA and ribosomal RNA in a very wide range of living organisms., Following transcription into RNA, group I and group II introns also make extensive internal interactions that allow them to fold into a specific, complex three-dimensional architecture. These complex architectures allow some group I and group II introns to be \"self-splicing\", that is, the intron-containing RNA molecule can rearrange its own covalent structure so as to precisely remove the intron and link the exons together in the correct order. In some cases, particular intron-binding proteins are involved in splicing, acting in such a way that they assist the intron in folding into the three-dimensional structure that is necessary for self-splicing activity. Group I and group II introns are distinguished by different sets of internal conserved sequences and folded structures, and by the fact that splicing of RNA molecules containing group II introns generates branched introns (like those of spliceosomal RNAs), while group I introns use a non-encoded guanosine nucleotide (typically GTP) to initiate splicing, adding it on to the 5'-end of the excised intron.\n\nWhile introns do not encode protein products, they are integral to gene expression regulation. Some introns themselves encode functional RNAs through further processing after splicing to generate noncoding RNA molecules. Alternative splicing is widely used to generate multiple proteins from a single gene. Furthermore, some introns play essential roles in a wide range of gene expression regulatory functions such as Nonsense-mediated decay and mRNA export.\n\nThe biological origins of introns are obscure. After the initial discovery of introns in protein-coding genes of the eukaryotic nucleus, there was significant debate as to whether introns in modern-day organisms were inherited from a common ancient ancestor (termed the introns-early hypothesis), or whether they appeared in genes rather recently in the evolutionary process (termed the introns-late hypothesis). Another theory is that the spliceosome and the intron-exon structure of genes is a relic of the RNA world (the introns-first hypothesis). There is still considerable debate about the extent to which of these hypotheses is most correct. The popular consensus at the moment is that introns arose within the eukaryote lineage as selfish elements.\n\nEarly studies of genomic DNA sequences from a wide range of organisms show that the intron-exon structure of homologous genes in different organisms can vary widely. More recent studies of entire eukaryotic genomes have now shown that the lengths and density (introns/gene) of introns varies considerably between related species. For example, while the human genome contains an average of 8.4 introns/gene (139,418 in the genome), the unicellular fungus \"Encephalitozoon cuniculi\" contains only 0.0075 introns/gene (15 introns in the genome). Since eukaryotes arose from a common ancestor (common descent), there must have been extensive gain or loss of introns during evolutionary time. This process is thought to be subject to selection, with a tendency towards intron gain in larger species due to their smaller population sizes, and the converse in smaller (particularly unicellular) species. Biological factors also influence which genes in a genome lose or accumulate introns.\n\nAlternative splicing of introns within a gene acts to introduce greater variability of protein sequences translated from a single gene, allowing multiple related proteins to be generated from a single gene and a single precursor mRNA transcript. The control of alternative RNA splicing is performed by a complex network of signaling molecules that respond to a wide range of intracellular and extracellular signals.\n\nIntrons contain several short sequences that are important for efficient splicing, such as acceptor and donor sites at either end of the intron as well as a branch point site, which are required for proper splicing by the spliceosome. Some introns are known to enhance the expression of the gene that they are contained in by a process known as intron-mediated enhancement (IME).\n\nActively transcribed regions of DNA frequently form R-loops that are vulnerable to DNA damage. In highly expressed yeast genes, introns inhibit R-loop formation and the occurrence of DNA damage. Genome-wide analysis in both yeast and humans revealed that intron-containing genes have decreased R-loop levels and decreased DNA damage compared to intronless genes of similar expression. Insertion of an intron within an R-loop prone gene can also suppress R-loop formation and recombination. Bonnet et al. (2017) speculated that the function of introns in maintaining genetic stability may explain their evolutionary maintenance at certain locations, particularly in highly expressed genes.\n\nThe physical presence of introns promotes cellular resistance to starvation via intron enhanced repression of ribosomal protein genes of nutrient-sensing pathways.\n\nIntrons may be lost or gained over evolutionary time, as shown by many comparative studies of orthologous genes. Subsequent analyses have identified thousands of examples of intron loss and gain events, and it has been proposed that the emergence of eukaryotes, or the initial stages of eukaryotic evolution, involved an intron invasion. Two definitive mechanisms of intron loss, Reverse Transcriptase-Mediated Intron Loss (RTMIL) and genomic deletions, have been identified, and are known to occur. The definitive mechanisms of intron gain, however, remain elusive and controversial. At least seven mechanisms of intron gain have been reported thus far: Intron Transposition, Transposon Insertion, Tandem Genomic Duplication, Intron Transfer, Intron Gain during Double-Strand Break Repair (DSBR), Insertion of a Group II Intron, and Intronization. In theory it should be easiest to deduce the origin of recently gained introns due to the lack of host-induced mutations, yet even introns gained recently did not arise from any of the aforementioned mechanisms. These findings thus raise the question of whether or not the proposed mechanisms of intron gain fail to describe the mechanistic origin of many novel introns because they are not accurate mechanisms of intron gain, or if there are other, yet to be discovered, processes generating novel introns.\n\nIn intron transposition, the most commonly purported intron gain mechanism, a spliced intron is thought to reverse splice into either its own mRNA or another mRNA at a previously intron-less position. This intron-containing mRNA is then reverse transcribed and the resulting intron-containing cDNA may then cause intron gain via complete or partial recombination with its original genomic locus. Transposon insertions can also result in intron creation. Such an insertion could intronize the transposon without disrupting the coding sequence when a transposon inserts into the sequence AGGT, resulting in the duplication of this sequence on each side of the transposon. It is not yet understood why these elements are spliced, whether by chance, or by some preferential action by the transposon. In tandem genomic duplication, due to the similarity between consensus donor and acceptor splice sites, which both closely resemble AGGT, the tandem genomic duplication of an exonic segment harboring an AGGT sequence generates two potential splice sites. When recognized by the spliceosome, the sequence between the original and duplicated AGGT will be spliced, resulting in the creation of an intron without alteration of the coding sequence of the gene. Double-stranded break repair via non-homologous end joining was recently identified as a source of intron gain when researchers identified short direct repeats flanking 43% of gained introns in Daphnia. These numbers must be compared to the number of conserved introns flanked by repeats in other organisms, though, for statistical relevance. For group II intron insertion, the retrohoming of a group II intron into a nuclear gene was proposed to cause recent spliceosomal intron gain.\n\nIntron transfer has been hypothesized to result in intron gain when a paralog or pseudogene gains an intron and then transfers this intron via recombination to an intron-absent location in its sister paralog. Intronization is the process by which mutations create novel introns from formerly exonic sequence. Thus, unlike other proposed mechanisms of intron gain, this mechanism does not require the insertion or generation of DNA to create a novel intron.\n\nThe only hypothesized mechanism of recent intron gain lacking any direct evidence is that of group II intron insertion, which when demonstrated in vivo, abolishes gene expression. Group II introns are therefore likely the presumed ancestors of spliceosomal introns, acting as site-specific retroelements, and are no longer responsible for intron gain. Tandem genomic duplication is the only proposed mechanism with supporting in vivo experimental evidence: a short intragenic tandem duplication can insert a novel intron into a protein-coding gene, leaving the corresponding peptide sequence unchanged. This mechanism also has extensive indirect evidence lending support to the idea that tandem genomic duplication is a prevalent mechanism for intron gain. The testing of other proposed mechanisms in vivo, particularly intron gain during DSBR, intron transfer, and intronization, is possible, although these mechanisms must be demonstrated in vivo to solidify them as actual mechanisms of intron gain. Further genomic analyses, especially when executed at the population level, may then quantify the relative contribution of each mechanism, possibly identifying species-specific biases that may shed light on varied rates of intron gain amongst different species.\n\nStructure:\nBULLET::::- Exon\nBULLET::::- mRNA\nBULLET::::- Eukaryotic chromosome fine structure\nBULLET::::- Small t intron\nSplicing:\nBULLET::::- Alternative splicing\nBULLET::::- Exitron\nBULLET::::- Minor spliceosome\nBULLET::::- Outron\nFunction\nBULLET::::- MicroRNA\nOthers:\nBULLET::::- Exon shuffling\nBULLET::::- Intein\nBULLET::::- Interrupted gene\nBULLET::::- Noncoding DNA\nBULLET::::- Noncoding RNA\nBULLET::::- Selfish DNA\nBULLET::::- Twintron\n\nBULLET::::- A search engine for exon/intron sequences defined by NCBI\nBULLET::::- Bruce Alberts, Alexander Johnson, Julian Lewis, Martin Raff, Keith Roberts, and Peter Walter \"Molecular Biology of the Cell\", 2007, . Fourth edition is available online through the NCBI Bookshelf: link\nBULLET::::- Jeremy M Berg, John L Tymoczko, and Lubert Stryer, \"Biochemistry\" 5th edition, 2002, W H Freeman. Available online through the NCBI Bookshelf: link\nBULLET::::- Intron finding tool for plant genomic sequences\nBULLET::::- Exon-intron graphic maker\n"}
{"id": "15345", "url": "https://en.wikipedia.org/wiki?curid=15345", "title": "IEE", "text": "IEE\n\nIEE may stand for:\n\nBULLET::::- Institution of Electrical Engineers, a British professional organisation now part of the Institution of Engineering and Technology\nBULLET::::- Instituto de Estudos Empresariais, a Brazilian non-profit\nBULLET::::- Intuitive Ethical Extrovert, in socionics\nBULLET::::- Institute for Energy & Environment, at New Mexico State University\nBULLET::::- Initial Environmental Evaluation, a preliminary environmental impact assessment\nBULLET::::- Intelligent Energy Europe, CIP Operational programme\n\nBULLET::::- Institute of Electrical and Electronics Engineers (IEEE)\n"}
{"id": "15346", "url": "https://en.wikipedia.org/wiki?curid=15346", "title": "Institute of National Remembrance", "text": "Institute of National Remembrance\n\nThe Institute of National Remembrance – Commission for the Prosecution of Crimes against the Polish Nation (; IPN) is a Polish government institution in charge of prosecution, archives, education, and, since 2007, lustration, in relation to crimes against the Polish nation. The \"IPN\" investigates Nazi and communist crimes committed between 1917 and 1990, documents its findings, and disseminates them to the public.\n\nThe Institute was established by the Polish Parliament on 18 December 1998 and incorporated the earlier, 1991-established Main Commission for the Prosecution of Crimes against the Polish Nation (which had replaced a 1945-established body on Nazi crimes). It began its activities on 1 July 2000. The \"IPN\" is a founding member of the Platform of European Memory and Conscience.\n\nIPN's main areas of activity, in line with its original mission statement, include researching and documenting the losses which were suffered by the Polish Nation as a result of World War II and during the post-war totalitarian period. The Institute informs about the patriotic traditions of resistance against the occupational forces, and the Polish citizens' fight for sovereignty of the nation, including their efforts in defence of freedom and human dignity in general. IPN investigates crimes committed on Polish soil against Polish citizens as well as people of other citizenships wronged in the country. War crimes which are not affected by statute of limitations according to Polish law include:\nBULLET::::1. crimes of the Soviet and Polish communist regimes committed in the country from 17 September 1939 until fall of communism on 31 December 1989,\nBULLET::::2. deportations to the Soviet Union of Polish soldiers of Armia Krajowa, and other Polish resistance organizations as well as Polish inhabitants of the former Polish eastern territories,\nBULLET::::3. pacifications of Polish communities between Vistula and Bug Rivers in the years 1944 to 1947 by UB-NKVD,\nBULLET::::4. crimes committed by the law enforcement agencies of the Polish People's Republic, particularly Ministry of Public Security of Poland and Main Directorate of Information of the Polish Army,\nBULLET::::5. crimes under the category of war crimes and crimes against humanity.\nIt is the IPN's duty to prosecute crimes against peace and humanity, as much as war crimes. Its mission includes the need to compensate for damages which were suffered by the repressed and harmed people at a time when human rights were disobeyed by the state,\nand educate the public about recent history of Poland. IPN collects, organises and archives all documents about the Polish communist security apparatus active from 22 July 1944 to 31 December 1989.\n\nFollowing the election of the Law and Justice party, the nationalist government formulated in 2016 a new IPN law. The 2016 law stipulates that the IPN should oppose publications that dishonor or harm the Polish nation and that history should be popularized as \"an element of patriotic education\". The new law also removed the influence of academia and the judiciary on the IPN, and four Law and Justice candidates were appointed to the IPN kolegium replacing the former independent members.\n\nA 2018 amendment to the law, often referred to as the \"Holocaust Law\", added an article 55a that attempts to defend the \"good name\" of Poland and its people against any accusation of complicity in the Holocaust. Initially conceived as a criminal offense (3 years and jail) with an exemption for arts and research, following an international outcry, the article was modified to a civil offense that may be tried in civil courts and the exemption was deleted. Defamation charges under the act may be made by the IPN as well as by accredited NGOs such as the Polish League Against Defamation.\n\nIPN was created by special legislation on 18 December 1998. The IPN is divided into:\nBULLET::::- Main Commission for the Prosecution of Crimes against the Polish Nation (\"Główna Komisja Ścigania Zbrodni Przeciwko Narodowi Polskiemu\")\nBULLET::::- Bureau of Provision and Archivization of Documents (\"Biuro Udostępniania i Archiwizacji Dokumentów\")\nBULLET::::- Bureau of Public Education (or Public Education Office, \"Biuro Edukacji Publicznej\")\nBULLET::::- Lustration Bureau (\"Biuro Lustracyjne\") (new bureau, since October 2006)\nBULLET::::- local chapters.\n\nOn 29 April 2010, acting president Bronislaw Komorowski signed into law a parliamentary act that reformed the Institute of National Remembrance.\n\nIPN is governed by the director, who has a sovereign position that is independent of the Polish state hierarchy. The director may not be dismissed during his term, unless he commits a harmful act. Prior to 2016, the election of the director was a complex procedure, which involves the selection of a panel of candidates by the IPN Collegium (members appointed by the Polish Parliament and judiciary). The Polish Parliament (Sejm) then elects one of the candidates, with a required supermajority (60%). The director has a 5-year term of office. Following 2016 legislation in the PiS controlled parliament, the former pluralist Collegium was replaced with a nine-member Collegium composed of PiS supporters, and the Sejm appoints the director after consulting with the College without an election between candidates.\n\nThe first director of the IPN was Leon Kieres, elected by the Sejm for five years on 8 June 2000 (term 30 June 2000 – 29 December 2005). The IPN granted some 6,500 people the \"victim of communism\" status and gathered significant archive material. The institute faced difficulties since it was new and also since the Democratic Left Alliance (containing former communists) attempted to close the institute. The publication of by Jan T. Gross, proved to be a lifeline for the IPN as Polish president Aleksander Kwaśniewski intervened to save the IPN since he deemed the IPN's research to be important as part of Jewish-Polish reconciliation and \"apology diplomacy\". \n\nThe second director was Janusz Kurtyka, elected on 9 December 2005 with a term that started 29 December 2005 until his death in the Smolensk airplane crash on 10 April 2010. The elections were controversial, as during the elections a leak against Andrzej Przewoźnik accusing him of collaboration with Służba Bezpieczeństwa caused him to withdraw his candidacy.. Przewoźnik was cleared of the accusations only after he had lost the election.\n\nIn 2006, the IPN opened a \"Lustration Bureau\" that increased the director's power. The bureau was assigned the task of examining the past of all candidates to public office. Kurtyka widened archive access to the public, and shifted focus from compensating victims to researching collaboration. Andrzej Friszke sees Kurtyka's term as the beginning of politicization of the IPN. Kurtyka's management was absolutist, and he surrounded himself with many PiS supporters. An official \"history policy\" was formulated that promoted martyrological and romantic formulations of history. Kurtyka has a close relationship with PiS party during his term. Researchers whose views were not aligned with the director left the IPN, and they were replaced with researchers of a similar viewpoint. \n\nFranciszek Gryciuk was acting director from 2010 to 2011.\n\nŁukasz Kamiński, was elected by the Sejm in 2011 following the death of his predecessor. Kamiński, an insider, headed the Wroclaw Regional Bureau of Public Education prior to his election. During his term the IPN faced a wide array of criticism calling for an overhaul or even replacement. Critics founds fault in the IPN being a state institution, the lack of historical knowledge of its prosecutors, a relatively high number of microhistories with a debatable methodology, overuse of the martyrology motif, research methodology, and isolationism from the wider research community. In response, Kamiński implemented several changes, including organizing public debates with outside historians to counter the charge of isolationism and has suggested refocusing on victims as opposed to agents.\n\nJarosław Szarek was appointed to head the IPN on 22 July 2016. Szarek is affiliated with PiS, and in his campaign to be elected said that \"Germans were the executors of the Jedwabne crime and that they had coerced a small group of Poles to become involved\". Following his appointment, Szarek dismissed Krzysztof Persak who was the coauthor of the two-volume 2002 IPN study on the Jedwabne pogrom. In subsequent months, the IPN was featured in media headlines for releasing controversial documents, additional Wałęsa documents, memory politics in schools and efforts to change communist street names, and legislation efforts. According to historian Idesbald Goddeeris, this marks a return of politics to the IPN.\n\nFollowing the public debate on Jan T. Gross's book \"Neighbors\", the IPN conducted an in-depth investigation into the Jedwabne pogrom. The investigation was politicized, and the IPN's director was involved in defending Poland's good name outside of Poland during the investigation.\n\nWhile the IPN's output of new historical knowledge has been significant, it has also faced criticism from academia for one-sided bias.\n\nThe IPN's Public Education Office (BEP) vaguely defined role in the IPN act is to inform society of communist and Nazi crimes and institutions. This vaguely defined role allowed Paweł Machcewicz, BEP's director in 2000, freedom to create a wide range of activities.\n\nResearchers at the IPN conduct not only research, but are required to take part in public outreach. BEP has published music CDs, DVDs, and serials. It has founded \"historical clubs\" for debates and lectures. It has also organized outdoor historical fairs, picnic, and games. \n\nThe \"IPN Bulletin\" () is a high circulation popular-scientific journal, intended for lay readers and youth. Some 12,000 of 15,000 copies of the \"Bulletin\" are distributed free of charge to secondary schools in Poland, and the rest are sold in bookstores. The \"Bulletin\" contains: popular-scientific and academic articles, polemics, manifestos, appeals to readers, promotional material on the IPN and BEP, denials and commentary on reports in the news, as well as multimedia supplements.\n\nThe IPN also publishes the \"Remembrance and Justice\" () scientific journal.\n\nThe Institution of National Remembrance has created several board games to help educate people about recent Polish history\nBULLET::::- \"303\" – a game about the Battle of Britain that focuses on the Polish 303 Squadron\nBULLET::::- \"Kolejka\" – a game about being forced to queue for basic household products during the Communist era.\n\nOne of the most controversial aspects of IPN is a by-product of its role in collecting and publishing previously secret archives from the Polish communist security apparatus, the Służba Bezpieczeństwa: revealing secret agents and collaborators (a process called \"lustration\").\n\nFollowing the election of a Law and Justice government in 2005, in a series of legislative amendments during 2006 and the beginning of 2007 file access and lustration powers were radically expanded. However, several articles of the 2006-7 amendments were judged unconstitutional by Poland's Constitutional Court on 11 May 2007. Following the court ruling the IPN's lustration power was still wider in relation to the original 1997 law, and include loss of position for those who submitted false lustration declarations as well as a lustration process of candidates for senior office as well as .\n\nAn incident which drew criticism involved the \"Wildstein list\", a partial list of persons who allegedly worked for the communist-era Polish intelligence service, copied in 2004 from IPN archives (without IPN permission) by journalist Bronisław Wildstein and published on the Internet in 2005. The list gained much attention in Polish media and politics, and IPN security procedures and handling of the matter came under criticism.\n\nIndividuals opposed by neo-\"Endeks\" (modern-day adherents of National Democracy principles), such as liberal clergy, independent journalists, Jacek Kuroń, and Zygmunt Bauman, have been targeted with \"leaks\" from the IPN archives about their alleged past communist ties.\n\nIn 2006 there was widespread protest against the IPN's publications about Kuroń. Nine Solidarity activists wrote the Polish president, complaining that the IPN was systematically slinging dirt at the Solidarity movement. In response, 200 individuals signed an open letter defending the IPN and stating that \"[The] history of Solidarity and anti-communist resistance in Poland cannot be damaged by scholarly studies and [the] resulting increase in our knowledge of the past.\"\n\nIn 2008 two IPN employees, Sławomir Cenckiewicz and Piotr Gontarczyk, published a book, \"SB a Lech Wałęsa. Przyczynek do biografii\" (The Security Service and Lech Wałęsa: A Contribution to a Biography). Reading more as political indictment than scholarship, major controversy ensued. The book's premise was that in the 1970s the Solidarity leader and later President of Poland Lech Wałęsa was a secret informant of the Polish communist Security Service. Michael Szporer writes that the book should have been more nuanced in its judgment of anti-communist leaders, and that it unfairly singled out Wałęsa.\n\nAs of 2012 some 10% of IPN's personnel (215 workers of which 26 are prosecutors) are in the Lustration office. Between 2007 and 2012, prepared four internet catalogs of: former Communist officials, security officers, those targeted by Security, and of people presently holding public office. In the same period, the IPN handled nearly 150,000 \"vetting declaration.\n\nIn 2005, after Law and Justice's (\"PiS\") electoral victory, the \"IPN\" focused on crimes against the Polish nation. Part of PiS's platform was \"historical policy\" () on the national and international level to promote the Polish point of view. During PiS's control of the government between 2005 and 2007, the \"IPN\" was the focus of heated public controversies, in particular in regard to the past of Solidarity leader Lech Wałęsa. As a result, in scholarly literature the \"IPN\" has been referred to as a \"Ministry of Memory\" or as an institution involved in \"memory games\".\n\nHistorian Dariusz Stola concludes that the \"IPN\" is a \"Ministry of Memory\", but bureaucratic in nature and not Orwellian. Stola notes that ironically the \"IPN\" has come to resemble past communist institutions that it was set up to deal with: centralist, heavy-handed, bureaucratic, ineffective, and focused on growth and quantity over quality.\n\nIn 2008, Adam Michnik said that the \"IPN\" is \"engaging in activities that destroy this memory. Today's memory police resort to the hateful methods of the communist secret services and direct them at a victim of this very secret service. These policemen violate the truth and fundamental ethical principles.\"\n\nConcerns have been raised of politicization of the \"IPN\", starting with its legal mandate (no comparable institution in any other European country holds prosecutorial power) and continuing to its choice of staff, which at times tended toward particular political views.\n\nSeveral scholars have criticized the \"IPN\" for turning in recent years, with the rise of the and the 2018 amendment to the \"IPN\" law, from objective historical research towards historical revisionism.\n\nFollowing the disruption of the 2019 New Polish School of Holocaust Scholarship conference in Paris, the \"IPN\" was criticized by French higher-education minister Frédérique Vidal, who said the disturbances had been \"highly regrettable\" and \"anti-Semitic\", and that the disturbances organized by \"Gazeta Polska\" activists appeared to have been condoned by the \"IPN\", whose representative did not condemn the disruption and which criticized the conference in social-media remarks that were re-tweeted by the Polish Embassy in Paris.\n\nIn September 2017, a historian in charge of education in Lublin for the IPN, wrote in a column in \"Gazeta Polska\" that \"after the aggression of Germany into Poland, the situation of the Jews did not look very bad\" and \"although the [Nazi] occupation authorities took over, they ordered the wearing of armbands with the star of David, charged them heavy taxes, began to designate Jews-only zones only for the Jews, but at the same time permitted the creation of Judenrat, that is, organs of self-government.\" In 2014, the same historian said in an expert opinion to a Polish court that the Nazi party was a leftist party and that the swastika is an ambiguous symbol. These statements were widely criticized by other historians including Dariusz Libionka, and the IPN issued a statement saying that the \"In connection with the thesis in the article by Tomasz Panfil in the Gazeta Polska, the Institute of National Remembrance declares that position presented there is in no way compatible with the historical knowledge about the situation of the Jewish population in Poland after September 1, 1939.\" and that it expects the historian \"will, in his scientific and journalistic activities, show diligence and respect to the principles of historical and research reliability.\" In October 2017, education minister Anna Zalewska presented the historian with a medal for \"special merits for education\".\n\nIn October 2017, the Simon Wiesenthal Center urged the IPN to fire the deputy director of its publishing office because he had published several books by Holocaust denier David Irving. The IPN responded that the official \"is not a Holocaust denier himself so there is no reason to dismiss him\".\n\nBULLET::::- Laws against Holocaust denial\n\nBULLET::::- IPN Home Page (English)\nBULLET::::- old Act of 18 December 1998 on the Institute of National Remembrance – Commission for Prosecution of Crimes against the Polish Nation (\"Ustawa z dnia 18 grudnia 1998 r. o Instytucie Pamięci Narodowej – Komisji Ścigania Zbrodni przeciwko Narodowi Polskiemu\")\nBULLET::::- old Act of 18 December 1998 on the Institute of National Remembrance – Commission for Prosecution of Crimes against the Polish Nation\n"}
{"id": "15347", "url": "https://en.wikipedia.org/wiki?curid=15347", "title": "Intelligence (disambiguation)", "text": "Intelligence (disambiguation)\n\nIntelligence is one or more capacities of the mind.\n\nIntelligence may also refer to:\n\nBULLET::::- Intelligence, information, in any useful form\nBULLET::::- Business intelligence, data transformed into meaningful and useful information for business analysis purposes\nBULLET::::- Espionage, or intelligence, the clandestine acquisition of confidential information\nBULLET::::- Intelligence assessment, the evaluation of sensitive commercial, military, scientific, or state information\nBULLET::::- Intelligence cycle, the stages of intelligence information processing\nBULLET::::- Military intelligence, the gathering and assessment of policy, strategic, and tactical, information\nBULLET::::- Strategic intelligence (STRATINT), the collection, processing, analysis, and dissemination of intelligence that is required for forming policy and military plans at the national and international level\nBULLET::::- Police intelligence, the gathering of information about crime in order to track and predict it with a view to curbing it\n\nBULLET::::- \"Intelligence\", a song by ...And You Will Know Us by the Trail of Dead from their EP \"The Secret of Elena's Tomb\" (2003)\nBULLET::::- The Intelligence, a noise rock band from Seattle with releases on In the Red Records\n\nBULLET::::- \"Intelligence\" (journal), a scientific journal dealing with intelligence and psychometrics\nBULLET::::- \"Intelligence\" (newspaper), an Australian newspaper\n\nBULLET::::- \"Intelligence\" (Canadian TV series), a Canadian television show that ran 2006–2007 on CBC Television\nBULLET::::- \"Intelligence\" (U.S. TV series), a 2014 American cyber-themed action/adventure television series\n\nBULLET::::- Intelligence (solitaire), a card game\nBULLET::::- \"Nous\" (intelligence), in classical and medieval philosophy, cosmology, and theology\n\nBULLET::::- Artificial intelligence (disambiguation)\nBULLET::::- Emotional intelligence,\nBULLET::::- Intellect (disambiguation)\nBULLET::::- Multiple intelligence\nBULLET::::- Signals intelligence\nBULLET::::- Social intelligence\n"}
{"id": "15352", "url": "https://en.wikipedia.org/wiki?curid=15352", "title": "Identical particles", "text": "Identical particles\n\nIdentical particles, also called indistinguishable or indiscernible particles, are particles that cannot be distinguished from one another, even in principle. Species of identical particles include, but are not limited to elementary particles such as electrons, composite subatomic particles such as atomic nuclei, as well as atoms and molecules. Quasiparticles also behave in this way. Although all known indistinguishable particles are \"tiny\", there is no exhaustive list of all possible sorts of particles nor a clear-cut limit of applicability, as explored in quantum statistics.\n\nThere are two main categories of identical particles: bosons, which can share quantum states, and fermions, which do not share quantum states as described by the Pauli exclusion principle. Examples of bosons are photons, gluons, phonons, helium-4 nuclei and all mesons. Examples of fermions are electrons, neutrinos, quarks, protons, neutrons, and helium-3 nuclei.\n\nThe fact that particles can be identical has important consequences in statistical mechanics. Calculations in statistical mechanics rely on probabilistic arguments, which are sensitive to whether or not the objects being studied are identical. As a result, identical particles exhibit markedly different statistical behaviour from distinguishable particles. For example, the indistinguishability of particles has been proposed as a solution to Gibbs' mixing paradox.\n\nThere are two methods for distinguishing between particles. The first method relies on differences in the intrinsic physical properties of the particles, such as mass, electric charge, and spin. If differences exist, it is possible to distinguish between the particles by measuring the relevant properties. However, it is an empirical fact that microscopic particles of the same species have completely equivalent physical properties. For instance, every electron in the universe has exactly the same electric charge; this is why it is possible to speak of such a thing as \"the charge of the electron\".\n\nEven if the particles have equivalent physical properties, there remains a second method for distinguishing between particles, which is to track the trajectory of each particle. As long as the position of each particle can be measured with infinite precision (even when the particles collide), then there would be no ambiguity about which particle is which.\n\nThe problem with the second approach is that it contradicts the principles of quantum mechanics. According to quantum theory, the particles do not possess definite positions during the periods between measurements. Instead, they are governed by wavefunctions that give the probability of finding a particle at each position. As time passes, the wavefunctions tend to spread out and overlap. Once this happens, it becomes impossible to determine, in a subsequent measurement, which of the particle positions correspond to those measured earlier. The particles are then said to be indistinguishable.\n\nWhat follows is an example to make the above discussion concrete, using the formalism developed in the article on the mathematical formulation of quantum mechanics.\n\nLet \"n\" denote a complete set of (discrete) quantum numbers for specifying single-particle states (for example, for the particle in a box problem, take \"n\" to be the quantized wave vector of the wavefunction.) For simplicity, consider a system composed of two particles that are not interacting with each other. Suppose that one particle is in the state \"n\", and the other is in the state \"n\". Intuitively, the quantum state of the system is written as\n\nwhere the state writing order matters such as the firstly written state is for the particle 1 and the secondly written state is for the particle 2 (so, if formula_2, then the particle 1 occupies the state \"n\" while the particle 2 occupies the state \"n\"). This is simply the canonical way of constructing a basis for a tensor product space formula_3 of the combined system from the individual spaces. This expression is valid for distinguishable particles, however, it is not appropriate for indistinguishable particles since formula_4 and formula_5 as a result of exchanging the particles are generally different states.\n\nBULLET::::- \"the particle 1 occupies the \"n\" state and the particle 2 occupies the \"n\" state\" ≠ \"the particle 1 occupies the \"n\" state and the particle 2 occupies the \"n\" state\".\n\nTwo states are physically equivalent only if they differ by a complex phase factor. For two indistinguishable particles, a state before the particle exchange must be physically equivalent to the state after the exchange, so these two state differ only by a complex phase factor. This fact suggests that a state for two indistinguishable (and non-interacting) particles is given by following two possibilities: \n\nStates where it is a sum are known as symmetric, while states involving the difference are called antisymmetric. More completely, symmetric states have the form\n\nwhile antisymmetric states have the form\n\nNote that if \"n\" and \"n\" are the same, the antisymmetric expression gives zero, which cannot be a state vector since it cannot be normalized. In other words, more than one identical particle cannot occupy an antisymmetric state (one antisymmetric state can be occupied only by one particle). This is known as the Pauli exclusion principle, and it is the fundamental reason behind the chemical properties of atoms and the stability of matter.\n\nThe importance of symmetric and antisymmetric states is ultimately based on empirical evidence. It appears to be a fact of nature that identical particles do not occupy states of a mixed symmetry, such as\n\nThere is actually an exception to this rule, which will be discussed later. On the other hand, it can be shown that the symmetric and antisymmetric states are in a sense special, by examining a particular symmetry of the multiple-particle states known as exchange symmetry.\n\nDefine a linear operator \"P\", called the exchange operator. When it acts on a tensor product of two state vectors, it exchanges the values of the state vectors:\n\n\"P\" is both Hermitian and unitary. Because it is unitary, it can be regarded as a symmetry operator. This symmetry may be described as the symmetry under the exchange of labels attached to the particles (i.e., to the single-particle Hilbert spaces).\n\nClearly, formula_11 (the identity operator), so the eigenvalues of \"P\" are +1 and −1. The corresponding eigenvectors are the symmetric and antisymmetric states:\n\nIn other words, symmetric and antisymmetric states are essentially unchanged under the exchange of particle labels: they are only multiplied by a factor of +1 or −1, rather than being \"rotated\" somewhere else in the Hilbert space. This indicates that the particle labels have no physical meaning, in agreement with the earlier discussion on indistinguishability.\n\nIt will be recalled that \"P\" is Hermitian. As a result, it can be regarded as an observable of the system, which means that, in principle, a measurement can be performed to find out if a state is symmetric or antisymmetric. Furthermore, the equivalence of the particles indicates that the Hamiltonian can be written in a symmetrical form, such as\n\nIt is possible to show that such Hamiltonians satisfy the commutation relation\n\nAccording to the Heisenberg equation, this means that the value of \"P\" is a constant of motion. If the quantum state is initially symmetric (antisymmetric), it will remain symmetric (antisymmetric) as the system evolves. Mathematically, this says that the state vector is confined to one of the two eigenspaces of \"P\", and is not allowed to range over the entire Hilbert space. Thus, that eigenspace might as well be treated as the actual Hilbert space of the system. This is the idea behind the definition of Fock space.\n\nThe choice of symmetry or antisymmetry is determined by the species of particle. For example, symmetric states must always be used when describing photons or helium-4 atoms, and antisymmetric states when describing electrons or protons.\n\nParticles which exhibit symmetric states are called bosons. The nature of symmetric states has important consequences for the statistical properties of systems composed of many identical bosons. These statistical properties are described as Bose–Einstein statistics.\n\nParticles which exhibit antisymmetric states are called fermions. Antisymmetry gives rise to the Pauli exclusion principle, which forbids identical fermions from sharing the same quantum state. Systems of many identical fermions are described by Fermi–Dirac statistics.\n\nParastatistics are also possible.\n\nIn certain two-dimensional systems, mixed symmetry can occur. These exotic particles are known as anyons, and they obey fractional statistics. Experimental evidence for the existence of anyons exists in the fractional quantum Hall effect, a phenomenon observed in the two-dimensional electron gases that form the inversion layer of MOSFETs. There is another type of statistic, known as braid statistics, which are associated with particles known as plektons.\n\nThe spin-statistics theorem relates the exchange symmetry of identical particles to their spin. It states that bosons have integer spin, and fermions have half-integer spin. Anyons possess fractional spin.\n\nThe above discussion generalizes readily to the case of \"N\" particles. Suppose there are \"N\" particles with quantum numbers \"n\", \"n\", ..., n. If the particles are bosons, they occupy a totally symmetric state, which is symmetric under the exchange of \"any two\" particle labels:\n\nHere, the sum is taken over all different states under permutations \"p\" acting on \"N\" elements. The square root left to the sum is a normalizing constant. The quantity \"m\" stands for the number of times each of the single-particle states \"n\" appears in the \"N\"-particle state. Note that \"∑ m = N\".\n\nIn the same vein, fermions occupy totally antisymmetric states:\n\nHere, is the sign of each permutation (i.e.formula_18 if formula_19 is composed of an even number of transpositions, and formula_20 if odd). Note that there is no formula_21 term, because each single-particle state can appear only once in a fermionic state. Otherwise the sum would again be zero due to the antisymmetry, thus representing a physically impossible state. This is the Pauli exclusion principle for many particles.\n\nThese states have been normalized so that\n\nSuppose there is a system of \"N\" bosons (fermions) in the symmetric (antisymmetric) state\n\nand a measurement is performed on some other set of discrete observables, \"m\". In general, this yields some result \"m\" for one particle, \"m\" for another particle, and so forth. If the particles are bosons (fermions), the state after the measurement must remain symmetric (antisymmetric), i.e.\n\nThe probability of obtaining a particular result for the \"m\" measurement is\n\nIt can be shown that \n\nwhich verifies that the total probability is 1. The sum has to be restricted to \"ordered\" values of \"m\", ..., \"m\" to ensure that each multi-particle state is not counted more than once.\n\nSo far, the discussion has included only discrete observables. It can be extended to continuous observables, such as the position \"x\".\n\nRecall that an eigenstate of a continuous observable represents an infinitesimal \"range\" of values of the observable, not a single value as with discrete observables. For instance, if a particle is in a state \"ψ\"⟩, the probability of finding it in a region of volume \"d\"\"x\" surrounding some position \"x\" is\n\nAs a result, the continuous eigenstates \"x\"⟩ are normalized to the delta function instead of unity:\n\nSymmetric and antisymmetric multi-particle states can be constructed from continuous eigenstates in the same way as before. However, it is customary to use a different normalizing constant:\n\nA many-body wavefunction can be written,\n\nwhere the single-particle wavefunctions are defined, as usual, by\n\nThe most important property of these wavefunctions is that exchanging any two of the coordinate variables changes the wavefunction by only a plus or minus sign. This is the manifestation of symmetry and antisymmetry in the wavefunction representation:\n\nThe many-body wavefunction has the following significance: if the system is initially in a state with quantum numbers \"n\", ..., n, and a position measurement is performed, the probability of finding particles in infinitesimal volumes near \"x\", \"x\", ..., \"x\" is\n\nThe factor of \"N\"! comes from our normalizing constant, which has been chosen so that, by analogy with single-particle wavefunctions,\n\nBecause each integral runs over all possible values of \"x\", each multi-particle state appears \"N\"! times in the integral. In other words, the probability associated with each event is evenly distributed across \"N\"! equivalent points in the integral space. Because it is usually more convenient to work with unrestricted integrals than restricted ones, the normalizing constant has been chosen to reflect this.\n\nFinally, antisymmetric wavefunction can be written as the determinant of a matrix, known as a Slater determinant:\n\nThe Hilbert space for formula_39 particles is given by the tensor product formula_40. The permutation group of formula_41 acts on this space by permuting the entries. By definition the expectation values for an observable formula_42 of formula_39 indistinguishable particles should be invariant under these permutation. This means that for all formula_44 and formula_45\nor equivalently for each formula_45\nTwo states are equivalent whenever their expectation values coincide for all observables. If we restrict to observables of formula_49 identical particles, and hence observables satisfying the equation above, we find that the following states (after normalization) are equivalent\nThe equivalence classes are in bijective relation with irreducible subspaces of formula_40 under formula_41.\n\nTwo obvious irreducible subspaces are the one dimensional symmetric/bosonic subspace and anti-symmetric/fermionic subspace. There are however more types of irreducible subspaces. States associated with these other irreducible subspaces are called parastatistic states. Young tableaux provide a way to classify all of these irreducible subspaces.\n\nThe indistinguishability of particles has a profound effect on their statistical properties. To illustrate this, consider a system of \"N\" distinguishable, non-interacting particles. Once again, let \"n\" denote the state (i.e. quantum numbers) of particle \"j\". If the particles have the same physical properties, the \"n\"'s run over the same range of values. Let \"ε\"(\"n\") denote the energy of a particle in state \"n\". As the particles do not interact, the total energy of the system is the sum of the single-particle energies. The partition function of the system is\n\nwhere \"k\" is Boltzmann's constant and \"T\" is the temperature. This expression can be factored to obtain\n\nwhere\n\nIf the particles are identical, this equation is incorrect. Consider a state of the system, described by the single particle states [\"n\", ..., \"n\"]. In the equation for \"Z\", every possible permutation of the \"n\"'s occurs once in the sum, even though each of these permutations is describing the same multi-particle state. Thus, the number of states has been over-counted.\n\nIf the possibility of overlapping states is neglected, which is valid if the temperature is high, then the number of times each state is counted is approximately \"N\"<nowiki>!</nowiki>. The correct partition function is\n\nNote that this \"high temperature\" approximation does not distinguish between fermions and bosons.\n\nThe discrepancy in the partition functions of distinguishable and indistinguishable particles was known as far back as the 19th century, before the advent of quantum mechanics. It leads to a difficulty known as the Gibbs paradox. Gibbs showed that in the equation \"Z\" = \"ξ\", the entropy of a classical ideal gas is\n\nwhere \"V\" is the volume of the gas and \"f\" is some function of \"T\" alone. The problem with this result is that \"S\" is not extensive – if \"N\" and \"V\" are doubled, \"S\" does not double accordingly. Such a system does not obey the postulates of thermodynamics.\n\nGibbs also showed that using \"Z\" = \"ξ\"/\"N\"! alters the result to\n\nwhich is perfectly extensive. However, the reason for this correction to the partition function remained obscure until the discovery of quantum mechanics.\n\nThere are important differences between the statistical behavior of bosons and fermions, which are described by Bose–Einstein statistics and Fermi–Dirac statistics respectively. Roughly speaking, bosons have a tendency to clump into the same quantum state, which underlies phenomena such as the laser, Bose–Einstein condensation, and superfluidity. Fermions, on the other hand, are forbidden from sharing quantum states, giving rise to systems such as the Fermi gas. This is known as the Pauli Exclusion Principle, and is responsible for much of chemistry, since the electrons in an atom (fermions) successively fill the many states within shells rather than all lying in the same lowest energy state.\n\nThe differences between the statistical behavior of fermions, bosons, and distinguishable particles can be illustrated using a system of two particles. The particles are designated A and B. Each particle can exist in two possible states, labelled formula_59 and formula_60, which have the same energy.\n\nThe composite system can evolve in time, interacting with a noisy environment. Because the formula_59 and formula_60 states are energetically equivalent, neither state is favored, so this process has the effect of randomizing the states. (This is discussed in the article on quantum entanglement.) After some time, the composite system will have an equal probability of occupying each of the states available to it. The particle states are then measured.\n\nIf A and B are distinguishable particles, then the composite system has four distinct states: formula_63, formula_64, formula_65, and formula_66. The probability of obtaining two particles in the formula_59 state is 0.25; the probability of obtaining two particles in the formula_60 state is 0.25; and the probability of obtaining one particle in the formula_59 state and the other in the formula_60 state is 0.5.\n\nIf A and B are identical bosons, then the composite system has only three distinct states: formula_63, formula_64, and formula_73. When the experiment is performed, the probability of obtaining two particles in the formula_59 state is now 0.33; the probability of obtaining two particles in the formula_60 state is 0.33; and the probability of obtaining one particle in the formula_59 state and the other in the formula_60 state is 0.33. Note that the probability of finding particles in the same state is relatively larger than in the distinguishable case. This demonstrates the tendency of bosons to \"clump.\"\n\nIf A and B are identical fermions, there is only one state available to the composite system: the totally antisymmetric state formula_78. When the experiment is performed, one particle is always in the formula_59 state and the other is in the formula_60 state.\n\nThe results are summarized in Table 1:\n\n+ Table 1: Statistics of two particles\n! Particles!!Both 0!!Both 1!!One 0 and one 1\n\nAs can be seen, even a system of two particles exhibits different statistical behaviors between distinguishable particles, bosons, and fermions. In the articles on Fermi–Dirac statistics and Bose–Einstein statistics, these principles are extended to large number of particles, with qualitatively similar results.\n\nTo understand why particle statistics work the way that they do, note first that particles are point-localized excitations and that particles that are spacelike separated do not interact. In a flat \"d\"-dimensional space \"M\", at any given time, the configuration of two identical particles can be specified as an element of \"M\" × \"M\". If there is no overlap between the particles, so that they do not interact directly, then their locations must belong to the space the subspace with coincident points removed. The element describes the configuration with particle I at x and particle II at y, while describes the interchanged configuration. With identical particles, the state described by ought to be indistinguishable from the state described by . Now consider the homotopy class of continuous paths from to , within the space . If \"M\" is R where , then this homotopy class only has one element. If \"M\" is R, then this homotopy class has countably many elements (i.e. a counterclockwise interchange by half a turn, a counterclockwise interchange by one and a half turns, two and a half turns, etc., a clockwise interchange by half a turn, etc.). In particular, a counterclockwise interchange by half a turn is \"not\" homotopic to a clockwise interchange by half a turn. Lastly, if \"M\" is R, then this homotopy class is empty.\n\nSuppose first that . The universal covering space of which is none other than itself, only has two points which are physically indistinguishable from , namely itself and . So, the only permissible interchange is to swap both particles. This interchange is an involution, so its only effect is to multiply the phase by a square root of 1. If the root is +1, then the points have Bose statistics, and if the root is −1, the points have Fermi statistics.\n\nIn the case \"M\" = R, the universal covering space of has infinitely many points that are physically indistinguishable from . This is described by the infinite cyclic group generated by making a counterclockwise half-turn interchange. Unlike the previous case, performing this interchange twice in a row does not recover the original state; so such an interchange can generically result in a multiplication by exp(\"iθ\") for any real \"θ\" (by unitarity, the absolute value of the multiplication must be 1). This is called anyonic statistics. In fact, even with two \"distinguishable\" particles, even though is now physically distinguishable from , the universal covering space still contains infinitely many points which are physically indistinguishable from the original point, now generated by a counterclockwise rotation by one full turn. This generator, then, results in a multiplication by exp(\"iφ\"). This phase factor here is called the mutual statistics.\n\nFinally, in the case \"M\" = R, the space is not connected, so even if particle I and particle II are identical, they can still be distinguished via labels such as \"the particle on the left\" and \"the particle on the right\". There is no interchange symmetry here.\n\nBULLET::::- Quasi-set theory\nBULLET::::- DeBroglie hypothesis\n\nBULLET::::- Exchange of Identical and Possibly Indistinguishable Particles by John S. Denker\nBULLET::::- Identity and Individuality in Quantum Theory (Stanford Encyclopedia of Philosophy)\nBULLET::::- Many-Electron States in E. Pavarini, E. Koch, and U. Schollwöck: Emergent Phenomena in Correlated Matter, Jülich 2013,\n"}
{"id": "15354", "url": "https://en.wikipedia.org/wiki?curid=15354", "title": "Interstitial cystitis", "text": "Interstitial cystitis\n\nInterstitial cystitis (IC), also known as bladder pain syndrome (BPS), is a type of chronic pain that affects the bladder. Symptoms include feeling the need to urinate right away, needing to urinate often, and pain with sex. IC/BPS is associated with depression and lower quality of life. Many of those affected also have irritable bowel syndrome and fibromyalgia.\nThe cause of IC/BPS is unknown. While it can, it does not typically run in a family. The diagnosis is usually based on the symptoms after ruling out other conditions. Typically the urine culture is negative. Ulceration or inflammation may be seen on cystoscopy. Other conditions which can produce similar symptoms include urinary tract infection (UTI), overactive bladder, sexually transmitted infections, endometriosis, bladder cancer, and prostatitis.\nThere is no cure for interstitial cystitis. Treatments that may improve symptoms include lifestyle changes, medications, or procedures. Lifestyle changes may include stopping smoking and reducing stress. Medications may include ibuprofen, pentosan polysulfate, or amitriptyline. Procedures may include bladder distention, nerve stimulation, or surgery. Pelvic floor exercises and long term antibiotics are not recommended.\nIn the United States and Europe, it is estimated that around 0.5% of people are affected. Women are affected about five times as often as men. Onset is typically in middle age. The term \"interstitial cystitis\" first came into use in 1887.\n\nThe most common symptoms of IC/BPS are suprapubic pain, urinary frequency, painful sexual intercourse, and waking up from sleep to urinate.\n\nIn general, symptoms may include painful urination described as a burning sensation in the urethra during urination, pelvic pain that is worsened with the consumption of certain foods or drinks, urinary urgency, and pressure in the bladder or pelvis. Other frequently described symptoms are urinary hesitancy (needing to wait for the urinary stream to begin, often caused by pelvic floor dysfunction and tension), and discomfort and difficulty driving, working, exercising, or traveling. Pelvic pain experienced by those with IC typically worsens with filling of the urinary bladder and may improve with urination.\n\nDuring cystoscopy, 5–10% of people with IC are found to have Hunner's ulcers. A person with IC may have discomfort only in the urethra, while another might struggle with pain in the entire pelvis. Interstitial cystitis symptoms usually fall into one of two patterns: significant suprapubic pain with little frequency or a lesser amount of suprapubic pain but with increased urinary frequency.\n\nSome people with IC/BPS have been diagnosed with other conditions such as irritable bowel syndrome (IBS), fibromyalgia, chronic fatigue syndrome, allergies, Sjögren syndrome, which raises the possibility that interstitial cystitis may be caused by mechanisms that cause these other conditions. There is also some evidence of an association between urologic pain syndromes, such as IC/BPS and CP/CPPS, with non-celiac gluten sensitivity in some people.\n\nIn addition, men with IC/PBS are frequently diagnosed as having chronic nonbacterial prostatitis, and there is an extensive overlap of symptoms and treatment between the two conditions, leading researchers to posit that the conditions may share the same cause and pathology.\n\nThe cause of IC/BPS is currently unknown. However, several explanations have been proposed and include the following: autoimmune theory, nerve theory, mast cell theory, leaky lining theory, infection theory, and a theory of production of a toxic substance in the urine. Other suggested etiological causes are neurologic, allergic, genetic, and stress-psychological. In addition, recent research shows that those with IC may have a substance in the urine that inhibits the growth of cells in the bladder epithelium. An infection may then predispose those people to develop IC. Current evidence from clinical and laboratory studies confirms that mast cells play a central role in IC/BPS possibly due to their ability to release histamine and cause pain, swelling, scarring, and interfere with healing. Research has shown a proliferation of nerve fibers is present in the bladders of people with IC which is absent in the bladders of people who have not been diagnosed with IC.\n\nRegardless of the origin, most people with IC/BPS struggle with a damaged urothelium, or bladder lining. When the surface glycosaminoglycan (GAG) layer is damaged (via a urinary tract infection (UTI), excessive consumption of coffee or sodas, traumatic injury, etc.), urinary chemicals can \"leak\" into surrounding tissues, causing pain, inflammation, and urinary symptoms. Oral medications like pentosan polysulfate and medications placed directly into the bladder via a catheter sometimes work to repair and rebuild this damaged/wounded lining, allowing for a reduction in symptoms. Most literature supports the belief that IC's symptoms are associated with a defect in the bladder epithelium lining, allowing irritating substances in the urine to penetrate into the bladder—essentially, a breakdown of the bladder lining (also known as the adherence theory). Deficiency in this glycosaminoglycan layer on the surface of the bladder results in increased permeability of the underlying submucosal tissues.\n\nGP51 has been identified as a possible urinary biomarker for IC with significant variations in GP51 levels in those with IC when compared to individuals without interstitial cystitis.\n\nNumerous studies have noted the link between IC, anxiety, stress, hyper-responsiveness, and panic. Another proposed cause for interstitial cystitis is that the body's immune system attacks the bladder. Biopsies on the bladder walls of people with IC usually contain mast cells. Mast cells containing histamine packets gather when an allergic reaction is occurring. The body identifies the bladder wall as a foreign agent, and the histamine packets burst open and attack. The body attacks itself, which is the basis of autoimmune disorders. Additionally, IC may be triggered by an unknown toxin or stimulus which causes nerves in the bladder wall to fire uncontrollably. When they fire, they release substances called neuropeptides that induce a cascade of reactions that cause pain in the bladder wall.\n\nSome genetic subtypes, in some people, have been linked to the disorder.\nBULLET::::- An antiproliferative factor is secreted by the bladders of people with IC/BPS which inhibits bladder cell proliferation, thus possibly causing the missing bladder lining.\nBULLET::::- PAND, at gene map locus 13q22–q32, is associated with a constellation of disorders (a \"pleiotropic syndrome\") including IC/BPS and other bladder and kidney problems, thyroid diseases, serious headaches/migraines, panic disorder, and mitral valve prolapse.\n\nA diagnosis of IC/BPS is one of exclusion, as well as a review of clinical symptoms. The AUA Guidelines recommend starting with a careful history of the person, physical examination and laboratory tests to assess and document symptoms of IC, as well as other potential disorders.\n\nThe KCl test, also known as the \"potassium sensitivity test\", is no longer recommended. The test uses a mild potassium solution to evaluate the integrity of the bladder wall. Though the latter is not specific for IC/BPS, it has been determined to be helpful in predicting the use of compounds, such as pentosan polysulphate, which are designed to help repair the GAG layer.\n\nFor complicated cases, the use of hydrodistention with cystoscopy may be helpful. Researchers, however, determined that this visual examination of the bladder wall after stretching the bladder was not specific for IC/BPS and that the test, itself, can contribute to the development of small glomerulations (petechial hemorrhages) often found in IC/BPS. Thus, a diagnosis of IC/BPS is one of exclusion, as well as a review of clinical symptoms.\n\nIn 2006, the ESSIC society proposed more rigorous and demanding diagnostic methods with specific classification criteria so that it cannot be confused with other, similar conditions. Specifically, they require that a person must have pain associated with the bladder, accompanied by one other urinary symptom. Thus, a person with just frequency or urgency would be excluded from a diagnosis. Secondly, they strongly encourage the exclusion of confusable diseases through an extensive and expensive series of tests including (A) a medical history and physical exam, (B) a dipstick urinalysis, various urine cultures, and a serum PSA in men over 40, (C) flowmetry and post-void residual urine volume by ultrasound scanning and (D) cystoscopy. A diagnosis of IC/BPS would be confirmed with a hydrodistention during cystoscopy with biopsy.\n\nThey also propose a ranking system based upon the physical findings in the bladder. People would receive a numeric and letter based score based upon the severity of their disease as found during the hydrodistention. A score of 1–3 would relate to the severity of the disease and a rating of A–C represents biopsy findings. Thus, a person with 1A would have very mild symptoms and disease while a person with 3C would have the worst possible symptoms. Widely recognized scoring systems such as the O'Leary Sant symptom and problem score have emerged to evaluate the severity of IC symptoms such as pain and urinary symptoms.\n\nThe symptoms of IC/BPS are often misdiagnosed as a urinary tract infection. However, IC/BPS has not been shown to be caused by a bacterial infection and antibiotics are an ineffective treatment. IC/BPS is commonly misdiagnosed as chronic prostatitis/chronic pelvic pain syndrome (CP/CPPS) in men, and endometriosis and uterine fibroids (in women).\n\nIn 2011, the American Urological Association released consensus-based guideline for the diagnosis and treatment of IC.\n\nThey include treatments ranging from conservative to more invasive: \nBULLET::::1. First-line treatments — education, self care (diet modification), stress management\nBULLET::::2. Second-line treatments — physical therapy, oral medications (amitriptyline, cimetidine or hydroxyzine, pentosan polysulfate), bladder instillations (DMSO, heparin, or lidocaine)\nBULLET::::3. Third-line treatments — treatment of Hunner's ulcers (laser, fulguration or triamcinolone injection), hydrodistention (low pressure, short duration)\nBULLET::::4. Fourth-line treatments — neuromodulation (sacral or pudendal nerve)\nBULLET::::5. Fifth-line treatments — cyclosporine A, botulinum toxin (BTX-A)\nBULLET::::6. Sixth-line treatments — surgical intervention (urinary diversion, augmentation, cystectomy)\n\nThe AUA guidelines also listed several discontinued treatments, including long-term oral antibiotics, intravesical bacillus Calmette Guerin, intravesical resiniferatoxin), high-pressure and long-duration hydrodistention, and systemic glucocorticoids.\n\nBladder distension while under general anesthesia, also known as hydrodistention (a procedure which stretches the bladder capacity), has shown some success in reducing urinary frequency and giving short-term pain relief to those with IC. However, it is unknown exactly how this procedure causes pain relief. Recent studies show pressure on pelvic trigger points can relieve symptoms. The relief achieved by bladder distensions is only temporary (weeks or months), so is not viable as a long-term treatment for IC/BPS. The proportion of people with IC/BPS who experience relief from hydrodistention is currently unknown and evidence for this modality is limited by a lack of properly controlled studies. Bladder rupture and sepsis may be associated with prolonged, high-pressure hydrodistention.\n\nBladder instillation of medication is one of the main forms of treatment of interstitial cystitis, but evidence for its effectiveness is currently limited. Advantages of this treatment approach include direct contact of the medication with the bladder and low systemic side effects due to poor absorption of the medication. Single medications or a mixture of medications are commonly used in bladder instillation preparations. DMSO is the only approved bladder instillation for IC/BPS yet it is much less frequently used in urology clinics.\n\nA 50% solution of DMSO had the potential to create irreversible muscle contraction. However, a lesser solution of 25% was found to be reversible. Long-term use of DMSO is questionable, as its mechanism of action is not fully understood though DMSO is thought to inhibit mast cells and may have anti-inflammatory, muscle-relaxing, and analgesic effects. Other agents used for bladder instillations to treat interstitial cystitis include: heparin, lidocaine, chondroitin sulfate, hyaluronic acid, pentosan polysulfate, oxybutynin, and botulinum toxin A. Preliminary evidence suggests these agents are efficacious in reducing symptoms of interstitial cystitis, but further study with larger, randomized, controlled clinical trials is needed.\n\nDiet modification is often recommended as a first-line method of self-treatment for interstitial cystitis, though rigorous controlled studies examining the impact diet has on interstitial cystitis signs and symptoms are currently lacking. Individuals with interstitial cystitis often experience an increase in symptoms when they consume certain foods and beverages. Avoidance of these potential trigger foods and beverages such as caffeine-containing beverages including coffee, tea, and soda, alcoholic beverages, chocolate, citrus fruits, hot peppers, and artificial sweeteners may be helpful in alleviating symptoms. Diet triggers vary between individuals with IC; the best way for a person to discover his or her own triggers is to use an elimination diet. Sensitivity to trigger foods may be reduced if calcium glycerophosphate and/or sodium bicarbonate is consumed. The foundation of therapy is a modification of diet to help people avoid those foods which can further irritate the damaged bladder wall.\n\nThe mechanism by which dietary modification benefits people with IC is unclear. Integration of neural signals from pelvic organs may mediate the effects of diet on symptoms of IC.\n\nThe antihistamine hydroxyzine failed to demonstrate superiority over placebo in treatment of people with IC in a randomized, controlled, clinical trial. \nAmitriptyline has been shown to be effective in reducing symptoms such as chronic pelvic pain and nocturia in many people with IC/BPS with a median dose of 75 mg daily. In one study, the antidepressant duloxetine was found to be ineffective as a treatment, although a patent exists for use of duloxetine in the context of IC, and is known to relieve neuropathic pain. The calcineurin inhibitor cyclosporine A has been studied as a treatment for interstitial cystitis due to its immunosuppressive properties. A prospective randomized study found cyclosporine A to be more effective at treating IC symptoms than pentosan polysulfate, but also had more adverse effects.\n\nOral pentosan polysulfate is believed to repair the protective glycosaminoglycan coating of the bladder, but studies have encountered mixed results when attempting to determine if the effect is statistically significant compared to placebo.\n\nUrologic pelvic pain syndromes, such as IC/BPS and CP/CPPS, are characterized by pelvic muscle tenderness, and symptoms may be reduced with pelvic myofascial physical therapy.\n\nThis may leave the pelvic area in a sensitized condition, resulting in a loop of muscle tension and heightened neurological feedback (neural wind-up), a form of myofascial pain syndrome. Current protocols, such as the Wise–Anderson Protocol, largely focus on stretches to release overtensed muscles in the pelvic or anal area (commonly referred to as trigger points), physical therapy to the area, and progressive relaxation therapy to reduce causative stress.\n\nPelvic floor dysfunction is a fairly new area of specialty for physical therapists worldwide. The goal of therapy is to relax and lengthen the pelvic floor muscles, rather than to tighten and/or strengthen them as is the goal of therapy for people with urinary incontinence. Thus, traditional exercises such as Kegel exercises, which are used to strengthen pelvic muscles, can provoke pain and additional muscle tension. A specially trained physical therapist can provide direct, hands on evaluation of the muscles, both externally and internally.\n\nSurgery is rarely used for IC/BPS. Surgical intervention is very unpredictable, and is considered a treatment of last resort for severe refractory cases of interstitial cystitis. Some people who opt for surgical intervention continue to experience pain after surgery. Typical surgical interventions for refractory cases of IC/BPS include: bladder augmentation, urinary diversion, transurethral fulguration and resection of ulcers, and bladder removal (cystectomy).\n\nNeuromodulation can be successful in treating IC/BPS symptoms, including pain. One electronic pain-killing option is TENS. Percutaneous tibial nerve stimulation stimulators have also been used, with varying degrees of success. Percutaneous sacral nerve root stimulation was able to produce statistically significant improvements in several parameters, including pain.\n\nThere is little evidence looking at the effects of alternative medicine though their use is common. There is tentative evidence that acupuncture may help pain associated with IC/BPS as part of other treatments. Despite a scarcity of controlled studies on alternative medicine and IC/BPS, \"rather good results have been obtained\" when acupuncture is combined with other treatments.\n\nBiofeedback, a relaxation technique aimed at helping people control functions of the autonomic nervous system, has shown some benefit in controlling pain associated with IC/BPS as part of a multimodal approach that may also include medication or hydrodistention of the bladder.\n\nIC/BPS has a profound impact on quality of life. A 2007 Finnish epidemiologic study showed that two-thirds of women at moderate to high risk of having interstitial cystitis reported impairment in their quality of life and 35% of people with IC reported an impact on their sexual life. A 2012 survey showed that among a group of adult women with symptoms of interstitial cystitis, 11% reported suicidal thoughts in the past two weeks. Other research has shown that the impact of IC/BPS on quality of life is severe and may be comparable to the quality of life experienced in end-stage kidney disease or rheumatoid arthritis.\n\nInternational recognition of interstitial cystitis has grown and international urology conferences to address the heterogeneity in diagnostic criteria have recently been held. IC/PBS is now recognized with an official disability code in the United States of America.\n\nIC/BPS affects men and women of all cultures, socioeconomic backgrounds, and ages. Although the disease was previously believed to be a condition of menopausal women, growing numbers of men and women are being diagnosed in their twenties and younger. IC/BPS is not a rare condition. Early research suggested that the number of IC/BPS cases ranged from 1 in 100,000 to 5.1 in 1,000 of the general population. In recent years, the scientific community has achieved a much deeper understanding of the epidemiology of interstitial cystitis. Recent studies have revealed that between 2.7 and 6.53 million women in the USA have symptoms of IC and up to 12% of women may have early symptoms of IC/BPS. Further study has estimated that the condition is far more prevalent in men than previously thought ranging from 1.8 to 4.2 million men having symptoms of interstitial cystitis.\n\nThe condition is officially recognized as a disability in the United States.\n\nPhiladelphia surgeon Joseph Parrish published the earliest record of interstitial cystitis in 1836 describing three cases of severe lower urinary tract symptoms without the presence of a bladder stone. The term \"interstitial cystitis\" was coined by Dr. Alexander Skene in 1887 to describe the disease. In 2002, the United States amended the Social Security Act to include interstitial cystitis as a disability. The first guideline for diagnosis and treatment of interstitial cystitis is released by a Japanese research team in 2009. The American Urological Association released the first American clinical practice guideline for diagnosing and treating IC/BPS in 2011.\n\nOriginally called \"interstitial cystitis\", this disorder was renamed to \"interstitial cystitis/bladder pain syndrome\" (IC/BPS) in the 2002–2010 timeframe. In 2007, the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) began using the umbrella term urologic chronic pelvic pain syndrome (UCPPS) to refer to pelvic pain syndromes associated with the bladder (e.g., interstitial cystitis/bladder pain syndrome) and with the prostate gland or pelvis (e.g., chronic prostatitis/chronic pelvic pain syndrome).\n\nIn 2008, terms currently in use in addition to IC/BPS include \"painful bladder syndrome\", \"bladder pain syndrome\" and \"hypersensitive bladder syndrome\", alone and in a variety of combinations. These different terms are being used in different parts of the world. The term \"interstitial cystitis\" is the primary term used in ICD-10 and MeSH. Grover et al. said, \"The International Continence Society named the disease interstitial cystitis/painful bladder syndrome (IC/PBS) in 2002 [Abrams et al. 2002], while the Multinational Interstitial Cystitis Association have labeled it as painful bladder syndrome/interstitial cystitis (PBS/IC) [Hanno et al. 2005]. Recently, the European Society for the study of Interstitial Cystitis (ESSIC) proposed the moniker, ‘bladder pain syndrome’ (BPS) [van de Merwe et al. 2008].\"\n\nBULLET::::- Chronic prostatitis/chronic pelvic pain syndrome—women have vestigial prostate glands that may cause IC/BPS-like symptoms. Men with IC/BPS may have prostatitis, and vice versa.\nBULLET::::- Overactive bladder\nBULLET::::- Trigger point—a key to myofascial pain syndrome.\n\nBULLET::::- The National Kidney and Urologic Diseases Information Clearinghouse (NKUDIC)\nBULLET::::- European Urology\n"}
{"id": "15355", "url": "https://en.wikipedia.org/wiki?curid=15355", "title": "ICI", "text": "ICI\n\nICI or Ici may refer to:\n\nBULLET::::- \"Ici\" (magazine), an alternative French language weekly newspaper in Montreal, Canada, now defunct\nBULLET::::- Ici Radio-Canada, branding of Radio-Canada, the French language service of the Canadian Broadcasting Corporation beginning in 2013\nBULLET::::- ICI (TV channel), full name International Channel/Canal International, Montreal ethnic / multicultural television channel, a.k.a. CFHD-DT\n\nBULLET::::- ICI Australia, Imperial Chemical Industries subsidiary which became Australian company Orica\nBULLET::::- ICI Homes, homebuilder in Florida\nBULLET::::- Imperial Chemical Industries, former British chemicals company\nBULLET::::- Independent Curators International, a non-profit headquartered in New York City\nBULLET::::- Indian Concrete Institute\nBULLET::::- Indian Citation Index, an online bibliographic database containing abstracts and citations/references from academic journals\nBULLET::::- Industrie Cinematografiche Italiane, Italian film distribution company\nBULLET::::- Institute of Cultural Inquiry, Los Angeles-based non-profit which sponsors art projects\nBULLET::::- Investment Company Institute, an American investment company trade organization\nBULLET::::- Istanbul Cooperation Initiative, an initiative launched during NATO's 2004 Istanbul Summit\nBULLET::::- International Compact with Iraq, a 2007 joint initiative of Iraq and the United Nations\n\nBULLET::::- ICI programming language, a computer programming language developed in 1992\nBULLET::::- Inter Carrier Interface, a transport protocol (IANA port 2200) for use with SMDS\nBULLET::::- Interactive Compilation Interface, transforms production compilers into research toolsets\nBULLET::::- Intracervical Insemination\n"}
{"id": "15356", "url": "https://en.wikipedia.org/wiki?curid=15356", "title": "Imperial Chemical Industries", "text": "Imperial Chemical Industries\n\nImperial Chemical Industries (ICI) was a British chemical company and was, for much of its history, the largest manufacturer in Britain.\nIt was formed by the merger of leading British chemical companies in 1926.\nIts headquarters were at Millbank in London, and it was a constituent of the FT 30 and later the FTSE 100 indices.\n\nICI made paints and speciality products, including food ingredients, speciality polymers, electronic materials, fragrances and flavourings.\nIn 2008, it was acquired by AkzoNobel,\nwhich immediately sold parts of ICI to Henkel, and integrated ICI's remaining operations within its existing organisation.\n\nThe company was founded in December 1926 from the merger of four companies: Brunner Mond, Nobel Explosives, the United Alkali Company, and British Dyestuffs Corporation. It established its head office at Millbank in London in 1928.\nCompeting with DuPont and IG Farben, the new company produced chemicals, explosives, fertilisers, insecticides, dyestuffs, non-ferrous metals, and paints.\nIn its first year turnover was £27 million.\n\nIn the 1920s and 30s, the company played a key role in the development of new chemical products, including the dyestuff phthalocyanine (1929), the acrylic plastic Perspex (1932), Dulux paints (1932, co-developed with DuPont), polyethylene (1937), and polyethylene terephthalate fibre known as Terylene (1941).\nIn 1940, ICI started British Nylon Spinners as a joint venture with Courtaulds.\n\nICI also owned the Sunbeam motorcycle business, which had come with Nobel Industries, and continued to build motorcycles until 1937.\n\nDuring the Second World War, ICI was involved with the United Kingdom's nuclear weapons programme codenamed Tube Alloys.\n\nIn the 1940s and 50s, the company established its pharmaceutical business and developed a number of key products, including Paludrine (1940s, an anti-malarial drug), halothane (1951, an anaesthetic agent), Inderal (1965, a beta-blocker), tamoxifen (1978, a frequently used drug for breast cancer),\nand PEEK (1979, a high performance thermoplastic). ICI formed ICI Pharmaceuticals in 1957.\n\nICI developed a fabric in the 1950s known as Crimplene, a thick polyester yarn used to make a fabric of the same name.\nThe resulting cloth is heavy and wrinkle-resistant, and retains its shape well.\nThe California-based fashion designer Edith Flagg was the first to import this fabric from Britain to the USA.\nDuring the first two years, ICI gave Flagg a large advertising budget to popularise the fabric across America.\n\nIn 1960, Paul Chambers became the first chairman appointed from outside the company.\nChambers employed the consultancy firm McKinsey to help with reorganising the company.\nHis eight-year tenure saw export sales double, but his reputation was severely damaged by a failed takeover bid for Courtaulds in 1961–62. In 1962, ICI developed the controversial herbicide, paraquat.\n\nICI was confronted with the nationalisation of its operations in Burma on 1 August 1962 as a consequence of the military coup.\n\nIn 1964, ICI acquired British Nylon Spinners (BNS), the company it had jointly set up in 1940 with Courtaulds.\nICI surrendered its 37.5 per cent holding in Courtaulds and paid Courtaulds £2 million a year for five years, \"to take account of the future development expenditure of Courtaulds in the nylon field.\"\nIn return, Courtaulds transferred to ICI their 50 per cent holding in BNS.\nBNS was absorbed into ICI's existing polyester operation, ICI Fibres.\nThe acquisition included BNS production plants in Pontypool, Gloucester and Doncaster, together with research and development in Pontypool.\nEarly pesticide development included Gramoxone (1962, a herbicide), the insecticides pirimiphos-methyl in 1967 and pirimicarb in 1970, brodifacoum (a rodenticide) was developed in 1974; in the late 1970s, ICI was involved in the early development of synthetic pyrethroid insecticides such as lambda-cyhalothrin.\n\nPeter Allen was appointed chairman between 1968 and 1971.\nHe presided over the purchase of Viyella.\nProfits shrank under his tenure. During his tenure, ICI created the wholly owned subsidiary Cleveland Potash Ltd, for the construction of Boulby Mine in Redcar and Cleveland, North Yorkshire. The first shaft was dug in 1968, with full production from 1976. ICI jointly owned the mine with Anglo American, and then with De Beers, before complete ownership was transferred to Israel Chemicals Ltd in 2002. \n\nJack Callard was appointed chairman from 1971 to 1975.\nHe almost doubled company profits between 1972 and 1974, and made ICI Britain's largest exporter.\nIn 1971, the company acquired Atlas Chemical Industries Inc., a major American competitor.\n\nIn 1977, Imperial Metal Industries was divested as an independent quoted company.\nFrom 1982 to 1987, the company was led by the charismatic John Harvey-Jones.\nUnder his leadership, the company acquired the Beatrice Chemical Division in 1985 and Glidden Coatings & Resins, a leading paints business, in 1986.\n\nIn 1991, ICI sold the agricultural and merchandising operations of BritAg and Scottish Agricultural Industries to Norsk Hydro,\nand fought off a hostile takeover bid from Hanson, who had acquired 2.8 percent of the company.\nIt also divested its soda ash products arm to Brunner Mond, ending an association with the trade that had existed since the company's inception, one that had been inherited from the original Brunner, Mond & Co. Ltd.\n\nIn 1992, the company sold its nylon business to DuPont.\nIn 1993, the company de-merged its pharmaceutical bio-science businesses: pharmaceuticals, agrochemicals, specialities, seeds and biological products were all transferred into a new and independent company called Zeneca. Zeneca subsequently merged with Astra AB to form AstraZeneca.\n\nCharles Miller Smith was appointed CEO in 1994, one of the few times that someone from outside ICI had been appointed to lead the company, Smith having previously been a director at Unilever.\nShortly afterwards, the company acquired a number of former Unilever businesses in an attempt to move away from its historical reliance on commodity chemicals. \nIn 1995, ICI acquired the American paint company Grow Group. In 1997, ICI acquired National Starch & Chemical, Quest International, Unichema, and Crosfield, the speciality chemicals businesses of Unilever for $8 billion.\nThis step was part of a strategy to move away from cyclical bulk chemicals and to progress up the value chain to become a higher growth, higher margin business.\nLater that year it went on to buy Rutz & Huber, a Swiss paints business.\n\nHaving taken on some £4 billion of debt to finance these acquisitions, the company had to sell off its commodity chemicals businesses:\nBULLET::::- Disposals of bulk chemicals businesses at that time included the sale of its Australian subsidiary, ICI Australia, for £1 billion in 1997, and of its polyester chemicals business to DuPont for $3 billion also in 1997.\nBULLET::::- In 1998, it sold Crosfield to WR Grace and bought Acheson Industries Inc., an electronic chemicals business.\nBULLET::::- In 2000, ICI sold its diisocyanate, advanced materials, and speciality chemicals businesses at Teesside and worldwide (including plants at Rozenburg in the Netherlands, and South Africa, Malaysia and Taiwan), and Tioxide, its titanium dioxide subsidiary, to Huntsman Corporation for £1.7 billion. It also sold the last of its industrial chemicals businesses to Ineos for £300 million.\nBULLET::::- In 2002, the ICE wholly transferred ownership of Boulby Mine to Israel Chemicals Ltd.\nBULLET::::- In 2006, the Company sold Quest International, its flavours and fragrances business, to Givaudan, for £1.2 billion and Uniqema, its oleochemical business, to Croda International, for £410 million.\n\nHaving sold much of its historically profitable commodities businesses, and many of the new speciality businesses which it had failed to integrate, the company consisted mainly of the Dulux paints business, which quickly found itself the subject of a takeover by AkzoNobel.\n\nDutch firm AkzoNobel (owner of Crown Berger paints) bid £7.2 billion (€10.66 billion or $14.5 billion) for ICI in June 2007.\nAn area of concern about a potential deal was ICI's British pension fund, which had future liabilities of more than £9 billion at the time.\nRegulatory issues in the UK and other markets where Dulux and Crown Paints brands each have significant market share were also a cause for concern for the boards of ICI and AkzoNobel.\nIn the UK, any combined operation without divestments would have seen AkzoNobel have a 54 per cent market share in the paint market.\nThe initial bid was rejected by the ICI board and the majority of shareholders.\nHowever, a subsequent bid for £8 billion (€11.82 billion) was accepted by ICI in August 2007, pending approval by regulators.\n\nAt 8a.m. on 2 January 2008, completion of the takeover of ICI plc by AkzoNobel was announced.\nShareholders of ICI received either £6.70 in cash or AkzoNobel loan notes to the value of £6.70 per one nominal ICI share.\nThe adhesives business of ICI was transferred to Henkel as a result of the deal,\nwhile AkzoNobel agreed to sell its Crown Paints subsidiary to satisfy the concerns of the European Commissioner for Competition.\nThe areas of concern regarding the ICI UK pension scheme were addressed by ICI and AkzoNobel.\n\nICI operated a number of chemical sites around the world.\nIn the UK, the main plants were as follows:\nBULLET::::- Billingham (in Stockton-on-Tees) and Wilton (in present-day Redcar and Cleveland): ICI used the Billingham site to manufacture fertilisers in the 1920s and went on to produce plastics at Billingham in 1934. During World War II it manufactured Synthonia, a synthetic ammonia for explosives. The Wilton R&D site was built to support the plastics division with R&D and chemical engineering facilities. The ICI Billingham Division was split into the ICI Heavy Organic Chemicals Division and ICI Agricultural Division in the 1960s. From 1971 to 1988 ICI Physics and Radioisotopes Section (later known as Tracerco) operated a small General Atomics TRIGA Mark I nuclear reactor at its Billingham factory for the production of radioisotopes used in the manufacture of flow and level instruments, among other products. The Agricultural Division was noted for the development of the world's largest bioreactor at the time - the 1.5 million litre Pruteen Reactor, used for the cultivation of animal feed. This had limited economic success but was followed by the much more successful development of Quorn.\nBULLET::::- Blackley (in Manchester) and Huddersfield: ICI used the sites to manufacture dyestuffs. The dye business, known as the ICI Dyestuffs Division in the 1960s, went through several reorganisations. Huddersfield was tied in with Wilton with the production of nitrobenzene and nitrotolulene. Huddersfield also produced insecticides. (Syngenta still manufacture insecticides at Huddersfield). Proxel Biocide was made at Huddersfield from the 80's onwards. Additives also made at Huddersield. Huddersfield became Zeneca then AstraZeneca, in 2004 Huddersfield was Syngenta, Avecia, Arch and Lubrizol running what were all ICI plants at one time. Through the years it was combined with other speciality chemicals businesses and became Organics Division. Then became ICI Colours and Fine Chemicals and then ICI Specialties.\nBULLET::::- Runcorn (in Cheshire): ICI operated a number of separate sites within the Runcorn area, including Caster-Kellner site, where ICI manufactured chlorine and sodium hydroxide (caustic soda). Adjacent to Castner-Kellner site was Rocksavage works, where a variety of chemicals based on chlorine products were manufactured, including Chloromethanes, Arklone dry cleaning fluid, Trichloethylene degreasing fluid and the Arcton range of CFCs. Also on that site were PVC manufacture and HF (Hydrogen fluoride) manufacture. At Runcorn Heath Research Laboratories, technical support, research and development for Mond Division products was carried out, and the support sections included chemical plan design and engineering sections. Just to the north of Runcorn, on an island between the Manchester Ship Canal and the River Mersey could be found the Wigg Works, which had been erected originally for producing poison gas in wartime. In Widnes could also be found several factories producing weedkillers and other products. For many years it was known as ICI Mond Division but later became part of the ICI Chemicals and Polymers Division. The Runcorn site was also responsible for the development of the HiGEE and Spinning Disc Reactor concepts. These were originated by Professor Colin Ramshaw and led to the concept of Process Intensification; research into these novel technologies is now being pursued by the Process Intensification Group at Newcastle University.\nBULLET::::- Winnington and Wallerscote (in Northwich, Cheshire): It was here that ICI manufactured sodium carbonate (soda ash) and its various by-products such as sodium bicarbonate (bicarbonate of soda), and sodium sesquicarbonate. The Winnington site, built in 1873 by the entrepreneurs John Tomlinson Brunner and Ludwig Mond, was also the base for the former company Brunner, Mond & Co. Ltd. and, after the merger which created ICI, the powerful and influential Alkali Division. It was at the laboratories on this site that polythene was discovered by accident in 1933 during experiments into high pressure reactions. Wallerscote was built in 1926, its construction delayed by the First World War, and became one of the largest factories devoted to a single product (soda ash) in the world. However, the decreasing importance of the soda ash trade to ICI in favour of newer products such as paints and plastics, meant that in 1984 the Wallerscote site was closed, and thereafter mostly demolished. The laboratory where polythene was discovered was sold off and the building became home to a variety of businesses including a go-kart track and paintballing, and the Winnington Works were divested to the newly formed company, Brunner Mond, in 1991. It was again sold in 2006, to Tata (an Indian-based company) and in 2011 was re branded as Tata Chemicals Europe. The Winnington plant closed in February 2014, with the last shift on 2 February bringing to a close 140 years of soda ash production in this Northwich site.\nBULLET::::- Ardeer (in Stevenston, Ayrshire): ICI Nobel used the site to manufacture dynamite and other explosives and nitrocellulose-based products. For a time, the site also produced nylon and nitric acid. Nobel Enterprises was sold in 2002 to Inabata.\nBULLET::::- Slough (in Berkshire): Headquarters of ICI Paints Division.\nBULLET::::- Welwyn Garden City (in Hertfordshire): Headquarters of ICI Plastics Division until the early 1990s.\n\nAn ICI subsidiary called Duperial operated in Argentine from 1928 to 1995, when it was renamed ICI.\n\nEstablished in the city of San Lorenzo, Santa Fe,\nit operates an integrated production site with commercial offices in Buenos Aires. Since 2009 it has made sulphuric acid with ISO certification under the company name Akzo Nobel Functional Chemicals S.A.\n\nThe subsidiary ICI Australia Ltd established the Dry Creek Saltfields at Dry Creek north of Adelaide, South Australia, in 1940, with an associated soda ash plant at nearby Osborne.\nIn 1989, these operations were sold to Penrice Soda Products.\nAn ICI plant was built at Botany Bay in New South Wales in the 1940s and was sold to Orica in 1997.\n\nThe plant once manufactured paints, plastics and industrial chemicals such as solvents. It was responsible for the Botany Bay Groundwater Plume contamination of a local aquifer.\n\nThe subsidiary ICI New Zealand provided substantial quantities of chemical products - including swimming pool chemicals, commercial healthcare products, herbicides and pesticides for use within New Zealand and the neighboring Pacific Islands. \n\nA fire at the ICI New Zealand store in Mount Wellington, Auckland, on 21 December 1984, killed an ICI employee and caused major health concerns. Over 200 firefighters were exposed to toxic smoke and effluents during the firefighting efforts. Six firefighters retired for medical reasons as a result of the fire. This incident was a major event in the history of the New Zealand Fire Service and subject to a formal investigation, led by future Chief Justice Sian Elias. The fire was a trigger for major reforms of the service; direct consequences included improved protective clothing for firefighters, a standard safety protocol for major incidents, the introduction of dedicated fireground safety officers, and changes to occupational health regulations. \n\nBULLET::::- Imperial Chemical House\nBULLET::::- IMI plc (formerly Imperial Metal Industries)\nBULLET::::- Pharmaceutical industry in the United Kingdom\n\n"}
{"id": "15357", "url": "https://en.wikipedia.org/wiki?curid=15357", "title": "Imperial Airways", "text": "Imperial Airways\n\nImperial Airways was the early British commercial long-range airline, operating from 1924 to 1939 and serving parts of Europe but principally the British Empire routes to South Africa, India and the Far East, including Malaya and Hong Kong.\n\nImperial Airways was merged into the British Overseas Airways Corporation (BOAC) in 1939, which in turn merged with the British European Airways (BEA) in 1974 to form British Airways.\n\nThe establishment of Imperial Airways occurred in the context of facilitating overseas settlement by making travel to and from the colonies quicker, and that flight would also speed up colonial government and trade that was until then dependent upon ships. The launch of the airline followed a burst of air route surveying in the British Empire after the First World War, and after some experimental (and often dangerous) long-distance flying to the margins of Empire.\n\nImperial Airways was created against a background of stiff competition from French and German airlines that enjoyed heavy government subsidies and following the advice of the government's Hambling Committee (formally known as the C.A.T Subsidies Committee) under Sir Herbert Hambling. The committee, set up on 2 January 1923, produced a report on 15 February 1923 recommending that four of the largest existing airlines, the Instone Air Line Company, owned by shipping magnate Samuel Instone, Noel Pemberton Billing's British Marine Air Navigation (part of the Supermarine flying-boat company), the Daimler Airway, under the management of George Edward Woods, and Handley Page Transport Co Ltd., should be merged.\nIt was hoped that this would create a company which could compete against French and German competition and would be strong enough to develop Britain's external air services while minimizing government subsidies for duplicated services. With this in view, a £1m subsidy over ten years was offered to encourage the merger. Agreement was made between the President of the Air Council and the British, Foreign and Colonial Corporation on 3 December 1923 for the company, under the title of the 'Imperial Air Transport Company' to acquire existing air transport services in the UK. The agreement set out the government subsidies for the new company: £137,000 in the first year diminishing to £32,000 in the tenth year as well as minimum mileages to be achieved and penalties if these weren't met.\n\nImperial Airways Limited was formed on 31 March 1924 with equipment from each contributing concern: British Marine Air Navigation Company Ltd, the Daimler Airway, Handley Page Transport Ltd and the Instone Air Line Ltd. Sir Eric Geddes was appointed the chairman of the board with one director from each of the merged companies. The government had appointed two directors, Hambling (who was also President of the Institute of Bankers) and Major John Hills, a former Treasury Financial Secretary.\n\nThe land operations were based at Croydon Airport to the south of London. IAL immediately discontinued its predecessors' service to points north of London, the airline being focused on international and imperial service rather than domestic. Thereafter the only IAL aircraft operating 'North of Watford' were charter flights.\n\nIndustrial troubles with the pilots delayed the start of services until 26 April 1924, when a daily London–Paris route was opened with a de Havilland DH.34. Thereafter the task of expanding the routes between England and the Continent began, with Southampton–Guernsey on 1 May 1924, London-Brussels–Cologne on 3 May, London–Amsterdam on 2 June 1924, and a summer service from London–Paris–Basel–Zürich on 17 June 1924. The first new airliner ordered by Imperial Airways, was the Handley Page W8f \"City of Washington\", delivered on 3 November 1924. In the first year of operation the company carried 11,395 passengers and 212,380 letters. In April 1925, the film \"The Lost World\" became the first film to be screened for passengers on a scheduled airliner flight when it was shown on the London-Paris route.\n\nBetween 16 November 1925 and 13 March 1926, Alan Cobham made an Imperial Airways' route survey flight from the UK to Cape Town and back in the Armstrong Siddeley Jaguar–powered de Havilland DH.50J floatplane \"G-EBFO\". The outward route was London–Paris–Marseille–Pisa–Taranto–Athens–Sollum–Cairo–Luxor–Aswan–Wadi Halfa–Atbara–Khartoum–Malakal–Mongalla–Jinja–Kisumu–Tabora–Abercorn–Ndola–Broken Hill–Livingstone–Bulawayo–Pretoria–Johannesburg–Kimberley–Blomfontein–Cape Town. On his return Cobham was awarded the Air Force Cross for his services to aviation.\n\nOn 30 June 1926, Cobham took off from the River Medway at Rochester in \"G-EBFO\" to make an Imperial Airways route survey for a service to Melbourne, arriving on 15 August 1926. He left Melbourne on 29 August 1926, and, after completing in 320 hours flying time over 78 days, he alighted on the Thames at Westminster on 1 October 1926. Cobham was met by the Secretary of State for Air, Sir Samuel Hoare, and was subsequently knighted by HM King George V.\n\nOn 27 December 1926, Imperial Airways de Havilland DH.66 Hercules \"G-EBMX City of Delhi\" left Croydon for a survey flight to India. The flight reached Karachi on 6 January 1927 and Delhi on 8 January 1927. The aircraft was named by Lady Irwin, wife of the Viceroy, on 10 January 1927. The return flight left on 1 February 1927 and arrived at Heliopolis, Cairo on 7 February 1927. The flying time from Croydon to Delhi was 62 hours 27 minutes and Delhi to Heliopolis 32 hours 50 minutes.\n\nRegular services on the Cairo to Basra route began on 12 January 1927 using DH.66 aircraft, replacing the previous RAF mail flight. Following 2 years of negotiations with the Persian authorities regarding overflight rights, a London to Karachi service started on 30 March 1929, taking 7 days and consisting of a flight from London to Basle, a train to Genoa and a Short S.8 Calcutta flying boats to Alexandria, a train to Cairo and finally a DH.66 flight to Karachi. The route was extended as far as Delhi on 29 December 1929. The route across Europe and the Mediterranean changed many times over the next few years but almost always involved a rail journey.\n\nIn April 1931 an experimental London-Australia air mail flight took place; the mail was transferred at the Dutch East Indies, and took 26 days in total to reach Sydney. For the passenger flight leaving London on 1 October 1932, the Eastern route was switched from the Persian to the Arabian side of the Persian Gulf, and Handley Page HP 42 airliners were introduced on the Cairo to Karachi sector. The move saw the establishment of an airport and rest house, Al Mahatta Fort, in the Trucial State of Sharjah now part of the United Arab Emirates.\n\nOn 29 May 1933 an England to Australia survey flight took off, operated by Imperial Airways Armstrong Whitworth Atalanta G-ABTL \"Astraea\". Major H G Brackley, Imperial Airways' Air Superintendent, was in charge of the flight. \"Astraea\" flew Croydon-Paris-Lyon-Rome-Brindisi-Athens-Alexandria-Cairo where it followed the normal route to Karachi then onwards to Jodhpur-Delhi-Calcutta-Akyab-Rangoon-Bangkok-Prachuab-Alor Setar-Singapore-Palembang-Batavia-Sourabaya-Bima-Koepang-Bathurst Island-Darwin-Newcastle Waters-Camooweal-Cloncurry-Longreach-Roma-Toowoomba reaching Eagle Farm, Brisbane on 23 June. Sydney was visited on 26 June, Canberra on 28 June and Melbourne on 29 June.\n\nThere followed a rapid eastern extension. The first London to Calcutta service departed on 1 July 1933, the first London to Rangoon service on 23 September 1933, the first London to Singapore service on 9 December 1933, and the first London to Brisbane service on 8 December 1934, with Qantas responsible for the Singapore to Brisbane sector. (The 1934 start was for mail; passenger flights to Brisbane began the following April.) The first London to Hong Kong passengers departed London on 14 March 1936 following the establishment of a branch from Penang to Hong Kong.\n\nOn 28 February 1931 a weekly service began between London and Mwanza on Lake Victoria in Tanganyika as part of the proposed route to Cape Town. On 9 December 1931 the Imperial Airways' service for Central Africa was extended experimentally to Cape Town for the carriage of Christmas mail. The aircraft used on the last sector, DH66 G-AARY \"City of Karachi\" arrived in Cape Town on 21 December 1931. On 20 January 1932 a mail-only route to London to Cape Town was opened. On 27 April this route was opened to passengers and took 10 days. In early 1933 Atalantas replaced the DH.66s on the Kisumu to Cape Town sector of the London to Cape Town route. On 9 February 1936 the trans-Africa route was opened by Imperial Airways between Khartoum and Kano in Nigeria. This route was extended to Lagos on 15 October 1936.\n\nIn 1937 with the introduction of Short Empire flying boats built at Short Brothers, Imperial Airways could offer a through-service from Southampton to the Empire. The journey to the Cape was via Marseille, Rome, Brindisi, Athens, Alexandria, Khartoum, Port Bell, Kisumu and onwards by land-based craft to Nairobi, Mbeya and eventually Cape Town. Survey flights were also made across the Atlantic and to New Zealand. By mid-1937 Imperial had completed its thousandth service to the Empire. Starting in 1938 Empire flying boats also flew between Britain and Australia via India and the Middle East.\n\nIn March 1939 three Shorts a week left Southampton for Australia, reaching Sydney after ten days of flying and nine overnight stops. Three more left for South Africa, taking six flying days to Durban.\n\nImperial's aircraft were small, most seating fewer than twenty passengers; about 50,000 passengers used Imperial Airways in the 1930s. Most passengers on intercontinental routes or on services within and between British colonies were men doing colonial administration, business or research. To begin with only the wealthy could afford to fly, but passenger lists gradually diversified. Travel experiences related to flying low and slow, and were reported enthusiastically in newspapers, magazines and books. There was opportunity for sightseeing from the air and at stops.\n\nImperial Airways stationed its all-male flight deck crew, cabin crew and ground crew along the length of its routes. Specialist engineers and inspectors – and ground crew on rotation or leave – travelled on the airline without generating any seat revenue. Several air crew lost their lives in accidents. At the end of the 1930s crew numbers approximated 3,000. All crew were expected to be ambassadors for Britain and the British Empire.\n\nIn 1934 the Government began negotiations with Imperial Airways to establish a service (Empire Air Mail Scheme) to carry mail by air on routes served by the airline. Indirectly these negotiations led to the dismissal in 1936 of Sir Christopher Bullock, the Permanent Under-Secretary at the Air Ministry, who was found by a Board of Inquiry to have abused his position in seeking a position on the board of the company while these negotiations were in train. The Government, including the Prime Minister, regretted the decision to dismiss him, later finding that, in fact, no corruption was alleged and sought Bullock's reinstatement which he declined.\n\nThe Empire Air Mail Programme started in July 1937, delivering anywhere for 1 d./oz. By mid-1938 a hundred tons of mail had been delivered to India and a similar amount to Africa. In the same year, construction was started on the Empire Terminal in Victoria, London, designed by A. Lakeman and with a statue by Eric Broadbent, \"Speed Wings Over the World\" gracing the portal above the main entrance. From the terminal there were train connections to Imperial's flying boats at Southampton and coaches to its landplane base at Croydon Airport. The terminal operated as recently as 1980.\n\nTo help promote use of the Air Mail service, in June and July 1939, Imperial Airways participated with Pan American Airways in providing a special \"around the world\" service; Imperial carried the souvenir mail from Foynes, Ireland, to Hong Kong, out of the eastbound New York to New York route. Pan American provided service from New York to Foynes (departing 24 June, via the first flight of Northern FAM 18) and Hong Kong to San Francisco (via FAM 14), and United Airlines carried it on the final leg from San Francisco to New York, arriving on 28 July.\n\nCaptain H.W.C. Alger was the pilot for the inaugural air mail flight carrying mail from England to Australia for the first time on the Short Empire flyingboat \"Castor\" for Imperial Airways' Empires Air Routes, in 1937.\n\nIn November 2016, 80 years later, the Crete2Cape Vintage Air Rally flew this old route with fifteen vintage aeroplanes - a celebration of the skill and determination of these early aviators.\n\nBefore the outbreak of war on 1 September 1939, the British government had already implemented the Air Navigation (Restriction in Time of War) Order 1939. That ordered military takeover of most civilian airfields in the UK, cessation of all private flying without individual flight permits, and other emergency measures. It was administered by a statutory department of the Air Ministry titled National Air Communications (NAC). By 1 September 1939, the aircraft and administrations of Imperial Airways and British Airways Ltd were physically transferred to Bristol (Whitchurch) Airport, to be operated jointly by NAC. On 1 April 1940, Imperial Airways Ltd and British Airways Ltd were officially combined into a new company, British Overseas Airways Corporation (BOAC), that had already been formed on 24 November 1939 with retrospective financial arrangements.\n\nBULLET::::- On 24 December 1924, de Havilland DH.34 G-EBBX \"City of Delhi\" crashed and caught fire shortly after take-off from Croydon Airport, killing the pilot and all seven passengers.\nBULLET::::- On 13 July 1928, Vickers Vulcan G-EBLB crashed at Purley during a test flight, killing four of the six people on board. As a result of the crash, Imperial Airways stopped the flying of staff (so called joy rides) during test flights.\nBULLET::::- On 17 June 1929, Handley Page W.10 G-EBMT \"City of Ottawa\" ditched in the English Channel following engine failure whilst on a flight from Croydon to Paris with the loss of seven lives.\nBULLET::::- On 6 September 1929, de Havilland Hercules G-EBMZ \"City of Jerusalem\" crashed and burned on landing at Jask, Iran in the dark due to the pilot misjudging the altitude and stalling the aircraft, killing three of five on board.\nBULLET::::- On 26 October 1929, Short Calcutta G-AADN \"City of Rome\" force-landed off Spezia, Italy in poor weather; the flying boat sank in the night during attempts to tow it to shore, killing all seven on board.\nBULLET::::- On 30 October 1930, Handley Page W.8g G-EBIX \"City of Washington\" struck high ground in fog at Boulogne, Paris, France, killing three of six on board.\nBULLET::::- On 28 March 1933, Armstrong Whitworth Argosy G-AACI \"City of Liverpool\" crashed at Diksmuide, Belgium following an in-flight fire. This is suspected to be the first case of sabotage in the air. All fifteen people on board were killed.\nBULLET::::- On 30 December 1933, Avro Ten G-ABLU \"Apollo\" collided with a radio mast at Ruysselede, Belgium and crashed. All ten people on board were killed.\nBULLET::::- On 31 December 1935, Short Calcutta G-AASJ \"City of Khartoum\" crashed off Alexandria, Egypt when all four engines failed on approach, possibly due to fuel starvation; twelve of 13 on board drowned when the flying boat sank.\nBULLET::::- On 22 August 1936, Short Kent G-ABFA \"Scipio\" sank at Mirabella, Crete after a heavy landing, killing two of 11 on board.\nBULLET::::- On 24 March 1937, Short Empire G-ADVA \"Capricornus \" crashed in the Beaujolois Mountains near Ouroux, France following a navigation error, killing five.\nBULLET::::- On 1 October 1937, Short Empire G-ADVC \"Courtier\" crashed on landing in Phaleron Bay, Greece due to poor visibility, killing two of 15 on board.\nBULLET::::- On 5 December 1937, Short Empire G-ADUZ \"Cygnus \" crashed on takeoff from Brindisi, Italy due to incorrect flap settings, killing two.\nBULLET::::- On 27 July 1938, Armstrong Whitworth Atalanta G-ABTG \"Amalthea\" flew into a hillside near Kisumu, Kenya shortly after takeoff, killing all four on board.\nBULLET::::- On 27 November 1938, Short Empire G-AETW \"Calpurnia\" crashed in Lake Habbaniyah, Iraq in bad weather after the pilot descended to maintain visual contact with the ground following spatial disorientation, killing all four crew.\nBULLET::::- On 21 January 1939, Short Empire G-ADUU \"Cavalier\" ditched in the Atlantic 285 mi off New York due to carburetor icing and loss of engine power; three drowned while ten survivors were picked up by the tanker \"Esso Baytown\". Thereafter Imperial Airways and Pan-American trans-oceanic flying boats had the upper surfaces of the wings painted with orange high visibility markings.\nBULLET::::- On 1 May 1939, Short Empire G-ADVD \"Challenger\" crashed in the Lumbo lagoon while attempting to land at Lumbo Airport, killing two of six on board.\nBULLET::::- On 1 March 1940, Flight 197, operated by Handley Page H.P.42 G-AAGX \"Hannibal\", disappeared over the Gulf of Oman with eight on board; no wreckage, cargo or occupants have been found. The cause of the crash remains unknown, but fuel starvation, a bird strike damaging a propeller and causing an engine or wing to separate, an in-flight breakup or multiple engine failure were theorized. Two months after the crash, the H.P.42 was withdrawn from passenger operations. It was also recommended that all commercial aircraft used in long flights over water be equipped with personal and group life saving gear; this would later become standard throughout the airline industry.\n\nBULLET::::- On 21 October 1926, Handley Page W.10 G-EBMS \" City of Melbourne\" ditched in the English Channel off the English coast after an engine failed. All 12 people on board were rescued by FV \"Invicta\".\nBULLET::::- On 19 April 1931, de Havilland DH.66 Hercules with registration G-EBMW, damaged beyond repair in a forced landing following fuel starvation at Surabaya. The airplane operated on a trial mail flight from India to Melbourne with en route stops at Semarang, Soerabaja and Kupang.\nBULLET::::- On 8 August 1931, Handley Page H.P.42 G-AAGX \"Hannibal\" was operating a scheduled passenger flight from Croydon to Paris when an engine failed and debris forced a second engine to be shut down. A forced landing at Five Oak Green, Kent resulted in extensive damage. No injuries occurred. Hannibal was dismantled and trucked to Croydon to be rebuilt.\nBULLET::::- On 9 November 1935, Short Kent G-ABFB \"Sylvanus\" caught fire and burned out during refueling in Brindisi Harbor; the refueling crew were able to jump clear of the burning aircraft and survived.\nBULLET::::- On 29 September 1936, Armstrong Whitworth Atalanta G-ABTK burned out in a hangar fire at Delhi, India.\nBULLET::::- On 31 May 1937, Handley Page H.P.45 (former H.P.42) G-AAXE \"Hengist\" was destroyed in a hangar fire at Karachi, India.\nBULLET::::- On 3 December 1938, de Havilland Express G-ADCN burned out at Bangkok.\nBULLET::::- On 12 March 1939 , Short S.23 Empire Flying Boat Mk 1 \"G-ADUY\", damaged beyond repair at Tandjong, Batavia, Netherlands East Indies. Struck a submerged object while taxiing after alighting. Aircraft beached but damaged beyond repair by immersion and mishandling during salvage. Aircraft dismantled and shipped to England but not returned to service.\nBULLET::::- On 7 November 1939, Handley Page H.P.42 G-AXXD \"Horatius\" was written off following a forced landing at a golf course at Tiverton, Devon.\nBULLET::::- On 19 March 1940, Handley Page H.P.45 G-AAXC \"Heracles\" and H.P.42 G-AAUD \"Hanno\" were written off after being blown over in a windstorm while parked at Whitchurch Airport.\n\nImperial Airways operated many types of aircraft from its formation on 1 April 1924 until 1 April 1940 when all aircraft still in service were transferred to BOAC.\n\n!width=\"21%\"Aircraft\n!width=\"10%\"Type\n!Number\n!Period\n!Names\n!width=\"24%\"Notes\nArmstrong Whitworth Argosy Mk.Ilandplane<br>\"City class\"3\n\"Birmingham\" (crashed 1931), \"City of Wellington\" (later \"City of Arundel\") (1934), \"Glasgow\" (retired 1934)\nlandplane<br>\"City class\"41929–35\n\"City of Edinburgh\" (wrecked 1926), \"City of Liverpool\" (wrecked 1933), \"City of Manchester\" (sold 1935) and \"City of Coventry\" (scrapped 1935)\nArmstrong Whitworth Atalantalandplane<br>\"Atalanta class\"81932–41\n\"Atalanta\" (sold), \"Andromeda\" (withdrawn 1939), \"Arethusa\" (renamed \"Atalanta\"), \"Artemis\", \"Astraea\", \"Athena\" (burnt 1936), \"Aurora\" (sold) and \"Amalthea\" (wrecked 1938).For Nairobi-Cape Town leg on South Africa route & Karachi-Singapore leg on Australia route.\nEmpire type (27 passengers) \"Ensign\", \"Egeria\", \"Elsinore\", \"Euterpe\", \"Explorer\", \"Euryalus\", \"Echo\", \"Endymion\" and Western Type (40 passengers) \"Eddystone\", \"Ettrick\", \"Empyrean\" and \"Elysian\"\"Everest\" & \"Enterprise\" delivered to BOAC. Intended to deliver 1st-class mail to the Empire by air.\nAvro 618 Tenlandplane21930–38\n\"Achilles\" (crashed 1938) \"Apollo\" (collided with radio mast 1933)licence-built Fokker F.VII 3/m \nAvro 652 landplane21936–38\n\"Avalon\" and \"Avatar\" (later \"Ava\") to RAF in 1938.Prototypes for Anson bomber/trainer\nBoulton & Paul P.71Alandplane<br>\"Bodiciea class\"21934–36\n\"Bodiciea\" (lost 1935) and \"Britomart\" (lost 1936)Experimental mailplanes\nBristol Type 75 Ten-seaterlandplane21924–26\n\"G-EAWY\", \"G-EBEV\" (retired 1925)ex-Instone Air Line used as freighters\nde Havilland DH.34landplane71924–26\nex-Instone Air Line \"G-EBBR\" (wrecked 1924), \"G-EBBT\" (scrapped 1930), \"G-EBBV\" (scrapped 1926), \"G-EBBW\" (scrapped 1926) and ex-Daimler Airway \"G-EBBX\" (wrecked 1924), \"G-EBBY\" (scrapped 1926), \"G-EBCX\" (wrecked 1924)\nde Havilland DH.50landplane31924–33\n\"G-EBFO\" (damaged 1924 and sold), \"G-EBFP\" (scrapped 1933), \"G-EBKZ\" (crashed 1928)G-EBFO used for surveys, later fitted with twin floats and sold in Australia\nde Havilland DH.54 Highclerelandplane11924–27\n\"G-EBKI\"freighter, destroyed in hangar collapse\nde Havilland Giant Mothlandplane11930-30\n\"G-AAEV\" (wrecked 1930)crashed in Northern Rhodesia 2 weeks after hand over.\nde Havilland Herculeslandplane9 1926–35\n\"City of Cairo\" (wrecked 1931), \"City of Delhi\" (to SAAF 1934), \"City of Baghdad\" (withdrawn 1933), \"City of Jerusalem\", \"City of Tehran\", \"City of Basra\" (to SAAF 1934), \"City of Karachi\" (withdrawn 1935), \"City of Jodhpur\" (sold) and \"City of Cape Town\" (sold)\nde Havilland DH.86 landplane<br>\"Diana\" class121934–41\n\"Daedalus\" (burned 1938), \"Danae\", \"Dardanus\", \"Delia\" (wrecked 1941), \"Delphinus\", \"Demeter\", \"Denebola\", \"Dido\", \"Dione\", \"Dorado\", \"Draco\" (wrecked 1935), and \"Dryad\" (sold 1938)All surviving aircraft impressed in 1941\nde Havilland Albatrosslandplane<br>\"Frobisher\" class71938–43\n\"Faraday\" (impressed 1940), \"Franklin\" (impressed 1940), \"Frobisher\" (destroyed 1940), \"Falcon\" (scrapped 1943), \"Fortuna\" (crashed 1943), \"Fingal\" (crashed 1940) and \"Fiona\" (scrapped 1943).1 used as long range mail carrier\nDesoutter IBlandplane11933–35\n\"G-ABMW\"Air-taxi No 6\nHandley Page O/10landplane11924-24\n\"G-EATH\"ex-Handley Page Transport but never used\nHandley Page W8blandplane31924–32\n\"Princess Mary\" (wrecked 1928), \"Prince George\" (retired 1929) and \"Prince Henry\" (retired 1932)ex-Handley Page Transport\nHandley Page W8f Hamiltonlandplane11924–30\n\"City of Washington\" (wrecked 1930)Converted to twin engines and redesignated as W8g in 1929\nHandley Page W9a Hampsteadlandplane11926–29\n\"City of New York\" (sold 1929)\nHandley Page W10landplane41926–33\n\"City of Melbourne\" (sold 1933), \"City of Pretoria\" (sold 1933), \"City of London\" (crashed 1926) and \"City of Ottawa\" (crashed 1929).\nHandley Page H.P.42Elandplane<br>\"Hannibal class\"41931–40\n\"Hannibal\" (wrecked 1940), \"Horsa\" (impressed 1940), \"Hanno\" (wrecked 1940), \"Hadrian\" (impressed 1940)\n(24 passengers) used on long \"Empire\" routes\nHandley Page H.P.42W/H.P.45landplane<br>\"Heracles class\"41931–40\n\"Heracles\" (wrecked 1940), \"Horatius\" (wrecked 1939), \"Hengist\" (wrecked 1937) and \"Helena\" (impressed 1940)\n(38 passengers) on short \"Western\" routes, \"Hengist\" and \"Helena\" converted to H.P.42E.\nShort S.8 Calcuttaflying boat51928–35\n\"City of Alexandria\" (wrecked 1936), \"City of Athens\" (later \"City of Stonehaven\") (scrapped), \"City of Rome\" (wrecked 1929), \"City of Khartoum\" (wrecked 1935) and \"City of Salonica\" (later \"City of Swanage\") (scrapped)\nShort S.17 Kentflying boat<br>\"Scipio class\"31931–38\n\"Scipio\" (wrecked 1936), \"Sylvanus\" (burned 1935) and \"Satyrus\" (scrapped 1938)\nShort L.17 Scyllalandplane21934–40\n\"Scylla\" (wrecked 1940) and \"Syrinx\" (scrapped 1940)Landplane version of Kent, replacement for lost H.P.42s.\nShort Mayo Compositeflying boat21938–40\n\"Mercury\" (scrapped 1941) and \"Maia\" (destroyed in German raid, 1942).Long range piggyback Composite aircraft derived from Short Empire. \nShort S.23 Empireflying boat<br>\"C class\"311936–47\n\"Canopus\", \"Caledonia\", \"Centaurus\", \"Cavalier\", \"Cambria\", \"Castor\", \"Cassiopea\", \"Capella\", \"Cygnus\", \"Capricornus\", \"Corsair\", \"Courtier\", \"Challenger\", \"Centurion\", \"Coriolanus\", \"Calpurnia\", \"Ceres\", \"Clio\", \"Circe\", \"Calypso\", \"Camilla\", \"Corinna\", \"Cordelia\", \"Cameronian\", \"Corinthian\", \"Coogee\", \"Corio\", and \"Coorong\". \"Carpentaria\", \"Coolangatta\", \"Cooee\" delivered but not used, and transferred to Qantasprovided mail and passenger service to Bermuda, South Africa and Australia.\nShort S.26flying boat<br>\"G class\"31939–40\n\"Golden Hind\", \"Golden Fleece\" and \"Golden Horn\"Built for trans-atlantic service, impressed by RAF before entering revenue service. 2 returned to BOAC service and used until 1947.\nShort S.30 Empireflying boat<br>\"C class\"91938–47\n\"Champion\", \"Cabot\", \"Caribou\", \"Connemara\", \"Clyde\", \"Clare\", \"Cathay\", \"Ao-tea-roa\" (to TEAL as \"Aotearoa\"), \"Captain Cook\" (to TEAL as \"Awarua\").long range variant of S.23\nSupermarine Sea Eagleflying boat21924–29\n\"Sarnia/G-EBGR\" (retired 1929) and \"G-EBGS\" (wrecked 1927)ex-British Marine Air Navigation\nSupermarine Southamptonflying boat11929–30\n\"G-AASH\"RAF \"S1235\" on loan for 3 months to replace crashed Calcutta on Genoa-Alexandria airmail run.\nSupermarine Swanflying boat11925–27\n\"G-EBJY\" (scrapped 1927)RAF prototype loaned for cross-Channel service\nVickers Vanguardlandplane11926–29\n\"G-EBCP\" (wrecked 1929)on loan from Air Ministry for evaluation\nVickers Velloxlandplane11934–36\n\"G-ABKY\" (wrecked 1936)cargo/experimental flights. Crashed at Croyden in August killing pilots and two wireless operators.\nVickers Vimy Commerciallandplane11924–25\n\"City of London\" (wrecked 1925)ex-Instone Air Line\nVickers Vulcanlandplane31924–28\n\"G-EBLB/City of Brussels\" (wrecked 1928), \"G-EBFC\" (withdrawn 1924 unused), G-EBEK (loaned from Air Ministry for 1925 Empire Exhibition Display.)\nWestland IV and Wessexlandplane31931–37\n\"G-AAGW\", \"G-ABEG\" (wrecked 1936), \"G-ACHI\" 2 leased to other operators. IV (G-AAGW) upgraded to Wessex.\n\nBULLET::::- Baldwin, N.C. 1950.\"Imperial Airways (and Subsidiary Companies): A History and Priced Check List of the Empire Air Mails.\" Sutton Coldfield, England: Francis J. Field.\nBULLET::::- Budd, Lucy \"Global Networks Before Globalisation: Imperial Airways and the Development of Long-Haul Air Routes\" Globalization and World Cities (GaWC) Research Bulletin 253, 5 December 2007.\nBULLET::::- Cluett, Douglas; Nash, Joanna; Learmonth Bob. 1980. Croydon Airport 1928 – 1939, The Great Days. London Borough of Sutton\nBULLET::::- Davies, R.E.G 2005. \"British Airways: An Airline and Its Aircraft, Volume 1: 1919–1939—The Imperial Years.\" McLean, VA: Paladwr Press.\nBULLET::::- Doyle, Neville. 2002. The Triple Alliance: The Predecessors of the first British Airways. Air-Britain.\nBULLET::::- Higham, Robin. 1960. \"Britain's Imperial Air Routes, 1918 to 1939: The Story of Britain's Overseas Airlines.\" London: G.T. Foulis; Hamden, CT: Shoe String.\nBULLET::::- Jackson, A.J. 1974.\"British Civil Aircraft since 1919\" Volume 3, London: Putnam. .\nBULLET::::- Moss, Peter W. 1962. Impressments Log (Vol I-IV). Air-Britain.\nBULLET::::- Moss, Peter W. October 1974. British Airways. \"Aeroplane Monthly\".\nBULLET::::- Pirie, G.H. 2004. Passenger traffic in the 1930s on British imperial air routes: refinement and revision. \"Journal of Transport History\", 25: 66–84.\nBULLET::::- Pirie, G.H. 2009. \"Air Empire: British Imperial Civil Aviation 1919–39\". Manchester: Manchester University Press. .\nBULLET::::- Pirie, G.H. 2009. Incidental tourism: British imperial air travel in the 1930s. \"Journal of Tourism History\", 1: 49–66.\nBULLET::::- Pirie, G.H. 2012.\"Cultures and Caricatures of British Imperial Aviation: Passengers, Pilots, Publicity\". Manchester: Manchester University Press. .\nBULLET::::- Pudney, J. 1959. \"The Seven Skies - A Study of BOAC and its forerunners since 1919\". London: Putnam.\nBULLET::::- Salt, Major A.E.W. 1930.\"Imperial Air Routes.\" London: John Murray.\nBULLET::::- Sanford, Kendall C. 2003. \"Air Crash Mail of Imperial Airways and Predecessor Airlines.\" Bristol: Stuart Rossiter Trust Fund.\nBULLET::::- Stroud, John 1962.\"Annals of British and Commonwealth Air Transport 1919–1960.\" London: Putnam.\nBULLET::::- Stroud, John. 2005. \"The Imperial Airways Fleet.\" Stroud, England: Tempus Publishing.\n\nBULLET::::- www.imperial-airways.com enthusiast website at archive.org\nBULLET::::- British Airways \"Explore our past\"\nBULLET::::- Imperial Airways Timetables\nBULLET::::- History Imperial Airways Eastern Route\nBULLET::::- Website for historical information on the airline\nBULLET::::- Website for the Imperial Airways Museum\nBULLET::::- Website for The Crete2Cape Vintage Air Rally\n"}
{"id": "15358", "url": "https://en.wikipedia.org/wiki?curid=15358", "title": "Insanity defense", "text": "Insanity defense\n\nThe insanity defense, also known as the mental disorder defense, is an affirmative defense by excuse in a criminal case, arguing that the defendant is not responsible for his or her actions due to an episodic or persistent psychiatric disease at the time of the criminal act. This is contrasted with an excuse of provocation, in which the defendant is responsible, but the responsibility is lessened due to a temporary mental state. It is also contrasted with a finding that a defendant cannot stand trial in a criminal case because a mental disease prevents them from effectively assisting counsel, from a civil finding in trusts and estates where a will is nullified because it was made when a mental disorder prevented a testator from recognizing the natural objects of their bounty, and from involuntary civil commitment to a mental institution, when anyone is found to be gravely disabled or to be a danger to themselves or to others.\n\nExemption from full criminal punishment on such grounds dates back to at least the Code of Hammurabi. Legal definitions of insanity or mental disorder are varied, and include the M'Naghten Rule, the Durham rule, the 1953 British Royal Commission on Capital Punishment report, the ALI rule (American Legal Institute Model Penal Code rule), and other provisions, often relating to a lack of \"mens rea\" (\"guilty mind\"). In the criminal laws of Australia and Canada, statutory legislation enshrines the \"M'Naghten Rules\", with the terms defense of mental disorder, defense of mental illness or not criminally responsible by reason of mental disorder employed. Being incapable of distinguishing right from wrong is one basis for being found to be legally insane as a criminal defense. It originated in the \"M'Naghten Rule\", and has been reinterpreted and modernized through more recent cases, such as \"People v. Serravo\".\n\nIn the United Kingdom, Ireland, and the United States, use of the defense is rare; however, since the Criminal Procedure (Insanity and Unfitness to Plead) Act 1991, insanity pleas have steadily increased in the UK. Mitigating factors, including things not eligible for the insanity defense such as intoxication (or, more frequently, diminished capacity), may lead to reduced charges or reduced sentences.\n\nThe defense is based on evaluations by forensic mental health professionals with the appropriate test according to the jurisdiction. Their testimony guides the jury, but they are not allowed to testify to the accused's criminal responsibility, as this is a matter for the jury to decide. Similarly, mental health practitioners are restrained from making a judgment on the issue of whether the defendant is or is not insane or what is known as the \"ultimate issue\".\n\nSome jurisdictions require the evaluation to address the defendant's ability to control their behavior at the time of the offense (the volitional limb). A defendant claiming the defense is pleading \"not guilty by reason of insanity\" (NGRI) or \"guilty but insane or mentally ill\" in some jurisdictions which, if successful, may result in the defendant being committed to a psychiatric facility for an indeterminate period.\n\nThe United States Supreme Court (in \"Penry v. Lynaugh\") and the United States Court of Appeals for the Fifth Circuit (in \"Bigby v. Dretke\") have been clear in their decisions that jury instructions in death penalty cases that do not ask about mitigating factors regarding the defendant's mental health violate the defendant's Eighth Amendment rights, saying that the jury is to be instructed to consider mitigating factors when answering unrelated questions. This ruling suggests specific explanations to the jury are necessary to weigh mitigating factors.\n\nDiminished responsibility or diminished capacity can be employed as a mitigating factor or partial defense to crimes and, in the United States, is applicable to more circumstances than the insanity defense. The Homicide Act 1957 is the statutory basis for the defense of diminished responsibility in England and Wales, whereas in Scotland it is a product of case law. The number of findings of diminished responsibility has been matched by a fall in unfitness to plead and insanity findings (Walker, 1968). A plea of diminished capacity is different from a plea of insanity in that \"reason of insanity\" is a full defense while \"diminished capacity\" is merely a plea to a lesser crime.\n\n\"Non compos mentis\" (Latin) is a legal term meaning \"not of sound mind\". \"Non compos mentis\" derives from the Latin \"non\" meaning \"not\", \"compos\" meaning \"having command\" or \"composed\", and \"mentis\" (genitive singular of \"mens\"), meaning \"of mind\". It is the direct opposite of \"Compos mentis\" (of a sound mind).\n\nAlthough typically used in law, this term can also be used metaphorically or figuratively; e.g. when one is in a confused state, intoxicated, or not of sound mind. The term may be applied when a determination of competency needs to be made by a physician for purposes of obtaining informed consent for treatments and, if necessary, assigning a surrogate to make health care decisions. While the proper sphere for this determination is in a court of law, this is practically, and most frequently, made by physicians in the clinical setting.\n\nIn English law, the rule of \"non compos mentis\" was most commonly used when the defendant invoked religious or magical explanations for behaviour.\n\nSeveral cases have ruled that persons found not guilty by reason of insanity may not withdraw the defense in a habeas petition to pursue an alternative, although there have been exceptions in other rulings. In Colorado v. Connelly, 700 A.2d 694 (Conn. App. Ct. 1997), the petitioner who had originally been found not guilty by reason of insanity and committed for ten years to the jurisdiction of a Psychiatric Security Review Board, filed a pro se writ of \"habeas corpus\" and the court vacated his insanity acquittal. He was granted a new trial and found guilty of the original charges, receiving a prison sentence of 40 years.\n\nIn the landmark case of \"Frendak v. United States\" in 1979, the court ruled that the insanity defense cannot be imposed upon an unwilling defendant if an intelligent defendant voluntarily wishes to forgo the defense.\n\nThose found to have been not guilty by reason of mental disorder or insanity are generally then required to undergo psychiatric treatment in a mental institution, except in the case of temporary insanity (see below). In England and Wales, under the Criminal Procedure (Insanity and Unfitness to Plead) Act of 1991 (amended by the Domestic Violence, Crime and Victims Act, 2004 to remove the option of a guardianship order), the court can mandate a hospital order, a restriction order (where release from hospital requires the permission of the Home Secretary), a \"supervision and treatment\" order, or an absolute discharge. Unlike defendants who are found guilty of a crime, they are not institutionalized for a fixed period, but rather held in the institution until they are determined not to be a threat. Authorities making this decision tend to be cautious, and as a result, defendants can often be institutionalized for longer than they would have been incarcerated in prison.\n\nIn \"Foucha v. Louisiana\" (1992) the Supreme Court of the United States ruled that a person could not be held \"indefinitely\".\n\nSo far, in the United States, those acquitted of a federal offense by reason of insanity have not been able to challenge their psychiatric confinement through a writ of habeas corpus or other remedies. In \"Archuleta v. Hedrick\", 365 F.3d 644 (8th Cir. 2004), the U.S. Court of Appeals for the Eighth Circuit the court ruled persons found not guilty by reason of insanity and later want to challenge their confinement may not attack their initial successful insanity defense:\nAn important distinction to be made is the difference between competency and criminal responsibility.\nBULLET::::- The issue of competency is whether a defendant is able to adequately assist his attorney in preparing a defense, make informed decisions about trial strategy and whether to plead guilty, accept a plea agreement or plead not guilty. This issue is dealt with in UK law as \"fitness to plead\".\n\nCompetency largely deals with the defendant's present condition, while criminal responsibility addresses the condition at the time the crime was committed.\n\nIn the United States, a trial in which the insanity defense is invoked typically involves the testimony of psychiatrists or psychologists who will, as expert witnesses, present opinions on the defendant's state of mind at the time of the offense.\n\nTherefore, a person whose mental disorder is not in dispute is determined to be sane if the court decides that despite a \"mental illness\" the defendant was responsible for the acts committed and will be treated in court as a normal defendant. If the person has a mental illness and it is determined that the mental illness interfered with the person's ability to determine right from wrong (and other associated criteria a jurisdiction may have) and if the person is willing to plead guilty or is proven guilty in a court of law, some jurisdictions have an alternative option known as either a Guilty but Mentally Ill (GBMI) or a Guilty but Insane verdict. The GBMI verdict is available as an alternative to, rather than in lieu of, a \"not guilty by reason of insanity\" verdict. Michigan (1975) was the first state to create a GBMI verdict, after two prisoners released after being found NGRI committed violent crimes within a year of release, one raping two women and the other killing his wife.\n\nThe notion of temporary insanity argues that a defendant \"was\" insane during the commission of a crime, but they later regained their sanity after the criminal act was carried out. This legal defense is commonly used to defend individuals that have committed crimes of passion. The defense was first successfully used by U.S. Congressman Daniel Sickles of New York in 1859 after he had killed his wife's lover, Philip Barton Key. Use of the defense became more common during the 1940s and 1950s.\n\nThe concept of defense by insanity has existed since ancient Greece and Rome. However, in colonial America a delusional Dorothy Talbye was hanged in 1638 for murdering her daughter, as at the time Massachusetts's common law made no distinction between insanity (or mental illness) and criminal behavior. Edward II, under English Common law, declared that a person was insane if their mental capacity was no more than that of a \"wild beast\" (in the sense of a dumb animal, rather than being frenzied). The first complete transcript of an insanity trial dates to 1724. It is likely that the insane, like those under 14, were spared trial by ordeal. When trial by jury replaced this, the jury members were expected to find the insane guilty but then refer the case to the King for a Royal Pardon. From 1500 onwards, juries could acquit the insane, and detention required a separate civil procedure (Walker, 1985). The Criminal Lunatics Act 1800, passed with retrospective effect following the acquittal of James Hadfield, mandated detention at the regent's pleasure (indefinitely) even for those who, although insane at the time of the offence, were now sane.\n\nThe M'Naghten Rules of 1843 were not a codification or definition of insanity but rather the responses of a panel of judges to hypothetical questions posed by Parliament in the wake of Daniel M'Naghten's acquittal for the homicide of Edward Drummond, whom he mistook for British Prime Minister Robert Peel. The rules define the defense as \"at the time of committing the act the party accused was labouring under such a defect of reason, from disease of the mind, as not to know the nature and quality of the act he was doing, or as not to know that what he was doing was wrong.\" The key is that the defendant could not appreciate the nature of his actions during the commission of the crime.\n\nIn \"Ford v. Wainwright\" 477 U.S. 399 (1986), the US Supreme Court upheld the common law rule that the insane cannot be executed. It further stated that a person under the death penalty is entitled to a competency evaluation and to an evidentiary hearing in court on the question of his competency to be executed.\nIn \"Wainwright v. Greenfield\", the Court ruled that it was fundamentally unfair for the prosecutor to comment during the court proceedings on the petitioner's silence invoked as a result of a Miranda warning. The prosecutor had argued that the respondent's silence after receiving Miranda warnings was evidence of his sanity.\n\nIn the United States, variances in the insanity defense between states, and in the federal court system, are attributable to differences with respect to three key issues:\nBULLET::::1. Availability: whether the jurisdiction allows a defendant to raise the insanity defense,\nBULLET::::2. Definition: when the defense is available, what facts will support a finding of insanity, and\nBULLET::::3. Burden of proof: whether the defendant has the duty of proving insanity or the prosecutor has the duty of disproving insanity, and by what standard of proof.\n\nIn the United States, a criminal defendant may plead insanity in federal court, and in the state courts of every state except for Idaho, Kansas, Montana, and Utah. However, defendants in states that disallow the insanity defense may still be able to demonstrate that a defendant was not capable of forming intent to commit a crime as a result of mental illness.\n\nEach state and the federal court system currently uses one of the following \"tests\" to define insanity for purposes of the insanity defense. Over its decades of use the definition of insanity has been modified by statute, with changes to the availability of the insanity defense, what constitutes legal insanity whether the prosecutor or defendant has the burden of proof, the standard of proof required at trial, trial procedures, and to commitment and release procedures for defendants who have been acquitted based on a finding of insanity.\n\nThe guidelines for the \"M'Naghten Rules\", state, \"inter alia\", and evaluating the criminal responsibility for defendants claiming to be insane were settled in the British courts in the case of Daniel M'Naghten in 1843. M'Naghten was a Scottish woodcutter who killed the secretary to the prime minister, Edward Drummond, in a botched attempt to assassinate the prime minister himself. M'Naghten apparently believed that the prime minister was the architect of the myriad of personal and financial misfortunes that had befallen him. During his trial, nine witnesses testified to the fact that he was insane, and the jury acquitted him, finding him \"not guilty by reason of insanity.\"\n\nThe House of Lords asked the judges of the common law courts to answer five questions on insanity as a criminal defence, and the formulation that emerged from their review—that a defendant should not be held responsible for his actions only if, as a result of his mental disease or defect, he (i) did not know that his act would be wrong; or (ii) did not understand the nature and quality of his actions—became the basis of the law governing legal responsibility in cases of insanity in England. Under the rules, loss of control because of mental illness was no defense. The M'Naghten rule was embraced with almost no modification by American courts and legislatures for more than 100 years, until the mid-20th century.\n\nThe strict M'Naghten standard for the insanity defense was widely used until the 1950s and the case of \"Durham v. United States\" case. In the \"Durham\" case, the court ruled that a defendant is entitled to acquittal if the crime was the \"product of\" his mental illness (i.e., crime would not have been committed but for the disease). The test, also called the Product Test, is broader than either the M'Naghten test or the irresistible impulse test. The test has more lenient guidelines for the insanity defense, but it addressed the issue of convicting mentally ill defendants, which was allowed under the M'Naghten Rule. However, the Durham standard drew much criticism because of its expansive definition of legal insanity.\n\nThe Model Penal Code, published by the American Law Institute, provides a standard for legal insanity that serves as a compromise between the strict M'Naghten Rule, the lenient Durham ruling, and the irresistible impulse test. Under the MPC standard, which represents the modern trend, a defendant is not responsible for criminal conduct \"if at the time of such conduct as a result of mental disease or defect he lacks \"substantial capacity\" either to appreciate the criminality of his conduct or to conform his conduct to the requirements of the law.\" The test thus takes into account both the cognitive and volitional capacity of insanity.\n\nAfter the perpetrator of President Reagan's assassination attempt was found not guilty by reason of insanity, Congress passed the Insanity Defense Reform Act of 1984. Under this act, the burden of proof was shifted from the prosecution to the defense and the standard of evidence in federal trials was increased from a preponderance of evidence to clear and convincing evidence. The ALI test was discarded in favor of a new test that more closely resembled M'Naghten's. Under this new test only perpetrators suffering from severe mental illnesses at the time of the crime could successfully employ the insanity defense. The defendant's ability to control himself or herself was no longer a consideration.\n\nThe Act also curbed the scope of expert psychiatric testimony and adopted stricter procedures regarding the hospitalization and release of those found not guilty by reason of insanity.\n\nAs an alternative to the insanity defense, some jurisdictions permit a defendant to plead guilty but mentally ill. A defendant who is found guilty but mentally ill may be sentenced to mental health treatment, at the conclusion of which the defendant will serve the remainder of his or her sentence in the same manner as any other defendant.\n\nIn a majority of states, the burden of proving insanity is placed on the defendant, who must prove insanity by a preponderance of the evidence.\n\nIn a minority of states, the burden is placed on the prosecution, who must prove sanity beyond a reasonable doubt.\n\nIn federal court, and in Arizona, the burden is placed on the defendant, who must prove insanity by clear and convincing evidence. See 18 U.S.C.S. Sec. 17(b); see also A.R.S. Sec. 13-502(C).\n\nThe insanity plea is used in the U.S Criminal Justice System in less than 1% of all criminal cases. Little is known about the criminal justice system and the mentally ill:\n\nSome U.S. states have begun to ban the use of the insanity defense, and in 1994 the Supreme Court denied a petition of certiorari seeking review of a Montana Supreme Court case that upheld Montana's abolition of the defense. Idaho, Kansas, and Utah have also banned the defense. However, a mentally ill defendant/patient can be found unfit to stand trial in these states. In 2001, the Nevada Supreme Court found that their state's abolition of the defense was unconstitutional as a violation of Federal due process. In 2006, the Supreme Court decided \"Clark v. Arizona\" upheld Arizona's limitations on the insanity defense. In that same ruling, the Court noted \"We have never held that the Constitution mandates an insanity defense, nor have we held that the Constitution does not so require.\"\n\nThe insanity defense is also complicated because of the underlying differences in philosophy between psychiatrists/psychologists and legal professionals. In the United States, a psychiatrist, psychologist or other mental health professional is often consulted as an expert witness in insanity cases, but the ultimate \"legal\" judgment of the defendant's sanity is determined by a jury, not by a psychologist. In other words, psychologists provide testimony and professional opinion but are not ultimately responsible for answering legal questions.\n\nIn Australia there are nine law units. All may have varying rules (see ). In South Australia, the Criminal Law Consolidation Act 1935 (SA) provides that:\n\n269C—Mental competence\n\nA person is mentally incompetent to commit an offence if, at the time of the conduct alleged to give rise to the offence, the person is suffering from a mental impairment and, in consequence of the mental impairment—\n269H—Mental unfitness to stand trial\n\nA person is mentally unfit to stand trial on a charge of an offence if the person's mental processes are so disordered or impaired that the person is—\n\nIn Victoria the current defence of mental impairment was introduced in the \"Crimes (Mental Impairment and Unfitness to be Tried) Act\" 1997 which replaced the common law defence of insanity and indefinite detention at the governor's pleasure with the following:\nThese requirements are almost identical to the M'Naghten Rules, substituting \"mental impairment\" for \"disease of the mind\".\n\nIn New South Wales, the defence has been renamed the 'Defence of Mental Illness' in Part 4 of the \"Mental Health (Forensic Provisions) Act 1990\". However, definitions of the defence are derived from M'Naghten's case and have not been codified. Whether a particular condition amounts to a disease of the mind is not a medical but a legal question to be decided in accordance with the ordinary rules of interpretation. This defence is an exception to the \"Woolmington v DPP\" (1935) 'golden thread', as the party raising the issue of the defence of mental illness bears the burden of proving this defence on the balance of probabilities. Generally, the defence will raise the issue of insanity. However, the prosecution can raise it in exceptional circumstances: \"R v Ayoub (1984).\" \n\nAustralian cases have further qualified and explained the \"M'Naghten Rules\". The NSW Supreme Court has held there are two limbs to the \"M'Naghten Rules\", that the accused did not know what he was doing, or that the accused did not appreciate that what he was doing was morally wrong, in both cases the accused must be operating under a 'defect of reason, from a disease of the mind'. The High Court in \"R v Porter\" stated that the condition of the accused’s mind is relevant only at the time of the actus reus. In \"Woodbridge v The Queen\" the court stated that a symptom indicating a disease of the mind must be prone to recur and be the result of an underlying pathological infirmity. A ‘defect of reason’ is the inability to think rationally and pertains to incapacity to reason, rather than having unsound ideas or difficulty with such a task. Examples of disease of the mind include Arteriosclerosis (considered so because the hardening of the arteries affects the mind.\n\nThe defence of mental disorder is codified in section 16 of the \"Criminal Code\" which states, in part:\n\nTo establish a claim of mental disorder the party raising the issue must show on a balance of probabilities first that the person who committed the act was suffering from a \"disease of the mind\", and second, that at the time of the offence they were either 1) unable to appreciate the \"nature and quality\" of the act, or 2) did not know it was \"wrong\".\n\nThe meaning of the word \"wrong\" was determined in the Supreme Court case of \"R. v. Chaulk\" [1990] 3 S.C.R. which held that \"wrong\" was NOT restricted to \"legally wrong\" but to \"morally wrong\" as well.\n\nThe current legislative scheme was created by the Parliament of Canada after the previous scheme was found unconstitutional by the Supreme Court of Canada in \"R. v. Swain\". The new provisions also replaced the old insanity defense with the current mental disorder defence.\n\nOnce a person is found not criminally responsible (\"NCR\"), he or she will have a hearing by a Review Board within 45 days (90 days if the court extends the delay). A Review Board is established under Part XX.1 of the \"Criminal Code\" and is composed of at least three members, a person who is a judge or eligible to be a judge, a psychiatrist and another expert in a relevant field, such as social work, criminology or psychology. Parties at a Review Board hearing are usually the accused, the Crown and the hospital responsible for the supervision or assessment of the accused. A Review Board is responsible for both accused persons found NCR or accused persons found unfit to stand trial on account of mental disorder. A Review Board dealing with an NCR offender must consider two questions: whether the accused is a \"significant threat to the safety of the public\" and, if so, what the \"least onerous and least restrictive\" restrictions on the liberty of the accused should be in order to mitigate such a threat. Proceedings before a Review Board are inquisitorial rather than adversarial. Often the Review Board will be active in conducting an inquiry. Where the Review Board is unable to conclude that the accused is a significant threat to the safety of the public, the review board must grant the accused an absolute discharge, an order essentially terminating the jurisdiction of the criminal law over the accused. Otherwise, the Review Board must order that the accused be either discharged subject to conditions or detained in a hospital, both subject to conditions. The conditions imposed must be the least onerous and least restrictive necessary to mitigate any danger the accused may pose to others.\n\nSince the Review Board is empowered under criminal law powers under s. 91(27) of the \"Constitution Act, 1867\" the sole justification for its jurisdiction is public safety. Therefore, the nature of the inquiry is the danger the accused may pose to public safety rather than whether the accused is \"cured.\" For instance, many \"sick\" accused persons are discharged absolutely on the basis that they are not a danger to the public while many \"sane\" accused are detained on the basis that they are dangerous. Moreover, the notion of \"significant threat to the safety of the public\" is a \"criminal threat.\" This means that the Review Board must find that the threat posed by the accused is of a criminal nature.\n\nWhile proceedings before a Review Board are less formal than in court, there are many procedural safeguards available to the accused given the potential indefinite nature of Part XX.1. Any party may appeal against the decision of a Review Board.\n\nIn 1992 when the new mental disorder provisions were enacted, Parliament included \"capping\" provisions which were to be enacted at a later date. These capping provisions limited the jurisdiction of a Review Board over an accused based on the maximum potential sentence had the accused been convicted (e.g. there would be a cap of 5 years if the maximum penalty for the index offence is 5 years). However, these provisions were never proclaimed into force and were subsequently repealed.\n\nA Review Board must hold a hearing every 12 months (unless extended to 24 months) until the accused is discharged absolutely.\n\nThe issue of mental disorder may also come into play before a trial even begins if the accused's mental state prevents the accused from being able to appreciate the nature of a trial and to conduct a defence.\n\nAn accused who is found to be unfit to stand trial is subject to the jurisdiction a Review Board. While the considerations are essentially the same, there are a few provisions which apply only to unfit accused. A Review Board must determine whether the accused is fit to stand trial. Regardless of the determination, the Review Board must then determine what conditions should be imposed on the accused, considering both the protection of the public and the maintenance of the fitness of the accused (or conditions which would render the accused fit). Previously an absolute discharge was unavailable to an unfit accused. However, in R. v. Demers, the Supreme Court of Canada struck down the provision restricting the availability of an absolute discharge to an accused person who is deemed both \"permanently unfit\" and not a significant threat to the safety of the public. Presently a Review Board may recommend a judicial stay of proceedings in the event that it finds the accused both \"permanently unfit\" and non-dangerous. The decision is left to the court having jurisdiction over the accused.\n\nAn additional requirement for an unfit accused is the holding of a \"prima facie case\" hearing every two years. The Crown must demonstrate to the court having jurisdiction over the accused that it still has sufficient evidence to try the accused. If the Crown fails to meet this burden then the accused is discharged and proceedings are terminated. The nature of the hearing is virtually identical to that of a preliminary hearing.\n\nAccording to section 20 of the German criminal code, those who commit an illegal act because a mental disorder makes them unable to see the wrong of the act or to act on this insight is considered not guilty. \n\nIf the ability to recognize the right or wrong of action or the ability to act accordingly is lost due to a mental disorder, then the defendant cannot be pursued under Japanese criminal law so if this is recognized during a trial then an innocent judgment will be given. This is, however, rare, happening in only around 1 in 500,000 cases.\n\nInsanity is determined through a judicial decision issued on the basis of expert opinions of psychiatrists and psychologists.\n\nA forensic psychiatric examination is used to establish insanity. The result of the forensic examination is then subjected to a legal assessment, taking into account other circumstances of the case, from which a conclusion is drawn about the defendants sanity or insanity. The Criminal Code of Russia establishes that a person who during the commission of an illegal act was in a state of insanity, that is, could not be aware of the actual nature and social danger of his actions or was unable to control his or her actions due to a chronic mental disorder, a temporary mental disorder, or dementia is not subject to criminal liability.\n\nThe Scottish Law Commission, in its Discussion Paper No 122 on Insanity and Diminished Responsibility (2003), pp. 16/18, confirms that the law has not substantially changed from the position stated in Hume's Commentaries:\nThe phrase \"absolute alienation of reason\" is still regarded as at the core of the defense in the modern law (see \"HM Advocate v Kidd\" (1960) JC 61 and \"Brennan v HM Advocate\" (1977)\n\nIn the Nordic countries, insanity is not a defense; instead, it is the responsibility of the court system as such to consider whether the accused may have been psychotic or suffering from other severe mental defects when perpetrating the criminal act. This explains why, in Norway, the court considered the sanity of Anders Behring Breivik, even if he himself declared to be sane.\n\nRules differ between Nordic countries.\n\nIn Sweden, psychotic perpetrators are seen as accountable, but the sanction is, if they are psychotic at the time of the trial, forensic mental care.\n\nIn Denmark and Norway, psychotic perpetrators are declared guilty, but not punished. Instead of prison, they are sentenced to mandatory treatment. Still, important differences exist between Norway and Denmark.\n\nIn Norway, §44 of the penal code states specifically that \"a person who at the time of the crime was insane or unconscious is not punished\".\n\nIn Denmark, §16 of the penal code states that \"Persons, who, at the time of the act, were irresponsible owing to mental illness or similar conditions or\nto a pronounced mental deficiency, are not punishable\". This means that in Denmark, 'insanity' is a legal term rather than a medical term and that the court retains the authority to decide whether an accused person is irresponsible or not.\n\nIn Finland, punishments can only be administered if the accused is \"compos mentis\", of sound mind; not if the accused is insane (\"syyntakeeton\", literally \"unable to guarantee [shoulder the responsibility of] guilt\"). Thus, an insane defendant may be found guilty based on the facts and his actions just as a sane defendant, but the insanity will only affect the punishment. The definition of insanity is similar to the M'Naught criterion above: \"the accused is insane, if during the act, due to a mental illness, profound mental retardation or a severe disruption of mental health or consciousness, he cannot understand the actual nature of his act or its illegality, or that his ability to control his behavior is critically weakened\". If an accused is suspected to be insane, the court must consult the National Institute for Health and Welfare (THL), which is obliged to place the accused in involuntary commitment if he is found insane. The offender receives no judicial punishment; he becomes a patient under the jurisdiction of THL, and must be released immediately once the conditions of involuntary commitment are no longer fulfilled. Diminished responsibility is also available, resulting in lighter sentences.\n\nThis increased coverage gives the impression that the defense is widely used, but this is not the case. According to an eight-state study, the insanity defense is used in less than 1% of all court cases and, when used, has only a 26% success rate. Of those cases that were successful, 90% of the defendants had been previously diagnosed with mental illness.\n\nBULLET::::- \"Archuleta v. Hedrick\"\nBULLET::::- \"By Reason of Insanity\", a documentary about a hospital in Ohio housing the guilty-but-insane\nBULLET::::- Diminished responsibility (or \"Limited Sanity\")\nBULLET::::- \"Frendak v. United States\"\nBULLET::::- Intoxication defence\nBULLET::::- Mentally ill people in American prisons\nBULLET::::- M'Naghten rules\nBULLET::::- \"\", a Canadian documentary film about the mental disorder defense\nBULLET::::- Non compos mentis\nBULLET::::- \"Nulla poena sine culpa\"\nBULLET::::- Sanity\nBULLET::::- Settled insanity\nBULLET::::- State v. Strasburg\nBULLET::::- Twinkie defense\nBULLET::::- United States federal laws governing offenders with mental diseases or defects\n\nBULLET::::- Mackay, RD (1995) \"Mental Condition Defences in the Criminal Law\", Oxford: Clarendon Press.\nBULLET::::- , pp15–16.\nBULLET::::- at p. 30\n\nBULLET::::- Boland, F. (1996). \"Insanity, the Irish Constitution and the European Convention on Human Rights\". 47 \"Northern Ireland Legal Quarterly\" 260.\nBULLET::::- Brown, M. (2007). \"The John Hinckley Trial & Its Effect on the Insanity Defense\".\nBULLET::::- Butler Committee. (1975). \"The Butler Committee on Mentally Abnormal Offenders\", London: HMSO, Cmnd 6244\nBULLET::::- Ellis, J. W. (1986). \"The Consequences of the Insanity Defense: Proposals to reform post-acquittal commitment laws\". 35 \"Catholic University Law Review\" 961.\nBULLET::::- Gostin, L. (1982). \"Human Rights, Judicial Review and the Mentally Disordered Offender\". (1982) \"Crim. LR\" 779.\nBULLET::::- Vatz, R. (December 19, 2013). “Affluenza: just the latest way to shirk legal responsibility”. \"The Baltimore Sun\" op-ed page.\n\nBULLET::::- Frontline—From Daniel M'Naughten to John Hinckley: A Brief History of the Insanity Defense\nBULLET::::- Evolution of the Insanity Plea\nBULLET::::- Survey of US states' insanity defense criteria\n"}
{"id": "15361", "url": "https://en.wikipedia.org/wiki?curid=15361", "title": "Ice age", "text": "Ice age\n\nAn ice age is a long period of reduction in the temperature of the Earth's surface and atmosphere, resulting in the presence or expansion of continental and polar ice sheets and alpine glaciers. Earth's climate alternates between ice ages and greenhouse periods, during which there are no glaciers on the planet. Earth is currently in the Quaternary glaciation, known in popular terminology as the Ice Age. Individual pulses of cold climate within an ice age are termed \"glacial periods\" (or, alternatively, \"glacials\", \"glaciations\", \"glacial stages\", \"stadials\", \"stades\", or colloquially, \"ice ages\"), and intermittent warm periods within an ice age are called \"interglacials\" or \"interstadials\", with both climatic pulses part of the Quaternary or other periods in Earth's history.\n\nIn the terminology of glaciology, \"ice age\" implies the presence of extensive ice sheets in both northern and southern hemispheres. By this definition, we are in an interglacial period—the Holocene. The amount of heat trapping gases emitted into Earth's oceans and atmosphere are predicted to prevent the next glacial period, which otherwise would begin in around 50,000 years, and likely more glacial cycles.\n\nIn 1742, Pierre Martel (1706–1767), an engineer and geographer living in Geneva, visited the valley of Chamonix in the Alps of Savoy. Two years later he published an account of his journey. He reported that the inhabitants of that valley attributed the dispersal of erratic boulders to the glaciers, saying that they had once extended much farther. Later similar explanations were reported from other regions of the Alps. In 1815 the carpenter and chamois hunter Jean-Pierre Perraudin (1767–1858) explained erratic boulders in the Val de Bagnes in the Swiss canton of Valais as being due to glaciers previously extending further. An unknown woodcutter from Meiringen in the Bernese Oberland advocated a similar idea in a discussion with the Swiss-German geologist Jean de Charpentier (1786–1855) in 1834. Comparable explanations are also known from the Val de Ferret in the Valais and the Seeland in western Switzerland and in Goethe's scientific work. Such explanations could also be found in other parts of the world. When the Bavarian naturalist Ernst von Bibra (1806–1878) visited the Chilean Andes in 1849–1850, the natives attributed fossil moraines to the former action of glaciers.\n\nMeanwhile, European scholars had begun to wonder what had caused the dispersal of erratic material. From the middle of the 18th century, some discussed ice as a means of transport. The Swedish mining expert Daniel Tilas (1712–1772) was, in 1742, the first person to suggest drifting sea ice in order to explain the presence of erratic boulders in the Scandinavian and Baltic regions. In 1795, the Scottish philosopher and gentleman naturalist, James Hutton (1726–1797), explained erratic boulders in the Alps by the action of glaciers. Two decades later, in 1818, the Swedish botanist Göran Wahlenberg (1780–1851) published his theory of a glaciation of the Scandinavian peninsula. He regarded glaciation as a regional phenomenon.\nOnly a few years later, the Danish-Norwegian geologist Jens Esmark (1762–1839) argued a sequence of worldwide ice ages. In a paper published in 1824, Esmark proposed changes in climate as the cause of those glaciations. He attempted to show that they originated from changes in Earth's orbit. During the following years, Esmark's ideas were discussed and taken over in parts by Swedish, Scottish and German scientists. At the University of Edinburgh Robert Jameson (1774–1854) seemed to be relatively open to Esmark's ideas, as reviewed by Norwegian professor of glaciology Bjørn G. Andersen (1992). Jameson's remarks about ancient glaciers in Scotland were most probably prompted by Esmark. In Germany, Albrecht Reinhard Bernhardi (1797–1849), a geologist and professor of forestry at an academy in Dreissigacker, since incorporated in the southern Thuringian city of Meiningen, adopted Esmark's theory. In a paper published in 1832, Bernhardi speculated about former polar ice caps reaching as far as the temperate zones of the globe.\n\nIn 1829, independently of these debates, the Swiss civil engineer Ignaz Venetz (1788–1859) explained the dispersal of erratic boulders in the Alps, the nearby Jura Mountains, and the North German Plain as being due to huge glaciers. When he read his paper before the Schweizerische Naturforschende Gesellschaft, most scientists remained sceptical. Finally, Venetz convinced his friend Jean de Charpentier. De Charpentier transformed Venetz's idea into a theory with a glaciation limited to the Alps. His thoughts resembled Wahlenberg's theory. In fact, both men shared the same volcanistic, or in de Charpentier's case rather plutonistic assumptions, about the Earth's history. In 1834, de Charpentier presented his paper before the Schweizerische Naturforschende Gesellschaft. In the meantime, the German botanist Karl Friedrich Schimper (1803–1867) was studying mosses which were growing on erratic boulders in the alpine upland of Bavaria. He began to wonder where such masses of stone had come from. During the summer of 1835 he made some excursions to the Bavarian Alps. Schimper came to the conclusion that ice must have been the means of transport for the boulders in the alpine upland. In the winter of 1835 to 1836 he held some lectures in Munich. Schimper then assumed that there must have been global times of obliteration (\"Verödungszeiten\") with a cold climate and frozen water. Schimper spent the summer months of 1836 at Devens, near Bex, in the Swiss Alps with his former university friend Louis Agassiz (1801–1873) and Jean de Charpentier. Schimper, de Charpentier and possibly Venetz convinced Agassiz that there had been a time of glaciation. During the winter of 1836/37, Agassiz and Schimper developed the theory of a sequence of glaciations. They mainly drew upon the preceding works of Venetz, de Charpentier and on their own fieldwork. Agassiz appears to have been already familiar with Bernhardi's paper at that time. At the beginning of 1837, Schimper coined the term \"ice age\" (\"\"Eiszeit\"\") for the period of the glaciers. In July 1837 Agassiz presented their synthesis before the annual meeting of the Schweizerische Naturforschende Gesellschaft at Neuchâtel. The audience was very critical and some opposed to the new theory because it contradicted the established opinions on climatic history. Most contemporary scientists thought that the Earth had been gradually cooling down since its birth as a molten globe.\n\nIn order to overcome this rejection, Agassiz embarked on geological fieldwork. He published his book \"Study on Glaciers\" (\"Études sur les glaciers\") in 1840. De Charpentier was put out by this, as he had also been preparing a book about the glaciation of the Alps. De Charpentier felt that Agassiz should have given him precedence as it was he who had introduced Agassiz to in-depth glacial research. Besides that, Agassiz had, as a result of personal quarrels, omitted any mention of Schimper in his book.\n\nAll together, it took several decades until the ice age theory was fully accepted by scientists. This happened on an international scale in the second half of the 1870s following the work of James Croll, including the publication of \"Climate and Time, in Their Geological Relations\" in 1875, which provided a credible explanation for the causes of ice ages.\n\nThere are three main types of evidence for ice ages: geological, chemical, and paleontological.\n\nGeological evidence for ice ages comes in various forms, including rock scouring and scratching, glacial moraines, drumlins, valley cutting, and the deposition of till or tillites and glacial erratics. Successive glaciations tend to distort and erase the geological evidence, making it difficult to interpret. Furthermore, this evidence was difficult to date exactly; early theories assumed that the glacials were short compared to the long interglacials. The advent of sediment and ice cores revealed the true situation: glacials are long, interglacials short. It took some time for the current theory to be worked out.\n\nThe chemical evidence mainly consists of variations in the ratios of isotopes in fossils present in sediments and sedimentary rocks and ocean sediment cores. For the most recent glacial periods ice cores provide climate proxies from their ice, and atmospheric samples from included bubbles of air. Because water containing heavier isotopes has a higher heat of evaporation, its proportion decreases with colder conditions. This allows a temperature record to be constructed. This evidence can be confounded, however, by other factors recorded by isotope ratios.\n\nThe paleontological evidence consists of changes in the geographical distribution of fossils. During a glacial period cold-adapted organisms spread into lower latitudes, and organisms that prefer warmer conditions become extinct or are squeezed into lower latitudes. This evidence is also difficult to interpret because it requires (1) sequences of sediments covering a long period of time, over a wide range of latitudes and which are easily correlated; (2) ancient organisms which survive for several million years without change and whose temperature preferences are easily diagnosed; and (3) the finding of the relevant fossils.\n\nDespite the difficulties, analysis of ice core and ocean sediment cores has shown periods of glacials and interglacials over the past few million years. These also confirm the linkage between ice ages and continental crust phenomena such as glacial moraines, drumlins, and glacial erratics. Hence the continental crust phenomena are accepted as good evidence of earlier ice ages when they are found in layers created much earlier than the time range for which ice cores and ocean sediment cores are available.\n\nThere have been at least five major ice ages in the Earth's history (the Huronian, Cryogenian, Andean-Saharan, late Paleozoic, and the latest Quaternary Ice Age). Outside these ages, the Earth seems to have been ice free even in high latitudes; such periods are known as greenhouse periods.\n\nRocks from the earliest well established ice age, called the Huronian, formed around 2.4 to 2.1 Ga (billion years) ago during the early Proterozoic Eon. Several hundreds of km of the Huronian Supergroup are exposed 10–100 km north of the north shore of Lake Huron extending from near Sault Ste. Marie to Sudbury, northeast of Lake Huron, with giant layers of now-lithified till beds, dropstones, varves, outwash, and scoured basement rocks. Correlative Huronian deposits have been found near Marquette, Michigan, and correlation has been made with Paleoproterozoic glacial deposits from Western Australia. The Huronian ice age was caused by the elimination of atmospheric methane, a greenhouse gas, during the Great Oxygenation Event.\n\nThe next well-documented ice age, and probably the most severe of the last billion years, occurred from 720 to 630 million years ago (the Cryogenian period) and may have produced a Snowball Earth in which glacial ice sheets reached the equator, possibly being ended by the accumulation of greenhouse gases such as produced by volcanoes. \"The presence of ice on the continents and pack ice on the oceans would inhibit both silicate weathering and photosynthesis, which are the two major sinks for at present.\" It has been suggested that the end of this ice age was responsible for the subsequent Ediacaran and Cambrian explosion, though this model is recent and controversial.\n\nThe Andean-Saharan occurred from 460 to 420 million years ago, during the Late Ordovician and the Silurian period.\n\nThe evolution of land plants at the onset of the Devonian period caused a long term increase in planetary oxygen levels and reduction of levels, which resulted in the late Paleozoic icehouse. Its former name, the Karoo glaciation, was named after the glacial tills found in the Karoo region of South Africa. There were extensive polar ice caps at intervals from 360 to 260 million years ago in South Africa during the Carboniferous and early Permian Periods. Correlatives are known from Argentina, also in the center of the ancient supercontinent Gondwanaland.\n\nThe Quaternary Glaciation / Quaternary Ice Age started about 2.58 million years ago at the beginning of the Quaternary Period when the spread of ice sheets in the Northern Hemisphere began. Since then, the world has seen cycles of glaciation with ice sheets advancing and retreating on 40,000- and 100,000-year time scales called glacial periods, glacials or glacial advances, and interglacial periods, interglacials or glacial retreats. The earth is currently in an interglacial, and the last glacial period ended about 10,000 years ago. All that remains of the continental ice sheets are the Greenland and Antarctic ice sheets and smaller glaciers such as on Baffin Island.\n\nThe definition of the Quaternary as beginning 2.58 Ma is based on the formation of the Arctic ice cap. The Antarctic ice sheet began to form earlier, at about 34 Ma, in the mid-Cenozoic (Eocene-Oligocene Boundary). The term Late Cenozoic Ice Age is used to include this early phase.\n\nIce ages can be further divided by location and time; for example, the names \"Riss\" (180,000–130,000 years bp) and \"Würm\" (70,000–10,000 years bp) refer specifically to glaciation in the Alpine region. The maximum extent of the ice is not maintained for the full interval. The scouring action of each glaciation tends to remove most of the evidence of prior ice sheets almost completely, except in regions where the later sheet does not achieve full coverage.\n\nWithin the ice ages (or at least within the current one), more temperate and more severe periods occur. The colder periods are called \"glacial periods\", the warmer periods \"interglacials\", such as the Eemian Stage.\n\nGlacials are characterized by cooler and drier climates over most of the earth and large land and sea ice masses extending outward from the poles. Mountain glaciers in otherwise unglaciated areas extend to lower elevations due to a lower snow line. Sea levels drop due to the removal of large volumes of water above sea level in the icecaps. There is evidence that ocean circulation patterns are disrupted by glaciations. Since the earth has significant continental glaciation in the Arctic and Antarctic, we are currently in a glacial minimum of a glaciation. Such a period between glacial maxima is known as an \"interglacial\". The glacials and interglacials also coincided with changes in Earth's orbit called Milankovitch cycles.\n\nThe earth has been in an interglacial period known as the Holocene for around 11,700 years, and an article in \"Nature\" in 2004 argues that it might be most analogous to a previous interglacial that lasted 28,000 years. Predicted changes in orbital forcing suggest that the next glacial period would begin at least 50,000 years from now, due to the Milankovitch cycles. Moreover, anthropogenic forcing from increased greenhouse gases is estimated to potentially outweigh the orbital forcing of the Milankovitch cycles for hundreds of thousand of years.\n\nEach glacial period is subject to positive feedback which makes it more severe, and negative feedback which mitigates and (in all cases so far) eventually ends it.\n\nIce and snow increase Earth's albedo, i.e. they make it reflect more of the sun's energy and absorb less. Hence, when the air temperature decreases, ice and snow fields grow, and this continues until competition with a negative feedback mechanism forces the system to an equilibrium. Also, the reduction in forests caused by the ice's expansion increases albedo.\n\nAnother theory proposed by Ewing and Donn in 1956 hypothesized that an ice-free Arctic Ocean leads to increased snowfall at high latitudes. When low-temperature ice covers the Arctic Ocean there is little evaporation or sublimation and the polar regions are quite dry in terms of precipitation, comparable to the amount found in mid-latitude deserts. This low precipitation allows high-latitude snowfalls to melt during the summer. An ice-free Arctic Ocean absorbs solar radiation during the long summer days, and evaporates more water into the Arctic atmosphere. With higher precipitation, portions of this snow may not melt during the summer and so glacial ice can form at lower altitudes \"and\" more southerly latitudes, reducing the temperatures over land by increased albedo as noted above. Furthermore, under this hypothesis the lack of oceanic pack ice allows increased exchange of waters between the Arctic and the North Atlantic Oceans, warming the Arctic and cooling the North Atlantic. (Current projected consequences of global warming include a largely ice-free Arctic Ocean within 5–20 years, see Arctic shrinkage.) Additional fresh water flowing into the North Atlantic during a warming cycle may also reduce the global ocean water circulation. Such a reduction (by reducing the effects of the Gulf Stream) would have a cooling effect on northern Europe, which in turn would lead to increased low-latitude snow retention during the summer. It has also been suggested that during an extensive glacial, glaciers may move through the Gulf of Saint Lawrence, extending into the North Atlantic Ocean far enough to block the Gulf Stream.\n\nIce sheets that form during glaciations cause erosion of the land beneath them. After some time, this will reduce land above sea level and thus diminish the amount of space on which ice sheets can form. This mitigates the albedo feedback, as does the lowering in sea level that accompanies the formation of ice sheets.\n\nAnother factor is the increased aridity occurring with glacial maxima, which reduces the precipitation available to maintain glaciation. The glacial retreat induced by this or any other process can be amplified by similar inverse positive feedbacks as for glacial advances.\n\nAccording to research published in \"Nature Geoscience\", human emissions of carbon dioxide (CO) will defer the next ice age. Researchers used data on Earth's orbit to find the historical warm interglacial period that looks most like the current one and from this have predicted that the next ice age would usually begin within 1,500 years. They go on to say that emissions have been so high that it will not.\n\nThe causes of ice ages are not fully understood for either the large-scale ice age periods or the smaller ebb and flow of glacial–interglacial periods within an ice age. The consensus is that several factors are important: atmospheric composition, such as the concentrations of carbon dioxide and methane (the specific levels of the previously mentioned gases are now able to be seen with the new ice core samples from EPICA Dome C in Antarctica over the past 800,000 years); changes in the earth's orbit around the Sun known as Milankovitch cycles; the motion of tectonic plates resulting in changes in the relative location and amount of continental and oceanic crust on the earth's surface, which affect wind and ocean currents; variations in solar output; the orbital dynamics of the Earth–Moon system; the impact of relatively large meteorites and volcanism including eruptions of supervolcanoes.\n\nSome of these factors influence each other. For example, changes in Earth's atmospheric composition (especially the concentrations of greenhouse gases) may alter the climate, while climate change itself can change the atmospheric composition (for example by changing the rate at which weathering removes ).\n\nMaureen Raymo, William Ruddiman and others propose that the Tibetan and Colorado Plateaus are immense \"scrubbers\" with a capacity to remove enough from the global atmosphere to be a significant causal factor of the 40 million year Cenozoic Cooling trend. They further claim that approximately half of their uplift (and \"scrubbing\" capacity) occurred in the past 10 million years.\n\nThere is evidence that greenhouse gas levels fell at the start of ice ages and rose during the retreat of the ice sheets, but it is difficult to establish cause and effect (see the notes above on the role of weathering). Greenhouse gas levels may also have been affected by other factors which have been proposed as causes of ice ages, such as the movement of continents and volcanism.\n\nThe Snowball Earth hypothesis maintains that the severe freezing in the late Proterozoic was ended by an increase in levels in the atmosphere, mainly from volcanoes, and some supporters of Snowball Earth argue that it was caused in the first place by a reduction in atmospheric . The hypothesis also warns of future Snowball Earths.\n\nIn 2009, further evidence was provided that changes in solar insolation provide the initial trigger for the earth to warm after an Ice Age, with secondary factors like increases in greenhouse gases accounting for the magnitude of the change.\n\nThere is considerable evidence that over the very recent period of the last 100–1000 years, the sharp increases in human activity, especially the burning of fossil fuels, has caused the parallel sharp and accelerating increase in atmospheric greenhouse gases which trap the sun's heat. The consensus theory of the scientific community is that the resulting greenhouse effect is a principal cause of the increase in global warming which has occurred over the same period, and a chief contributor to the accelerated melting of the remaining glaciers and polar ice. A 2012 investigation finds that dinosaurs released methane through digestion in a similar amount to humanity's current methane release, which \"could have been a key factor\" to the very warm climate 150 million years ago.\n\nWilliam Ruddiman has proposed the early anthropocene hypothesis, according to which the anthropocene era, as some people call the most recent period in the earth's history when the activities of the human species first began to have a significant global impact on the earth's climate and ecosystems, did not begin in the 18th century with the advent of the Industrial Era, but dates back to 8,000 years ago, due to intense farming activities of our early agrarian ancestors. It was at that time that atmospheric greenhouse gas concentrations stopped following the periodic pattern of the Milankovitch cycles. In his overdue-glaciation hypothesis Ruddiman states that an incipient glacial would probably have begun several thousand years ago, but the arrival of that scheduled glacial was forestalled by the activities of early farmers.\n\nAt a meeting of the American Geophysical Union (December 17, 2008), scientists detailed evidence in support of the controversial idea that the introduction of large-scale rice agriculture in Asia, coupled with extensive deforestation in Europe began to alter world climate by pumping significant amounts of greenhouse gases into the atmosphere over the last 1,000 years. In turn, a warmer atmosphere heated the oceans making them much less efficient storehouses of carbon dioxide and reinforcing global warming, possibly forestalling the onset of a new glacial age.\n\nThe geological record appears to show that ice ages start when the continents are in positions which block or reduce the flow of warm water from the equator to the poles and thus allow ice sheets to form. The ice sheets increase Earth's reflectivity and thus reduce the absorption of solar radiation. With less radiation absorbed the atmosphere cools; the cooling allows the ice sheets to grow, which further increases reflectivity in a positive feedback loop. The ice age continues until the reduction in weathering causes an increase in the greenhouse effect.\n\nThere are three main contributors from the layout of the continents that obstruct the movement of warm water to the poles:\nBULLET::::- A continent sits on top of a pole, as Antarctica does today.\nBULLET::::- A polar sea is almost land-locked, as the Arctic Ocean is today.\nBULLET::::- A supercontinent covers most of the equator, as Rodinia did during the Cryogenian period.\n\nSince today's Earth has a continent over the South Pole and an almost land-locked ocean over the North Pole, geologists believe that Earth will continue to experience glacial periods in the geologically near future.\n\nSome scientists believe that the Himalayas are a major factor in the current ice age, because these mountains have increased Earth's total rainfall and therefore the rate at which carbon dioxide is washed out of the atmosphere, decreasing the greenhouse effect. The Himalayas' formation started about 70 million years ago when the Indo-Australian Plate collided with the Eurasian Plate, and the Himalayas are still rising by about 5 mm per year because the Indo-Australian plate is still moving at 67 mm/year. The history of the Himalayas broadly fits the long-term decrease in Earth's average temperature since the mid-Eocene, 40 million years ago.\n\nAnother important contribution to ancient climate regimes is the variation of ocean currents, which are modified by continent position, sea levels and salinity, as well as other factors. They have the ability to cool (e.g. aiding the creation of Antarctic ice) and the ability to warm (e.g. giving the British Isles a temperate as opposed to a boreal climate). The closing of the Isthmus of Panama about 3 million years ago may have ushered in the present period of strong glaciation over North America by ending the exchange of water between the tropical Atlantic and Pacific Oceans.\n\nAnalyses suggest that ocean current fluctuations can adequately account for recent glacial oscillations. During the last glacial period the sea-level has fluctuated 20–30 m as water was sequestered, primarily in the Northern Hemisphere ice sheets. When ice collected and the sea level dropped sufficiently, flow through the Bering Strait (the narrow strait between Siberia and Alaska is about 50 m deep today) was reduced, resulting in increased flow from the North Atlantic. This realigned the thermohaline circulation in the Atlantic, increasing heat transport into the Arctic, which melted the polar ice accumulation and reduced other continental ice sheets. The release of water raised sea levels again, restoring the ingress of colder water from the Pacific with an accompanying shift to northern hemisphere ice accumulation.\n\nMatthias Kuhle's geological theory of Ice Age development was suggested by the existence of an ice sheet covering the Tibetan Plateau during the Ice Ages (Last Glacial Maximum?). According to Kuhle, the plate-tectonic uplift of Tibet past the snow-line has led to a surface of c. 2,400,000 square kilometres (930,000 sq mi) changing from bare land to ice with a 70% greater albedo. The reflection of energy into space resulted in a global cooling, triggering the Pleistocene Ice Age. Because this highland is at a subtropical latitude, with 4 to 5 times the insolation of high-latitude areas, what would be Earth's strongest heating surface has turned into a cooling surface.\n\nKuhle explains the interglacial periods by the 100,000-year cycle of radiation changes due to variations in Earth's orbit. This comparatively insignificant warming, when combined with the lowering of the Nordic inland ice areas and Tibet due to the weight of the superimposed ice-load, has led to the repeated complete thawing of the inland ice areas.\n\nThe Milankovitch cycles are a set of cyclic variations in characteristics of the Earth's orbit around the Sun. Each cycle has a different length, so at some times their effects reinforce each other and at other times they (partially) cancel each other.\n\nThere is strong evidence that the Milankovitch cycles affect the occurrence of glacial and interglacial periods within an ice age. The present ice age is the most studied and best understood, particularly the last 400,000 years, since this is the period covered by ice cores that record atmospheric composition and proxies for temperature and ice volume. Within this period, the match of glacial/interglacial frequencies to the Milanković orbital forcing periods is so close that orbital forcing is generally accepted. The combined effects of the changing distance to the Sun, the precession of the Earth's axis, and the changing tilt of the Earth's axis redistribute the sunlight received by the Earth. Of particular importance are changes in the tilt of the Earth's axis, which affect the intensity of seasons. For example, the amount of solar influx in July at 65 degrees north latitude varies by as much as 22% (from 450 W/m² to 550 W/m²). It is widely believed that ice sheets advance when summers become too cool to melt all of the accumulated snowfall from the previous winter. Some believe that the strength of the orbital forcing is too small to trigger glaciations, but feedback mechanisms like may explain this mismatch.\n\nWhile Milankovitch forcing predicts that cyclic changes in the Earth's orbital elements can be expressed in the glaciation record, additional explanations are necessary to explain which cycles are observed to be most important in the timing of glacial–interglacial periods. In particular, during the last 800,000 years, the dominant period of glacial–interglacial oscillation has been 100,000 years, which corresponds to changes in Earth's orbital eccentricity and orbital inclination. Yet this is by far the weakest of the three frequencies predicted by Milankovitch. During the period 3.0–0.8 million years ago, the dominant pattern of glaciation corresponded to the 41,000-year period of changes in Earth's obliquity (tilt of the axis). The reasons for dominance of one frequency versus another are poorly understood and an active area of current research, but the answer probably relates to some form of resonance in the Earth's climate system. Recent work suggests that the 100K year cycle dominates due to increased southern-pole sea-ice increasing total solar reflectivity.\n\nThe \"traditional\" Milankovitch explanation struggles to explain the dominance of the 100,000-year cycle over the last 8 cycles. Richard A. Muller, Gordon J. F. MacDonald, and others have pointed out that those calculations are for a two-dimensional orbit of Earth but the three-dimensional orbit also has a 100,000-year cycle of orbital inclination. They proposed that these variations in orbital inclination lead to variations in insolation, as the Earth moves in and out of known dust bands in the solar system. Although this is a different mechanism to the traditional view, the \"predicted\" periods over the last 400,000 years are nearly the same. The Muller and MacDonald theory, in turn, has been challenged by Jose Antonio Rial.\n\nAnother worker, William Ruddiman, has suggested a model that explains the 100,000-year cycle by the modulating effect of eccentricity (weak 100,000-year cycle) on precession (26,000-year cycle) combined with greenhouse gas feedbacks in the 41,000- and 26,000-year cycles. Yet another theory has been advanced by Peter Huybers who argued that the 41,000-year cycle has always been dominant, but that the Earth has entered a mode of climate behavior where only the second or third cycle triggers an ice age. This would imply that the 100,000-year periodicity is really an illusion created by averaging together cycles lasting 80,000 and 120,000 years. This theory is consistent with a simple empirical multi-state model proposed by Didier Paillard. Paillard suggests that the late Pleistocene glacial cycles\ncan be seen as jumps between three quasi-stable climate states. The jumps are induced by the orbital forcing, while in the early Pleistocene the 41,000-year glacial cycles resulted from jumps between only two climate states. A dynamical\nmodel explaining this behavior was proposed by Peter Ditlevsen. This is in support of the suggestion that the late Pleistocene glacial cycles are not due to the weak 100,000-year eccentricity cycle, but a non-linear response to mainly the 41,000-year obliquity cycle.\n\nThere are at least two types of variation in the Sun's energy output\nBULLET::::- In the very long term, astrophysicists believe that the Sun's output increases by about 7% every one billion (10) years.\nBULLET::::- Shorter-term variations such as sunspot cycles, and longer episodes such as the Maunder Minimum, which occurred during the coldest part of the Little Ice Age.\n\nThe long-term increase in the Sun's output cannot be a cause of ice ages.\n\nVolcanic eruptions may have contributed to the inception and/or the end of ice age periods. At times during the paleoclimate, carbon dioxide levels were two or three times greater than today. Volcanoes and movements in continental plates contributed to high amounts of CO in the atmosphere. Carbon dioxide from volcanoes probably contributed to periods with highest overall temperatures. One suggested explanation of the Paleocene-Eocene Thermal Maximum is that undersea volcanoes released methane from clathrates and thus caused a large and rapid increase in the greenhouse effect. There appears to be no geological evidence for such eruptions at the right time, but this does not prove they did not happen.\n\nThe current geological period, the Quaternary, which began about 2.6 million years ago and extends into the present, is marked by warm and cold episodes, cold phases called glacials (Quaternary ice age) lasting about 100,000 years, and which are then interrupted by the warmer interglacials which lasted about 10,000–15,000 years. The last cold episode of the last glacial period ended about 10,000 years ago. Earth is currently in an interglacial period of the Quaternary, called the Holocene.\n\nThe major glacial stages of the current ice age in North America are the Illinoian, Eemian and Wisconsin glaciation. The use of the Nebraskan, Afton, Kansan, and Yarmouthian stages to subdivide the ice age in North America has been discontinued by Quaternary geologists and geomorphologists. These stages have all been merged into the Pre-Illinoian in the 1980s.\n\nDuring the most recent North American glaciation, during the latter part of the Last Glacial Maximum (26,000 to 13,300 years ago), ice sheets extended to about 45th parallel north. These sheets were thick.\nThis Wisconsin glaciation left widespread impacts on the North American landscape. The Great Lakes and the Finger Lakes were carved by ice deepening old valleys. Most of the lakes in Minnesota and Wisconsin were gouged out by glaciers and later filled with glacial meltwaters. The old Teays River drainage system was radically altered and largely reshaped into the Ohio River drainage system. Other rivers were dammed and diverted to new channels, such as Niagara Falls, which formed a dramatic waterfall and gorge, when the waterflow encountered a limestone escarpment. Another similar waterfall, at the present Clark Reservation State Park near Syracuse, New York, is now dry.\n\nThe area from Long Island to Nantucket, Massachusetts was formed from glacial till, and the plethora of lakes on the Canadian Shield in northern Canada can be almost entirely attributed to the action of the ice. As the ice retreated and the rock dust dried, winds carried the material hundreds of miles, forming beds of loess many dozens of feet thick in the Missouri Valley. Post-glacial rebound continues to reshape the Great Lakes and other areas formerly under the weight of the ice sheets.\n\nThe Driftless Area, a portion of western and southwestern Wisconsin along with parts of adjacent Minnesota, Iowa, and Illinois, was not covered by glaciers.\nA specially interesting climatic change during glacial times has taken place in the semi-arid Andes. Beside the expected cooling down in comparison with the current climate, a significant precipitation change happened here. So, researches in the presently semiarid subtropic Aconcagua-massif (6,962 m) have shown an unexpectedly extensive glacial glaciation of the type \"ice stream network\". The connected valley glaciers exceeding 100 km in length, flowed down on the East-side of this section of the Andes at 32–34°S and 69–71°W as far as a height of 2,060 m and on the western luff-side still clearly deeper. Where current glaciers scarcely reach 10 km in length, the snowline (ELA) runs at a height of 4,600 m and at that time was lowered to 3,200 m asl, i.e. about 1,400 m. From this follows that—beside of an annual depression of temperature about c. 8.4 °C— here was an increase in precipitation. Accordingly, at glacial times the humid climatic belt that today is situated several latitude degrees further to the S, was shifted much further to the N.\n\nAlthough the last glacial period ended more than 8,000 years ago, its effects can still be felt today. For example, the moving ice carved out the landscape in Canada (See Canadian Arctic Archipelago), Greenland, northern Eurasia and Antarctica. The erratic boulders, till, drumlins, eskers, fjords, kettle lakes, moraines, cirques, horns, etc., are typical features left behind by the glaciers.\n\nThe weight of the ice sheets was so great that they deformed the Earth's crust and mantle. After the ice sheets melted, the ice-covered land rebounded. Due to the high viscosity of the Earth's mantle, the flow of mantle rocks which controls the rebound process is very slow—at a rate of about 1 cm/year near the center of rebound area today.\n\nDuring glaciation, water was taken from the oceans to form the ice at high latitudes, thus global sea level dropped by about 110 meters, exposing the continental shelves and forming land-bridges between land-masses for animals to migrate. During deglaciation, the melted ice-water returned to the oceans, causing sea level to rise. This process can cause sudden shifts in coastlines and hydration systems resulting in newly submerged lands, emerging lands, collapsed ice dams resulting in salination of lakes, new ice dams creating vast areas of freshwater, and a general alteration in regional weather patterns on a large but temporary scale. It can even cause temporary reglaciation. This type of chaotic pattern of rapidly changing land, ice, saltwater and freshwater has been proposed as the likely model for the Baltic and Scandinavian regions, as well as much of central North America at the end of the last glacial maximum, with the present-day coastlines only being achieved in the last few millennia of prehistory. Also, the effect of elevation on Scandinavia submerged a vast continental plain that had existed under much of what is now the North Sea, connecting the British Isles to Continental Europe.\n\nThe redistribution of ice-water on the surface of the Earth and the flow of mantle rocks causes changes in the gravitational field as well as changes to the distribution of the moment of inertia of the Earth. These changes to the moment of inertia result in a change in the angular velocity, axis, and wobble of the Earth's rotation.\n\nThe weight of the redistributed surface mass loaded the lithosphere, caused it to flex and also induced stress within the Earth. The presence of the glaciers generally suppressed the movement of faults below. During deglaciation, the faults experience accelerated slip triggering earthquakes. Earthquakes triggered near the ice margin may in turn accelerate ice calving and may account for the Heinrich events. As more ice is removed near the ice margin, more intraplate earthquakes are induced and this positive feedback may explain the fast collapse of ice sheets.\n\nIn Europe, glacial erosion and isostatic sinking from weight of ice made the Baltic Sea, which before the Ice Age was all land drained by the Eridanos River.\n\nBULLET::::- Cracking the Ice Age from PBS\nBULLET::::- Historical Simulation\nBULLET::::- Eduard Y. Osipov, Oleg M. Khlystov. Glaciers and meltwater flux to Lake Baikal during the Last Glacial Maximum.\n"}
{"id": "15362", "url": "https://en.wikipedia.org/wiki?curid=15362", "title": "Irving Langmuir", "text": "Irving Langmuir\n\nIrving Langmuir (; January 31, 1881 – August 16, 1957) was an American chemist, physicist, and engineer. He was awarded the Nobel Prize in Chemistry in 1932 for his work in surface chemistry.\n\nLangmuir's most famous publication is the 1919 article \"The Arrangement of Electrons in Atoms and Molecules\" in which, building on Gilbert N. Lewis's cubical atom theory and Walther Kossel's chemical bonding theory, he outlined his \"concentric theory of atomic structure\". Langmuir became embroiled in a priority dispute with Lewis over this work; Langmuir's presentation skills were largely responsible for the popularization of the theory, although the credit for the theory itself belongs mostly to Lewis. While at General Electric from 1909 to 1950, Langmuir advanced several fields of physics and chemistry, invented the gas-filled incandescent lamp and the hydrogen welding technique. The Langmuir Laboratory for Atmospheric Research near Socorro, New Mexico, was named in his honor, as was the American Chemical Society journal for surface science called \"Langmuir\".\n\nIrving Langmuir was born in Brooklyn, New York, on January 31, 1881. He was the third of the four children of Charles Langmuir and Sadie, Comings. During his childhood, Langmuir's parents encouraged him to carefully observe nature and to keep a detailed record of his various observations. When Irving was eleven, it was discovered that he had poor eyesight. When this problem was corrected, details that had previously eluded him were revealed, and his interest in the complications of nature was heightened.\n\nDuring his childhood, Langmuir was influenced by his older brother, Arthur Langmuir. Arthur was a research chemist who encouraged Irving to be curious about nature and how things work. Arthur helped Irving set up his first chemistry lab in the corner of his bedroom, and he was content to answer the myriad questions that Irving would pose. Langmuir's hobbies included mountaineering, skiing, piloting his own plane, and classical music. In addition to his professional interest in the politics of atomic energy, he was concerned about wilderness conservation.\n\nLangmuir attended several schools and institutes in America and Paris (1892–1895) before graduating high school from Chestnut Hill Academy (1898), an elite private school located in the affluent Chestnut Hill area in Philadelphia. He graduated with a Bachelor of Science degree in metallurgical engineering (Met.E.) from the Columbia University School of Mines in 1903. He earned his Ph.D. in 1906 under Friedrich Dolezalek in Göttingen, for research done using the \"Nernst glower\", an electric lamp invented by Nernst. His doctoral thesis was entitled \"On the Partial Recombination of Dissolved Gases During Cooling.\" He later did postgraduate work in chemistry. Langmuir then taught at Stevens Institute of Technology in Hoboken, New Jersey, until 1909, when he began working at the General Electric research laboratory (Schenectady, New York).\n\nHis initial contributions to science came from his study of light bulbs (a continuation of his Ph.D. work). His first major development was the improvement of the diffusion pump, which ultimately led to the invention of the high-vacuum rectifier and amplifier tubes. A year later, he and colleague Lewi Tonks discovered that the lifetime of a tungsten filament could be greatly lengthened by filling the bulb with an inert gas, such as argon, the critical factor (overlooked by other researchers) being the need for extreme cleanliness in all stages of the process. He also discovered that twisting the filament into a tight coil improved its efficiency. These were important developments in the history of the incandescent light bulb. His work in surface chemistry began at this point, when he discovered that molecular hydrogen introduced into a tungsten-filament bulb dissociated into atomic hydrogen and formed a layer one atom thick on the surface of the bulb.\n\nHis assistant in vacuum tube research was his cousin William Comings White.\n\nAs he continued to study filaments in vacuum and different gas environments, he began to study the emission of charged particles from hot filaments (thermionic emission). He was one of the first scientists to work with plasmas, and he was the first to call these ionized gases by that name because they reminded him of blood plasma. Langmuir and Tonks discovered electron density waves in plasmas that are now known as Langmuir waves.\n\nHe introduced the concept of electron temperature and in 1924 invented the diagnostic method for measuring both temperature and density with an electrostatic probe, now called a Langmuir probe and commonly used in plasma physics. The current of a biased probe tip is measured as a function of bias voltage to determine the local plasma temperature and density. He also discovered atomic hydrogen, which he put to use by inventing the atomic hydrogen welding process; the first plasma weld ever made. Plasma welding has since been developed into gas tungsten arc welding.\n\nIn 1917, he published a paper on the chemistry of oil films that later became the basis for the award of the 1932 Nobel Prize in chemistry. Langmuir theorized that oils consisting of an aliphatic chain with a hydrophilic end group (perhaps an alcohol or acid) were oriented as a film one molecule thick upon the surface of water, with the hydrophilic group down in the water and the hydrophobic chains clumped together on the surface. The thickness of the film could be easily determined from the known volume and area of the oil, which allowed investigation of the molecular configuration before spectroscopic techniques were available.\n\nFollowing World War I Langmuir contributed to atomic theory and the understanding of atomic structure by defining the modern concept of valence shells and isotopes.\n\nLangmuir was president of the Institute of Radio Engineers in 1923.\n\nBased on his work at General Electric, John B. Taylor developed a detector ionizing beams of alkali metals, called nowadays the Langmuir-Taylor detector.\n\nHe joined Katharine B. Blodgett to study thin films and surface adsorption. They introduced the concept of a monolayer (a layer of material one molecule thick) and the two-dimensional physics which describe such a surface. In 1932 he received the Nobel Prize in Chemistry \"for his discoveries and investigations in surface chemistry.\"\n\nIn 1938, Langmuir's scientific interests began to turn to atmospheric science and meteorology. One of his first ventures, although tangentially related, was a refutation of the claim of entomologist Charles H. T. Townsend that the deer botfly flew at speeds of over 800 miles per hour. Langmuir estimated the fly's speed at 25 miles per hour.\n\nAfter observing windrows of drifting seaweed in the Sargasso Sea he discovered a wind-driven surface circulation in the sea. It is now called the Langmuir circulation.\n\nDuring World War II, Langmuir worked on improving naval sonar for submarine detection, and later to develop protective smoke screens and methods for deicing aircraft wings. This research led him to theorize that the introduction of dry ice and iodide into a sufficiently moist cloud of low temperature could induce precipitation (cloud seeding); though in frequent practice, particularly in Australia and the People's Republic of China, the efficiency of this technique remains controversial today.\n\nIn 1953 Langmuir coined the term \"pathological science\", describing research conducted with accordance to the scientific method, but tainted by unconscious bias or subjective effects. This is in contrast to pseudoscience, which has no pretense of following the scientific method. In his original speech, he presented ESP and flying saucers as examples of pathological science; since then, the label has been applied to polywater and cold fusion.\n\nHis house in Schenectady, was designated a National Historic Landmark in 1976.\n\nLangmuir was married to Marion Mersereau (1883-1971) in 1912 with whom he adopted two children: Kenneth and Barbara. After a short illness, he died in Woods Hole, Massachusetts from a heart attack on August 16, 1957. His obituary ran on the front page of \"The New York Times\".\n\nOn his religious views, Langmuir was an agnostic.\n\nAccording to author Kurt Vonnegut, Langmuir was the inspiration for his fictional scientist Dr. Felix Hoenikker in the novel \"Cat's Cradle\". The character's invention of ice-nine eventually destroyed the world. Langmuir had worked with Vonnegut's brother, Bernard Vonnegut.\n\nBULLET::::- Fellow of the American Academy of Arts and Sciences (1918)\nBULLET::::- Perkin Medal (1928)\nBULLET::::- Nobel Prize in Chemistry (1932)\nBULLET::::- Franklin Medal (1934)\nBULLET::::- Faraday Medal (1944)\nBULLET::::- John J. Carty Award of the National Academy of Sciences (1950)\nBULLET::::- Mount Langmuir (elevation 8022 ft / 2445m ) in Alaska is named after him (Chugach National Forest, Copper River, AK)\nBULLET::::- Langmuir College, a residential college at Stony Brook University in H-Quad, named for him in 1970\nBULLET::::- grandson, Roger R Summerhayes, directed/wrote/produced/edited a 57-minute documentary in 1999 called Langmuir's World\n\nBULLET::::- Langmuir, , \"\"Incandescent Electric Lamp\"\"\nBULLET::::- Langmuir, , \"\"Electron-discharge apparatus and method of operating the same\"\"\nBULLET::::- Langmuir, , \"\"Method of and apparatus for controlling x-ray tubes\"\"\n\nBULLET::::- 18-electron rule\nBULLET::::- Irving Langmuir House\nBULLET::::- Langmuir isotherm\nBULLET::::- Langmuir trough\nBULLET::::- Langmuir equation, an equation that relates the coverage or adsorption of molecules on a solid surface to gas pressure or concentration of a medium above the solid surface at a fixed temperature\nBULLET::::- Langmuir wave, a rapid oscillation of the electron density in conducting media such as plasmas or metals\nBULLET::::- Langmuir states, three-dimensional quantum states of Helium when both electrons move in phase on Bohr circular orbits and mutually repel\nBULLET::::- Langmuir–Blodgett film\nBULLET::::- Child–Langmuir law\nBULLET::::- Langmuir–Taylor detector\nBULLET::::- List of things named after Irving Langmuir\n\nBULLET::::- Langmuir Journal ACS Chemistry Journal of Surfaces and Colloids\nBULLET::::- \"\"Langmuir, Irving\"\" Infoplease.com.\nBULLET::::- \"\" Irving Langmuir's Ball Lightning Tube\"\". Ball Lightning Page. Science Hobbyist.\nBULLET::::- \"\"Irving Langmuir shows Whitney one of his inventions, the Pliotron tube. ca. 1920.\"\". Willis Rodney Whitney: the \"Father of basic research in industry\".\nBULLET::::- \"Pathological Science\" – noted lecture of 18 December 1953 at GE Labs\nBULLET::::- \"The Arrangement of Electrons in Atoms and Molecules\" JACS, Vol. 41, No. 6, 868.\nBULLET::::- \"The adsorption of gases on plane surfaces of glass, mica and platinum\" JACS, Vol. 40, No. 9, 1361.\nBULLET::::- \"Irving Langmuir a great physical Chemist\"; Resonance, July 2008\nBULLET::::- Key Participants: Irving Langmuir – \"Linus Pauling and the Nature of the Chemical Bond: A Documentary History\"\nBULLET::::- National Academy of Sciences Biographical Memoir\n"}
{"id": "15365", "url": "https://en.wikipedia.org/wiki?curid=15365", "title": "International Association of Travel Agents Network", "text": "International Association of Travel Agents Network\n\nThe International Airlines Travel Agent Network (IATAN) is an industry association in the USA designed to represent the interests of its member companies (airlines) and the U.S. travel distribution network (travel agencies). It is an independent department of the International Air Transport Association (IATA).\n\nIn addition, it (along with the IATA) is the body responsible for the standard international codes for airlines, airports, hotels, cities and car rental firms (for example, the three-character codes that designate London Heathrow Airport as LHR). These codes provide a method to link international travel network with international suppliers.\n\nBULLET::::- American Society of Travel Agents\nBULLET::::- IATA airport code\nBULLET::::- International Air Transport Association\nBULLET::::- List of airports\nBULLET::::- Travel agency\n"}
{"id": "15368", "url": "https://en.wikipedia.org/wiki?curid=15368", "title": "Insider trading", "text": "Insider trading\n\nInsider trading is the trading of a public company's stock or other securities (such as bonds or stock options) based on material nonpublic information about the company. In various countries, some kinds of trading based on insider information is illegal. This is because it is seen as unfair to other investors who do not have access to the information, as the investor with insider information could potentially make larger profits than a typical investor could make. The rules governing insider trading are complex and vary significantly from country to country. The extent of enforcement also varies from one country to another. The definition of insider in one jurisdiction can be broad, and may cover not only insiders themselves but also any persons related to them, such as brokers, associates, and even family members. A person who becomes aware of non-public information and trades on that basis may be guilty of a crime.\n\nTrading by specific insiders, such as employees, is commonly permitted as long as it does not rely on material information not in the public domain. Many jurisdictions require that such trading be reported so that the transactions can be monitored. In the United States and several other jurisdictions, trading conducted by corporate officers, key employees, directors, or significant shareholders must be reported to the regulator or publicly disclosed, usually within a few business days of the trade. In these cases, insiders in the United States are required to file a Form 4 with the U.S. Securities and Exchange Commission (SEC) when buying or selling shares of their own companies. The authors of one study claim that illegal insider trading raises the cost of capital for securities issuers, thus decreasing overall economic growth. However, some economists, such as Henry Manne, have argued that insider trading should be allowed and could, in fact, benefit markets.\n\nThere has long been \"considerable academic debate\" among business and legal scholars over whether or not insider trading should be illegal. Several arguments against outlawing insider trading have been identified: for example, although insider trading is illegal, most insider trading is never detected by law enforcement, and thus the illegality of insider trading might give the public the potentially misleading impression that \"stock market trading is an unrigged game that anyone can play.\" Some legal analysis has questioned whether insider trading actually harms anyone in the legal sense, since some have questioned whether insider trading causes anyone to suffer an actual \"loss,\" and whether anyone who suffers a loss is owed an actual legal duty by the insiders in question.\n\nRules prohibiting or criminalizing insider trading on material non-public information exist in most jurisdictions around the world (Bhattacharya and Daouk, 2002), but the details and the efforts to enforce them vary considerably. In the United States, Sections 16(b) and 10(b) of the Securities Exchange Act of 1934 directly and indirectly address insider trading. The U.S. Congress enacted this law after the stock market crash of 1929. While the United States is generally viewed as making the most serious efforts to enforce its insider trading laws, the broader scope of the European model legislation provides a stricter framework against illegal insider trading. In the European Union and the United Kingdom all trading on non-public information is, under the rubric of market abuse, subject at a minimum to civil penalties and to possible criminal penalties as well. UK's Financial Conduct Authority has the responsibility to investigate and prosecute insider dealing, defined by the Criminal Justice Act 1993.\n\nIn the United States, Canada, Australia and Germany, for mandatory reporting purposes, corporate insiders are defined as a company's officers, directors and any beneficial owners of more than 10% of a class of the company's equity securities. Trades made by these types of insiders in the company's own stock, based on material non-public information, are considered fraudulent since the insiders are violating the fiduciary duty that they owe to the shareholders. The corporate insider, simply by accepting employment, has undertaken a legal obligation to the shareholders to put the shareholders' interests before their own, in matters related to the corporation. When insiders buy or sell based upon company-owned information, they are said to be violating their obligation to the shareholders.\n\nFor example, illegal insider trading would occur if the chief executive officer of Company A learned (prior to a public announcement) that Company A will be taken over and then bought shares in Company A while knowing that the share price would likely rise.\n\nIn the United States and many other jurisdictions, however, \"insiders\" are not just limited to corporate officials and major shareholders where illegal insider trading is concerned but can include any individual who trades shares based on material non-public information in violation of some duty of trust. This duty may be imputed; for example, in many jurisdictions, in cases of where a corporate insider \"tips\" a friend about non-public information likely to have an effect on the company's share price, the duty the corporate insider owes the company is now imputed to the friend and the friend violates a duty to the company if he trades on the basis of this information.\n\nLiability for inside trading violations generally cannot be avoided by passing on the information in an \"I scratch your back; you scratch mine\" or \"quid pro quo\" arrangement if the person receiving the information knew or should have known that the information was material non-public information. In the United States, at least one court has indicated that the insider who releases the non-public information must have done so for an improper purpose. In the case of a person who receives the insider information (called the \"tippee\"), the tippee must also have been aware that the insider released the information for an improper purpose.\n\nOne commentator has argued that if Company A's CEO did not trade on undisclosed takeover news, but instead passed the information on to his brother-in-law who traded on it, illegal insider trading would still have occurred (albeit by proxy, by passing it on to a \"non-insider\" so Company A's CEO would not get his hands dirty).\n\nA newer view of insider trading, the misappropriation theory, is now accepted in U.S. law. It states that anyone who misappropriates information from his or her employer and trades on that information in \"any\" stock (either the employer's stock or the company's competitor stocks) may be guilty of insider trading.\n\nProving that someone has been responsible for a trade can be difficult because traders may try to hide behind nominees, offshore companies, and other proxies. The Securities and Exchange Commission (SEC) prosecutes over 50 cases each year, with many being settled administratively out of court. The SEC and several stock exchanges actively monitor trading, looking for suspicious activity. The SEC does not have criminal enforcement authority, but can refer serious matters to the U.S. Attorney's Office for further investigation and prosecution.\n\nIn the United States and most non-European jurisdictions not all trading on non-public information is illegal insider trading. For example, a person in a restaurant who hears the CEO of Company A at the next table tell the CFO that the company's profits will be higher than expected and then buys the stock is not guilty of insider trading—unless he or she had some closer connection to the company or company officers. However, even where the tippee is not himself an insider, where the tippee knows that the information is non-public and the information is paid for, or the tipper receives a benefit for giving it, then in the broader-scope jurisdictions the subsequent trading is illegal.\n\nNotwithstanding, information about a tender offer (usually regarding a merger or acquisition) is held to a higher standard. If this type of information is obtained (directly or indirectly) and there is reason to believe it is nonpublic, there is a duty to disclose it or abstain from trading.\n\nIn the United States in addition to civil penalties, the trader may also be subject to criminal prosecution for fraud or where SEC regulations have been broken, the U.S. Department of Justice (DOJ) may be called to conduct an independent parallel investigation. If the DOJ finds criminal wrongdoing, the Department may file criminal charges.\n\nLegal trades by insiders are common, as employees of publicly traded corporations often have stock or stock options. These trades are made public in the United States through Securities and Exchange Commission filings, mainly Form 4.\n\nU.S. SEC Rule 10b5-1 clarified that the prohibition against insider trading does not require proof that an insider actually used material nonpublic information when conducting a trade; possession of such information alone is sufficient to violate the provision, and the SEC would infer that an insider in possession of material nonpublic information used this information when conducting a trade. However, SEC Rule 10b5-1 also created for insiders an affirmative defense if the insider can demonstrate that the trades conducted on behalf of the insider were conducted as part of a pre-existing contract or written binding plan for trading in the future.\n\nFor example, if an insider expects to retire after a specific period of time and, as part of retirement planning, the insider has adopted a written binding plan to sell a specific amount of the company's stock every month for two years, and the insider later comes into possession of material nonpublic information about the company, trades based on the original plan might not constitute prohibited insider trading.\n\nUntil the 21st century and the European Union's market abuse laws, the United States was the leading country in prohibiting insider trading made on the basis of material non-public information. Thomas Newkirk and Melissa Robertson of the SEC summarize the development of US insider trading laws. Insider trading has a base offense level of 8, which puts it in Zone A under the U.S. Sentencing Guidelines. This means that first-time offenders are eligible to receive probation rather than incarceration.\n\nU.S. insider trading prohibitions are based on English and American common law prohibitions against fraud. In 1909, well before the Securities Exchange Act was passed, the United States Supreme Court ruled that a corporate director who bought that company's stock when he knew the stock's price was about to increase committed fraud by buying but not disclosing his inside information.\n\nSection 15 of the Securities Act of 1933 contained prohibitions of fraud in the sale of securities, later greatly strengthened by the Securities Exchange Act of 1934.\n\nSection 16(b) of the Securities Exchange Act of 1934 prohibits short-swing profits (from any purchases and sales within any six-month period) made by corporate directors, officers, or stockholders owning more than 10% of a firm's shares. Under Section 10(b) of the 1934 Act, SEC Rule 10b-5, prohibits fraud related to securities trading.\n\nThe Insider Trading Sanctions Act of 1984 and the Insider Trading and Securities Fraud Enforcement Act of 1988 place penalties for illegal insider trading as high as three times the amount of profit gained or loss avoided from the illegal trading.\n\nSEC regulation FD (\"Fair Disclosure\") requires that if a company intentionally discloses material non-public information to one person, it must simultaneously disclose that information to the public at large. In the case of an unintentional disclosure of material non-public information to one person, the company must make a public disclosure \"promptly.\"\n\nInsider trading, or similar practices, are also regulated by the SEC under its rules on takeovers and tender offers under the Williams Act.\n\nMuch of the development of insider trading law has resulted from court decisions.\n\nIn 1909, the Supreme Court of the United States ruled in \"Strong v. Repide\" that a director who expects to act in a way that affects the value of shares cannot use that knowledge to acquire shares from those who do not know of the expected action. Even though, in general, ordinary relations between directors and shareholders in a business corporation are not of such a fiduciary nature as to make it the duty of a director to disclose to a shareholder general knowledge regarding the value of the shares of the company before he purchases any from a shareholder, some cases involve special facts that impose such duty.\n\nIn 1968, the Second Circuit Court of Appeals advanced a \"level playing field\" theory of insider trading in \"SEC v. Texas Gulf Sulphur Co.\" The court stated that anyone in possession of inside information must either disclose the information or refrain from trading. Officers of the Texas Gulf Sulphur Company had used inside information about the discovery of the Kidd Mine to make profits by buying shares and call options on company stock.\n\nIn 1984, the Supreme Court of the United States ruled in the case of \"Dirks v. Securities and Exchange Commission\" that tippees (receivers of second-hand information) are liable if they had reason to believe that the tipper had breached a fiduciary duty in disclosing confidential information. One such example would be if the tipper received any personal benefit from the disclosure, thereby breaching his or her duty of loyalty to the company. In \"Dirks\", the \"tippee\" received confidential information from an insider, a former employee of a company. The reason the insider disclosed the information to the tippee, and the reason the tippee disclosed the information to third parties, was to blow the whistle on massive fraud at the company. As a result of the tippee's efforts the fraud was uncovered, and the company went into bankruptcy. But, while the tippee had given the \"inside\" information to clients who made profits from the information, the U.S. Supreme Court ruled that the tippee could not be held liable under the federal securities laws—for the simple reason that the insider from whom he received the information was not releasing the information for an improper purpose (a personal benefit), but rather for the purpose of exposing the fraud. The Supreme Court ruled that the tippee could not have been aiding and abetting a securities law violation committed by the insider—for the simple reason that no securities law violation had been committed by the insider.\n\nIn \"Dirks\", the Supreme Court also defined the concept of \"constructive insiders,\" who are lawyers, investment bankers, and others who receive confidential information from a corporation while providing services to the corporation. Constructive insiders are also liable for insider trading violations if the corporation expects the information to remain confidential, since they acquire the fiduciary duties of the true insider.\n\nThe next expansion of insider trading liability came in \"SEC vs. Materia\" 745 F.2d 197 (2d Cir. 1984), the case that first introduced the misappropriation theory of liability for insider trading. Materia, a financial printing firm proofreader, and clearly not an insider by any definition, was found to have determined the identity of takeover targets based on proofreading tender offer documents during his employment. After a two-week trial, the district court found him liable for insider trading, and the Second Circuit Court of Appeals affirmed holding that the theft of information from an employer, and the use of that information to purchase or sell securities in another entity, constituted a fraud in connection with the purchase or sale of a securities. The misappropriation theory of insider trading was born, and liability further expanded to encompass a larger group of outsiders.\n\nIn \"United States v. Carpenter\" (1986) the U.S. Supreme Court cited an earlier ruling while unanimously upholding mail and wire fraud convictions for a defendant who received his information from a journalist rather than from the company itself. The journalist R. Foster Winans was also convicted, on the grounds that he had misappropriated information belonging to his employer, the \"Wall Street Journal\". In that widely publicized case, Winans traded in advance of \"Heard on the Street\" columns appearing in the Journal.\n\nThe Court stated in \"Carpenter\": \"It is well established, as a general proposition, that a person who acquires special knowledge or information by virtue of a confidential or fiduciary relationship with another is not free to exploit that knowledge or information for his own personal benefit but must account to his principal for any profits derived therefrom.\"\n\nHowever, in upholding the securities fraud (insider trading) convictions, the justices were evenly split.\n\nIn 1997, the U.S. Supreme Court adopted the misappropriation theory of insider trading in \"United States v. O'Hagan\", 521 U.S. 642, 655 (1997). O'Hagan was a partner in a law firm representing Grand Metropolitan, while it was considering a tender offer for Pillsbury Company. O'Hagan used this inside information by buying call options on Pillsbury stock, resulting in profits of over $4.3 million. O'Hagan claimed that neither he nor his firm owed a fiduciary duty to Pillsbury, so he did not commit fraud by purchasing Pillsbury options.\n\nThe Court rejected O'Hagan's arguments and upheld his conviction.\n\nThe \"misappropriation theory\" holds that a person commits fraud \"in connection with\" a securities transaction and thereby violates 10(b) and Rule 10b-5, when he misappropriates confidential information for securities trading purposes, in breach of a duty owed to the source of the information. Under this theory, a fiduciary's undisclosed, self-serving use of a principal's information to purchase or sell securities, in breach of a duty of loyalty and confidentiality, defrauds the principal of the exclusive use of the information. In lieu of premising liability on a fiduciary relationship between company insider and purchaser or seller of the company's stock, the misappropriation theory premises liability on a fiduciary-turned-trader's deception of those who entrusted him with access to confidential information.\n\nThe Court specifically recognized that a corporation's information is its property: \"A company's confidential information ... qualifies as property to which the company has a right of exclusive use. The undisclosed misappropriation of such information in violation of a fiduciary duty ... constitutes fraud akin to embezzlement – the fraudulent appropriation to one's own use of the money or goods entrusted to one's care by another.\"\n\nIn 2000, the SEC enacted SEC Rule 10b5-1, which defined trading \"on the basis of\" inside information as any time a person trades while aware of material nonpublic information. It is no longer a defense for one to say that one would have made the trade anyway. The rule also created an affirmative defense for pre-planned trades.\n\nIn \"Morgan Stanley v. Skowron\", 989 F. Supp. 2d 356 (S.D.N.Y. 2013), applying New York's faithless servant doctrine, the court held that a hedge fund's portfolio manager engaging in insider trading in violation of his company's code of conduct, which also required him to report his misconduct, must repay his employer the full $31 million his employer paid him as compensation during his period of faithlessness. The court called the insider trading the \"ultimate abuse of a portfolio manager's position.\" The judge also wrote: \"In addition to exposing Morgan Stanley to government investigations and direct financial losses, Skowron's behavior damaged the firm's reputation, a valuable corporate asset.\"\n\nIn 2014, in the case of \"United States v. Newman\", the United States Court of Appeals for the Second Circuit cited the Supreme Court's decision in \"Dirks\", and ruled that for a \"tippee\" (a person who used information they received from an insider) to be guilty of insider trading, the tippee must have been aware not only that the information was insider information, but must also have been aware that the insider released the information for an improper purpose (such as a personal benefit). The Court concluded that the insider's breach of a fiduciary duty not to release confidential information—in the absence of an improper purpose on the part of the insider—is not enough to impose criminal liability on either the insider or the tippee.\n\nIn 2016, in the case of \"Salman v. United States\", the U.S. Supreme Court held that the benefit a tipper must receive as predicate for an insider-trader prosecution of a tippee need not be pecuniary, and that giving a 'gift' of a tip to a family member is presumptively an act for the personal though intangible benefit of the tipper.\n\nMembers of the US Congress are exempt from the laws that ban insider trading. Because they generally do not have a confidential relationship with the source of the information they receive, however, they do not meet the usual definition of an \"insider.\" House of Representatives rules may however consider congressional insider trading unethical. A 2004 study found that stock sales and purchases by Senators outperformed the market by 12.3% per year. Peter Schweizer points out several examples of insider trading by members of Congress, including action taken by Spencer Bachus following a private, behind-the-doors meeting on the evening of September 18, 2008 when Hank Paulson and Ben Bernanke informed members of Congress about the issues due to the financial crisis of 2007–2008, Bachus then shorted stocks the next morning and cashed in his profits within a week. Also attending the same meeting were Senator Dick Durbin and John Boehner; the same day (trade effective the next day), Durbin sold mutual-fund shares worth $42,696, and reinvested it all with Warren Buffett. Also the same day (trade effective the next day), Congressman Boehner cashed out of an equity mutual fund.\n\nIn May 2007, a bill entitled the \"Stop Trading on Congressional Knowledge Act, or STOCK Act\" was introduced that would hold congressional and federal employees liable for stock trades they made using information they gained through their jobs and also regulate analysts or \"Political Intelligence\" firms that research government activities. The 2012 STOCK Act was passed on April 4, 2012.\n\nSome economists and legal scholars (such as Henry Manne, Milton Friedman, Thomas Sowell, Daniel Fischel, and Frank H. Easterbrook) have argued that laws against insider trading should be repealed. They claim that insider trading based on material nonpublic information benefits investors, in general, by more quickly introducing new information into the market.\n\nFriedman, laureate of the Nobel Memorial Prize in Economics, said: \"You want more insider trading, not less. You want to give the people most likely to have knowledge about deficiencies of the company an incentive to make the public aware of that.\" Friedman did not believe that the trader should be required to make his trade known to the public, because the buying or selling pressure itself is information for the market.\n\nOther critics argue that insider trading is a victimless act: a willing buyer and a willing seller agree to trade property that the seller rightfully owns, with no prior contract (according to this view) having been made between the parties to refrain from trading if there is asymmetric information. \"The Atlantic\" has described the process as \"arguably the closest thing that modern finance has to a victimless crime.\"\n\nLegalization advocates also question why \"trading\" where one party has more information than the other is legal in other markets, such as real estate, but not in the stock market. For example, if a geologist knows there is a high likelihood of the discovery of petroleum under Farmer Smith's land, he may be entitled to make Smith an offer for the land, and buy it, without first telling Farmer Smith of the geological data.\n\nAdvocates of legalization make free speech arguments. Punishment for communicating about a development pertinent to the next day's stock price might seem an act of censorship. If the information being conveyed is proprietary information and the corporate insider has contracted to not expose it, he has no more right to communicate it than he would to tell others about the company's confidential new product designs, formulas, or bank account passwords.\n\nSome authors have used these arguments to propose legalizing insider trading on negative information (but not on positive information). Since negative information is often withheld from the market, trading on such information has a higher value for the market than trading on positive information.\n\nThere are very limited laws against \"insider trading\" in the commodities markets if, for no other reason than that the concept of an \"insider\" is not immediately analogous to commodities themselves (corn, wheat, steel, etc.). However, analogous activities such as front running are illegal under US commodity and futures trading laws. For example, a commodity broker can be charged with fraud for receiving a large purchase order from a client (one likely to affect the price of that commodity) and then purchasing that commodity before executing the client's order to benefit from the anticipated price increase.\n\nThe advent of the Internet has provided a forum for the commercialisation of trading on insider information. In 2016 a number of dark web sites were identified as marketplaces where such non-public information was bought and sold. At least one such site used bitcoins to avoid currency restrictions and to impede tracking. Such sites also provide a place for soliciting for corporate informants, where non-public information may be used for purposes other than stock trading.\n\nThe US and the UK vary in the way the law is interpreted and applied with regard to insider trading. In the UK, the relevant laws are the Criminal Justice Act 1993, Part V, Schedule 1; the Financial Services and Markets Act 2000, which defines an offence of \"Market Abuse\"; and the European Union Regulation No 596/2014. The principle is that it is illegal to trade on the basis of market-sensitive information that is not generally known. This is a much broader scope that under U.S. law. The key differences from U.S. law are that no relationship to either the issuer of the security or the tipster is required; all that is required is that the guilty party traded (or caused trading) whilst having inside information, and there is no \"scienter\" requirement under UK law.\n\nJapan enacted its first law against insider trading in 1988. Roderick Seeman said, \"Even today many Japanese do not understand why this is illegal. Indeed, previously it was regarded as common sense to make a profit from your knowledge.\"\n\nIn Malta the law follows the European broader scope model. The relevant statute is the Prevention of Financial Markets Abuse Act of 2005, as amended. Earlier acts included the Financial Markets Abuse Act in 2002, and the Insider Dealing and Market Abuse Act of 1994.\n\nThe International Organization of Securities Commissions (IOSCO) paper on the \"Objectives and Principles of Securities Regulation\" (updated to 2003) states that the three objectives of good securities market regulation are investor protection, ensuring that markets are fair, efficient and transparent, and reducing systemic risk.\n\nThe discussion of these \"Core Principles\" state that \"investor protection\" in this context means \"Investors should be protected from misleading, manipulative or fraudulent practices, including insider trading, front running or trading ahead of customers and the misuse of client assets.\" More than 85 percent of the world's securities and commodities market regulators are members of IOSCO and have signed on to these Core Principles.\n\nThe World Bank and International Monetary Fund now use the IOSCO Core Principles in reviewing the financial health of different country's regulatory systems as part of these organization's financial sector assessment program, so laws against insider trading based on non-public information are now expected by the international community. Enforcement of insider trading laws varies widely from country to country, but the vast majority of jurisdictions now outlaw the practice, at least in principle.\n\nLarry Harris claims that differences in the effectiveness with which countries restrict insider trading help to explain the differences in executive compensation among those countries. The US, for example, has much higher CEO salaries than do Japan or Germany, where insider trading is less effectively restrained.\n\nIn 2014, the European Union (EU) adopted legislation (Criminal Sanctions for Market Abuse Directive) that harmonised criminal sanctions for insider dealing. All EU Member States agreed to introduce maximum prison sentences of at least four years for serious cases of market manipulation and insider dealing, and at least two years for improper disclosure of insider information.\n\nIn 2009, a journalist in Nettavisen (Thomas Gulbrandsen) was sentenced to 4 months in prison for insider trading.\n\nThe longest prison sentence in a Norwegian trial where the main charge was insider trading, was for eight years (two suspended) when Alain Angelil was convicted in a district court on December 9, 2011.\n\nAlthough insider trading in the UK has been illegal since 1980, it proved difficult to successfully prosecute individuals accused of insider trading. There were a number of notorious cases where individuals were able to escape prosecution. Instead the UK regulators relied on a series of fines to punish market abuses.\n\nThese fines were widely perceived as an ineffective deterrent (Cole, 2007), and there was a statement of intent by the UK regulator (the Financial Services Authority) to use its powers to enforce the legislation (specifically the Financial Services and Markets Act 2000). Between 2009–2012 the FSA secured 14 convictions in relation to insider dealing.\n\nAnil Kumar, a senior partner at management consulting firm McKinsey & Company, pleaded guilty in 2010 to insider trading in a \"descent from the pinnacle of the business world.\"\n\nChip Skowron, a hedge fund co-portfolio manager of FrontPoint Partners LLC's health care funds, was convicted of insider trading in 2011, for which he served five years in prison. He had been tipped off by a consultant to a company that the company was about to make a negative announcement regarding its clinical trial for a drug. At first Skowron denied the charges against him, and his defense attorney said he would plead not guilty, saying \"We look forward to responding to the allegations more fully in court at the appropriate time\". However, after the consultant charged with tipping him off pleaded guilty, he changed his position, and admitted his guilt.\n\nRajat Gupta, who had been managing partner of McKinsey & Co. and a director at Goldman Sachs Group Inc. and Procter & Gamble Co., was convicted by a federal jury in 2012 and sentence to two years in prison for leaking inside information to hedge fund manager Raj Rajaratnam who was sentenced to 11 years in prison. The case was prosecuted by the office of United States Attorney for the Southern District of New York Preet Bharara.\n\nMathew Martoma, former hedge fund trader and portfolio manager at S.A.C. Capital Advisors, was accused of generating possibly the largest single insider trading transaction profit in history at a value of $276 million. He was convicted in February 2014, and is serving a nine-year prison sentence.\n\nWith the guilty plea by Perkins Hixon in 2014 for insider trading from 2010–2013 while at Evercore Partners, Bharara said in a press release that 250 defendants whom his office had charged since August 2009 had now been convicted.\n\nOn December 10, 2014, a federal appeals court overturned the insider trading convictions of two former hedge fund traders, Todd Newman and Anthony Chiasson, based on the \"erroneous\" instructions given to jurors by the trial judge. The decision was expected to affect the appeal of the separate insider-trading conviction of former SAC Capital portfolio manager Michael Steinberg and the U.S. Attorney and the SEC in 2015 did drop their cases against Steinberg and others.\n\nIn 2016, Sean Stewart, a former managing director at Perella Weinberg Partners LP and vice president at JPMorgan Chase, was convicted on allegations he tipped his father on pending health-care deals. The father, Robert Stewart, previously had pleaded guilty but didn't testify during his son's trial. It was argued that by way of compensation for the tip, the father had paid more than $10,000 for Sean's wedding photographer.\n\nIn 2017, Billy Walters, Las Vegas sports bettor, was convicted of making $40 million on private information of Dallas-based dairy processing company Dean Foods, and sentenced to five years in prison. Walters's source, company director Thomas C. Davis employing a prepaid cell phone and sometimes the code words \"Dallas Cowboys\" for Dean Foods, helped him from 2008 to 2014 realize profits and avoid losses in the stock, the federal jury found. Golfer Phil Mickelson \"was also mentioned during the trial as someone who had traded in Dean Foods shares and once owed nearly $2 million in gambling debts to\" Walters. Mickelson \"made roughly $1 million trading Dean Foods shares; he agreed to forfeit those profits in a related civil case brought by the Securities and Exchange Commission\". Walters appealed the verdict, but in December 2018 his conviction was upheld by the 2nd U.S. Circuit Court of Appeals in Manhattan.\n\nIn 2008, police uncovered an insider trading conspiracy involving Bay Street and Wall Street lawyer Gil Cornblum who had worked at Sullivan & Cromwell and was working at Dorsey & Whitney, and a former lawyer, Stan Grmovsek, who were found to have gained over $10 million in illegal profits over a 14-year span. Cornblum committed suicide by jumping from a bridge as he was under investigation and shortly before he was to be arrested but before criminal charges were laid against him, one day before his alleged co-conspirator Grmovsek pled guilty. Grmovsek pleaded guilty to insider trading and was sentenced to 39 months in prison. This was the longest term ever imposed for insider trading in Canada. These crimes were explored in Mark Coakley's 2011 non-fiction book, \"Tip and Trade\".\n\nThe U.S. SEC alleged that in 2009 Kuwaiti trader Hazem Al-Braikan engaged in insider trading after misleading the public about possible takeover bids for two companies. Three days after Al-Braikan was sued by the SEC, he was found dead of a gunshot wound to the head in his home in Kuwait City on July 26, 2009, in what Kuwaiti police called a suicide. The SEC later reached a $6.5 million settlement of civil insider trading charges, with his estate and others.\n\nThe majority of shares in China before 2005 were non-tradeable shares that were not sold on the stock exchange publicly but privately. To make shares more accessible, the China Securities Regulation Commission (CSRC) required the companies to convert the non-tradeable shares into tradeable shares. There was a deadline for companies to convert their shares and the deadline was short, due to this there was a massive amount of exchanges and in the midst of these exchanges many people committed insider trading knowing that the selling of these shares would affect prices. Chinese people did not fear insider trading as much as one may in the United States because there is no possibility of imprisonment. Punishment may include monetary fees or temporary relieving from a position in the company. The Chinese do not view insider trading as a crime worth prison time because generally the person has a clean record and a path of success with references to deter them from being viewed as a criminal. On October 1, 2015, Chinese fund manager Xu Xiang was arrested due to insider trading.\n\nInsider trading in India is an offense according to Sections 12A, 15G of the Securities and Exchange Board of India Act, 1992. Insider trading is when one with access to non-public, price-sensitive information about the securities of the company subscribes, buys, sells, or deals, or agrees to do so or counsels another to do so as principal or agent. Price-sensitive information is information that materially affects the value of the securities. The penalty for insider trading is imprisonment, which may extend to five years, and a minimum of five lakh rupees (500,000) to 25 crore rupees (250 million) or three times the profit made, whichever is higher.\n\n\"The Wall Street Journal\", in a 2014 article entitled \"Why It’s Hard to Catch India’s Insider Trading,\" said that despite a widespread belief that insider trading takes place on a regular basis in India, there were few examples of insider traders being prosecuted in India. One former top regulator said that in India insider trading is deeply rooted and especially rampant because regulators don't have the tools to address it. In the few cases where prosecution has taken place, cases have sometimes taken more than a decade to reach trial, and punishments have been light; and despite SEBI by law having the ability to demand penalties of up to $4 million, the few fines that were levied for insider trading have usually been under $200,000.\n\nThe current Australian legislation arose out of the report of a 1989 parliamentary committee report which recommended removal of the requirement that the trader be ‘connected’ with the body corporate.. This may have weakened the importance of the fiduciary duty rationale and possibly brought new potential offenders within its ambit. In Australia if a person possesses inside information and knows, or ought reasonably to know, that the information is not generally available and is materially price sensitive then the insider must not trade. Nor must she or he procure another to trade and must not tip another. Information will be considered generally available if it consists of readily observable matter or it has been made known to common investors and a reasonable period for it to be disseminated among such investors has elapsed.\n\nUnder Republic Act 8799 or the Securities Regulation Code, insider trading in the Philippines is illegal.\n\nBULLET::::- Mark J. Astarita, Insider Trading: Legal vs. Illegal Insider trading: Legal vs. Illegal,\nBULLET::::- Stephen M. Bainbridge, Securities Law: Insider Trading (1999) .\nBULLET::::- M. Duffy, Insider Trading: Addressing the Continuing Problems of Proof (2009) 23(2) \"Australian Journal of Corporate Law\" 149. (link).\nBULLET::::- Larry Harris, Trading & Exchanges, Oxford Press, Oxford, 2003. Chapter 29 \"Insider Trading\" .\nBULLET::::- Grechenig, The Marginal Incentive of Insider Trading: an Economics Reinterpretation of the Case Law, 37 The University of Memphis Law Review 75-148 (2006) (link).\nBULLET::::- \"Review of Financial Studies\"; May2009, Vol. 22 Issue 5, pp. 1845–1887\nBULLET::::- Grechenig, Positive and Negative Information – Insider Trading Rethought\nBULLET::::- Pierre Hauck, Europe’s commitment to countering insider dealing and market manipulation on the basis of Art. 83 para. 2 TFEU A critical evaluation\nBULLET::::- International Standard Book Number-13: 978-1-4200-7403-1 (eBook - PDF)\n\nBULLET::::- General information\nBULLET::::- Insider Trading Informational page from the U.S. Security and Exchange Commission (SEC)\nBULLET::::- Testimony Concerning Insider Trading, by Linda Thomsen, Director of the SEC's Division of Enforcement, before the U.S. Senate Judicial Committee (September 26, 2006)\nBULLET::::- SEC Forms 3, 4 and 5\nBULLET::::- Insider Trading: Information on Bounties\nBULLET::::- Hoffman, Liz, \"Towers Watson CEO Sold Stock Before Big Deal: John Haley netted nearly $10 million on preannouncement sales\", \"Wall Street Journal\", September 23, 2015. Towers Watson CEO John J. Haley's pre-deal sale of personally owned stock questioned.\n\nBULLET::::- Articles and opinions\nBULLET::::- Insider Trading: The Legal and Illegal SECLaw.com, 2002\nBULLET::::- Timothy Sullivan We're still against fraud, aren't we? United States v. O'Hagan: Trimming the Oak in the wrong season St. John's Law Review, Winter 1997.\nBULLET::::- An opinion on Why Insider Trading Should be Legal Larry Elder Interviews Henry Manne\nBULLET::::- Why forbid insider trading? by Ajay Shah, consultant to the Ministry of Finance, India\nBULLET::::- \"Information, Privilege, Opportunity and Insider Trading by Robert W. Mcgee and Walter E. Blocka scholarly work that opposes regulations against insider trading\nBULLET::::- \"Free Samuel Waksal\" argues that businessman's insider trading should not be considered a crime\nBULLET::::- Rule: Ownership Reports and Trading by Officers, Directors and Principal Security\n\nBULLET::::- Data on insider trading\nBULLET::::- SEC Edgar Database on current Form 3, Form 4 and Form 5 filings\n"}
{"id": "15369", "url": "https://en.wikipedia.org/wiki?curid=15369", "title": "International Brigades", "text": "International Brigades\n\nThe International Brigades () were paramilitary units set up by the Communist International to assist the Popular Front government of the Second Spanish Republic during the Spanish Civil War. The organisation existed for two years, from 1936 until 1938. It is estimated that during the entire war, between 40,000 and 59,000 members served in the International Brigades, including 15,000 who died in combat.\n\nThe headquarters of the brigade was located at the Gran Hotel, Albacete, Castilla-La Mancha. They participated in the battles of Madrid, Jarama, Guadalajara, Brunete, Belchite, Teruel, Aragon and the Ebro. Most of these ended in defeat. For the last year of its existence, the International Brigades were integrated into the Spanish Republican Army as part of the Spanish Foreign Legion. The organisation was dissolved on 23 September 1938 by Spanish Prime Minister, Juan Negrín, in a vain attempt to get more support from the liberal democracies on the Non-Intervention Committee.\n\nThe International Brigades was strongly supported by the Comintern and represented the Soviet Union's commitment to provide assistance to the Spanish Republic (with arms, logistics, military advisers and the NKVD), just as Fascist Italy, Corporatist Portugal and Nazi Germany were providing assistance to the opposing Nationalist insurgency. The largest number of volunteers came from France (where the French Communist Party had many members) and communist exiles from Italy and Germany. Many Jews from the English-speaking world and Eastern Europe also participated. Republican volunteers who were opposed to Stalinism did not join the Brigades but instead enlisted in the separate Popular Front, the POUM, formed from Trotskyist, Bukharinist and other anti-Stalinist groups, which did not separate Spaniards and foreign volunteers (such as George Orwell), or anarcho-syndicalist groups such as the Durruti Column, the IWA and the CNT.\n\nUsing foreign communist parties to recruit volunteers for Spain was first proposed in the Soviet Union in September 1936—apparently at the suggestion of Maurice Thorez—by Willi Münzenberg, chief of Comintern propaganda for Western Europe. As a security measure, non-communist volunteers would first be interviewed by an NKVD agent.\n\nBy the end of September, the Italian and French Communist Parties had decided to set up a column. Luigi Longo, ex-leader of the Italian Communist Youth, was charged to make the necessary arrangements with the Spanish government. The Soviet Ministry of Defense also helped, since they had experience of dealing with corps of international volunteers during the Russian Civil War. The idea was initially opposed by Largo Caballero, but after the first setbacks of the war, he changed his mind, and finally agreed to the operation on 22 October. However, the Soviet Union did not withdraw from the Non-Intervention Committee, probably to avoid diplomatic conflict with France and the United Kingdom.\n\nThe main recruitment centre was in Paris, under the supervision of Soviet colonel Karol \"Walter\" Świerczewski. On 17 October 1936, an open letter by Joseph Stalin to José Díaz was published in \"Mundo Obrero\", arguing that victory for the Spanish second republic was a matter not only for Spaniards, but also for the whole of \"progressive humanity\"; in short order, communist activists joined with moderate socialist and liberal groups to form anti-fascist “popular front” militias in several countries, most of them under the control of or influenced by the Comintern.\n\nEntry to Spain was arranged for volunteers, for instance, a Yugoslav, Josip Broz, who would become famous as Marshal Josip Broz Tito, was in Paris to provide assistance, money and passports for volunteers from Eastern Europe. Volunteers were sent by train or ship from France to Spain, and sent to the base at Albacete. Many of them also went by themselves to Spain. The volunteers were under no contract, nor defined engagement period, which would later prove a problem.\n\nAlso many Italians, Germans, and people from other countries joined the movement, with the idea that combat in Spain was a first step to restore democracy or advance a revolutionary cause in their own country. There were also many unemployed workers (especially from France), and adventurers. Finally, some 500 communists who had been exiled to Russia were sent to Spain (among them, experienced military leaders from the First World War like \"Kléber\" Stern, \"Gomez\" Zaisser, \"Lukacs\" Zalka and \"Gal\" Galicz, who would prove invaluable in combat).\n\nThe operation was met with enthusiasm by communists, but by anarchists with skepticism, at best. At first, the anarchists, who controlled the borders with France, were told to refuse communist volunteers, but reluctantly allowed their passage after protests. A group of 500 volunteers (mainly French, with a few exiled Poles and Germans) arrived in Albacete on 14 October 1936. They were met by international volunteers who had already been fighting in Spain: Germans from the Thälmann Battalion, Italians from the Centuria Gastone Sozzi and French from the Commune de Paris Battalion. Among them was British poet John Cornford. Men were sorted according to their experience and origin, and dispatched to units.\n\nOn 30 May 1937, the Spanish liner \"Ciudad de Barcelona\", carrying 200–250 volunteers from Marseille to Spain, was torpedoed by a Nationalist submarine off the coast of Malgrat de Mar. The ship sunk and up to 65 volunteers are estimated to have drowned.\n\nAlbacete soon became the International Brigades headquarters and its main depot. It was run by a \"troika\" of Comintern heavyweights: André Marty was commander; Luigi Longo (\"Gallo\") was Inspector-General; and Giuseppe Di Vittorio (\"Nicoletti\") was chief political commissar.\n\nThe French Communist Party provided uniforms for the Brigades. They were organized into mixed brigades, the basic military unit of the Republican People's Army. Discipline was severe. For several weeks, the Brigades were locked in their base while their strict military training was under way.\n\nThe battle of Madrid was a major success for the Republic. It staved off the prospect of a rapid defeat at the hands of Francisco Franco's forces. The role of the International Brigades in this victory was generally recognised, but was exaggerated by Comintern propaganda, so that the outside world heard only of their victories, and not those of Spanish units. So successful was such propaganda that the British Ambassador, Sir Henry Chilton, declared that there were no Spaniards in the army which had defended Madrid. The International Brigade forces that fought in Madrid arrived after other successful Republican fighting. Of the 40,000 Republican troops in the city, the foreign troops numbered less than 3,000. Even though the International Brigades did not win the battle by themselves, nor significantly change the situation, they certainly did provide an example by their determined fighting, and improved the morale of the population by demonstrating the concern of other nations in the fight. Many of the older members of the International Brigades provided valuable combat experience, having fought during the First World War (Spain remained neutral in 1914–1918) and the Irish War of Independence (Some had fought in the British Army while others had fought in the IRA).\n\nOne of the strategic positions in Madrid was the Casa de Campo. There the Nationalist troops were Moroccans, commanded by General José Enrique Varela. They were stopped by III and IV Brigades of the Spanish Republican Army.\n\nOn 9 November 1936, the XI International Brigade – comprising 1,900 men from the Edgar André Battalion, the Commune de Paris Battalion and the Dabrowski Battalion, together with a British machine-gun company — took up position at the Casa de Campo. In the evening, its commander, General Kléber, launched an assault on the Nationalist positions. This lasted for the whole night and part of the next morning. At the end of the fight, the Nationalist troops had been forced to retreat, abandoning all hopes of a direct assault on Madrid by Casa de Campo, while the XIth Brigade had lost a third of its personnel.\n\nOn 13 November, the 1,550-man strong XII International Brigade, made up of the Thälmann Battalion, the Garibaldi Battalion and the André Marty Battalion, deployed. Commanded by General \"Lukacs\", they assaulted Nationalist positions on the high ground of Cerro de los Angeles. As a result of language and communication problems, command issues, lack of rest, poor coordination with armoured units, and insufficient artillery support, the attack failed.\n\nOn 19 November, the anarchist militias were forced to retreat, and Nationalist troops — Moroccans and Spanish Foreign Legionnaires, covered by the Nazi Condor Legion — captured a foothold in the University City. The 11th Brigade was sent to drive the Nationalists out of the University City. The battle was extremely bloody, a mix of artillery and aerial bombardment, with bayonet and grenade fights, room by room. Anarchist leader Buenaventura Durruti was shot there on 19 November 1936, and died the next day. The battle in the University went on until three quarters of the University City was under Nationalist control. Both sides then started setting up trenches and fortifications. It was then clear that any assault from either side would be far too costly; the nationalist leaders had to renounce the idea of a direct assault on Madrid, and prepare for a siege of the capital.\n\nOn 13 December 1936, 18,000 nationalist troops attempted an attack to close the encirclement of Madrid at Guadarrama — an engagement known as the Battle of the Corunna Road. The Republicans sent in a Soviet armoured unit, under General Dmitry Pavlov, and both XI and XII International Brigades. Violent combat followed, and they stopped the Nationalist advance.\n\nAn attack was then launched by the Republic on the Córdoba front. The battle ended in a form of stalemate; a communique was issued, saying: \"During the day the advance continued without the loss of any territory.\" Poets Ralph Winston Fox and John Cornford were killed. Eventually, the Nationalists advanced, taking the hydroelectric station at El Campo. André Marty accused the commander of the Marseillaise Battalion, Gaston Delasalle, of espionage and treason and had him executed. (It is doubtful that Delasalle would have been a spy for Francisco Franco; he was denounced by his own second-in-command, André Heussler, who was subsequently executed for treason during World War II by the French Resistance.)\n\nFurther Nationalist attempts after Christmas to encircle Madrid met with failure, but not without extremely violent combat. On 6 January 1937, the Thälmann Battalion arrived at Las Rozas, and held its positions until it was destroyed as a fighting force. On 9 January, only 10 km had been lost to the Nationalists, when the XIII International Brigade and XIV International Brigade and the 1st British Company, arrived in Madrid. Violent Republican assaults were launched in attempt to retake the land, with little success. On 15 January, trenches and fortifications were built by both sides, resulting in a stalemate.\n\nThe Nationalists did not take Madrid until the very end of the war, in March 1939, when they marched in unopposed. There were some pockets of resistance during the subsequent months.\n\nOn 6 February 1937, following the fall of Málaga, the nationalists launched an attack on the Madrid–Andalusia road, south of Madrid. The Nationalists quickly advanced on the little town Ciempozuelos, held by the XV International Brigade, which was composed of the British Battalion (British Commonwealth and Irish), the Dimitrov Battalion (miscellaneous Balkan nationalities), the 6 Février Battalion (Belgians and French), the Canadian Mackenzie-Papineau Battalion and the Abraham Lincoln Brigade.\n\nAn independent 80-men-strong (mainly) Irish unit, known as the Connolly Column, made up of people from both sides of the Irish border also fought. Several histories of the Irish in Spain record that they included an ex-Catholic Christian Brother and an ordained Church of Ireland (Anglican Protestant) Clergyman, fighting and dying on the same side. These battalions were not composed entirely of one nationality or another, rather they were for the most part a mix of many.\n\nOn 11 February 1937, a Nationalist brigade launched a surprise attack on the André Marty Battalion (XIV International Brigade), stabbing its sentries and crossing the Jarama. The Garibaldi Battalion stopped the advance with heavy fire. At another point, the same tactic allowed the Nationalists to move their troops across the river.\n\nOn 12 February, the British Battalion, XV International Brigade took the brunt of the attack, remaining under heavy fire for seven hours. The position became known as \"Suicide Hill\". At the end of the day, only 225 of the 600 members of the British battalion remained. One company was captured by ruse, when Nationalists advanced among their ranks singing \"The Internationale\".\n\nOn 17 February, the Republican Army counter-attacked. On 23 and 27 February, the International Brigades were engaged, but with little success. The Lincoln Battalion was put under great pressure, with no artillery support. It suffered 120 killed and 175 wounded. Amongst the dead was the Irish poet Charles Donnelly and Leo Greene.\n\nThere were heavy casualties on both sides, and although \"both claimed victory ... both suffered defeats\". It resulted in a stalemate, with both sides digging in, creating elaborate trench systems.\n\nOn 22 February 1937 the League of Nations Non-Intervention Committee ban on foreign volunteers went into effect.\n\nAfter the failed assault on the Jarama, the Nationalists attempted another assault on Madrid, from the North-East this time. The objective was the town of Guadalajara, 50 km from Madrid. The whole Italian expeditionary corps — 35,000 men, with 80 battle tanks and 200 field artillery — was deployed, as Benito Mussolini wanted the victory to be credited to Italy. On 9 March 1937, the Italians made a breach in the Republican lines, but did not properly exploit the advance. However, the rest of the Nationalist army was advancing, and the situation appeared critical for the Republicans. A formation drawn from the best available units of the Republican army, including the XI and XII International Brigades, was quickly assembled.\n\nAt dawn on 10 March, the Nationalists closed in, and by noon, the Garibaldi Battalion counterattacked. Some confusion arose from the fact that the sides were not aware of each other's movements, and that both sides spoke Italian; this resulted in scouts from both sides exchanging information without realising they were enemies. The Republican lines advanced and made contact with XI International Brigade. Nationalist tanks were shot at and infantry patrols came into action.\n\nOn 11 March, the Nationalist army broke the front of the Republican army. The Thälmann Battalion suffered heavy losses, but succeeded in holding the Trijueque–Torija road. The Garibaldi also held its positions. On 12 March, Republican planes and tanks attacked. The Thälmann Battalion attacked Trijuete in a bayonet charge and re-took the town, capturing numerous prisoners.\n\nThe International Brigades also saw combat in the Battle of Teruel in January 1938. The 35th International Division suffered heavily in this battle from aerial bombardment as well as shortages of food, winter clothing and ammunition. The XIV International Brigade fought in the Battle of Ebro in July 1938, the last Republican offensive of the war.\n\nAlthough exact figures are not available, an estimated 5,857 to 25,229 brigadiers died in Spain, of an estimated 23,670 to 59,380 who served, with estimated death rates of 16.7% to 29.2%. These high casualty rates are blamed on lack of training, poor leadership and use as shock troops.\n\nIn October 1938, at the height of the Battle of the Ebro, the Non-Intervention Committee ordered the withdrawal of the International Brigades which were fighting on the Republican side. The Republican government of Juan Negrín announced the decision in the League of Nations on 21 September 1938. The disbandment was part of an ill-advised effort to get the Nationalists' foreign backers to withdraw their troops and to persuade the Western democracies such as France and Britain to end their arms embargo on the Republic.\n\nBy this time there were about an estimated 10,000 foreign volunteers still serving in Spain for the Republican side, and about 50,000 foreign conscripts for the Nationalists (excluding another 30,000 Moroccans). Perhaps half of the International Brigadists were exiles or refugees from Nazi Germany, Fascist Italy or other countries, such as Hungary, which had authoritarian right-wing governments at the time. These men could not safely return home and some were instead given honorary Spanish citizenship and integrated into Spanish units of the Popular Army. The remainder were repatriated to their own countries. The Belgian and Dutch volunteers lost their citizenship because they had served in a foreign army.\n\nThe first brigades were composed mostly of French, Belgian, Italian, and German volunteers, backed by a sizeable contingent of Polish miners from Northern France and Belgium. The XIth, XIIth and XIIIth were the first brigades formed. Later, the XIVth and XVth Brigades were raised, mixing experienced soldiers with new volunteers. Smaller Brigades — the 86th, 129th and 150th - were formed in late 1937 and 1938, mostly for temporary tactical reasons.\n\nAbout 32,000 people volunteered to defend the Spanish Republic. Many were veterans of World War I. Their early engagements in 1936 during the Siege of Madrid amply demonstrated their military and propaganda value.\n\nThe international volunteers were mainly socialists, communists, or under communist authority, and a high proportion were Jewish. Some were involved in the fighting in Barcelona against Republican opponents of the Communists: the Workers' Party of Marxist Unification (POUM) (\"Partido Obrero de Unificación Marxista\", an anti-Stalinist Marxist party) and anarchists. These more libertarian groups like the POUM fought together on the front with the anarchist federations of the CNT (CNT, Confederación Nacional del Trabajo) and the FAI (FAI, Iberian Anarchist Federation) who had large support in the area of Catalonia. However, overseas volunteers from anarchist, socialist, liberal and other political positions also served with the international brigades.\n\nTo simplify communication, the battalions usually concentrated people of the same nationality or language group. The battalions were often (formally, at least) named after inspirational people or events. From Spring 1937 onwards, many battalions contained one Spanish volunteer company of about 150 men.\n\nLater in the war, military discipline tightened and learning Spanish became mandatory. By decree of 23 September 1937, the International Brigades formally became units of the Spanish Foreign Legion.<ref name=\"Beevor 2006/309\"></ref> This made them subject to the Spanish Code of Military Justice. However the Spanish Foreign Legion itself sided with the Nationalists throughout the coup and the civil war. The same decree also specified that non-Spanish officers in the Brigades should not exceed Spanish ones by more than 50 per cent.\n\nMKVD created in 1937 ‘Control and Security Service’.\n\nBULLET::::- Abraham Lincoln Battalion: from the United States, Canada and Irish Free State, with some British, Cypriots and Chileans who lived in New York and were members of the Chilean worker club of New York.\nBULLET::::- Connolly Column: This mostly Irish republican group fought as a section of the Lincoln Battalion\nBULLET::::- Mickiewicz Battalion: predominantly Polish.\nBULLET::::- André Marty Battalion: predominantly French and Belgian, named after André Marty.\nBULLET::::- British Battalion: Mainly British but with many from the Irish Free State, Australia, New Zealand, South Africa, Cyprus and other Commonwealth countries.\nBULLET::::- Checo-Balcánico Battalion: Czechoslovakian and Balkan.\nBULLET::::- Commune de Paris Battalion: predominantly French.\nBULLET::::- Deba Blagoiev Battalion: predominantly Bulgarian, later merged into the Djakovic Battalion.\nBULLET::::- Dimitrov Battalion: Greek, Yugoslavian, Bulgarian, Czechoslovakian, Hungarian and Romanian. Named after Georgi Dimitrov.\nBULLET::::- Djuro Djakovic Battalion: Yugoslav, Bulgarian, anarchist, named for former Yugoslav communist party secretary Đuro Đaković.\nBULLET::::- Dabrowski Battalion: mostly Polish and Hungarian. Also Czechoslovakian, Ukrainian, Bulgarian and Palestinian Jews.\nBULLET::::- Edgar André Battalion: mostly German. Also Austrian, Yugoslavian, Bulgarian, Albanian, Romanian, Danish, Swedish, Norwegian and Dutch.\nBULLET::::- Español Battalion: Mexican, Cuban, Puerto Rican, Chilean, Argentine and Bolivian.\nBULLET::::- Figlio Battalion: mostly Italian; later merged with the Garibaldi Battalion.\nBULLET::::- Garibaldi Battalion: Raised as the Italoespañol Battalion and renamed. Mostly Italian and Spanish, but contained some Albanians.\nBULLET::::- George Washington Battalion: the second U.S. battalion. Later merged with the Lincoln Battalion, to form the Lincoln-Washington Battalion.\nBULLET::::- Hans Beimler Battalion: mostly German; later merged with the Thälmann Battalion.\nBULLET::::- Henri Barbusse Battalion: predominantly French.\nBULLET::::- Henri Vuilleman Battalion: predominantly French.\nBULLET::::- (Matteotti Battalion): predominantly Italian and the first international group to reach Spain\nBULLET::::- Louise Michel Battalions: French-speaking, later merged with the Henri Vuillemin Battalion.\nBULLET::::- Mackenzie–Papineau Battalion: the \"Mac-Paps\", predominantly Canadian.\nBULLET::::- Marseillaise Battalion: predominantly French-commanded by George Nathan.\nBULLET::::- Incorporated one separate British company.\nBULLET::::- Palafox Battalion: Yugoslavian, Polish, Czechoslovakian, Hungarian, Jewish and French.\nBULLET::::- Naftali Botwin Company: a Jewish unit formed within the Palafox Battalion in December 1937.\nBULLET::::- Pierre Brachet Battalion: mostly French.\nBULLET::::- Rakosi Battalion: mainly Hungarian, also Czechoslovakians, Ukrainians, Poles, Chinese, Mongolians and Palestinian Jews.\nBULLET::::- Nine Nations Battalion (also known as the \"Sans nons\" and \"Neuf Nationalités\": French, Belgian, Italian, German, Austrian, Dutch, Danish, Swiss and Polish.\nBULLET::::- Sixth of February Battalion: French, Belgian, Moroccan, Algerian, Libyan, Syrian, Iranian, Iraqi, Chinese, Japanese, Indian and Palestinian Jewish.\nBULLET::::- Thälmann Battalion: predominantly German, named after German communist leader Ernst Thälmann.\nBULLET::::- Tom Mann Centuria: A small, mostly British, group who operated as a section of the Thälmann Battalion.\nBULLET::::- Thomas Masaryk Battalion: mostly Czechoslovakian.\nBULLET::::- \"Chapaev\" Battalion: composed of 21 nationalities (Ukrainian, Polish, Czechoslovakian, Bulgarian, Yugoslavian, Turkish, Italian, German, Austrian, Finnish, Swedish, Norwegian, Danish, Belgian, French, Greek, Albanian, Dutch, Swiss and Baltic).\nBULLET::::- Vaillant-Couturier Battalion: French, Belgian, Czechoslovakian, Bulgarian, Swedish, Norwegian and Danish.\nBULLET::::- Veinte Battalion: American, British, Italian, Yugoslavian and Bulgarian.\nBULLET::::- Zwölfte Februar Battalion: mostly Austrian.\nBULLET::::- Company De Zeven Provinciën: Dutch.\n\n! Country !! Estimate !! Notes \nBalkan countries\n\n300-600\n\nSince the Civil War was eventually won by the Nationalists, the Brigadiers were initially on the \"wrong side\" of history, especially since most of their home countries had a right-wing government (in France, for instance, the Popular Front was not in power any more).\n\nHowever, since most of these countries found themselves at war with the very powers which had been supporting the Nationalists, the Brigadists gained some prestige as the first guard of the democracies, having fought a prophetical combat. Retrospectively, it was clear that the war in Spain was as much a precursor of the Second World War as a Spanish civil war.\n\nSome glory therefore accrued to the volunteers (a great many of the survivors also fought during World War II), but this soon faded in the fear that it would promote (by association) communism.\n\nAn exception is among groups to the left of the Communist Parties, for example anarchists. Among these groups the Brigades, or at least their leadership, are criticised for their alleged role in suppressing the Spanish Revolution. An example of a modern work which promotes this view is Ken Loach's film \"Land and Freedom\". A well-known contemporary account of the Spanish Civil War which also takes this view is George Orwell's book \"Homage to Catalonia\".\n\nGermany was undivided until after the Second World War. At that time, the new German Democratic Republic began to create a national identity which was separate from and antithetical to the former Nazi Germany. The Spanish Civil War, and especially the role of the International Brigades, became a substantial part of East Germany's memorial rituals because of the substantial numbers of German communists who had served in the brigades. These showcased a commitment by many Germans to antifascism at a time when Germany and Nazism were often conflated together.\n\nSurvivors of the Mackenzie-Papineau Battalion were often investigated by the Royal Canadian Mounted Police and denied employment when they returned to Canada. Some were prevented from serving in the military during the Second World War due to \"political unreliability\".\n\nIn 1995 a monument to veterans of the war was built near Ontario's provincial parliament. On 12 February 2000, a bronze statue \"The Spirit of the Republic\" based on an original poster from the Spanish Republic, by sculptor Jack Harman, was placed on the grounds of the BC Legislature. And in 2001, the few remaining Canadian veterans of the Spanish Civil War dedicated a monument to Canadian members of the International Brigades in Ottawa's Green Island Park.\n\nIn Switzerland, public sympathy was high for the Republican cause, but the federal government banned all fundraising and recruiting activities a month after the start of the war so as to preserve Swiss neutrality. Around 800 Swiss volunteers joined the International Brigades, among them a small number of women. Sixty percent of Swiss volunteers identified as communists, while the others included socialists, anarchists and antifascists.\n\nSome 170 Swiss volunteers were killed in the war. The survivors were tried by military courts upon their return to Switzerland for violating the criminal prohibition on foreign military service. The courts pronounced 420 sentences which ranged from around two weeks to four years in prison, and often also stripped the convicts of their political rights. In the judgment of Swiss historian Mauro Cerutti, volunteers were punished more harshly in Switzerland than in any other democratic country.\n\nMotions to pardon the Swiss brigadists on the account that they fought for a just cause have been repeatedly introduced in the Swiss federal parliament. A first such proposal was defeated in 1939 on neutrality grounds. In 2002, Parliament again rejected a pardon of the Swiss war volunteers, with a majority arguing that they did break a law that remains in effect to this day. In March 2009, Parliament adopted a third bill of pardon, retroactively rehabilitating Swiss brigadists, only a handful of whom were still alive.\n\nOn disbandment, 305 British volunteers left Spain. They arrived at Victoria Station on 7 December, to be met by a crowd of supporters including Clement Attlee, Stafford Cripps, Willie Gallacher, and Will Lawther.\n\nThe last surviving British member of the International Brigades, Geoffrey Servante, died in April 2019 aged 99.\n\nIn the United States, the returned volunteers were labeled \"premature anti-fascists\" by the FBI, denied promotion during service in the US military during World War II, and pursued by Congressional committees during the Red Scare of 1947–1957. However, threats of loss of citizenship were not carried out.\n\nOn 26 January 1996, the Spanish government gave Spanish citizenship to the Brigadists. At that time, roughly 600 remained. At the end of 1938, Prime Minister Juan Negrín had promised Spanish citizenship to the Brigadists, which was of course not recognized by the Nationalists who were about to take over the entire country.\n\nIn 1996, Jacques Chirac, then French President, granted the former French members of the International Brigades the legal status of former service personnel (\"anciens combattants\") following the request of two French communist Members of Parliament, Lefort and Asensi, both children of volunteers. Before 1996, the same request was turned down several times including by François Mitterrand, the former Socialist President.\n\nThe International Brigades were inheritors of a socialist aesthetic. The flags featured the colours of the Spanish Republic: red, yellow and purple, often along with socialist symbols (red flags, hammer and sickle, fist). The emblem of the brigades themselves was the three-pointed red star, which is often featured.\n\nBULLET::::- William Aalto — American poet and communist\nBULLET::::- Anton Ackermann — Leader of the Political School of the International Brigades.\nBULLET::::- Todor Angelov — Bulgarian anarcho-communist\nBULLET::::- Akseli Anttila — Finnish-born Soviet general\nBULLET::::- Shapour Bakhtiar — last Prime Minister of Iran under the Pahlavi dynasty\nBULLET::::- Hans Beimler — After his death the XI International Brigade was named in his honour.\nBULLET::::- Norman Bethune — Canadian physician with the mobile blood transfusion unit.\nBULLET::::- Herman Bottcher — two-time winner of the Distinguished Service Crosses during World War II\nBULLET::::- John Edward Boulting — English filmmaker, ambulance driver\nBULLET::::- Willy Brandt — West German Chancellor from 1969 to 1974, Nobel Peace Prize winner, leader of the Socialist International\nBULLET::::- Ernst Busch — singer of broadcast battle songs - \"Voice of the XI Brigade\"\nBULLET::::- Robert Capa — Hungarian-born war photographer\nBULLET::::- Edward A. Carter Jr. — American soldier who earned the Medal of Honor in World War II.\nBULLET::::- Alfred Chakin, American volunteer, captured and executed\nBULLET::::- Lewis Clive, Olympic gold medalist, killed at the Battle of the Ebro\nBULLET::::- Fred Copeman — Royal Navy sailor\nBULLET::::- Vladimir Ćopić — 1937 commander of the XV International Brigade\nBULLET::::- John Cornford — British poet killed at Lopera, near Córdoba\nBULLET::::- Georgi Damyanov — Commander of the Albacete base under the nom de guerre of Colonel Belov\nBULLET::::- Peko Dapčević — Montenegrin and Yugoslav communist politician and Chief of Staff\nBULLET::::- Carmelo Delgado Delgado — Puerto Rican nationalist\nBULLET::::- Charles Donnelly — poet\nBULLET::::- Paul Éluard — French surrealist poet\nBULLET::::- Ralph Winston Fox — British journalist\nBULLET::::- Janos Galicz — General \"Gal\"\nBULLET::::- Bill Gannon — Irish Republican and communist\nBULLET::::- Ermenegildo Gasperoni — Sammarinese communist, later head of state of San Marino\nBULLET::::- Pierre Georges — French communist\nBULLET::::- Nordahl Grieg — Norwegian writer\nBULLET::::- David Guest — Communist British mathematician and philosopher\nBULLET::::- Paul René Gauguin, painter and graphic designer, grandson of Paul Gauguin\nBULLET::::- Ernest Hemingway — author and war reporter\nBULLET::::- Joris Ivens — Dutch filmmaker\nBULLET::::- Fernanda Jacobsen — commandant of the Scottish Ambulance Unit\nBULLET::::- Jack Jones — political commissar of the Major Attlee Company of the XV International Brigade, later General Secretary of the Transport and General Workers' Union\nBULLET::::- James Robertson Justice — British actor\nBULLET::::- Ali Kelmendi — Albanian communist\nBULLET::::- Bernard Knox — English classicist; moved to the United States and joined the Army after the Civil War\nBULLET::::- František Kriegel — Czechoslovak politician\nBULLET::::- Otakar Hromádko — Czechoslovak communist, journalist\nBULLET::::- Arthur H. Landis — fantasy and non-fiction author, wrote \"Spain! The Unfinished Revolution\", Order of Friendship of Peoples recipient\nBULLET::::- Jef Last — Dutch leftist writer\nBULLET::::- Oliver Law — African-American labor organizer and Abraham Lincoln Brigade commander\nBULLET::::- Laurie Lee — British poet\nBULLET::::- Tuure Lehén — Finnish communist and later Soviet general\nBULLET::::- Arthur Lehning — Dutch anarchist writer\nBULLET::::- Bert \"Yank\" Levy - Jewish author of a handbook on guerrilla warfare, officer in the Saklatava Battalion, under Tom Wintringham\nBULLET::::- Luigi Longo — political commissar of all International Brigades\nBULLET::::- André Malraux — French novelist and activist\nBULLET::::- Petro Marko — Albanian novelist\nBULLET::::- André Marty — Political commissar, nicknamed \"Butcher of Albacete\", later parliamentarian\nBULLET::::- Matti Mattson — American labor organizer\nBULLET::::- Erich Mielke — future GDR secret police chief\nBULLET::::- Ferenc Münnich (political commissar of Rakosi Battalion) became Chairman of the Council of Ministers of Hungary from 1958 to 1961.\nBULLET::::- Conlon Nancarrow — American-born composer\nBULLET::::- George Nathan — Chief of Staff of the XV International Brigade from 1937\nBULLET::::- Guido Nonveiller — Croatian professor\nBULLET::::- George Orwell — British writer\nBULLET::::- Abe Osheroff — American activist\nBULLET::::- Randolfo Pacciardi — commander of the Garibaldi Battalion\nBULLET::::- Jules Paivio — Canadian architect\nBULLET::::- Ezekias Papaioannou — Greek Cypriot communist and later general secretary of AKEL\nBULLET::::- László Rajk — political commissar of the Rakosi Battalion; became Hungarian foreign secretary, was accused of espionage, and shot after a show trial in Hungary in 1949.\nBULLET::::- Pramod Ranjan Sengupta - Indian revolutionary and member of Indian National Army\nBULLET::::- Heinrich Rau — 1938 commander of the XI International Brigade\nBULLET::::- Ludwig Renn — German writer and 1936 commander of the Thälmann Battalion in the Battle of Madrid, then chief of staff XI International Brigade\nBULLET::::- Paul Robeson — troop entertainer, fundraiser, honorary member\nBULLET::::- Henri Rol-Tanguy — French communist\nBULLET::::- Valter Roman — Romanian communist\nBULLET::::- Esmond Romilly — English upper-class communist\nBULLET::::- Franc Rozman — Slovenian partisan general, national hero\nBULLET::::- William Rust (journalist) — Daily Worker's correspondent with the International Brigades\nBULLET::::- Frank Ryan — Irish Republican Army fighter who led the Connolly Column\nBULLET::::- Antoine de Saint-Exupéry — French pilot, reporter\nBULLET::::- Elman Service — American anthropologist\nBULLET::::- Mehmet Shehu — future Albanian Communist Premier\nBULLET::::- David Alfaro Siqueiros — Mexican muralist and member of the Mexican Communist Party\nBULLET::::- Humphrey (Hugh) Slater — British painter\nBULLET::::- John Sommerfield — British author\nBULLET::::- George Sossenko — Russian-American writer\nBULLET::::- Žikica Jovanović Španac — Serb activist\nBULLET::::- Stephen Spender — British novelist\nBULLET::::- Manfred Stern — General \"Kléber\" - commander of the first (\"XI\") Int. Brigade — called \"Savior of Madrid\" by the international press, then quietly replaced and his name later no longer mentioned.\nBULLET::::- Karol Świerczewski — Soviet and Polish Communist general\nBULLET::::- Gerda Taro — war photographer\nBULLET::::- Asim Vokshi — Albanian commander of the Garibaldi Battalion\nBULLET::::- Simone Weil — French philosopher\nBULLET::::- Tom Wintringham — British historian\nBULLET::::- Milton Wolff — last commander of the Abraham Lincoln Battalion\nBULLET::::- Wilhelm Zaisser — future GDR secret police chief, 1936 commander of XIII International Brigade, 1937 the international forces in Spain\nBULLET::::- Mate Zalka — General \"Lukacs\" — commander XII International Brigade\nBULLET::::- Foreign involvement in the Spanish Civil War\n\nBULLET::::- Alvarez, Santiago. \"Historia politica y militar de las brigadas internacionales\" Madrid: Compañía Literaria, 1996.\nBULLET::::- Anderson, James W. \"The Spanish Civil War: A History and Reference Guide\". Santa Barbara: Greenwood Press, 2003.\nBULLET::::- Beevor, Antony. [1982] \"The Spanish Civil War\". Reissued London: Weidenfeld & Nicolson (Cassell), 1999.\nBULLET::::- Beevor, Antony. (2006). \"The Battle for Spain: The Spanish Civil War 1936–1939\". London: Weidenfeld & Nicolson, 2006.\nBULLET::::- Bradley, Ken \"International Brigades in Spain 1936-39\" with Mike Chappell (Illustrator) Published by Elite. .\nBULLET::::- Castells, Andreu. \"Las brigadas internacionales en la guerra de España.\" Barcelona: Editorial Ariel, 1974.\nBULLET::::- Copeman, Fred (1948). \"Reason in Revolt\". London: Blandford Press, 1948.\nBULLET::::- Eby, Cecil. \"Comrades and Commissars\". Pennsylvania: Penn State University Press, 2007.\nBULLET::::- Gurney, Jason (1974) \"Crusade in Spain\". London: Faber, 1974.\nBULLET::::- Kantorowicz, Alfred (1938, 1948), \"Spanisches Tagebuch\", Madrid (1938), Berlin (1948).\nBULLET::::- Kuuli, O; Riis, V; Utt, O; (editors) (1965) \"Hispaania tules. Mälestusi ja dokumente fašismivastasest võitlusest Hispaanias 1936.-1939. aastal\". Tallinn: Eesti raamat.\nBULLET::::- Lefebvre, Michel; Skoutelsky, Rémi. \"Las brigadas internacionales\". Barcelona: Lunwerg Editores (2003).\nBULLET::::- Marco, Jorge and Thomas, Maria, \"‘Mucho malo for fascisti’: Languages and Transnational Soldiers in the Spanish Civil War\", \"War & Society\", 38-2 (2019)\nBULLET::::- Marco, Jorge, \"The Antifascist Tower of Babel: Language Barriers in Civil-War Spain\", \"The Volunteer\", December (2019)\nBULLET::::- Marco, Jorge, \"Transnational Soldiers and Guerrilla Warfare from the Spanish Civil War to the Second World War\", \"War i History\" (2018)\nBULLET::::- Marco, Jorge and Anderson, Peter, \"Legitimacy by proxy:searching for a usable past through the International Brigades in Spain’s Post-Franco democracy, 1975-2015\", \"Journal of Modern European History\", 14-3 (2016)\nBULLET::::- Orwell, George. [1938] \"A Homage to Catalonia\". London: Penguin Books, 1969. (New edition)\nBULLET::::- Thomas, Hugh. (1961) \"The Spanish Civil War\". London: Eyre & Spottiswoode, 1961.\nBULLET::::- Thomas, Hugh. (2003) \"The Spanish Civil War\", 2003. London: Penguin (Revised 4th edition), 2003.\nBULLET::::- Wainwright, John, L. (2011) \"The Last to Fall: the Life and Letters of Ivor Hickman - an International Brigader in Spain\". Southampton: Hatchet Green Publishing.\n\nBULLET::::- IBMT the international brigade memorial trust\nBULLET::::- Abraham Lincoln Brigade Archives\nBULLET::::- Private Collection about German Exile and Spanish Civil War\n"}
{"id": "15373", "url": "https://en.wikipedia.org/wiki?curid=15373", "title": "Iron Duke", "text": "Iron Duke\n\nIron Duke may refer to:\n\nBULLET::::- William Mark Duke (1879–1971), Archbishop of Vancouver\nBULLET::::- Irvin Khoza (born 1948), South African football administrator\nBULLET::::- John F. Thompson (1920–1965), U.S. politician\nBULLET::::- Luís Alves de Lima e Silva, Duke of Caxias (1803–1880), Brazilian army officer and politician\nBULLET::::- Fernando Álvarez de Toledo, 3rd Duke of Alba (1507–1582), Spanish noble, general, and diplomat involved in the Eighty Years' War\nBULLET::::- Arthur Wellesley, 1st Duke of Wellington (1769–1852), British soldier and statesman\nBULLET::::- Robert William Wilcox (1855–1903), Hawaiian revolutionary soldier and politician\n\nBULLET::::- , a British Royal Navy shipname\nBULLET::::- HMS \"Iron Duke\" (1870), a battleship sold for scrap in 1906\nBULLET::::- HMS \"Iron Duke\" (1912), the fleet flagship at the Battle of Jutland\nBULLET::::- HMS \"Iron Duke\" (F234), a Type 23 frigate launched in 1991\n\nBULLET::::- GWR Iron Duke Class, a class of locomotive built by the Great Western Railway in England\nBULLET::::- \"Iron Duke\", a GWR 3031 Class locomotive built in 1892\n\nBULLET::::- Iron Duke engine, a 2.5 L I4 piston engine made by General Motors\nBULLET::::- Iron Duke (pub), public house in Great Yarmouth, England\n\nBULLET::::- \"The Iron Duke\" (film), 1934 film starring George Arliss\nBULLET::::- \"The Iron Duke\" (novel), by L. Ron Hubbard\nBULLET::::- The Iron Dukes, the name the 2nd Battalion 37th Armored Regiment\n\nBULLET::::- Iron Baron (disambiguation)\nBULLET::::- Iron Lady (disambiguation)\nBULLET::::- Iron Lord (disambiguation)\nBULLET::::- Iron Man (disambiguation)\nBULLET::::- Iron Woman (disambiguation)\n"}
{"id": "15374", "url": "https://en.wikipedia.org/wiki?curid=15374", "title": "Food irradiation", "text": "Food irradiation\n\nFood irradiation is the process of exposing food and food packaging to ionizing radiation. Ionizing radiation, such as from gamma rays, x-rays, or electron beams, is energy that can be transmitted without direct contact to the source of the energy (radiation) capable of freeing electrons from their atomic bonds (ionization) in the targeted food. The radiation can be emitted by a radioactive substance or generated electrically. This treatment is used to improve food safety by extending product shelf-life (preservation), reducing the risk of foodborne illness, delaying or eliminating sprouting or ripening, by sterilization of foods, and as a means of controlling insects and invasive pests. Food irradiation primarily extends the shelf-life of irradiated foods by effectively destroying organisms responsible for spoilage and foodborne illness and inhibiting sprouting.\n\nAlthough consumer perception of foods treated with irradiation is more negative than those processed by other means, because people imagine that the food is radioactive or mutated, these thoughts don't agree with the understood mechanism by which irradiation works. The food itself is already not alive, so irradiation will not affect it meaningfully. Irradiation will kill the living bacteria, however. Additionally, all independent research, the U.S. Food and Drug Administration (FDA), the World Health Organization (WHO), the Centers for Disease Control and Prevention (CDC), and U.S. Department of Agriculture (USDA) have performed studies that confirm irradiation to be safe. In order for a food to be irradiated in the US, the FDA will still require that the specific food be thoroughly tested for irradiation safety.\n\nFood irradiation is permitted by over 60 countries, with about 500,000 metric tons of food annually processed worldwide. The regulations that dictate how food is to be irradiated, as well as the food allowed to be irradiated, vary greatly from country to country. In Austria, Germany, and many other countries of the European Union only dried herbs, spices, and seasonings can be processed with irradiation and only at a specific dose, while in Brazil all foods are allowed at any dose.\n\nIrradiation is used to reduce or eliminate the risk of food-borne illnesses, prevent or slow down spoilage, arrest maturation or sprouting and as a treatment against pests. Depending on the dose, some or all of the pathogenic organisms, microorganisms, bacteria, and viruses present are destroyed, slowed down, or rendered incapable of reproduction. Irradiation cannot return spoiled or over-ripe food to a fresh state. If this food was processed by irradiation, further spoilage would cease and ripening would slow down, yet the irradiation would not destroy the toxins or repair the texture, color, or taste of the food. When targeting bacteria, most foods are irradiated to significantly reduce the number of active microbes, not to sterilize all microbes in the product. In this respect it is similar to pasteurization.\n\nIrradiation is used to create safe foods for people at high risk of infection, or for conditions where food must be stored for long periods of time and proper storage conditions are not available. Foods that can tolerate irradiation at sufficient doses are treated to ensure that the product is completely sterilized. This is most commonly done with rations for astronauts, and special diets for hospital patients.\n\nIrradiation is used to create shelf-stable products. Since irradiation reduces the populations of spoilage microorganisms, and because pre-packed food can be irradiated, the packaging prevents recontamination of the final product.\n\nIrradiation is used to reduce post-harvest losses. It reduces populations of spoilage micro-organisms in the food and can slow down the speed at which enzymes change the food, and therefore slows spoilage and ripening, and inhibits sprouting (e.g., of potato, onion, and garlic).\n\nFood is also irradiated to prevent the spread of invasive pest species through trade in fresh vegetables and fruits, either within countries, or trade across international boundaries. Pests such as insects could be transported to new habitats through trade in fresh produce which could significantly affect agricultural production and the environment were they to establish themselves. This \"phytosanitary irradiation\" aims to render any hitch-hiking pest incapable of breeding. The pests are sterilized when the food is treated by low doses of irradiation. In general, the higher doses required to destroy pests such as insects, mealybugs, mites, moths, and butterflies either affect the look or taste, or cannot be tolerated by fresh produce. Low dosage treatments (less than 1000 gray) enables trade across quarantine boundaries and may also help reduce spoilage.\n\nIrradiation reduces the risk of infection and spoilage, does not make food radioactive, and the food is shown to be safe, but it does cause chemical reactions that alter the food and therefore alters the chemical makeup, nutritional content, and the sensory qualities of the food. Some of the potential secondary impacts of irradiation are hypothetical, while others are demonstrated. These effects include cumulative impacts to pathogens, people, and the environment due to the reduction of food quality, the transportation and storage of radioactive goods, and destruction of pathogens, changes in the way we relate to food and how irradiation changes the food production and shipping industries.\n\nThe radiation source supplies energetic particles or waves. As these waves/particles pass through a target material they collide with other particles. Around the sites of these collisions chemical bonds are broken, creating short lived radicals (e.g. the hydroxyl radical, the hydrogen atom and solvated electrons). These radicals cause further chemical changes by bonding with and or stripping particles from nearby molecules. When collisions damage DNA or RNA, effective reproduction becomes unlikely, also when collisions occur in cells, cell division is often suppressed.\n\nIrradiation (within the accepted energy limits, as 10 MeV for electrons, 5 MeV for X-rays [US 7.5 MeV] and gamma rays from Cobalt-60) can not make food radioactive, but it does produce radiolytic products, and free radicals in the food. A few of these products are unique, but not considered dangerous.\n\nIrradiation can also alter the nutritional content and flavor of foods, much like cooking. The scale of these chemical changes is not unique. Cooking, smoking, salting, and other less novel techniques, cause the food to be altered so drastically that its original nature is almost unrecognizable, and must be called by a different name. Storage of food also causes dramatic chemical changes, ones that eventually lead to deterioration and spoilage.\n\nA major concern is that irradiation might cause chemical changes that are harmful to the consumer. Several national expert groups and two international expert groups evaluated the available data and concluded that any food at any dose is wholesome and safe to consume as long as it remains palatable and maintains its technical properties (e.g. feel, texture, or color).\n\nIrradiated food does not become radioactive, just as an object exposed to light does not start producing light. Radioactivity is the ability of a substance to emit high energy particles. When particles hit the target materials they may free other highly energetic particles. This ends shortly after the end of the exposure, much like objects stop reflecting light when the source is turned off and warm objects emit heat until they cool down but do not continue to produce their own heat. To modify a material so that it keeps emitting radiation (induce radiation) the atomic cores (nucleus) of the atoms in the target material must be modified.\n\nIt is impossible for food irradiators to induce radiation in a product. Irradiators emit electrons or photons and the radiation is intrinsically radiated at precisely known strengths (wavelengths for photons, and speeds for electrons). These radiated particles at these strengths can never be strong enough to modify the nucleus of the targeted atom in the food, regardless of how many particles hit the target material, and radioactivity can not be induced without modifying the nucleus.\n\nCompounds known as free radicals form when food is irradiated. Most of these are oxidizers (i.e., accept electrons) and some react very strongly. According to the free-radical theory of aging excessive amounts of these free radicals can lead to cell injury and cell death, which may contribute to many diseases. However, this generally relates to the free radicals generated in the body, not the free radicals consumed by the individual, as much of these are destroyed in the digestive process.\nMost of the substances found in irradiated food are also found in food that has been subjected to other food processing treatments, and are therefore not unique. One family of chemicals (2ACB's) are uniquely formed by irradiation (unique radiolytic products), and this product is nontoxic. When fatty acids are irradiated, a family of compounds called 2-alkylcyclobutanones (2-ACBs) are produced. These are thought to be unique radiolytic products.\nWhen irradiating food, all other chemicals occur in a lower or comparable frequency to other food processing techniques. Furthermore, the quantities in which they occur in irradiated food are lower or similar to the quantities formed in heat treatments.\n\nThe radiation doses to cause toxic changes are much higher than the doses used during irradiation, and taking into account the presence of 2-ACBs along with what is known of free radicals, these results lead to the conclusion that there is no significant risk from radiolytic products.\n\nIonizing radiation can change food quality but in general very high levels of radiation treatment (many thousands of gray) are necessary to adversely change nutritional content, as well as the sensory qualities (taste, appearance, and texture). Irradiation to the doses used commercially to treat food have very little negative impact on the sensory qualities and nutrient content in foods. When irradiation is used to maintain food quality for a longer period of time (improve the shelf stability of some sensory qualities and nutrients) the improvement means that more consumers have access to the original taste, texture, appearance, and nutrients. The changes in quality and nutrition depend on the degree of treatment and may vary greatly from food to food.\n\nThere has been low level gamma irradiation that has been attempted on arugula, spinach, cauliflower, ash gourd, bamboo shoots, coriander, parsley, and watercress. There has been limited information, however, regarding the physical, chemical and/or bioactive properties and the shelf life on these minimally processed vegetables.\n\nThere is some degradation of vitamins caused by irradiation, but is similar to or even less than the loss caused by other processes that achieve the same result. Other processes like chilling, freezing, drying, and heating also result in some vitamin loss.\n\nThe changes in the flavor of fatty foods like meats, nuts and oils are sometimes noticeable, while the changes in lean products like fruits and vegetables are less so. Some studies by the irradiation industry show that for some properly treated fruits and vegetables irradiation is seen by consumers to improve the sensory qualities of the product compared to untreated fruits and vegetables.\n\nWatercress (\"Nasturtium Officinale\") is a rapidly growing aquatic or semi aquatic perennial plant. Because chemical agents do not provide efficient microbial reductions, watercress has been tested with gamma irradiation treatment in order to improve both safety and the shelf life of the product. It is traditionally used on horticultural products to prevent sprouting and post-packaging contamination, delay post-harvest ripening, maturation and senescence.\n\nIn a Food Chemistry food journal, scientists studied the suitability of gamma irradiation of 1, 2, and 5 kGy for preserving quality parameters of the fresh cut watercress at around 4 degrees Celsius for 7 days. They determined that a 2 kGy dose of irradiation was the dose that contained most similar qualities to non-stored control samples, which is one of the goals of irradiation. 2 kGy preserved high levels of reducing sugars and favoured polyunsaturated fatty acids (PUFA); while samples of the 5 kGy dose revealed high contents of sucrose and monounsaturated fat (MUFA). Both cases the watercress samples obtained healthier fatty acids profiles. However, a 5kGy dose better preserved the antioxidant activity and total flavonoids.\n\nIf the majority of food was irradiated at high-enough levels to significantly decrease its nutritional content, there would be an increased risk of developing nutritionally-based illnesses if additional steps, such as changes in eating habits, were not taken to mitigate this. Furthermore, for at least three studies on cats, the consumption of irradiated food was associated with a loss of tissue in the myelin sheath, leading to reversible paralysis. Researchers suspect that reduced levels of vitamin A and high levels of free radicals may be the cause. This effect is thought to be specific to cats and has not been reproduced in any other animal. To produce these effects, the cats were fed solely on food that was irradiated at a dose at least five times higher than the maximum allowable dose.\n\nIt may seem reasonable to assume that irradiating food might lead to radiation-tolerant strains, similar to the way that strains of bacteria have developed resistance to antibiotics. Bacteria develop a resistance to antibiotics after an individual uses antibiotics repeatedly. Much like pasteurization plants, products that pass through irradiation plants are processed once, and are not processed and reprocessed. Cycles of heat treatment have been shown to produce heat-tolerant bacteria, yet no problems have appeared so far in pasteurization plants. Furthermore, when the irradiation dose is chosen to target a specific species of microbe, it is calibrated to doses several times the value required to target the species. This ensures that the process randomly destroys all members of a target species. Therefore, the more irradiation-tolerant members of the target species are not given any evolutionary advantage. Without evolutionary advantage, selection does not occur. As to the irradiation process directly producing mutations that lead to more virulent, radiation-resistant strains, the European Commission's Scientific Committee on Food found that there is no evidence; on the contrary, irradiation has been found to cause loss of virulence and infectivity, as mutants are usually less competitive and less adapted.\n\nSome who advocate against food irradiation argue the safety of irradiated food is not scientifically proven because there are a lack of long-term studies in spite of the fact that hundreds of animal feeding studies of irradiated food, including multigenerational studies, have been performed since 1950. Endpoints investigated have included subchronic and chronic changes in metabolism, histopathology, function of most systems, reproductive effects, growth, teratogenicity, and mutagenicity. A large number of studies have been performed; meta-studies have supported the safety of irradiated food.\n\nThe below experiments are cited by food irradiation opponents, but either could not be verified in later experiments, could not be clearly attributed to the radiation effect, or could be attributed to an inappropriate design of the experiment.\nBULLET::::- India's National Institute of Nutrition (NIN) found an elevated rate of cells with more than one set of genes (polyploidy) in humans and animals when fed wheat that was irradiated recently (within 12 weeks). Upon analysis, scientists determined that the techniques used by the NIN allowed for too much human error and statistical variation; therefore, the results were unreliable. After multiple studies by independent agencies and scientists, no correlation between polyploidy and irradiation of food could be found.\n\nThe indirect effects of irradiation are the concerns and benefits of irradiation that are related to how making food irradiation a common process will change the world, with emphasis on the system of food production.\n\nIf irradiation were to become common in the food handling process there would be a reduction of the prevalence of foodborne illness and potentially the eradication of specific pathogens. However, multiple studies suggest that an increased rate of pathogen growth may occur when irradiated food is cross-contaminated with a pathogen, as the competing spoilage organisms are no longer present. This being said, cross contamination itself becomes less prevalent with an increase in usage of irradiated foods.\n\nThe ability to remove bacterial contamination through post-processing by irradiation may reduce the fear of mishandling food which could cultivate a cavalier attitude toward hygiene and result in contaminants other than bacteria. However, concerns that the pasteurization of milk would lead to increased contamination of milk were prevalent when mandatory pasteurization was introduced, but these fears never materialized after adoption of this law. Therefore, it is unlikely for irradiation to cause an increase of illness due to nonbacteria-based contamination.\n\nUp to the point where the food is processed by irradiation, the food is processed in the same way as all other food. To treat the food, they are exposed to a radioactive source, for a set period of time to achieve a desired dose. Radiation may be emitted by a radioactive substance, or by X-ray and electron beam accelerators. Special precautions are taken to ensure the food stuffs never come in contact with the radioactive substances and that the personnel and the environment are protected from exposure radiation.\nIrradiation treatments are typically classified by dose (high, medium, and low), but are sometimes classified by the effects of the treatment (radappertization, radicidation and radurization). Food irradiation is sometimes referred to as \"cold pasteurization\" or \"electronic pasteurization\" because ionizing the food does not heat the food to high temperatures during the process, and the effect is similar to heat pasteurization. The term \"cold pasteurization\" is controversial because the term may be used to disguise the fact the food has been irradiated and pasteurization and irradiation are fundamentally different processes.\n\nTreatment costs vary as a function of dose and facility usage. A pallet or tote is typically exposed for several minutes to hours depending on dose. Low-dose applications such as disinfestation of fruit range between US$0.01/lbs and US$0.08/lbs while higher-dose applications can cost as much as US$0.20/lbs.\n\nFood processors and manufacturers today struggle with using affordable, efficient packaging materials for irradiation based processing. The implementation of irradiation on prepackaged foods has been found to impact foods by inducing specific chemical alterations to the food packaging material that migrates into the food. Cross-linking in various plastics can lead to physical and chemical modifications that can increase the overall molecular weight. On the other hand, chain scission is fragmentation of polymer chains that leads to a molecular weight reduction.\n\nThe radiation absorbed dose is the amount energy absorbed per unit weight of the target material. Dose is used because, when the same substance is given the same dose, similar changes are observed in the target material. The SI unit for dose is grays (Gy or J/kg). Dosimeters are used to measure dose, and are small components that, when exposed to ionizing radiation, change measurable physical attributes to a degree that can be correlated to the dose received. Measuring dose (dosimetry) involves exposing one or more dosimeters along with the target material.\n\nFor purposes of legislation doses are divided into low (up to 1 kGy), medium (1 kGy to 10 kGy), and high-dose applications (above 10 kGy). High-dose applications are above those currently permitted in the US for commercial food items by the FDA and other regulators around the world. Though these doses are approved for non commercial applications, such as sterilizing frozen meat for NASA astronauts (doses of 44 kGy) and food for hospital patients.\n+Applications of food irradiation\nApplication\nDose (kGy)\nInhibit sprouting (potatoes, onions, yams, garlic)\n0.06 - 0.2\nDelay in ripening (strawberries, potatoes)\n0.5 - 1.0\nPrevent insect infestation (grains, cereals, coffee beans, spices, dried nuts, dried fruits, dried fish, mangoes, papayas)\n0.15 - 1.0\nParasite control and inactivation (tape worm, trichina)\n0.3 - 1.0\nExtend shelf-life (raw and fresh fish, seafood, fresh produce, refrigerated and frozen meat products)\n1.0 - 7.0\nReduce risk of pathogenic and spoilage microbes (meat, seafood, spices, and poultry)\n1.0 - 7.0\nIncreased juice yield, reduction in cooking time of dried vegetables\n3.0 - 7.0\nEnzymes (dehydrated)\n10.0\nSterilization of spices, dry vegetable seasonings\n30.0 max\nSterilization of packaging material\n10.0 - 25.0\nSterilization of foods (NASA and hospitals)\n44.0\n\nGamma irradiation is produced from the radioisotopes cobalt-60 and caesium-137, which are derived by neutron bombardment of cobalt-59 and as a nuclear source by-product, respectively. Cobalt-60 is the most common source of gamma rays for food irradiation in commercial scale facilities as it is water insoluble and hence has little risk of environmental contamination by leakage into the water systems. As for transportation of the radiation source, cobalt-60 is transported in special trucks that prevent release of radiation and meet standards mentioned in the Regulations for Safe Transport of Radioactive Materials of the International Atomic Energy Act. The special trucks must meet high safety standards and pass extensive tests to be approved to ship radiation sources. Conversely, caesium-137, is water soluble and poses a risk of environmental contamination. Insufficient quantities are available for large scale commercial use. An incident where water-soluble caesium-137 leaked into the source storage pool requiring NRC intervention has led to near elimination of this radioisotope.\n\nGamma irradiation is widely used due to its high penetration depth and dose uniformity, allowing for large-scale applications with high through puts. Additionally, gamma irradiation is significantly less expensive than using an X-ray source In most designs, the radioisotope, contained in stainless steel pencils, is stored in a water-filled storage pool which absorbs the radiation energy when not in use. For treatment, the source is lifted out of the storage tank, and product contained in totes is passed around the pencils to achieve required processing.\n\nTreatment of electron beams is created as a result of high energy electrons in an accelerator that generates electrons accelerated to 99% the speed of light. This system uses electrical energy and can be powered on and off. The high power correlates with a higher throughput and lower unit cost, but electron beams have low dose uniformity and a penetration depth of centimeters. Therefore, electron beam treatment works for products that have low thickness.\nX-rays are produced by bombardment of dense target material with high energy accelerated electrons(this process is known as bremsstrahlung-conversion), giving rise to a continuous energy spectrum. Heavy metals, such as tantalum and tungsten, are used because of their high atomic numbers and high melting temperatures.Tantalum is usually preferred versus tungsten for industrial, large-area, high-power targets because it is more workable than tungsten and has a higher threshold energy for induced reactions. Like electron beams, x-rays do not require the use of radioactive materials and can be turned off when not in use. X-rays have high penetration depths and high dose uniformity but they are a very expensive source of irradiation as only 8% of the incident energy is converted into X-rays.\n\nThe cost of food irradiation is influenced by dose requirements, the food's tolerance of radiation, handling conditions, i.e., packaging and stacking requirements, construction costs, financing arrangements, and other variables particular to the situation. Irradiation is a capital-intensive technology requiring a substantial initial investment, ranging from $1 million to $5 million. In the case of large research or contract irradiation facilities, major capital costs include a radiation source, hardware (irradiator, totes and conveyors, control systems, and other auxiliary equipment), land (1 to 1.5 acres), radiation shield, and warehouse. Operating costs include salaries (for fixed and variable labor), utilities, maintenance, taxes/insurance, cobalt-60 replenishment, general utilities, and miscellaneous operating costs. Perishable food items, like fruits, vegetables and meats would still require to be handled in the cold chain, so all other supply chain costs remain the same.\n\nNegative connotations associated with the word \"radiation\" are thought to be responsible for low consumer acceptance. Several national expert groups and two international expert groups evaluated the available data and concluded that any food at any dose is wholesome and safe to consume.\n\nIrradiation has been approved by many countries. For example, in the U.S. the FDA has approved food irradiation for over fifty years. However, in the past decade the major growth area is for fruits and vegetables that are irradiated to prevent the spread of pests. In the early 2000s in the US, irradiated meat was common at some grocery stores, but because of lack of consumer demand, it is no longer common. Because consumer demand for irradiated food is low, reducing the spoilage between manufacturer and consumer purchase and reducing the risk of food borne illness is currently not sufficient incentive for most manufacturers to supplement their process with irradiation. Nevertheless, food irradiation does take place commercially and volumes are in general increasing at a slow rate, even in the European Union where all member countries allow the irradiation of dried herbs spices and vegetable seasonings but only a few allow other foods to be sold as irradiated.\n\nAlthough there are some consumers who choose not to purchase irradiated food, a sufficient market has existed for retailers to have continuously stocked irradiated products for years. When labeled irradiated food is offered for retail sale, these consumers buy it and re-purchase it, indicating that it is possible to successfully market irradiated foods, therefore retailers not stocking irradiated foods might be a major bottleneck to the wider adoption of irradiated foods. It is however, widely believed that consumer perception of foods treated with irradiation is more negative than those processed by other means and some industry studies indicate the number of consumers concerned about the safety of irradiated food decreased between 1985 and 1995 to levels comparable to those of people concerned about food additives and preservatives. Even though is it is untrue \"People think the product is radioactive,\" said Harlan Clemmons, president of Sadex, a food irradiation company based in Sioux City, Iowa. Because of these concerns and the increased cost of irradiated foods, there is not a widespread public demand for the irradiation of foods for human consumption. Irradiated food does not become radioactive.\n\nThe Codex Alimentarius represents the global standard for irradiation of food, in particular under the WTO-agreement. Regardless of treatment source, all processing facilities must adhere to safety standards set by the International Atomic Energy Agency (IAEA), Codex Code of Practice for the Radiation Processing of Food, Nuclear Regulatory Commission (NRC), and the International Organization for Standardization (ISO). More specifically, ISO 14470 and ISO 9001 provide in-depth information regarding safety in irradiation facilities.\n\nAll commercial irradiation facilities contain safety systems which are designed to prevent exposure of personnel to radiation. The radiation source is constantly shielded by water, concrete, or metal. Irradiation facilities are designed with overlapping layers of protection, interlocks, and safeguards to prevent accidental radiation exposure. Additionally, \"melt-downs\" do not occur in facilities because the radiation source gives off radiation and decay heat; however, the heat is not sufficient to melt any material.\n\nThe provisions of the Codex Alimentarius are that any \"first generation\" product must be labeled \"irradiated\" as any product derived directly from an irradiated raw material; for ingredients the provision is that even the last molecule of an irradiated ingredient must be listed with the ingredients even in cases where the unirradiated ingredient does not appear on the label. The RADURA-logo is optional; several countries use a graphical version that differs from the Codex-version. The suggested rules for labeling is published at CODEX-STAN – 1 (2005), and includes the usage of the Radura symbol for all products that contain irradiated foods. The Radura symbol is not a designator of quality. The amount of pathogens remaining is based upon dose and the original content and the dose applied can vary on a product by product basis.\n\nThe European Union follows the Codex's provision to label irradiated ingredients down to the last molecule of irradiated food. The European Community does not provide for the use of the Radura logo and relies exclusively on labeling by the appropriate phrases in the respective languages of the Member States. The European Union enforces its irradiation labeling laws by requiring its member countries to perform tests on a cross section of food items in the market-place and to report to the European Commission. The results are published annually in the OJ of the European Communities.\n\nThe US defines irradiated foods as foods in which the irradiation causes a material change in the food, or a material change in the consequences that may result from the use of the food. Therefore, food that is processed as an ingredient by a restaurant or food processor is exempt from the labeling requirement in the US. All irradiated foods must include a prominent Radura symbol followed in addition to the statement \"treated with irradiation\" or \"treated by irradiation. Bulk foods must be individually labeled with the symbol and statement or, alternatively, the Radura and statement should be located next to the sale container.\n\nUnder section 409 of the Federal Food, Drug, and Cosmetic Act, irradiation of prepackaged foods requires premarket approval for not only the irradiation source for a specific food but also for the food packaging material. Approved packaging materials include various plastic films, yet does not cover a variety of polymers and adhesive based materials that have been found to meet specific standards. The lack of packaging material approval limits manufacturers production and expansion of irradiated prepackaged foods.\n\nApproved materials by FDA for Irradiation according to 21 CFR 179.45:\nMaterial\nPaper (kraft)\nPaper (glassine)\nPaperboard\nCellophane (coated)\nPolyolefin film\nPolyestyrene film\nNylon-6\nVegetable Parchment\nNylon 11\nIrradiation (kGy)\n.05\n10\n10\n10\n10\n10\n10\n60\n60\n\nIn 2003, the Codex Alimentarius removed any upper dose limit for food irradiation as well as clearances for specific foods, declaring that all are safe to irradiate. Countries such as Pakistan and Brazil have adopted the Codex without any reservation or restriction.\n\nStandards that describe calibration and operation for radiation dosimetry, as well as procedures to relate the measured dose to the effects achieved and to report and document such results, are maintained by the American Society for Testing and Materials (ASTM international) and are also available as ISO/ASTM standards.\n\nAll of the rules involved in processing food are applied to all foods before they are irradiated.\n\nThe U.S. Food and Drug Administration (FDA) is the agency responsible for regulation of radiation sources in the United States. Irradiation, as defined by the FDA is a \"food additive\" as opposed to a food process and therefore falls under the food additive regulations. Each food approved for irradiation has specific guidelines in terms of minimum and maximum dosage as determined safe by the FDA. Packaging materials containing the food processed by irradiation must also undergo approval. The United States Department of Agriculture (USDA) amends these rules for use with meat, poultry, and fresh fruit.\n\nThe United States Department of Agriculture (USDA) has approved the use of low-level irradiation as an alternative treatment to pesticides for fruits and vegetables that are considered hosts to a number of insect pests, including fruit flies and seed weevils. Under bilateral agreements that allows less-developed countries to earn income through food exports agreements are made to allow them to irradiate fruits and vegetables at low doses to kill insects, so that the food can avoid quarantine.\n\nEuropean law dictates that all member countries must allow the sale of irradiated dried aromatic herbs, spices and vegetable seasonings. However, these Directives allow Member States to maintain previous clearances food categories the EC's Scientific Committee on Food (SCF) had previously approved (the approval body is now the European Food Safety Authority). Presently, Belgium, Czech Republic, France, Italy, Netherlands, Poland, and the United Kingdom allow the sale of many different types of irradiated foods. Before individual items in an approved class can be added to the approved list, studies into the toxicology of each of such food and for each of the proposed dose ranges are requested. It also states that irradiation shall not be used \"as a substitute for hygiene or health practices or good manufacturing or agricultural practice\". These Directives only control food irradiation for food retail and their conditions and controls are not applicable to the irradiation of food for patients requiring sterile diets.\n\nBecause of the Single Market of the EC any food, even if irradiated, must be allowed to be marketed in any other Member State even if a general ban of food irradiation prevails, under the condition that the food has been irradiated legally in the state of origin.\nFurthermore, imports into the EC are possible from third countries if the irradiation facility had been inspected and approved by the EC and the treatment is legal within the EC or some Member state.\n\nAustralia banned irradiated cat food after a national scare where cats suffered from paralyzation after eating a specific brand of highly irradiated catfood for an extended period of time. The suspected culprit was malnutrition from consuming food depleted of Vitamin A by the irradiation process. The incident was linked only to a single batch of one brand's product and no illness was linked to any of that brand's other irradiated batches of the same product or to any other brand of irradiated cat food. This, along with incomplete evidence indicating that the cat food was not sufficiently depleted of Vitamin A makes irradiation a less likely cause. Further research has been able to experimentally induce the paralyzation of cats by via Vitamin A deficiency by feeding highly irradiated food. For more details see the long term impacts section.\n\nInterlocks and safeguards are mandated to minimize this risk. There have been radiation-related accidents, deaths, and injury at such facilities, many of them caused by operators overriding the safety related interlocks. In a radiation processing facility, radiation specific concerns are supervised by special authorities, while \"Ordinary\" occupational safety regulations are handled much like other businesses.\n\nThe safety of irradiation facilities is regulated by the United Nations International Atomic Energy Agency and monitored by the different national Nuclear Regulatory Commissions. The regulators enforce a safety culture that mandates that all incidents that occur are documented and thoroughly analyzed to determine the cause and improvement potential. Such incidents are studied by personnel at multiple facilities, and improvements are mandated to retrofit existing facilities and future design.\n\nIn the US the Nuclear Regulatory Commission (NRC) regulates the safety of the processing facility, and the United States Department of Transportation (DOT) regulates the safe transport of the radioactive sources.\n\nAs of 2010, the quantities of foods irradiated in Asia, the EU and the US were 285,200, 9,300, and 103,000 tons. Authorities in some countries use tests that can detect the irradiation of food items to enforce labeling standards and to bolster consumer confidence. The European Union monitors the market to determine the quantity of irradiated foods, if irradiated foods are labeled as irradiated, and if the irradiation is performed at approved facilities.\n\nIrradiation of fruits and vegetables to prevent the spread of pest and diseases across borders has been increasing globally. In 2010, 18,446 tonnes of fruits and vegetables were irradiated in six countries for export quarantine control. 97% of this was exported to the United States.\n\nIn total, 103,000 tonnes of food products were irradiated on mainland United States in 2010. The three types of foods irradiated the most were spices (77.7%), fruits and vegetables (14.6%) and meat and poultry (7.77%). 17,953 tonnes of irradiated fruits and vegetables were exported to the mainland United States. Mexico, the United States' state of Hawaii, Thailand, Vietnam and India export irradiated produce to the mainland U.S. Mexico, followed by the United States' state of Hawaii, is the largest exporter of irradiated produce to the mainland U.S.\n\nIn total, 6,876 tonnes of food products were irradiated in European Union countries in 2013,mainly in four member state countries: Belgium (49.4%), the Netherlands (24.4%), Spain (12.7%) and France (10.0%). The two types of foods irradiated the most were frog legs (46%), and dried herbs and spices (25%). There has been a decrease of 14% in the total quantity of products irradiated in the EU compared to the previous year 2012 (7,972 tonnes).\n\nThe U.S. Food and Drug Administration and the U.S. Department of Agriculture have approved irradiation of the following foods and purposes:\n\nBULLET::::- Packaged refrigerated or frozen red meat — to control pathogens (E. Coli O157:H7 and Salmonella) and to extend shelf life.\nBULLET::::- Packaged poultry — control pathogens (Salmonella and Camplylobacter).\nBULLET::::- Fresh fruits, vegetables, and grains — to control insects and inhibit growth, ripening and sprouting.\nBULLET::::- Pork — to control trichinosis.\nBULLET::::- Herbs, spices and vegetable seasonings — to control insects and microorganisms.\nBULLET::::- Dry or dehydrated enzyme preparations — to control insects and microorganisms.\nBULLET::::- White potatoes — to inhibit sprout development.\nBULLET::::- Wheat and wheat flour — to control insects.\nBULLET::::- Loose or bagged fresh iceberg lettuce and spinach\nBULLET::::- Crustaceans (lobster, shrimp, and crab)\nBULLET::::- Shellfish (oysters, clams, mussels, and scallops)\n\nBULLET::::- 1895 Wilhelm Conrad Röntgen discovers X-rays (\"bremsstrahlung\", from German for radiation produced by deceleration)\nBULLET::::- 1896 Antoine Henri Becquerel discovers natural radioactivity; Minck proposes the therapeutic use\nBULLET::::- 1904 Samuel Prescott describes the bactericide effects Massachusetts Institute of Technology (MIT)\nBULLET::::- 1906 Appleby & Banks: UK patent to use radioactive isotopes to irradiate particulate food in a flowing bed\nBULLET::::- 1918 Gillett: U.S. Patent to use X-rays for the preservation of food\nBULLET::::- 1921 Schwartz describes the elimination of Trichinella from food\nBULLET::::- 1930 Wuest: French patent on food irradiation\nBULLET::::- 1943 MIT becomes active in the field of food preservation for the U.S. Army\nBULLET::::- 1951 U.S. Atomic Energy Commission begins to co-ordinate national research activities\nBULLET::::- 1958 World first commercial food irradiation (spices) at Stuttgart, Germany\nBULLET::::- 1970 Establishment of the International Food Irradiation Project (IFIP), headquarters at the Federal Research Centre for Food Preservation, Karlsruhe, Germany\nBULLET::::- 1980 FAO/IAEA/WHO Joint Expert Committee on Food Irradiation recommends the clearance generally up to 10 kGy \"overall average dose\"\nBULLET::::- 1981/1983 End of IFIP after reaching its goals\nBULLET::::- 1983 Codex Alimentarius General Standard for Irradiated Foods: any food at a maximum \"overall average dose\" of 10 kGy\nBULLET::::- 1984 International Consultative Group on Food Irradiation (ICGFI) becomes the successor of IFIP\nBULLET::::- 1998 The European Union's Scientific Committee on Food (SCF) voted \"positive\" on eight categories of irradiation applications\nBULLET::::- 1997 FAO/IAEA/WHO Joint Study Group on High-Dose Irradiation recommends to lift any upper dose limit\nBULLET::::- 1999 The European Union issues Directives 1999/2/EC (framework Directive) and 1999/3/EC (implementing Directive) limiting irradiation a positive list whose sole content is one of the eight categories approved by the SFC, but allowing the individual states to give clearances for any food previously approved by the SFC.\nBULLET::::- 2000 Germany leads a veto on a measure to provide a final draft for the positive list.\nBULLET::::- 2003 Codex Alimentarius General Standard for Irradiated Foods: no longer any upper dose limit\nBULLET::::- 2003 The SCF adopts a \"revised opinion\" that recommends against the cancellation of the upper dose limit.\nBULLET::::- 2004 ICGFI ends\nBULLET::::- 2011 The successor to the SFC, European Food Safety Authority (EFSA), reexamines the SFC's list and makes further recommendations for inclusion.\n\nBULLET::::- \"Deinococcus radiodurans\"\nBULLET::::- Food labeling regulations\nBULLET::::- Food and cooking hygiene\nBULLET::::- Irradiated mail\nBULLET::::- Chemical sterilization\nBULLET::::- Radurization\n\nBULLET::::- World Health Organization publications:\nBULLET::::- Safety and nutritional adequacy of irradiated food, WHO, Geneva, 1994\nBULLET::::- High-dose irradiation: Wholesomeness of food irradiated with doses above 10 kGy, WHO, Geneva, 1999, Technical Report Series No. 890\nBULLET::::- Diehl, J.F., Safety of irradiated foods, Marcel Dekker, N.Y., 1995 (2. ed.)\nBULLET::::- Satin, M., Food irradiation, Technomic, Lancaster, 1996 (2. ed.)\nBULLET::::- Urbain, W.M., Food irradiation, Academic Press, Orlando, 1986\nBULLET::::- Molins, R. (ed.), Food irradiation – Principles and applications, Wiley Interscience, N.Y., 2001\nBULLET::::- Sommers, C.H. and Fan, X. (eds.), Food Irradiation Research and Technology, Blackwell Publishing, Ames, IA, 2006\nBULLET::::- \"The Food That Would Last Forever : Understanding the Dangers of Food Irradiation\", by Gary Gibbs, Garden City Park, N.Y. : Avery Pub. Group, c1993\nBULLET::::- anon., Food Irradiation: Available Research Indicates That Benefits Outweigh Risks, RCED-00-217, August 24, 2000, Government Accountability Office, United States General Accounting Office, Resources, Community, and Economic Development Division, Washington, D.C. 20548 \"Food Irradiation\"\nBULLET::::- Farkas, J. and Mohácsi-Farkas, C., History and future of food irradiation, Food Sci. Technol. 22(2011),121-128\nBULLET::::- Evaluation of the Significance of 2-Dodecylcyclobutanone and other Alkylcyclobutanones\n\nBULLET::::- Codex Alimentarius\nBULLET::::- Codex Alimentarius Recommended International Code of Practice Code for Radiation Processing of Foods (CAC/RCP 19-1979, rev.2 – 2003)\nBULLET::::- General Standard for the Labelling of Prepacked Foods (CODEX STAN 1-1985)\nBULLET::::- Food Irradiation Processing Alliance FIPA represents the irradiation service industry, manufacturers of food irradiators and suppliers of cobalt-60 sources.\nBULLET::::- , Center for Food Safety and Applied Nutrition (US Government)\nBULLET::::- , a series of 14 fact sheets, International Consultative Group on Food Irradiation, International Atomic Energy Agency, Vienna, 1991\nBULLET::::- Bibliography on Food Irradiation, Federal Research Centre for Nutrition and Food, Karlsruhe, Germany\n"}
{"id": "15378", "url": "https://en.wikipedia.org/wiki?curid=15378", "title": "Copper IUDs", "text": "Copper IUDs\n\nIntrauterine device (IUD) with copper also known as intrauterine coil, is a type of intrauterine device which contains copper. It is used for birth control and emergency contraception within five days of unprotected sex. It is one of the most effective forms of birth control with a one-year failure rate around 0.7%. The device is placed in the uterus and lasts up to twelve years. It may be used by women of all ages regardless of whether or not they have had children. Following removal, fertility quickly returns.\nSide effects include heavy menstrual periods, painful periods, or the device may come out. It is less recommended in people at high risk of sexually transmitted infections as it may increase the risk of pelvic inflammatory disease in the first three weeks after insertion. If a woman becomes pregnant with an IUD in place removal is recommended. Rarely uterine perforation can occur during insertion. The copper IUD is a type of long-acting reversible birth control. It primarily works by killing the sperm.\nThe copper IUD came into medical use in the 1970s. It is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system. The wholesale cost in the developing world is about US$0.37–3.00 per IUD. In the United Kingdom they cost the NHS about £10 GBP. In the United States they cost around $750. They are used by more than 170 million women globally.\n\nCopper IUDs are a form of long-acting reversible contraception and are one of the most effective forms of birth control available. The type of frame and amount of copper can affect the effectiveness of different copper IUD models. The failure rates for different models vary between 0.1 and 2.2% after 1 year of use. The T-shaped models with a surface area of 380 mm² of copper have the lowest failure rates. The TCu 380A (ParaGard) has a one-year failure rate of 0.8% and a cumulative 12-year failure rate of 2.2%. Over 12 years of use, the models with less surface area of copper have higher failure rates. The TCu 220A has a 12-year failure rate of 5.8%. The frameless GyneFix also has a failure rate of less than 1% per year. Worldwide, older IUD models with lower effectiveness rates are no longer produced.\n\nUnlike other forms of reversible contraception, the typical use failure rate and the perfect use failure rate for the copper IUDs are the same because the IUD does not depend on user action. A 2008 review of the available T-shaped copper IUDs recommended that the TCu 380A and the TCu 280S be used as the first choice for copper IUDs because those two models have the lowest failure rates and the longest lifespans. The effectiveness of the copper IUD (failure rate of 0.8%) is comparable to tubal sterilization (failure rate of 0.5%) for the first year. However, the effects of the copper IUD are reversible, which can be viewed as either an advantage or a disadvantage, depending on a person's goals for contraception.\n\nIt was first discovered in 1976 that the copper IUD could be used as a form of emergency contraception (EC).\nThe copper IUD is the most effective form of emergency contraception. It is more effective than the hormonal EC pills currently available.\nThe pregnancy rate among those using the copper IUD for EC is 0.09%. It can be used for EC up to 5 days after the act of unprotected sex and does not decrease in effectiveness during the 5 days.\nAn additional advantage of using the copper IUD for emergency contraception is that it can be used as a form of birth control for 10–12 years after insertion.\n\nRemoval of the copper IUD should also be performed by a qualified medical practitioner. Fertility has been shown to return to previous levels quickly after removal of the device. One study found that the median amount of time from removal to planned pregnancy was three months for those women using the TCu 380Ag.\n\nExpulsion: Sometimes the copper IUD can be spontaneously expelled from the uterus. Expulsion rates can range from 2.2% to 11.4% of users from the first year to the 10th year. The TCu380A may have lower rates of expulsion than other models. Unusual vaginal discharge, cramping or pain, spotting between periods, postcoital (after sex) spotting, dyspareunia, or the absence or lengthening of the strings can be signs of a possible expulsion. If expulsion occurs, the woman is not protected against pregnancy. If an IUD with copper is inserted after an expulsion has occurred, the risk of re-expulsion has been estimated in one study to be approximately one third of cases after one year. Magnetic resonance imaging may cause dislocation of a copper IUD, and it is therefore recommended to check the location of the IUD both before and after MRI.\n\nPerforation: Very rarely, the IUD can move through the wall of the uterus. Risk of perforation is mostly determined by the skill of the practitioner performing the insertion. For experienced medical practitioners, the risk of perforation is 1 per 1,000 insertions or less. If perforation does occur it can damage the internal organs, and in some cases surgery is needed to remove the IUD.\n\nInfection: The insertion of a copper IUD poses a transient risk of pelvic inflammatory disease (PID) in the first 21 days after insertion. However, it is a small risk and is attributable to preexisting gonorrhea or chlamydia infection at the time of insertion, and not to the IUD itself. Proper infection prevention procedures have little or no effect on the course of gonorrhea or chlamydia infections, but is important in helping protect both clients and providers from infection in general. Such infection prevention practices include washing hands and then putting on gloves, cleaning the cervix and vagina, making minimal contact with non-sterile surfaces (using a \"no touch insertion technique\") and, after the procedure, washing hands again and then processing instruments. The device itself carries no increased risk of PID beyond the time of insertion.\n\nCramping: Many women feel cramping or pain during the IUD insertion process and immediately after as a result of cervix dilation during insertion. Taking NSAIDS before the procedure can reduce discomfort, as can the use of a local anaesthetic. Misoprostol 6 to 12 hrs before insertion can help with cervical dilation. Some women may have cramps for 1 to 2 weeks following insertion. The copper IUD can also increase cramps during a woman's period. This symptom will clear up for some women in 3 to 6 months, but may not for others.\n\nHeavier periods: The copper IUD increases the amount of blood flow during a woman's menstrual periods. On average, menstrual blood loss increases by 20–50% after insertion of a copper-T IUD; increased menstrual discomfort is the most common medical reason for IUD removal. This symptom may clear up for some women after 3 to 6 months, but may not for others.\n\nIrregular bleeding and spotting: For the first 3 to 6 months after insertion, the copper IUD can cause irregular periods and spotting between periods.\nString problems: A small portion of men report that they can feel the strings during intercourse. In this case, strings can be trimmed. However, very short strings can prevent the woman from checking the strings for expulsion. Medical ultrasonography may be required in such cases to check the location of the IUD.\n\nPregnancy: Although rare, if pregnancy does occur with the copper IUD in place there can be serious side effects. The risk of ectopic pregnancy to a woman using an IUD is lower than the risk of ectopic pregnancy to a woman using no form of birth control. However, of pregnancies that do occur during IUD use, a higher than expected percentage (3–4%) are ectopic. If a pregnancy occurs with the IUD in place there is a higher risk of miscarriage or early delivery. If this occurs and the IUD strings are visible, the IUD should be removed immediately by a clinician. Although the Dalkon Shield IUD was associated with septic abortions (infections associated with miscarriage), other brands of IUD are not. IUDs are also \"not\" associated with birth defects.\n\nSome barrier contraceptives protect against STIs. Hormonal contraceptives reduce the risk of developing pelvic inflammatory disease (PID), a serious complication of certain STIs. IUDs, by contrast, do \"not\" protect against STIs or PID.\n\nA category 3 condition indicates conditions where the theoretical or proven risks usually outweigh the advantages of inserting a copper IUD. A category 4 condition indicates conditions that represent an unacceptable health risk if a copper IUD is inserted.\n\nWomen should not use a copper IUD if they:\n\nBULLET::::- Are pregnant or think they may be pregnant\nBULLET::::- Having a septic pregnancy or abortion\nBULLET::::- Have unexplained abnormal vaginal bleeding\nBULLET::::- Have untreated cervical cancer\nBULLET::::- Have malignant gestational trophoblastic disease\nBULLET::::- Have uterine cancer\nBULLET::::- Have certain uterine abnormalities\nBULLET::::- Have or may have had a pelvic infection within the past three months\nBULLET::::- Have or may have an STI\nBULLET::::- Have pelvic tuberculosis\n\nBULLET::::- Are postpartum between 48 hours and 4 weeks (increased IUD expulsion rate with delayed postpartum insertion). The CDC and WHO criteria differ in their recommendation for women postpartum between 48 hours and 4 weeks. The CDC does not list this as a contraindication.\nBULLET::::- Have benign gestational trophoblastic disease\nBULLET::::- Have ovarian cancer\nBULLET::::- Have AIDS (unless clinically well on anti-retroviral therapy)\nBULLET::::- Have very high individual likelihood of exposure to gonorrhea or chlamydial STIs\n\nA full list of contraindications can be found in the WHO \"Medical Eligibility Criteria for Contraceptive Use\" and the CDC \"United States Medical Eligibility Criteria for Contraceptive Use\".\n\nWhile nulliparous women (women who have never given birth) are somewhat more likely to have side effects, this is not a contraindication for IUD use. Overall, IUDs are safe and acceptable also in young nulliparous women. The same is likely the case for virgin women, unless there is a microperforate hymen that obstructs any insertion of the IUD.\n\nThere are a number of models of the copper IUD available around the world. Most copper devices consist of a plastic core that is wrapped in a copper wire.\nMany of the devices have a T-shape similar to the hormonal IUD. However, there are \"frameless\" copper IUDs available around the world as well. ParaGard is the only model currently available in the United States. At least three copper IUD models are available in Canada, two of which are a slimmer T-shape version used for women who have not had children. Early copper IUDs had copper around only the vertical stem, but more recent models have copper sleeves wrapped around the horizontal arms as well, increasing effectiveness.\nSome newer models also contain a silver core instead of a plastic core to delay copper fragmentation as well as increase the lifespan of the device. The lifespan of the devices range from 3 years to 10 years; however, some studies have demonstrated that the TCu 380A may be effective through 12 years.\n\nIts ATC code is .\n\nThe copper IUD must be inserted by a qualified medical practitioner. A copper IUD can be inserted at any phase of the menstrual cycle, but the optimal time is right after the menstrual period, when the cervix is softest and the woman is least likely to be pregnant. The insertion process generally takes five minutes or less. The procedure can cause cramping or be painful for some women.\nBefore placement of an IUD, a medical history and physical examination by a medical professional is useful to check for any contraindications or concerns. It is also recommended by some clinicians that patients be tested for gonorrhea and chlamydia, as these two infections increase the risk of contracting pelvic inflammatory disease shortly after insertion.\nImmediately prior to insertion, the clinician will perform a pelvic exam to determine the position of the uterus.\nAfter the pelvic exam, the vagina is held open with a speculum. A tenaculum is used to steady the cervix and uterus. Uterine sounding may be used to measure the length and direction of the cervical canal and uterus in order to decrease the risk of uterine perforation. The IUD is placed using a narrow tube, which is inserted through the cervix into the uterus. Short monofilament plastic/nylon strings hang down from the uterus into the vagina. The clinician will trim the threads so that they only protrude 3 to 4 cm out of the cervix and remain in the upper vagina. The strings allow the patient or clinician to periodically check to ensure the IUD is still in place and to enable easy removal of the device.\n\nThe copper IUD can be inserted at any time in a woman's menstrual cycle as long as the woman is not pregnant. An IUD can also be inserted immediately postpartum and post-abortion as long as no infection has occurred. Breastfeeding is not a contraindication for the use of the copper IUD. The IUD can be inserted in women with HIV or AIDS as it does not increase the risk of transmission.\nAlthough previously not recommended for nulliparous women (women who have not had children), the IUD is now recommended for most women who are past menarche (their first period), including adolescents.\n\nAfter the insertion is finished, normal activities such as sex, exercise, and swimming can be performed as soon as it feels comfortable. Strenuous physical activity does not affect the position of the IUD.\n\nMany different types of copper IUDs are currently manufactured worldwide, but availability varies by country. In the United States, only one type of copper IUD is approved for use, while in the United Kingdom, over ten varieties are available. One company, Mona Lisa N.V. offers generic versions of many existing IUDs.\n\n! IUD !! Type !! Copper (mm) !! Life (years) !! Manufacturer !! Distinguishing characteristics\nProtect TCu 380A\nT-shaped (banded)\n380\n12\nSMB corp\nWHO UNFPA Prequalified IUD Manufacturer\nProtect Multi-arm Cu 375 standard\nU-shaped\n375\n5\nSMB corp\nWHO UNFPA Prequalified IUD Manufacturer\nProtect Multi-arm Cu 375 short\nU-shaped\n375\n5\nSMB corp\nWHO UNFPA Prequalified IUD Manufacturer\n\nThe frameless IUD eliminates the use of the frame that gives conventional IUDs their signature T-shape. This change in design was made to reduce discomfort and expulsion associated with prior IUDs; without a solid frame, the frameless IUD should mold to the shape of the uterus. It may reduce expulsion and discontinuation rates compared to framed copper IUDs.\n\nGynefix is the only frameless IUD brand currently available. It consists of hollow copper tubes on a polypropylene thread. It is inserted through the cervix with a special applicator that sutures the thread to the fundus (top) of the uterus; the thread is then cut with a tail hanging outside of the cervix, similar to frame IUDs. When this tail is pulled, the suture comes undone and the device can be removed. This requires more force than removing a T-shaped IUD, but results in comparable discomfort during removal. Gynefix is not approved for use in the United States.\n\nThe copper IUD's primary mechanism of action is to prevent fertilization. Copper acts as a spermicide within the uterus. The presence of copper increases the levels of copper ions, prostaglandins, and white blood cells within the uterine and tubal fluids.\n\nAlthough not a primary mechanism of action, some experts in human reproduction believe there is sufficient evidence to suggest that IUDs with copper can disrupt implantation, especially when used for emergency contraception. Despite this, there has been no definitive evidence that IUD users have higher rates of embryonic loss than women not using contraception. Therefore, the copper IUD is considered to be a true contraceptive and not an abortifacient.\n\nGlobally, the IUD is the most widely used method of reversible birth control. The most recent data indicates that there are 169 million IUD users around the world. This includes both the nonhormonal and hormonal IUDs. IUDs are most popular in Asia, where the prevalence is almost 30%. In Africa and Europe the prevalence is around 20%. As of 2009, levels of IUD use in the United States are estimated to be 5.5%. Data in the United States does not distinguish between hormonal and nonhormonal IUDs. In Europe, copper IUD prevalence ranges from under 5% in the United Kingdom to over 10% in Denmark in 2006.\n\nAccording to popular legend, Arab traders inserted small stones into the uteruses of their camels to prevent pregnancy during long desert treks. The story was originally a tall tale to entertain delegates at a scientific conference on family planning; although it was later repeated as truth, it has no known historical basis.\n\nPrecursors to IUDs were first marketed in 1902. Developed from stem pessaries (where the stem held the pessary in place over the cervix), the 'stem' on these devices actually extended into the uterus itself. Because they occupied both the vagina and the uterus, this type of stem pessary was also known as an \"interuterine device\". Use of \"interuterine\" devices was associated with high rates of infection; for this reason, they were condemned by the medical community.\n\nThe first intrauterine device (contained entirely in the uterus) was described in a German publication in 1909, although the author appears to have never marketed his product.\n\nIn 1929, Ernst Gräfenberg of Germany published a report on an IUD made of silk suture. He had found a 3% pregnancy rate among 1,100 women using his ring. In 1930, Gräfenberg reported a lower pregnancy rate of 1.6% among 600 women using an improved ring wrapped in silver wire. Unbeknownst to Gräfenberg, the silver wire was contaminated with 26% copper. Copper's role in increasing IUD efficacy would not be recognized until nearly 40 years later.\n\nIn 1934, Japanese physician Tenrei Ota developed a variation of the \"Gräfenberg ring\" that contained a supportive structure in the center. The addition of this central disc lowered the IUD's expulsion rate. These devices still had high rates of infection, and their use and development was further stifled by World War II politics: contraception was forbidden in both Nazi Germany and Axis-allied Japan. The Allies did not learn of the work by Gräfenberg and Ota until well after the war ended.\n\nThe first plastic IUD, the \"Margulies Coil\" or \"Margulies Spiral\", was introduced in 1958. This device was somewhat large, causing discomfort to a large proportion of women users, and had a hard plastic tail, causing discomfort to their male partners. The modern colloquialism \"coil\" is based on the coil-shaped design of early IUDs.\n\nThe \"Lippes Loop\", a slightly smaller device with a monofilament tail, was introduced in 1962 and gained in popularity over the Margulies device.\n\nThe stainless steel single-ring IUD was developed in the 1970s and widely used in China because of low manufacturing costs. The Chinese government banned production of steel IUDs in 1993 due to high failure rates (up to 10% per year).\n\nHoward Tatum, in the US, conceived the plastic T-shaped IUD in 1968. Shortly thereafter Jaime Zipper, in Chile, introduced the idea of adding copper to the devices to improve their contraceptive effectiveness. It was found that copper-containing devices could be made in smaller sizes without compromising effectiveness, resulting in fewer side effects such as pain and bleeding. T-shaped devices had lower rates of expulsion due to their greater similarity to the shape of the uterus.\n\nThe poorly designed Dalkon Shield plastic IUD (which had a multifilament tail) was manufactured by the A. H. Robins Company and sold by Robins in the United States for three and a half years from January 1971 through June 1974, before sales were suspended by Robins on June 28, 1974 at the request of the FDA because of safety concerns following reports of 110 septic spontaneous abortions in women with the Dalkon Shield in place, seven of whom had died.\nRobins stopped international sales of the Dalkon Shield in April 1975.\n\nTatum developed many different models of the copper IUD. He created the TCu220 C, which had copper collars as opposed to copper filament, which prevented metal loss and increased the lifespan of the device. Second-generation copper-T IUDs were also introduced in the 1970s. These devices had higher surface areas of copper, and for the first time consistently achieved effectiveness rates of greater than 99%. The last model Tatum developed was the TCu380A, the model that is most recommended today. In addition to T-shaped IUDs, there are also U-shaped IUDs (such as the Multiload) and 7-shaped Gravigard Copper 7 (with a mini version for nulliparous women introduced in the 1980s). More recently, a frameless IUD called Gynefix was introduced.\n\nThe ParaGard T-380A is an IUD with copper, manufactured and marketed in the United States by The Cooper Companies. It is the only copper-containing intrauterine device approved for use in the U.S. (three hormonal uterine devices, Mirena, Skyla and Liletta are also approved). The ParaGard consists of a T-shaped polyethylene frame wound with copper wire, along with two monofilament threads to aid in removal of the IUD.\n\nThe ParaGard T 380A was developed in the 1970s by the Population Council and Finishing Enterprises Inc. (FEI). The Population Council's ParaGard new drug application (NDA) was approved by the U.S. Food and Drug Administration (FDA) and FEI began manufacturing it for distribution outside the United States in 1984. GynoPharma (originally GynoMed) began marketing it in the U.S. in May 1988. On August 2, 1995, Ortho-McNeil acquired GynoPharma and began marketing ParaGard in the U.S. On January 1, 2004, FEI Women's Health acquired the patent from the Population Council and U.S. marketing rights from Ortho-McNeil. On November 10, 2005, Duramed Pharmaceuticals, a subsidiary of Barr Pharmaceuticals, acquired FEI Women's Health and ParaGard. On July 18, 2008, it was announced that Teva Pharmaceutical Industries Ltd. would acquire Barr Pharmaceuticals.\n\nOn Nov. 01, 2017, The Cooper Companies acquired Paragard from Teva Pharmaceutical Industries for approximately $1.1 billion.\n\nThe original FDA approval of ParaGard in 1984 was for 4 years continuous use, this was later extended to 6 years in 1989, then 8 years in 1991, then 10 years in 1994. (ATC code )\n\nBULLET::::- Birth control\n\nBULLET::::- Association of Reproductive Health Professionals' Clinical Proceedings: New Developments in Intrauterine Contraception\n"}
{"id": "15379", "url": "https://en.wikipedia.org/wiki?curid=15379", "title": "Isle Royale National Park", "text": "Isle Royale National Park\n\nIsle Royale National Park is an American national park consisting of Isle Royale and hundreds of adjacent islands, as well as the surrounding waters of Lake Superior, in the state of Michigan. Isle Royale National Park was established on April 3, 1940, then additionally protected from development by wilderness area designation in 1976, and declared a UNESCO International Biosphere Reserve in 1980. The park covers , with of land and of surrounding waters. The park's northern boundary lies adjacent to the Canadian Lake Superior National Marine Conservation Area along the international border.\n\nIsle Royale, the largest island in Lake Superior, is over in length and wide at its widest point. The park is made up of Isle Royale itself and approximately 400 smaller islands, along with any submerged lands within of the surrounding islands (16USC408g).\n\nAccording to the Köppen climate classification system, Isle Royale National Park has a mild summer Humid continental climate (\"Dfb\"). According to the United States Department of Agriculture, the Plant Hardiness zone is 4b at 1178 ft (359 m) elevation with an average annual extreme minimum temperature of -24.2 °F (-31.2 °C). \n\nLarge quantities of copper artifacts found in indian mounds and settlements, some dating back to 3000 B.C., were most likely mined on Isle Royale and the nearby Keweenaw Peninsula. The island has hundreds of pits from these indigenous peoples, with most in the McCargoe Cove area. Carbon-14 testing of a charred log found at one of these pits yielded an age of 1,500 B.C. The Jesuit missionary Dablon published an account in 1669-70 of \"an island called \"Menong\", celebrated for its copper.\" \"Menong\", or \"Minong\", was the native term for the island, and is the basis for Minong Ridge. Prospecting began in earnest when the Chippewas relinquished their claims to the island in 1843, starting with many of the original native pits. This activity had ended by 1855, when no economic deposits were found. The Minong Mine and Island Mine were the result of renewed but short-lived activity from 1873 to 1881.\n\nIn \"Prehistoric Copper Mining in the Lake Superior Region\", published in 1961, Drier and Du Temple estimated that over 1.5 billion pounds (630,400 t) of copper had been mined from the region. However, David Johnson and Susan Martin contend that their estimate was based on exaggerated and inaccurate assumptions.\n\nIn the mid-1840s, a report by Douglass Houghton, Michigan's first state geologist, set off a copper boom in the state, and the first modern copper mines were opened on the island. Evidence of the earlier mining efforts was everywhere, in the form of many stone hammers, some copper artifacts, and places where copper had been partially worked out of the rock but left in place. The ancient pits and trenches led to the discovery of many of the copper deposits that were mined in the 19th century.\n\nThe island was once the site of a resort community. The fishing industry has declined considerably, but continues at Edisen Fishery. Because numerous small islands surround Isle Royale, ships were once guided through the area by lighthouses at Passage Island, Rock Harbor, Rock of Ages, and Isle Royale Lighthouse on Menagerie Island.\n\nWithin the waters of Isle Royale National Park are several shipwrecks. The area’s notoriously harsh weather, dramatic underwater topography, the island’s central location on historic shipping routes, and the cold, fresh water have resulted in largely intact, well preserved wrecks throughout the park. These were documented in the 1980s, with follow up occurring in 2009, by the National Park Service Submerged Resources Center.\n\nAccording to the A. W. Kuchler U.S. Potential natural vegetation Types, Isle Royale National Park has a Great Lakes Spruce/Fir (\"93\") potential vegetation type and a Northern Conifer Forest (\"22\") potential vegetation form .\n\nThe predominant floral habitats of Isle Royale are within the Laurentian Mixed Forest Province. The area is a temperate broadleaf and mixed forests biome transition zone between the true boreal forest to the north and Big Woods to the south, with characteristics of each. It has areas of both broadleaf and conifer forest cover, and bodies of water ranging from conifer bogs to swamps.\n\nConifers include jack pines (\"Pinus banksiana\"), black and white spruces (\"Picea mariana\" and \"Picea glauca\"), balsam firs (\"Abies balsamea\"), and eastern redcedars (\"Juniperus virginiana\").\n\nDeciduous trees include quaking aspens (\"Populus tremuloides\"), red oaks (\"Quercus rubra\"), paper birches (\"Betula papyrifera\"), American mountain ash (\"Sorbus americana\"), red maples (\"Acer rubrum\"), sugar maples (\"Acer saccharum\"), and mountain maples (\"Acer spicatum\").\n\nIsle Royale National Park is known for its wolf and moose populations which are studied by scientists investigating predator-prey relationships in a closed environment. This is made easier because Isle Royale has been colonized by roughly just one third of the mainland mammal species, because it is so remote. In addition, the environment is unique in that it is the only known place where wolves and moose coexist without the presence of bears.\n\nHistorically neither moose nor wolves inhabited Isle Royale. Just prior to becoming a national park the large mammals on Isle Royale were Canada lynx and the boreal woodland caribou. Archeological evidence indicates both of these species were present on Isle Royale for 3,500 years prior to being removed by direct human actions (hunting, trapping, mining, logging, fires, competition for resources from exotic species and possibly disease due to the introduction of invasive species). The last caribou documented on Isle Royale was in 1925. Though lynx were removed by the 1930s some have periodically crossed the ice bridge from neighboring Ontario, Canada, the most recent being an individual sighting in 1980. Although lynx are no longer present on\nthe island, their primary prey, snowshoe hares, remain. Before the appearance of wolves, coyotes were also predators on the island. Coyotes appeared around 1905 and disappeared shortly after wolves arrived in the 1950s.\nMoose are believed to have colonized Isle Royale sometime between 1905 and 1912. It was initially believed that a small herd of moose (moose typically do not travel in herds) colonized the islands by crossing the ice from the adjacent mainland; later this theory was modified to a herd of moose swimming 20 miles across Lake Superior from the nearest mainland. The improbability of these theories received little scrutiny until recent years. Although no thorough scientific investigation to determine how moose arrived on Isle Royale has been carried out to date, both cultural and genetic evidence indicates they were likely introduced by humans to create a private hunting preserve in the early 1900s. The cultural evidence that moose were trapped in northwestern Minnesota and transported to Isle Royale sounded far fetched to many until decades later when genetic evidence revealed the moose on Isle Royale were more closely related to moose in the far northwestern Minnesota/Manitoba border area than the mainland adjacent to Isle Royale in far northeastern Minnesota bordering Ontario. Further evidence has also shown that the Washington Harbor Club, a group of well-to-do businessmen, owned various buildings on Isle Royale in addition to railroads that ran from Baudette to Duluth and Two Harbors and so had the means to transport moose from northwestern Minnesota to Two Harbors.\n\nThere are usually around 25 wolves and 1000 moose on the island, but the numbers change greatly year to year. In the 2006-2007 winter, 385 moose were counted, as well as 21 wolves, in three packs. In spring 2008, 23 wolves and approximately 650 moose were counted. However, recent reductions in winter pack ice have ended replenishment of the wolf population from the mainland. Due to genetic inbreeding, wolf populations had declined to only two in 2016, and the current population will not survive. By November 2017, the population was down to one, a female.\n\nIn December 2016, the National Park Service (NPS) put forward an initial plan in which they would bring additional wolves to the island in order to prevent the pack from disappearing completely. As of June 7, 2018, the decision to relocate 20-30 wolves to the island has been approved and the NPS is actively developing specific implementation strategies.\n\nThe two main rock assemblages found on the island include the Portage Lake Volcanics and the Copper Harbor Conglomerate, both Precambrian in age. The volcanics are mainly ophitic flood basalts, some 100 individual flows over an accumulated thickness of at least 10,000 feet. The conglomerate outcrops on the southwestern portion of the island and consists of sedimentary rock derived from volcanic rocks in present-day Minnesota. Glacial erosion accentuated the ridge and valley topography from pre-glacial stream erosion. Glacial striations indicate a generally westward movement of the glaciers as do the recessional moraines west of Lake Desor. Drumlins are found west of Siskiwit Lake.\n\nRecent analyses by the USGS of both unmineralized basalt and copper-mineralized rock show that a small amount of naturally occurring mercury is associated with mineralization.\n\nNative copper and chlorastrolite, the official state gem of Michigan, are secondary minerals filling pore spaces formed by vesicles and fractures within the volcanic rocks. Prehnite and agate amygdules are also plentiful island gemstones.\n\nThe Greenstone Ridge is a high ridge in the center of the island and carries the longest trail in the park, the Greenstone Ridge Trail, which runs from one end of the island to the other. This is generally done as a 4 or 5 day hike. A boat shuttle can carry hikers back to their starting port. In total there are of hiking trails. There are also canoe/kayak routes, many involving portages, along coastal bays and inland lakes.\n\nThe park has two developed areas:\n\nWindigo, at the southwest end of the island (docking site for the ferries from Minnesota), with a campstore, showers, campsites, rustic camper cabins for those wanting to sleep off of the ground and a boat dock.\n\nRock Harbor on the south side of the northeast end (docking site for the ferries from Michigan), with a campstore, showers, restaurant, lodge, campsites, and a boat dock. Non-camping sleeping accommodations at the park are limited to the lodge at Rock Harbor and the camper cabins at Windigo.\n\nThe park has 36 designated wilderness campgrounds. Some campgrounds in the interior are accessible only by trail or by canoe/kayak on the island lakes. Other campgrounds are accessible only by private boat. The campsites vary in capacity but typically include a few three-sided wood shelters (the fourth wall is screened) with floors and roofs, and several individual sites suitable for pitching a small tent. Some tent sites with space for groups of up to 10 are available, and are used for overflow if all the individual sites are filled.\n\nThe only amenities at the campgrounds are pit toilets, picnic tables, and fire-rings at specific areas. Campfires are not permitted at most campgrounds; gas or alcohol camp stoves are recommended. Drinking and cooking water must be drawn from local water sources (Lake Superior and inland lakes) and filtered, treated, or boiled to avoid parasites. Hunting is not permitted, but fishing is, and edible berries (blueberries, thimbleberries) may be picked from the trail.\n\nThe park is accessible by ferries, floatplanes, and passenger ships during the summer months—from Houghton and Copper Harbor in Michigan; and Grand Portage in Minnesota. Private boats travel to the island from the coasts of Michigan, Minnesota, and Ontario. Isle Royale is quite popular with day-trippers in private boats, and day-trip ferry service is provided from Copper Harbor and Grand Portage to and from the park.\n\nIsle Royale is the only American national park to entirely close in the winter months, from November 1 through April 15, due to extreme weather conditions and for the safety and protection of visitors. Isle Royale is the least-visited national park in the contiguous United States, due to the winter closing and the distance across Lake Superior to reach the park. The average annual visitation was about 19,000 in the period from 2009 to 2018, with 25,798 visiting in 2018. Only three of the most remote Alaskan national parksLake Clark, Kobuk Valley and Gates of the Arcticreceive fewer visitors.\n\nScheduled ferry service operates from Grand Portage, Copper Harbor and Houghton.\n\nThe Grand Portage ferries reach the island in 1 1/2 hours, and stay 4 hours at the island, allowing time for hiking, a guided hike or program by the park staff, and picnics.\n\nThe \"Isle Royale Queen\" serves park visitors out of Copper Harbor, on the northern Upper Peninsula coast of Michigan. It arrives at Rock Harbor in the park in 3 to 3 1/2 hours, spends 3 1/2 hours before returning to Copper Harbor.\n\nThe \"Sea Hunter\" operates round-trips and offers day trips to the Windigo visitor center through much of the season, and less frequently in early summer and autumn; it will transport kayaks and canoes for visitors wanting to explore the park from the water. It is the fastest ferry serving the island and arrives in 1 1/2 hours, including some sightseeing points along the way out and back. Because of the relatively short boat ride, day visitors are able to get four hours on the island, and get back to the mainland earlier in the afternoon. This gives visitors on a tight schedule time to visit the Grand Portage National Monument or other attractions in the same day.\n\nThe \"Ranger III\" is a ship that serves park visitors from Houghton, Michigan to Rock Harbor. It is operated by the National Park Service, and is said to be the largest piece of equipment in the National Park system. It carries 125 passengers, along with canoes, kayaks, and even small powerboats. It is a six-hour voyage from Houghton to the park. The ship stays overnight at Rock Harbor before returning the next day, making two round trips each week from June to mid-September. Briefly in the 2008 season, the Ranger III carried visitors to and from Windigo. This was not continued after four trips, due to low interest and long crossing times. In 2012, Park Superintendent Phyllis Green required the \"Ranger III\" to purify its ballast water.\n\nThe \"Voyageur II\", out of Grand Portage, crosses up to three times a week, overnighting at Rock Harbor and providing transportation between popular lakeside campgrounds. In the fall season, in addition to carrying campers and hikers, it provides day-trip service to Windigo on weekends. The Voyageur transports kayaks and canoes for visitors wanting to explore the island from the water. The \"Voyageur II\" and other boat taxi services ferry hikers to points along the island, allowing a one-way hike back to Rock Harbor or Windigo. Visitors may land at Rock Harbor and depart from Windigo several days later, or vice versa. Hikers frequently ride it in one direction to do a cross-island hike and then get picked up at the other end.\n\nBULLET::::- List of islands in Isle Royale National Park\nBULLET::::- List of fish of Isle Royale National Park\nBULLET::::- List of birds of Isle Royale National Park\nBULLET::::- List of shipwrecks of Isle Royale\nBULLET::::- List of national parks of the United States\nBULLET::::- National Register of Historic Places listings in Isle Royale National Park\n\nBULLET::::- of the National Park Service\nBULLET::::- Forest Resources of Isle Royale National Park, U.S. Department of Agriculture\n"}
{"id": "15381", "url": "https://en.wikipedia.org/wiki?curid=15381", "title": "NATO Integrated Air Defense System", "text": "NATO Integrated Air Defense System\n\nThe NATO Integrated Air Defense System (short: NATINADS) is a command and control network combining radars and other facilities spread throughout the NATO alliance's air defence forces. It formed in the mid-1950s and became operational in 1962 as NADGE. It has been constantly upgraded since its formation, notably with the integration of Airborne Early Warning aircraft in the 1970s. The United Kingdom maintained its own network, but was fully integrated with the network since the introduction of the Linesman/Mediator network in the 1970s. Similarly, the German network maintained an independent nature through GEADGE.\n\nDevelopment was approved by the NATO Military Committee in December 1955. The system was to be based on four air defense regions (ADRs) coordinated by SACEUR (Supreme Allied Commander Europe). Starting from 1956 early warning coverage was extended across Western Europe using 18 radar stations. This part of the system was completed by 1962. Linked to existing national radar sites the coordinated system was called the NATO Air Defence Ground Environment (NADGE).\n\nFrom 1960 NATO countries agreed to place all their air defence forces under the command of SACEUR in the event of war. These forces included command & control (C2) systems, radar installations, and Surface-to-Air (SAM) missile units as well as interceptor aircraft.\n\nBy 1972 NADGE was converted into NATINADS consisting of 84 radar sites and associated Control Reporting Centers (CRC) and in the 1980s the Airborne Early Warning / Ground Environment Integration Segment (AEGIS) upgraded the NATINADS with the possibility to integrate the AWACS radar picture and all of its information into its visual displays. (NOTE: This AEGIS is not to be confused with the U.S.Navy AEGIS, a shipboard fire control radar and weapons system.) AEGIS processed the information through Hughes H5118ME computers, which replaced the H3118M computers installed at NADGE sites in the late 1960s and early 1970s.\n\nNATINADS ability to handle data increased with faster clock rates. The H5118M computer had a staggering 1 megabyte of memory and could handle 1.2 million instructions per second while the former model had a memory of only 256 kilobytes and a clock speed of 150,000 instructions per seconds.\n\nNATINADS/AEGIS were complemented, in West Germany by the German Air Defence Ground Environment (GEADGE), an updated radar network adding the southern part of Germany to the European system and Coastal Radar Integration System (CRIS), adding data links from Danish coastal radars.\n\nIn order to counter the hardware obsolescence, during the mid-90's NATO started the AEGIS Site Emulator (ASE) program allowing the NATINADS/AEGIS sites to replace the proprietary hardware (the 5118ME computer and the various operator consoles IDM-2, HMD-22, IDM-80) with commercial-off-the-shelf (COTS) servers and workstations.\n\nIn the first years 2000, the initial ASE capability was expanded with the possibility to run, thanks to the new hardware power, multiple site emulators on the same hardware, so the system was renamed into Multi-AEGIS Site Emulator (MASE). The NATO system designed to replace MASE in the near future is the Air Command and Control System (ACCS).\n\nBecause of changing politics, NATO expanding and financial crises most European (NATO) countries are trying to cut defence budgets; as a direct result, lots of obsolete and outdated NATINADS facilities are phased out earlier. Currently (2013) still operational NATO radar sites in Europe are these:\n\nAllied Air Command (AIRCOM) is the central command of all NATO air forces on the European continent. The command is based at Ramstein Air Base in Germany and has two subordinate commands in Germany and Spain. The Royal Canadian Air Force and United States Air Force fall under command of the Canadian/American North American Aerospace Defense Command.\n\nBULLET::::- Allied Air Command, at Ramstein Air Base, Germany\nBULLET::::- CAOC Torrejón, at Torrejón Air Base, Spain - responsible for the airspace South of the Alps\nBULLET::::- Albania: Air Surveillance Centre, at Tirana International Airport\nBULLET::::- Bulgaria: Air Sovereignty Operations Centre, in Sofia\nBULLET::::- Croatia: Airspace Surveillance Centre, in Podvornica\nBULLET::::- Greece: Air Operations Centre, at Larissa Air Base\nBULLET::::- Italy: Air Operations Centre, in Poggio Renatico\nBULLET::::- Montenegro: Air Surveillance and Reporting Centre, at Podgorica Airport\nBULLET::::- Portugal: Control and Reporting Centre, in Monsanto\nBULLET::::- Romania: Air Operations Center, in Bucharest\nBULLET::::- Slovenia: Airspace Surveillance and Control Centre, in Brnik\nBULLET::::- Spain: Air Operations Centre, in Torrejón\nBULLET::::- Central Command and Control Group, at Torrejón Air Base\nBULLET::::- Northern Command and Control Group, at Zaragoza Air Base\nBULLET::::- Turkey: Control and Reporting Centre, in Ahlatlıbel\nBULLET::::- CAOC Uedem, in Uedem, Germany - responsible for the airspace North of the Alps\nBULLET::::- Baltic Air Surveillance Network - Regional Airspace Surveillance Coordination Centre, in Karmėlava\nBULLET::::- Estonia: Air Operations Control Centre, at Ämari Air Base\nBULLET::::- Latvia: Air Operations Centre, at Lielvārde Air Base\nBULLET::::- Lithuania: Airspace Control Centre, in Karmėlava\nBULLET::::- Belgium: Control and Reporting Centre, at Beauvechain Air Base\nBULLET::::- Czech Republic: Control and Reporting Centre, in Hlavenec\nBULLET::::- Denmark: Control and Reporting Centre, at Karup Air Base\nBULLET::::- Germany: Air Operations Centre, in Uedem\nBULLET::::- Control and Reporting Centre 2, in Erndtebrück\nBULLET::::- Control and Reporting Centre 3, in Schönewalde\nBULLET::::- Hungary: Air Operations Centre, in Veszprém\nBULLET::::- Iceland: Control and Reporting Centre, at Keflavik Air Base\nBULLET::::- Luxembourg: airspace controlled by Belgium's Control and Reporting Centre, at Beauvechain Air Base\nBULLET::::- Netherlands: Control and Reporting Centre, in Nieuw-Milligen\nBULLET::::- Norway: Control and Reporting Centre, in Sørreisa\nBULLET::::- Poland: Air Operations Centre, in Warsaw-Pyry\nBULLET::::- 22nd Command and Control Centre, in Osówiec\nBULLET::::- 32nd Command and Control Centre, in Balice\nBULLET::::- Slovakia: Air Operations Centre, at Sliač Air Base\nBULLET::::- United Kingdom: Control and Reporting Centre, at RAF Boulmer\n\nThe Albanian Air Force does not possess any fixed radar installations. Its air space is monitored by Italian Air Force and Greek Air Force radars. The Albanian Air Force's Air Surveillance Centre at Tirana International Airport reports to CAOC Torrejón in Spain, while the Italian Air Force's 36th Wing at Gioia del Colle Air Base is responsible for the air defense of Albania. Albania is buying two mobile Lockheed Martin AN/TPS-77 radars to provide its Armed Forces with its own radar capability.\n\nThe Belgian Air Component's Control and Reporting Centre was based at Glons, where also its main radar was located. The radar was deactivated in 2015 and the Centre moved to Beauvechain Air Base in 2018. The Belgian Control and Reporting Centre reports to CAOC Uedem in Germany and is also responsible for guarding the airspace of Luxembourg. At the new location the Control and Reporting Centre uses digital radar data of the civilian radars of Belgocontrol and the Marconi S-723 radar of the Air Component's Air Traffic Control Centre in Semmerzake.\n\nThe Bulgarian Air Force's Air Sovereignty Operations Centre is located in Sofia and reports to CAOC Torrejón. The Bulgarian Air Force fields three control and surveillance zones, which operate obsolete Soviet-era radars. The Bulgarian Air Force intends to replace these radars with fewer, but more capable Western 3-D radars as soon as possible. The future locations of the new radars are as of 2018 unknown.\n\nBULLET::::- Joint Forces Command, in Sofia\nBULLET::::- Air Sovereignty Operational Center (ASOC), in Sofia\nBULLET::::- Base Operative Center (part of 3rd Air Base), Graf Ignatievo Air Base, operational control of fighter aviation\nBULLET::::- Command, Control and Surveillance Base, in Sofia\nBULLET::::- 1st Control and Surveillance Zone, in Bozhurishte, Sofia Province\nBULLET::::- 2nd Control and Surveillance Zone, in Trud, Plovdiv Province\nBULLET::::- 3rd Control and Surveillance Zone, in Bratovo, Burgas Province\n\nThe Royal Canadian Air Force's control centres and radar stations are part of the Canadian/American North American Aerospace Defense Command.\n\nThe Croatian Air Force and Air Defense's Airspace Surveillance Centre is headquartered in Podvornica and reports to CAOC Torrejón.\n\nBULLET::::- Air Force and Air Defense Command\nBULLET::::- Airspace Surveillance and Control Battalion, at 91st Air Force Base (Zagreb - Pleso)\nBULLET::::- Airspace Surveillance Centre, in Podvornica\nBULLET::::- Sector Operational Centre, in Split\nBULLET::::- Mount Sljeme Radar Post, with AN/FPS-117(E)1T\nBULLET::::- Borinci Radar Post, with AN/FPS-117(E)1T\nBULLET::::- Papuk Radar Post, with AN/FPS-117(E)1T\nBULLET::::- Učka Radar Post, with AN/FPS-117(E)1T\nBULLET::::- Mount Rota, with AN/FPS-117(E)1T\n\nThe Czech Air Force's Control and Reporting Centre is located in Hlavenec and reports to CAOC Uedem.\n\nBULLET::::- Air Force Command, in Prague\nBULLET::::- 26th Air Command, Control and Surveillance Regiment, in Stará Boleslav\nBULLET::::- 261st Control and Reporting Centre (CRC), in Hlavenec\nBULLET::::- 262nd Radiotechnical Battalion, in Hlavenec\nBULLET::::- 1st Radiotechnical Company, in Nepolisy, with RAT-31DL\nBULLET::::- 4th Radiotechnical Company, in Sokolnice, with RAT-31DL\nBULLET::::- 263nd Support Battalion, in Hlavenec\nBULLET::::- Reserve Control and Reporting Centre, in Větrušice\n\nThe Royal Danish Air Force's Combined Air Operations Centre (CAOC 1) in Finderup was deactivated in 2008 and replaced at the same location by the Combined Air Operations Centre Finderup (CAOC F), which had responsibility for the airspaces of Iceland, Norway, Denmark and the United Kingdom. CAOC F was deactivated in 2013 and its responsibilities were transferred to CAOC Uedem in Germany. The national Danish Control and Reporting Centre is located at Karup Air Base and it reports to CAOC Uedem.\n\nThe Thule Air Base in Greenland is a United States Air Force installation and its radars are part of the North American Aerospace Defense Command.\n\nBULLET::::- Air Force Tactical Command, at Karup Air Base\nBULLET::::- Air Control Wing, at Karup Air Base\nBULLET::::- Control and Reporting Centre, at Karup Air Base\nBULLET::::- Radar Station Skagen, in Skagen, with RAT-31DL\nBULLET::::- Radar Station Skrydstrup, at Skrydstrup Air Base, with AN/TPS-77\nBULLET::::- Radar Station Bornholm, in Almindingen, with Marconi S-723\n\nThe Estonian Air Force's Air Operations Control Centre is located at Ämari Air Base and reports to the Baltic Air Surveillance Network's Regional Airspace Surveillance Coordination Centre (RASCC) in Karmėlava, Lithuania, which in turn reports to CAOC Uedem.\n\nBULLET::::- Air Force Command, in Tallinn\nBULLET::::- Air Surveillance Wing, at Ämari Air Base\nBULLET::::- Air Operations Control Centre, at Ämari Air Base\nBULLET::::- Engineering and Technical Group, at Ämari Air Base\nBULLET::::- Radar Station, in Levalõpme, with GM 403\nBULLET::::- Radar Station, in Otepää, with GM 403\nBULLET::::- Radar Station, in Kellavere, with AN/TPS-77(V)\nBULLET::::- Airport Surveillance Radar at Ämari Air Base, with ASR-8\n\nThe French Air Force's Air Operations Centre is located at Mont Verdun Air Base and reports to CAOC Uedem. Most French radar sites use the PALMIER radar, which is being taken out of service. By 2022 all PALMIER radars will have been replaced with new radar stations using the GM 403 radar.\n\nBULLET::::- Air Defense and Air Operations Command\nBULLET::::- Air Operations Brigade, at Mont Verdun Air Base\nBULLET::::- Air Operations Centre, at Mont Verdun Air Base\nBULLET::::- Control and Reporting Centre, at Mont-de-Marsan Air Base\nBULLET::::- Control and Reporting Centre, in Cinq-Mars-la-Pile\nBULLET::::- Mont Verdun Air Base radar, with GM GM 406\nBULLET::::- Élément Air Rattaché (EAR) 943, on Mont Agel, with GM 406\n\nAdditionally the French Air Force fields a GM 406 radar at the Cayenne-Rochambeau Air Base in French Guiana to protect the Guiana Space Centre in Kourou.\n\nThe German Air Force's Combined Air Operations Centre (CAOC 2) in Uedem was deactivated in 2008 and reactivated as CAOC Uedem in 2013. CAOC Uedem is responsible for the NATO airspace North of the Alps. The HADR radars are a variant of the HR-3000 radar, while the RRP-117 radars are a variant of the AN/FPS-117.\n\nBULLET::::- Air Operations Centre (Zentrum Luftoperationen der Luftwaffe) (NATO CAOC Uedem), in Uedem\nBULLET::::- Control and Reporting Centre 2 (Einsatzführungsbereich 2), in Erndtebrück\nBULLET::::- Operations Squadron 21, in Erndtebrück\nBULLET::::- Operations Support Squadron 22, in Erndtebrück\nBULLET::::- Sensor Platoon I, in Lauda\nBULLET::::- Remote Radar Post 240 \"Loneship\", in Erndtebrück with GM 406F\nBULLET::::- Remote Radar Post 246 \"Hardwheel\", on Erbeskopf with HADR\nBULLET::::- Remote Radar Post 247 \"Batman\", in Lauda with GM 406F\nBULLET::::- Remote Radar Post 248 \"Coldtrack\", in Freising with GM 406F\nBULLET::::- Remote Radar Post 249 \"Sweet Apple\", in Meßstetten with HADR\nBULLET::::- Sensor Platoon II, in Auenhausen\nBULLET::::- Remote Radar Post 241 \"Crabtree\", in Marienbaum with HADR\nBULLET::::- Remote Radar Post 242 \"Backwash\", in Auenhausen with GM 406F\nBULLET::::- Remote Radar Post 243 \"Silver Cork\", in Visselhövede with GM 406F\nBULLET::::- Remote Radar Post 244 \"Round up\", in Brockzetel with HADR\nBULLET::::- Remote Radar Post 245 \"Bugle\", in Brekendorf with GM 406F\nBULLET::::- Control and Reporting Training Inspection 23, in Erndtebrück\nBULLET::::- Education and Training Centre, in Erndtebrück\nBULLET::::- Education, Test and Training Group, in Erndtebrück\nBULLET::::- Control and Reporting Centre 3 (Einsatzführungsbereich 3), in Schönewalde\nBULLET::::- Operations Squadron 31, in Schönewalde\nBULLET::::- Operations Support Squadron 32, in Schönewalde\nBULLET::::- Sensor Platoon III, in Cölpin\nBULLET::::- Remote Radar Post 351 \"Matchpoint\", in Putgarten with RRP-117\nBULLET::::- Remote Radar Post 352 \"Mindreader\", in Cölpin with RRP-117\nBULLET::::- Remote Radar Post 353 \"Teddy Bear\", in Tempelhof with RRP-117\nBULLET::::- Remote Radar Post 356 \"\", in Elmenhorst with RRP-117\nBULLET::::- Sensor Platoon IV, in Regen\nBULLET::::- Remote Radar Post 354 \"Blackmoor\", in Döbern with RRP-117\nBULLET::::- Remote Radar Post 355 \"Royal Flash\", in Gleina with RRP-117\nBULLET::::- Remote Radar Post 357 \"\", on Döbraberg with RRP-117\nBULLET::::- Remote Radar Post 358 \"Snow Cap\", on Großer Arber with RRP-117\n\n1st Area Control Centre, inside Mount Chortiatis, with Marconi S-743D\n2nd Area Control Centre, inside Mount Parnitha, with Marconi S-743D\n9th Control and Warning Station Squadron, on Mount Pelion, with Marconi S-743D\n10th Control and Warning Station Squadron, on Mount Chortiatis, with Marconi S-743D\n\nThe Hellenic Air Force's Combined Air Operations Centre (CAOC 7) at Larissa Air Base was deactivated in 2013 and its responsibilities transferred to the CAOC Torrejón in Spain. The Hellenic Air Force fields two HR-3000, four AR-327 and six Marconi S-743D radar systems, however as of 2018 the air force is in the process of replacing some of its older systems with three RAT-31DL radars.\n\nBULLET::::- Air Force Tactical Command, at Larissa Air Base\nBULLET::::- Air Operations Centre, at Larissa Air Base\nBULLET::::- 1st Area Control Centre, inside Mount Chortiatis\nBULLET::::- 2nd Area Control Centre, inside Mount Parnitha\nBULLET::::- 1st Control and Warning Station Squadron, in Didymoteicho, with AR-327\nBULLET::::- 2nd Control and Warning Station Squadron, on Mount Ismaros, with HR-3000\nBULLET::::- 3rd Control and Warning Station Squadron, on Mount Vitsi, with Marconi S-743D\nBULLET::::- 4th Control and Warning Station Squadron, on Mount Elati, with RAT-31DL\nBULLET::::- 5th Control and Warning Station Squadron, in Kissamos, with Marconi S-743D\nBULLET::::- 6th Control and Warning Station Squadron, on Mykonos, with AR-327\nBULLET::::- 7th Control and Warning Station Squadron, on Mount Mela, with AR-327\nBULLET::::- 8th Control and Warning Station Squadron, on Lemnos, with AR-327\nBULLET::::- 9th Control and Warning Station Squadron, on Mount Pelion, with Marconi S-743D\nBULLET::::- 10th Control and Warning Station Squadron, on Mount Chortiatis, with Marconi S-743D\nBULLET::::- 11th Control and Warning Station Squadron, in Ziros, with HR-3000\n\nThe Hungarian Air Force's Air Operations Centre is located in Veszprém and reports to CAOC Uedem. There are additional three radar companies with Soviet-era equipment subordinate to the 54th Radar Regiment \"\"Veszprém\"\", however it is unclear if they will remain in service once Hungary's newest radar at Medina reaches full operational capability.\n\nBULLET::::- Air Force Command, in Budapest\nBULLET::::- Air Operations Centre, in Veszprém\nBULLET::::- 54th Radar Regiment \"\"Veszprém\"\", in Veszprém\nBULLET::::- 1st Radar Data Centre, in Békéscsaba, with RAT-31DL\nBULLET::::- 2nd Radar Data Centre, in Medina, with RAT-31DL\nBULLET::::- 3rd Radar Data Centre, in Bánkút, with RAT-31DL\n\nThe Iceland Air Defense System, which is part of the Icelandic Coast Guard, monitors Iceland's airspace. Air Defense is provided by fighter jets from NATO allies, which rotate units for the Icelandic Air Policing mission to Keflavik Air Base.\nThe Iceland Air Defense System's Control and Reporting Centre is at Keflavik Air Base and reports to CAOC Uedem in Germany.\n\nBULLET::::- Iceland Air Defense System, at Keflavik Air Base\nBULLET::::- Control and Reporting Centre, at Keflavik Air Base\nBULLET::::- H1 Radar Station, at Miðnesheiði, with AN/FPS-117(V)5\nBULLET::::- H2 Radar Station, on Mount Gunnolfsvík, with AN/FPS-117(V)5\nBULLET::::- H3 Radar Station, at Stokksnes, with AN/FPS-117(V)5\nBULLET::::- H4 Radar Station, on Mount Bolafjalli, with AN/FPS-117(V)5\n\nThe Italian Air Force's Combined Air Operations Centre (CAOC 5) in Poggio Renatico was deactivated in 2013 and replaced with the Mobile Command and Control Regiment (RMCC) at Bari Air Base, while the Centre's responsibilities were transferred to the CAOC Torrejón in Spain.\n\nBULLET::::- Air Operations Command (COA), in Poggio Renatico\nBULLET::::- Air Operations Centre, in Poggio Renatico\nBULLET::::- Integrated Missile Air-defense Regiment (Rep. DAMI), in Poggio Renatico\nBULLET::::- 11th Integrated Missile Air-defense Squadron, in Poggio Renatico\nBULLET::::- 22nd Air Force Radar Squadron (GrRAM), in Licola, with AN/FPS-117(V)\nBULLET::::- 112th Remote Radar Station Flight, in Mortara, with RAT-31DL\nBULLET::::- 113th Remote Radar Station Flight, in Lame di Concordia, with RAT-31DL\nBULLET::::- 114th Remote Radar Station Flight, in Potenza Picena, with RAT-31DL\nBULLET::::- 115th Remote Radar Station Flight, in Capo Mele, with RAT-31DL\nBULLET::::- 121st Remote Radar Station Flight, in Poggio Ballone, with AN/FPS-117(V)\nBULLET::::- 123rd Remote Radar Station Flight, in Capo Frasca, with AN/FPS-117(V)\nBULLET::::- 131st Remote Radar Station Flight, in Jacotenente, with RAT-31DL\nBULLET::::- 132nd Remote Radar Station Flight, in Capo Rizzuto, with RAT-31DL\nBULLET::::- 133rd Remote Radar Station Flight, in San Giovanni Teatino, with AN/FPS-117(V)\nBULLET::::- 134th Remote Radar Station Flight, in Lampedusa, with RAT-31DL\nBULLET::::- 135th Remote Radar Station Flight, in Marsala, with RAT-31DL\nBULLET::::- 136th Remote Radar Station Flight, in Otranto, with RAT-31DL\nBULLET::::- 137th Remote Radar Station Flight, in Mezzogregorio, with RAT-31DL\n\nThe Latvian Air Force's Air Operations Centre is located at Lielvārde Air Base and reports to the Baltic Air Surveillance Network's Regional Airspace Surveillance Coordination Centre (RASCC) in Karmėlava, Lithuania, which in turn reports to CAOC Uedem.\n\nBULLET::::- Air Force Headquarters, at Lielvārde Air Base\nBULLET::::- Air Surveillance Squadron, at Lielvārde Air Base\nBULLET::::- Air Operations Centre, at Lielvārde Air Base\nBULLET::::- 1st Radiotechnical (Radar) Post, at Lielvārde Air Base, with AN/TPS-77(V)\nBULLET::::- 2nd Radiotechnical (Radar) Post, in Audriņi, with AN/TPS-77(V)\nBULLET::::- 3rd Radiotechnical (Radar) Post, in Čalas, with AN/TPS-77(V)\nBULLET::::- Mobile Radar Section, with TPS-77 MRR\n\nThe Lithuanian Air Force's Air Operations Control Centre is located in Karmėlava and reports to the Baltic Air Surveillance Network's Regional Airspace Surveillance Coordination Centre (RASCC) co-located in Karmėlava, which in turn reports to CAOC Uedem.\n\nBULLET::::- Lithuanian Air Force Headquarters, in Kaunas\nBULLET::::- Airspace Surveillance and Control Command, in Kaunas\nBULLET::::- Airspace Control Centre, in Karmėlava\nBULLET::::- 1st Radar Post, in Antaveršis, with AN/TPS-77(V)\nBULLET::::- 3rd Radar Post, in Degučiai, with AN/TPS-77(V)\nBULLET::::- 4th Radar Post, in Ceikiškės, with AN/TPS-77(V)\n\nLuxembourg's airspace is monitored and guarded by the Belgian Air Component's Control and Reporting Centre at Beauvechain Air Base.\n\nThe Armed Forces of Montenegro do not possess a modern air defense radar and the country's airspace is monitored by Italian Air Force radar sites. The Armed Forces Air Surveillance and Reporting Centre is located at Podgorica Airport in Golubovci and reports to CAOC Torrejón in Spain.\n\nThe Royal Netherlands Air Force's Air Operations Centre is located at Nieuw-Milligen and reports to CAOC Uedem. The air force's main radars are being replaced with two modern SMART-L GB radars.\n\nBULLET::::- Air Force Command, in The Hague\nBULLET::::- Air Operations Control Station, in Nieuw-Milligen\nBULLET::::- Control and Reporting Centre, in Nieuw-Milligen\nBULLET::::- Radar Station South, in Nieuw-Milligen, with SMART-L GB\nBULLET::::- Radar Station North, at Wier, with SMART-L GB\n\nThe Royal Norwegian Air Force's Combined Air Operations Centre (CAOC 3) in Reitan was deactivated in 2008 and its responsibilities were transferred to the Combined Air Operations Centre Finderup (CAOC F). After CAOC F was deactivated in 2013 the responsibility for the air defense of Norway was transferred to CAOC Uedem in Germany and the Royal Norwegian Air Force's Control and Reporting Centre in Sørreisa reports to it. Until 2016 the Royal Norwegian Air Force's radar installations were distributed between two CRCs. That year the CRC Mågerø was disbanded. In its place a wartime mobilization back-up CRC has been formed with a reduction in personnel from the around active 170 duty to about 50 air force home guardsmen. The SINDRE I radars are a variant of the HR-3000 radar, which is also used in the German HADR radars. The newer RAT-31SL/N radars are sometimes designated SINDRE II.\n\nBULLET::::- Armed Forces Operational Headquarters, Reitan near Bodø Main Air Station\nBULLET::::- 131 Air Wing, in Sørreisa\nBULLET::::- Control and Reporting Centre Sørreisa\nBULLET::::- Radar Station Njunis, with RAT-31SL/N\nBULLET::::- Radar Station Senja, with RAT-31SL/N\nBULLET::::- Radar Station Honningsvåg, with RAT-31SL/N\nBULLET::::- Radar Station Vestvågøy, with SINDRE I\nBULLET::::- Radar Station Vågsøy, with SINDRE I\nBULLET::::- Radar Station Skykula, with SINDRE I\n\nThe Polish Armed Forces Operational Command's Air Operations Centre is located in the Warsaw-Pyry neighborhood and reports to CAOC Uedem. The 3rd \"Wrocław\" Radiotechnical Brigade is responsible for the operation of the armed forces' radar equipment and fields mainly obsolete Soviet-era radars. As of 2018 the Polish Air Force possesses three modern RAT-31DL radars, which are listed below.\n\nBULLET::::- Armed Forces Operational Command, in Warsaw\nBULLET::::- Air Operations Centre - Air Component Command, in Warsaw-Pyry\nBULLET::::- Mobile Air Operations Command Unit, in Babki\nBULLET::::- 22nd Command and Control Centre, in Osówiec\nBULLET::::- 32nd Command and Control Centre, at Kraków-Balice Air Base\nBULLET::::- 1st Air Operations Coordination Centre, in Gdynia\nBULLET::::- 2nd Air Operations Coordination Centre, in Krakow\nBULLET::::- 4th Air Operations Coordination Centre, in Szczecin\nBULLET::::- 3rd \"Wrocław\" Radiotechnical Brigade, in Wrocław\nBULLET::::- 3rd \"Sandomierz\" Radiotechnical Battalion, in Sandomierz\nBULLET::::- 110th Long Range Radiolocating Post, in Łabunie, with RAT-31DL\nBULLET::::- 8th \"Szczeciń\" Radiotechnical Battalion, in Lipowiec\nBULLET::::- 184th Long Range Radiolocating Post, in Szypliszki, with RAT-31DL\nBULLET::::- 211th Long Range Radiolocating Post, in Chruściel, with RAT-31DL\nBULLET::::- 31st Radiotechnical Battalion, in Wrocław\nBULLET::::- 34th Radiotechnical Battalion, in Chojnice\n\nThe Portuguese Air Force's Combined Air Operations Centre (CAOC 10) in Lisbon was deactivated in 2013 and its responsibilities were transferred to CAOC Torrejón in Spain.\n\nBULLET::::- Air Command, in Lisbon\nBULLET::::- Control and Reporting Centre, in Monsanto\nBULLET::::- Radar Station 1, on Monte Fóia, with HR-3000\nBULLET::::- Radar Station 2, on Monte Pilar in Paços de Ferreira, with HR-3000\nBULLET::::- Radar Station 3, at Montejunto, with HR-3000\nBULLET::::- Radar Station 4, on Pico do Arieiro, on the island of Madeira, with LANZA 3-D\n\nThe Romanian Air Force's Air Operations Centre is headquartered in Bucharest and reports to CAOC Torrejón. The radar station in Bârnova is officially designated and operated as a civilian radar station, however its data is fed into the military air surveillance system.\n\nBULLET::::- Air Operations Centre, in Bucharest\nBULLET::::- 2nd Airspace Surveillance Centre \"North\", at 71st Air Base, in Câmpia Turzii\nBULLET::::- Radar Station, in Ovidiu, with AN/FPS-117(V)\nBULLET::::- Radar Station, at Giarmata Airport, with AN/FPS-117(V)\nBULLET::::- Radar Station, in Suceava, with AN/FPS-117(V)\nBULLET::::- Radar Station, in Craiova, with AN/FPS-117(V)\nBULLET::::- Radar Station, on Muntele Mare, with AN/FPS-117(V)\nBULLET::::- Civil/Military Radar Station, in Bârnova, with AN/FPS-117(V)\n\nThe Slovak Air Force's Air Operations Centre is located at Sliač Air Base and reports to CAOC Uedem. The Slovak Air Force still operates obsolete Soviet-era radars, which it intends to replace with fewer, but more capable Western 3-D radars as soon as possible. The future locations of the new radars are as of 2018 unknown.\n\nBULLET::::- Air Force Command, at Sliač Air Base\nBULLET::::- Command, Control and Surveillance Wing, at Sliač Air Base\nBULLET::::- Air Operations Centre, at Sliač Air Base\nBULLET::::- Radar Surveillance Battalion, in Sliač Air Base\n\nThe Slovenian Air Force and Air Defense's Airspace Surveillance and Control Centre is headquartered in Brnik and reports to CAOC Torrejón.\n\nThe Italian Air Force's 4th Wing at Grosseto Air Base and 36th Wing at Gioia del Colle Air Base rotate a QRA flight of Eurofighter Typhoons to Istrana Air Base, which are responsible for the air defense of Northern Italy and Slovenia.\n\nBULLET::::- Forces Command, in Vrhnika\nBULLET::::- 15th Military Aviation Regiment, at Cerklje ob Krki Air Base\nBULLET::::- 16th Airspace Surveillance and Control Battalion in Brnik\nBULLET::::- Airspace Surveillance and Control Centre, in Brnik\nBULLET::::- 1st Radar Station, in Vrhnika, with GM 403\nBULLET::::- 2nd Radar Station, in Hočko Pohorje, with GM 403\n\nThe Spanish Air Force's Combined Air Operations Centre (CAOC 8) at Torrejón Air Base was deactivated in 2013 and replaced at same location by CAOC Torrejon, which took over the functions of CAOC 5, CAOC 7, CAOC 8 and CAOC 10. CAOC Torrejón is responsible for the NATO airspace South of the Alps.\n\nBULLET::::- Combat Air Command, at Torrejón Air Base\nBULLET::::- Combat Air Command Headquarter (CGMACOM), at Torrejón Air Base\nBULLET::::- Air Operations Centre / NATO CAOC Torrejón\nBULLET::::- Command and Control Systems Headquarter (JSMC), at Torrejón Air Base\nBULLET::::- Central Command and Control Group (GRUCEMAC), at Torrejón Air Base\nBULLET::::- Northern Command and Control Group (GRUNOMAC), at Zaragoza Air Base\nBULLET::::- Mobile Air Control Group (GRUMOCA) at Tablada Air Base\nBULLET::::- 1st Air Surveillance Squadron (EVA 1) radar station, at Air Station El Frasno, with LANZA 3-D\nBULLET::::- 2nd Air Surveillance Squadron (EVA 2) radar station, at Air Station Villatobas, with RAT-31SL/T\nBULLET::::- 3rd Air Surveillance Squadron (EVA 3) radar station, at Air Station Constantina, with LANZA 3-D\nBULLET::::- 4th Air Surveillance Squadron (EVA 4) radar station, at Air Station Roses, with LANZA 3-D\nBULLET::::- 5th Air Surveillance Squadron (EVA 5) radar station, at Air Station Aitana, with RAT-31SL/T\nBULLET::::- 7th Air Surveillance Squadron (EVA 7) radar station, at Air Station Puig Major, with LANZA 3-D\nBULLET::::- 9th Air Surveillance Squadron (EVA 9) radar station, at Air Station Motril, with RAT-31SL/T\nBULLET::::- 10th Air Surveillance Squadron (EVA 10) radar station, at Air Station Barbanza, with LANZA 3-D\nBULLET::::- 11th Air Surveillance Squadron (EVA 11) radar station, at Air Station Alcalá de los Gazules, with LANZA 3-D\nBULLET::::- 12th Air Surveillance Squadron (EVA 12) radar station, at Air Station Espinosa de los Monteros, with RAT-31SL/T\nBULLET::::- 13th Air Surveillance Squadron (EVA 13) radar station, at Air Station Sierra Espuña, with LANZA 3-D\nBULLET::::- 21st Air Surveillance Squadron (EVA 21) radar station, at Vega de San Mateo on Gran Canaria, with LANZA 3-D\nBULLET::::- 22nd Air Surveillance Squadron (EVA 22) radar station, in Haría on Lanzarote, with RAT-31SL/T\n\nThe Turkish Air Force's Combined Air Operations Centre (CAOC 6) in Eskisehir was deactivated in 2013 and its responsibilities were transferred to CAOC Torrejón in Spain. Turkey's Air Force fields a mix of HR-3000, AN/FPS-117, RAT-31SL and RAT-31DL radars, however the exact number of each of these radar and their location in the Turkish radar system is unknown.\n\nBULLET::::- Air Force Command (COA), in\nBULLET::::- Control and Reporting Centre, in Ahlatlıbel\nBULLET::::- Aerial Surveillance Radar Post, in Ahlatlıbel, with\nBULLET::::- Aerial Surveillance Radar Post, in Körfez, with\nBULLET::::- Aerial Surveillance Radar Post, in Karabelen, with\nBULLET::::- Aerial Surveillance Radar Post, in Çanakkale, with\nBULLET::::- Aerial Surveillance Radar Post, in Erzurum, with\nBULLET::::- Aerial Surveillance Radar Post, in Datça, with\nBULLET::::- Aerial Surveillance Radar Post, in İnebolu, with\nBULLET::::- Aerial Surveillance Radar Post, in İskenderun, with\nBULLET::::- Aerial Surveillance Radar Post, in Rize, with\n\nThe Royal Air Force's Combined Air Operations Centre (CAOC 9) at RAF High Wycombe was deactivated in 2008 and its responsibilities were transferred to the Combined Air Operations Centre Finderup (CAOC F). After CAOC F was deactivated in 2013 the responsibility for the air defense of the United Kingdom was transferred to CAOC Uedem in Germany. The Royal Air Force's Control and Reporting Centres report to it.\n\nBULLET::::- No. 1 Group RAF, at RAF High Wycombe\nBULLET::::- UK Air Surveillance and Control Systems, at RAF Boulmer\nBULLET::::- Control and Reporting Centre, at RAF Boulmer\nBULLET::::- No. 1 Air Control Centre, at RAF Scampton (National Air Control Centre)\nBULLET::::- RRH Benbecula, in North Uist, with AN/TPS-77\nBULLET::::- RRH Brizlee Wood, in Shipley, with AN/FPS-117\nBULLET::::- RRH Buchan, in Boddam, with AN/TPS-77\nBULLET::::- RRH Portreath, in Portreath, with AR-327\nBULLET::::- RRH Saxa Vord, in Unst, with AN/TPS-77\nBULLET::::- RRH Trimingham, in Trimingham, with AN/FPS-117 (satellite station of RRH Neatishead)\nBULLET::::- RRH Staxton Wold, in Scarborough, had an AN/TPS-77 radar, which was moved to RRH Saxa Vord in 2017, future plans for RRH Staxton Wold are as of 2018 unknown.\n\nThe United States Air Force's control centres and radar stations are part of the Canadian/American North American Aerospace Defense Command.\n\nBULLET::::- Austrian Air Force - GOLDHAUBE system:\nBULLET::::- Command and Control Center \"\"Basisraum\"\", in St Johann im Pongau\nBULLET::::- Kolomansberg Radar Station\nBULLET::::- Großer Speikkogel Radar Station\nBULLET::::- Steinmandl Radar Station\n\nBULLET::::- Swiss Air Force - FLORAKO system:\nBULLET::::- Air Defence & Direction Center, at Dübendorf Air Base\nBULLET::::- Pilatus Radar Station\nBULLET::::- Scopi Radar Station\nBULLET::::- Weisshorn Radar Station\nBULLET::::- Weissfluh Radar Station\n"}
{"id": "15382", "url": "https://en.wikipedia.org/wiki?curid=15382", "title": "Invisible balance", "text": "Invisible balance\n\nThe invisible balance or balance of trade on services is that part of the balance of trade that refers to services and other products that do not result in the transfer of physical objects. Examples include consulting services, shipping services, tourism, and patent license revenues. This figure is usually generated by tertiary industry. The term 'invisible balance' is especially common in the United Kingdom.\n\nFor countries that rely on service exports or on tourism, the invisible balance is particularly important. For instance the United Kingdom and Saudi Arabia receive significant international income from financial services, while Japan and Germany rely more on exports of manufactured goods.\n\nInvisibles are both international payments for services (as opposed to goods), as well as movements of money without exchange for goods or services. These invisibles are called 'transfer payments' or 'remittances' and may include money sent from one country to another by an individual, business, government or non-governmental organisations (NGO) – often charities.\n\nAn individual remittance may include money sent to a relative overseas. Business transfers may include profits sent by a foreign subsidiary to a parent company or money invested by a business in a foreign country. Bank loans to foreign countries are also included in this category, as are license fees paid for the use of patents and trademarks. Government transfers may involve loans made or official aid given to foreign countries, while transfers made by NGO's include money designated for charitable work within foreign countries, respectively.\n\nIn many countries a useful distinction is drawn between the balance of trade and the balance of payments. 'Balance of trade' refers to the trade of both tangible (physical) objects as well as the trade in services – collectively known as exports and imports (in other words, 'visibles plus services') – while the 'balance of payments' also includes transfers of Capital in the form of loans, investments in shares or direct investment in projects.\n\nA nation may have a visibles balance surplus but this can be offset by a larger deficit in the invisibles balance (creating a Balance of Trade deficit overall) – if, for example, there are large payments made to foreign businesses for invisibles such as shipping or tourism. On the other hand, a Visibles Balance deficit can be offset by a strong surplus on the invisibles balance if, for example, foreign aid is being provided.\n\nIn a similar way, a nation may also have a surplus 'balance of trade' because it exports more than it imports but a negative (or deficit) 'balance of payments' because, it has a much greater shortfall in transfers of capital. And, just as easily, a deficit in the 'balance of trade' may be offset by a larger surplus in capital transfers from overseas to produce a balance of payments surplus overall.\n\nProblems with a country's balance of trade (or balance of payments) are often associated with an inappropriate valuation of its currency, its country's foreign exchange rate.\n\nIf a country's exchange rate is too high, its exports will become uncompetitive as buyers in foreign countries require more of their own currency to pay for them. In the meantime, it also becomes cheaper for the citizens of the country to buy goods from overseas,as opposed to buying locally produced goods), because an overvalued currency makes foreign products less expensive.\n\nThe simultaneous decline in currency inflows from decreased exports and the rise in outflows, due to increased imports, sends the balance of trade into deficit, which then needs to be paid for by a transfer of funds in some form, either invisible transfers (aid, etc.) or capital flows (loans, etc.). However, relying on funds like that to support a trade deficit, is unsustainable, and the country may eventually require its currency to be devalued.\n\nIf, on the other hand, a currency is undervalued, its exports will become cheaper and therefore more competitive internationally. At the same time, imports will also become more costly, stimulating the production of domestic substitutes to replace them. That will result in a growth of currency flowing into the country and a decline in currency flowing out of it, resulting in an improvement in the country's balance of trade.\n\nBecause a nation's exchange rate has a big impact on its 'balance of trade' and its 'balance of payments', many economists favour freely floating exchange rates over the older, fixed (or pegged) rates of foreign currency exchange. Floating exchange rates allow more regular adjustments in exchange rates to occur, allowing the greater opportunity for international payments to maintain equilibrium.\n"}
{"id": "15387", "url": "https://en.wikipedia.org/wiki?curid=15387", "title": "Irreducible complexity", "text": "Irreducible complexity\n\nIrreducible complexity (IC) involves the idea that certain biological systems cannot evolve by successive small modifications to pre-existing functional systems through natural selection. Irreducible complexity has become central to the creationist concept of intelligent design, but the scientific community, which regards intelligent design as pseudoscience, rejects the concept of irreducible complexity. Irreducible complexity is one of two main arguments used by intelligent-design proponents, alongside specified complexity.\n\nCreation science presented the theological argument from design with assertions that evolution could not explain complex molecular mechanisms, and in 1993 Michael Behe, a professor of biochemistry at Lehigh University, presented these arguments in a revised version of the school textbook \"Of Pandas and People\". In his 1996 book \"Darwin's Black Box\" he called this concept \"irreducible complexity\" and said it made evolution through natural selection of random mutations impossible. This was based on the mistaken assumption that evolution relies on improvement of existing functions, ignoring how complex adaptations originate from changes in function, and disregarding published research. Evolutionary biologists have published rebuttals showing how systems discussed by Behe can evolve, and examples documented through comparative genomics show that complex molecular systems are formed by the addition of components as revealed by different temporal origins of their proteins.\n\nIn the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe gave testimony on the subject of irreducible complexity. The court found that \"Professor Behe's claim for irreducible complexity has been refuted in peer-reviewed research papers and has been rejected by the scientific community at large.\"\n\nMichael Behe defined irreducible complexity in natural selection in his book \"Darwin's Black Box\":\n... a single system which is composed of several well-matched, interacting parts that contribute to the basic function, and where the removal of any one of the parts causes the system to effectively cease functioning.\n\nA second definition given by Behe (his \"evolutionary definition\") is as follows:\nAn irreducibly complex evolutionary pathway is one that contains one or more unselected steps (that is, one or more necessary-but-unselected mutations). The degree of irreducible complexity is the number of unselected steps in the pathway.\n\nIntelligent design advocate William A. Dembski gives this definition:\nA system performing a given basic function is irreducibly complex if it includes a set of well-matched, mutually interacting, nonarbitrarily individuated parts such that each part in the set is indispensable to maintaining the system's basic, and therefore original, function. The set of these indispensable parts is known as the irreducible core of the system.\n\nThe argument from irreducible complexity is a descendant of the teleological argument for God (the argument from design or from complexity). This states that because certain things in nature appear very complicated, they must have been designed. William Paley famously argued, in his 1802 watchmaker analogy, that complexity in nature implies a God for the same reason that the existence of a watch implies the existence of a watchmaker. This argument has a long history, and one can trace it back at least as far as Cicero's \"De Natura Deorum\" ii.34, written in 45 BC.\n\nGalen (1st and 2nd centuries AD) wrote about the large number of parts of the body and their relationships, which observation was cited as evidence for creation. The idea that the interdependence between parts would have implications for the origins of living things was raised by writers starting with Pierre Gassendi in the mid-17th century and by John Wilkins (1614-1672), who wrote (citing Galen), \"Now to imagine, that all these things, according to their several kinds, could be brought into this regular frame and order, to which such an infinite number of Intentions are required, without the contrivance of some wise Agent, must needs be irrational in the highest degree.\"\n\nChapter XV of Paley's \"Natural Theology\" discusses at length what he called \"relations\" of parts of living things as an indication of their design.\n\nGeorges Cuvier applied his principle of the \"correlation of parts\" to describe an animal from fragmentary remains. For Cuvier, this related to another principle of his, the \"conditions of existence\", which excluded the possibility of transmutation of species.\n\nWhile he did not originate the term, Charles Darwin identified the argument as a possible way to falsify a prediction of the theory of evolution at the outset. In \"The Origin of Species\" (1859), he wrote, \"If it could be demonstrated that any complex organ existed, which could not possibly have been formed by numerous, successive, slight modifications, my theory would absolutely break down. But I can find out no such case.\" Darwin's theory of evolution challenges the teleological argument by postulating an alternative explanation to that of an intelligent designer—namely, evolution by natural selection. By showing how simple unintelligent forces can ratchet up designs of extraordinary complexity without invoking outside design, Darwin showed that an intelligent designer was not the necessary conclusion to draw from complexity in nature. The argument from irreducible complexity attempts to demonstrate that certain biological features cannot be purely the product of Darwinian evolution.\n\nIn the late 19th century, in a dispute between supporters of the adequacy of natural selection and those who held for inheritance of acquired characteristics, one of the arguments made repeatedly by Herbert Spencer, and followed by others, depended on what Spencer referred to as \"co-adaptation\" of \"co-operative\" parts, as in: \"We come now to Professor Weismann's endeavour to disprove my second thesis — that it is impossible to explain by natural selection alone the co-adaptation of co-operative parts. It is thirty years since this was set forth in \"The Principles of Biology.\" In §166, I instanced the enormous horns of the extinct Irish elk, and contended that in this and in kindred cases, where for the efficient use of some one enlarged part many other parts have to be simultaneously enlarged, it is out of the question to suppose that they can have all spontaneously varied in the required proportions.\" Darwin responded to Spencer's objections in chapter XXV of \"The Variation of Animals and Plants under Domestication\" (1868). The history of this concept in the dispute has been characterized: \"An older and more religious tradition of idealist thinkers were committed to the explanation of complex adaptive contrivances by intelligent design. ... Another line of thinkers, unified by the recurrent publications of Herbert Spencer, also saw co-adaptation as a composed, irreducible whole, but sought to explain it by the inheritance of acquired characteristics.\"\n\nSt. George Jackson Mivart raised the objection to natural selection that \"Complex and simultaneous co-ordinations … until so far developed as to effect the requisite junctions, are useless\" which \"amounts to the concept of \"irreducible complexity\" as defined by … Michael Behe\".\n\nHermann Muller, in the early 20th century, discussed a concept similar to irreducible complexity. However, far from seeing this as a problem for evolution, he described the \"interlocking\" of biological features as a consequence to be expected of evolution, which would lead to irreversibility of some evolutionary changes. He wrote, \"Being thus finally woven, as it were, into the most intimate fabric of the organism, the once novel character can no longer be withdrawn with impunity, and may have become vitally necessary.\"\n\nIn 1974 the young Earth creationist Henry M. Morris introduced a similar concept in his book \"Scientific Creationism\", in which he wrote; \"This issue can actually be attacked quantitatively, using simple principles of mathematical probability. The problem is simply whether a complex system, in which many components function unitedly together, and in which each component is uniquely necessary to the efficient functioning of the whole, could ever arise by random processes.\"\n\nIn 1975 Thomas H. Frazzetta published a book-length study of a concept similar to irreducible complexity, explained by gradual, step-wise, non-teleological evolution. Frazzetta wrote: \"A complex adaptation is one constructed of \"several\" components that must blend together operationally to make the adaptation \"work\". It is analogous to a machine whose performance depends upon careful cooperation among its parts. In the case of the machine, no single part can greatly be altered without changing the performance of the entire machine.\" The machine that he chose as an analog is the Peaucellier–Lipkin linkage, and one biological system given extended description was the jaw apparatus of a python. The conclusion of this investigation, rather than that evolution of a complex adaptation was impossible, \"awed by the adaptations of living things, to be stunned by their complexity and suitability\", was \"to accept the inescapable but not humiliating fact that much of mankind can be seen in a tree or a lizard.\"\n\nIn 1981, Ariel Roth, in defense of the creation-science position in the trial \"McLean v. Arkansas\", said of \"complex integrated structures\": \"This system would not be functional until all the parts were there ... How did these parts survive during evolution ...?\"\n\nIn 1985 Cairns-Smith wrote of \"interlocking\": \"How can a complex collaboration between components evolve in small steps?\" and used the analogy of the scaffolding called centering - used to build an arch then removed afterwards: \"Surely there was 'scaffolding'. Before the multitudinous components of present biochemistry could come to lean together \"they had to lean on something else.\"\" However, neither Muller or Cairns-Smith claimed their ideas as evidence of something supernatural.\n\nAn essay in support of creationism published in 1994 referred to bacterial flagella as showing \"multiple, integrated components\", where \"nothing about them works unless every one of their complexly fashioned and integrated components are in place\". The author asked the reader to \"imagine the effects of natural selection on those organisms that fortuitously evolved the flagella ... without the concommitant control mechanisms\".\n\nAn early concept of irreducibly complex systems comes from Ludwig von Bertalanffy (1901-1972), an Austrian biologist. He believed that complex systems must be examined as complete, irreducible systems in order to fully understand how they work. He extended his work on biological complexity into a general theory of systems in a book titled \"General Systems Theory\".\n\nAfter James Watson and Francis Crick published the structure of DNA in the early 1950s, General Systems Theory lost many of its adherents in the physical and biological sciences.\nHowever, systems theory remained popular in the social sciences long after its demise in the physical and biological sciences.\n\nMichael Behe developed his ideas on the concept around 1992, in the early days of the 'wedge movement', and first presented his ideas about \"irreducible complexity\" in June 1993 when the \"Johnson-Behe cadre of scholars\" met at Pajaro Dunes in California. He set out his ideas in the second edition of \"Of Pandas and People\" published in 1993, extensively revising Chapter 6 \"Biochemical Similarities\" with new sections on the complex mechanism of blood clotting and on the origin of proteins.\n\nHe first used the term \"irreducible complexity\" in his 1996 book \"Darwin's Black Box\", to refer to certain complex biochemical cellular systems. He posits that evolutionary mechanisms cannot explain the development of such \"irreducibly complex\" systems. Notably, Behe credits philosopher William Paley for the original concept (alone among the predecessors) and suggests that his application of the concept to biological systems is entirely original.\n\nIntelligent design advocates argue that irreducibly complex systems must have been deliberately engineered by some form of intelligence.\n\nIn 2001, Michael Behe wrote: \"[T]here is an asymmetry between my current definition of irreducible complexity and the task facing natural selection. I hope to repair this defect in future work.\" Behe specifically explained that the \"current definition puts the focus on removing a part from an already functioning system\", but the \"difficult task facing Darwinian evolution, however, would not be to remove parts from sophisticated pre-existing systems; it would be to bring together components to make a new system in the first place\". In the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe testified under oath that he \"did not judge [the asymmetry] serious enough to [have revised the book] yet.\"\n\nBehe additionally testified that the presence of irreducible complexity in organisms would not rule out the involvement of evolutionary mechanisms in the development of organic life. He further testified that he knew of no earlier \"peer reviewed articles in scientific journals discussing the intelligent design of the blood clotting cascade,\" but that there were \"probably a large number of peer reviewed articles in science journals that demonstrate that the blood clotting system is indeed a purposeful arrangement of parts of great complexity and sophistication.\" (The judge ruled that \"intelligent design is not science and is essentially religious in nature\".)\n\nAccording to the theory of evolution, genetic variations occur without specific design or intent. The environment \"selects\" the variants that have the highest fitness, which are then passed on to the next generation of organisms. Change occurs by the gradual operation of natural forces over time, perhaps slowly, perhaps more quickly (see punctuated equilibrium). This process is able to adapt complex structures from simpler beginnings, or convert complex structures from one function to another (see spandrel). Most intelligent design advocates accept that evolution occurs through mutation and natural selection at the \"micro level\", such as changing the relative frequency of various beak lengths in finches, but assert that it cannot account for irreducible complexity, because none of the parts of an irreducible system would be functional or advantageous until the entire system is in place.\n\nBehe uses the mousetrap as an illustrative example of this concept. A mousetrap consists of five interacting pieces: the base, the catch, the spring, the hammer, and the hold-down bar. All of these must be in place for the mousetrap to work, as the removal of any one piece destroys the function of the mousetrap. Likewise, he asserts that biological systems require multiple parts working together in order to function. Intelligent design advocates claim that natural selection could not create from scratch those systems for which science is currently unable to find a viable evolutionary pathway of successive, slight modifications, because the selectable function is only present when all parts are assembled.\n\nIn his 2008 book \"Only A Theory\", biologist Kenneth R. Miller challenges Behe's claim that the mousetrap is irreducibly complex. Miller observes that various subsets of the five components can be devised to form cooperative units, ones that have different functions from the mousetrap and so, in biological terms, could form functional spandrels before being adapted to the new function of catching mice. In an example taken from his high school experience, Miller recalls that one of his classmates...struck upon the brilliant idea of using an old, broken mousetrap as a spitball catapult, and it worked brilliantly... It had worked perfectly as something other than a mousetrap... my rowdy friend had pulled a couple of parts --probably the hold-down bar and catch-- off the trap to make it easier to conceal and more effective as a catapult... [leaving] the base, the spring, and the hammer. Not much of a mousetrap, but a helluva spitball launcher... I realized why [Behe's] mousetrap analogy had bothered me. It was wrong. The mousetrap is not irreducibly complex after all.\n\nOther systems identified by Miller that include mousetrap components include the following:\nBULLET::::- use the spitball launcher as a tie clip (same three-part system with different function)\nBULLET::::- remove the spring from the spitball launcher/tie clip to create a two-part key chain (base + hammer)\nBULLET::::- glue the spitball launcher/tie clip to a sheet of wood to create a clipboard (launcher + glue + wood)\nBULLET::::- remove the hold-down bar for use as a toothpick (single element system)\n\nThe point of the reduction is that - in biology - most or all of the components were already at hand, by the time it became necessary to build a mousetrap. As such, it required far fewer steps to develop a mousetrap than to design all the components from scratch.\n\nThus, the development of the mousetrap, said to consist of five different parts which had no function on their own, has been reduced to one step: the assembly from parts that are already present, performing other functions.\n\nSupporters of intelligent design argue that anything less than the complete form of such a system or organ would not work at all, or would in fact be a \"detriment\" to the organism, and would therefore never survive the process of natural selection. Although they accept that some complex systems and organs \"can\" be explained by evolution, they claim that organs and biological features which are \"irreducibly complex\" cannot be explained by current models, and that an intelligent designer must have created life or guided its evolution. Accordingly, the debate on irreducible complexity concerns two questions: whether irreducible complexity can be found in nature, and what significance it would have if it did exist in nature.\n\nBehe's original examples of irreducibly complex mechanisms included the bacterial flagellum of \"E. coli\", the blood clotting cascade, cilia, and the adaptive immune system.\n\nBehe argues that organs and biological features which are irreducibly complex cannot be wholly explained by current models of evolution. In explicating his definition of \"irreducible complexity\" he notes that:\nAn irreducibly complex system cannot be produced directly (that is, by continuously improving the initial function, which continues to work by the same mechanism) by slight, successive modifications of a precursor system, because any precursor to an irreducibly complex system that is missing a part is by definition nonfunctional.\n\nIrreducible complexity is not an argument that evolution does not occur, but rather an argument that it is \"incomplete\". In the last chapter of \"Darwin's Black Box\", Behe goes on to explain his view that irreducible complexity is evidence for intelligent design. Mainstream critics, however, argue that irreducible complexity, as defined by Behe, can be generated by known evolutionary mechanisms. Behe's claim that no scientific literature adequately modeled the origins of biochemical systems through evolutionary mechanisms has been challenged by TalkOrigins. The judge in the \"Dover\" trial wrote \"By defining irreducible complexity in the way that he has, Professor Behe attempts to exclude the phenomenon of exaptation by definitional fiat, ignoring as he does so abundant evidence which refutes his argument. Notably, the NAS has rejected Professor Behe's claim for irreducible complexity...\"\n\nBehe and others have suggested a number of biological features that they believed to be irreducibly complex.\n\nThe process of blood clotting or coagulation cascade in vertebrates is a complex biological pathway which is given as an example of apparent irreducible complexity.\n\nThe irreducible complexity argument assumes that the necessary parts of a system have always been necessary, and therefore could not have been added sequentially. However, in evolution, something which is at first merely advantageous can later become necessary. Natural selection can lead to complex biochemical systems being built up from simpler systems, or to existing functional systems being recombined as a new system with a different function. For example, one of the clotting factors that Behe listed as a part of the clotting cascade (Factor XII, also called Hageman factor) was later found to be absent in whales, demonstrating that it is not essential for a clotting system. Many purportedly irreducible structures can be found in other organisms as much simpler systems that utilize fewer parts. These systems, in turn, may have had even simpler precursors that are now extinct. Behe has responded to critics of his clotting cascade arguments by suggesting that homology is evidence for evolution, but not for natural selection.\n\nThe \"improbability argument\" also misrepresents natural selection. It is correct to say that a set of simultaneous mutations that form a complex protein structure is so unlikely as to be unfeasible, but that is not what Darwin advocated. His explanation is based on small accumulated changes that take place without a final goal. Each step must be advantageous in its own right, although biologists may not yet understand the reason behind all of them—for example, jawless fish accomplish blood clotting with just six proteins instead of the full ten.\n\nThe eye is an example of a supposedly irreducibly complex structure, due to its many elaborate and interlocking parts, seemingly all dependent upon one another. It is frequently cited by intelligent design and creationism advocates as an example of irreducible complexity. Behe used the \"development of the eye problem\" as evidence for intelligent design in \"Darwin's Black Box\". Although Behe acknowledged that the evolution of the larger anatomical features of the eye have been well-explained, he pointed out that the complexity of the minute biochemical reactions required at a molecular level for light sensitivity still defies explanation. Creationist Jonathan Sarfati has described the eye as evolutionary biologists' \"greatest challenge as an example of superb 'irreducible complexity' in God's creation\", specifically pointing to the supposed \"vast complexity\" required for transparency.\n\nIn an often misquoted passage from \"On the Origin of Species\", Charles Darwin appears to acknowledge the eye's development as a difficulty for his theory. However, the quote in context shows that Darwin actually had a very good understanding of the evolution of the eye (see fallacy of quoting out of context). He notes that \"to suppose that the eye ... could have been formed by natural selection, seems, I freely confess, absurd in the highest possible degree\". Yet this observation was merely a rhetorical device for Darwin. He goes on to explain that if gradual evolution of the eye could be shown to be possible, \"the difficulty of believing that a perfect and complex eye could be formed by natural selection ... can hardly be considered real\". He then proceeded to roughly map out a likely course for evolution using examples of gradually more complex eyes of various species.\n\nSince Darwin's day, the eye's ancestry has become much better understood. Although learning about the construction of ancient eyes through fossil evidence is problematic due to the soft tissues leaving no imprint or remains, genetic and comparative anatomical evidence has increasingly supported the idea of a common ancestry for all eyes.\n\nCurrent evidence does suggest possible evolutionary lineages for the origins of the anatomical features of the eye. One likely chain of development is that the eyes originated as simple patches of photoreceptor cells that could detect the presence or absence of light, but not its direction. When, via random mutation across the population, the photosensitive cells happened to have developed on a small depression, it endowed the organism with a better sense of the light's source. This small change gave the organism an advantage over those without the mutation. This genetic trait would then be \"selected for\" as those with the trait would have an increased chance of survival, and therefore progeny, over those without the trait. Individuals with deeper depressions would be able to discern changes in light over a wider field than those individuals with shallower depressions. As ever deeper depressions were advantageous to the organism, gradually, this depression would become a pit into which light would strike certain cells depending on its angle. The organism slowly gained increasingly precise visual information. And again, this gradual process continued as individuals having a slightly shrunken aperture of the eye had an advantage over those without the mutation as an aperture increases how collimated the light is at any one specific group of photoreceptors. As this trait developed, the eye became effectively a pinhole camera which allowed the organism to dimly make out shapes—the nautilus is a modern example of an animal with such an eye. Finally, via this same selection process, a protective layer of transparent cells over the aperture was differentiated into a crude lens, and the interior of the eye was filled with humours to assist in focusing images. In this way, eyes are recognized by modern biologists as actually a relatively unambiguous and simple structure to evolve, and many of the major developments of the eye's evolution are believed to have taken place over only a few million years, during the Cambrian explosion. Behe asserts that this is only an explanation of the gross anatomical steps, however, and not an explanation of the changes in discrete biochemical systems that would have needed to take place.\n\nBehe maintains that the complexity of light sensitivity at the molecular level and the minute biochemical reactions required for those first \"simple patches of photoreceptor[s]\" still defies explanation, and that the proposed series of infinitesimal steps to get from patches of photoreceptors to a fully functional eye would actually be considered great, complex leaps in evolution if viewed on the molecular scale. Other intelligent design proponents claim that the evolution of the entire visual system would be difficult rather than the eye alone.\n\nThe flagella of certain bacteria constitute a molecular motor requiring the interaction of about 40 different protein parts. Behe presents this as a prime example of an irreducibly complex structure defined as \"a single system composed of several well-matched, interacting parts that contribute to the basic function, wherein the removal of any one of the parts causes the system to effectively cease functioning\", and argues that since \"an irreducibly complex system that is missing a part is by definition nonfunctional\", it could not have evolved gradually through natural selection.\n\nReducible complexity. In contrast to Behe's claims, many proteins can be deleted or mutated and the flagellum still works, even though sometimes at reduced efficiency. In fact, the composition of flagella is surprisingly diverse across bacteria with many proteins only found in some species but not others. Hence the flagellar apparatus is clearly very flexible in evolutionary terms and perfectly able to lose or gain protein components. Further studies have shown that, contrary to claims of \"irreducible complexity\", flagella and related protein transport mechanisms show evidence of evolution through Darwinian processes, providing case studies in how complex systems can evolve from simpler components. Multiple processes were involved in the evolution of the flagellum, including horizontal gene transfer.\n\nEvolution from type three secretion systems. Scientists regard this argument as having been disproved in the light of research dating back to 1996 as well as more recent findings. They point out that the basal body of the flagella has been found to be similar to the Type III secretion system (TTSS), a needle-like structure that pathogenic germs such as \"Salmonella\" and \"Yersinia pestis\" use to inject toxins into living eucaryote cells. The needle's base has ten elements in common with the flagellum, but it is missing forty of the proteins that make a flagellum work. The TTSS system negates Behe's claim that taking away any one of the flagellum's parts would prevent the system from functioning. On this basis, Kenneth Miller notes that, \"The parts of this supposedly irreducibly complex system actually have functions of their own.\" Studies have also shown that similar parts of the flagellum in different bacterial species can have different functions despite showing evidence of common descent, and that certain parts of the flagellum can be removed without completely eliminating its functionality.\n\nDembski has argued that phylogenetically, the TTSS is found in a narrow range of bacteria which makes it seem to him to be a late innovation, whereas flagella are widespread throughout many bacterial groups, and he argues that it was an early innovation. Against Dembski's argument, different flagella use completely different mechanisms, and publications show a plausible path in which bacterial flagella could have evolved from a secretion system.\n\nThe cilium construction of axoneme microtubules movement by the sliding of dynein protein was cited by Behe as an example of irreducible complexity. He further said that the advances in knowledge in the subsequent 10 years had shown that the complexity of intraflagellar transport for two hundred components cilium and many other cellular structures is substantially greater than was known earlier.\n\nThe bombardier beetle is able to defend itself by directing a spray of hot fluid at an attacker. The mechanism involves a system for mixing hydroquinones and hydrogen peroxide, which react violently to attain a temperature near boiling point, and in some species a nozzle which allows the spray to be directed accurately in any direction.\n\nThe unique combination of features of the bombardier beetle's defense mechanism—strongly exothermic reactions, boiling-hot fluids, and explosive release—have been claimed by creationists and proponents of intelligent design to be examples of irreducible complexity. Biologists such as the taxonomist Mark Isaak note however that step-by-step evolution of the mechanism could readily have occurred. In particular, quinones are precursors to sclerotin, used to harden the skeleton of many insects, while peroxide is a common by-product of metabolism.\n\nLike intelligent design, the concept it seeks to support, irreducible complexity has failed to gain any notable acceptance within the scientific community. \n\nResearchers have proposed potentially viable evolutionary pathways for allegedly irreducibly complex systems such as blood clotting, the immune system and the flagellum - the three examples Behe proposed. John H. McDonald even showed his example of a mousetrap to be reducible. If irreducible complexity is an insurmountable obstacle to evolution, it should not be possible to conceive of such pathways.\n\nNiall Shanks and Karl H. Joplin, both of East Tennessee State University, have shown that systems satisfying Behe's characterization of irreducible biochemical complexity can arise naturally and spontaneously as the result of self-organizing chemical processes. They also assert that what evolved biochemical and molecular systems actually exhibit is \"redundant complexity\"—a kind of complexity that is the product of an evolved biochemical process. They claim that Behe overestimated the significance of irreducible complexity because of his simple, linear view of biochemical reactions, resulting in his taking snapshots of selective features of biological systems, structures, and processes, while ignoring the redundant complexity of the context in which those features are naturally embedded. They also criticized his over-reliance of overly simplistic metaphors, such as his mousetrap.\n\nA computer model of the co-evolution of proteins binding to DNA in the peer-reviewed journal \"Nucleic Acids Research\" consisted of several parts (DNA binders and DNA binding sites) which contribute to the basic function; removal of either one leads immediately to the death of the organism. This model fits the definition of irreducible complexity exactly, yet it evolves. (The program can be run from Ev program.)\n\nIn addition, research published in the peer-reviewed journal \"Nature\" has shown that computer simulations of evolution demonstrate that it is possible for complex features to evolve naturally.\n\nOne can compare a mousetrap with a cat in this context. Both normally function so as to control the mouse population. The cat has many parts that can be removed leaving it still functional; for example, its tail can be bobbed, or it can lose an ear in a fight. Comparing the cat and the mousetrap, then, one sees that the mousetrap (which is not alive) offers better evidence, in terms of irreducible complexity, for intelligent design than the cat. Even looking at the mousetrap analogy, several critics have described ways in which the parts of the mousetrap could have independent uses or could develop in stages, demonstrating that it is not irreducibly complex.\n\nMoreover, even cases where removing a certain component in an organic system will cause the system to fail do not demonstrate that the system could not have been formed in a step-by-step, evolutionary process. By analogy, stone arches are irreducibly complex—if you remove any stone the arch will collapse—yet humans build them easily enough, one stone at a time, by building over centering that is removed afterward. Similarly, naturally occurring arches of stone form by the weathering away of bits of stone from a large concretion that has formed previously.\n\nEvolution can act to simplify as well as to complicate. This raises the possibility that seemingly irreducibly complex biological features may have been achieved with a period of increasing complexity, followed by a period of simplification.\n\nA team led by Joseph Thornton, assistant professor of biology at the University of Oregon's Center for Ecology and Evolutionary Biology, using techniques for resurrecting ancient genes, reconstructed the evolution of an apparently irreducibly complex molecular system. The April 7, 2006 issue of \"Science\" published this research.\n\nIrreducible complexity may not actually exist in nature, and the examples given by Behe and others may not in fact represent irreducible complexity, but can be explained in terms of simpler precursors. The theory of facilitated variation challenges irreducible complexity. Marc W. Kirschner, a professor and chair of Department of Systems Biology at Harvard Medical School, and John C. Gerhart, a professor in Molecular and Cell Biology, University of California, Berkeley, presented this theory in 2005. They describe how certain mutation and changes can cause apparent irreducible complexity. Thus, seemingly irreducibly complex structures are merely \"very complex\", or they are simply misunderstood or misrepresented.\n\nThe precursors of complex systems, when they are not useful in themselves, may be useful to perform other, unrelated functions. Evolutionary biologists argue that evolution often works in this kind of blind, haphazard manner in which the function of an early form is not necessarily the same as the function of the later form. The term used for this process is exaptation. The mammalian middle ear (derived from a jawbone) and the panda's thumb (derived from a wrist bone spur) provide classic examples. A 2006 article in \"Nature\" demonstrates intermediate states leading toward the development of the ear in a Devonian fish (about 360 million years ago). Furthermore, recent research shows that viruses play a heretofore unexpected role in evolution by mixing and matching genes from various hosts.\n\nArguments for irreducibility often assume that things started out the same way they ended up—as we see them now. However, that may not necessarily be the case. In the \"Dover\" trial an expert witness for the plaintiffs, Ken Miller, demonstrated this possibility using Behe's mousetrap analogy. By removing several parts, Miller made the object unusable as a mousetrap, but he pointed out that it was now a perfectly functional, if unstylish, tie clip.\n\nIrreducible complexity can be seen as equivalent to an \"uncrossable valley\" in a fitness landscape. A number of mathematical models of evolution have explored the circumstances under which such valleys can, nevertheless, be crossed.\n\nSome critics, such as Jerry Coyne (professor of evolutionary biology at the University of Chicago) and Eugenie Scott (a physical anthropologist and former executive director of the National Center for Science Education) have argued that the concept of irreducible complexity and, more generally, intelligent design is not falsifiable and, therefore, not scientific.\n\nBehe argues that the theory that irreducibly complex systems could not have evolved can be falsified by an experiment where such systems are evolved. For example, he posits taking bacteria with no flagellum and imposing a selective pressure for mobility. If, after a few thousand generations, the bacteria evolved the bacterial flagellum, then Behe believes that this would refute his theory.\n\nOther critics take a different approach, pointing to experimental evidence that they consider falsification of the argument for Intelligent Design from irreducible complexity. For example, Kenneth Miller describes the lab work of Barry G. Hall on E. coli as showing that \"Behe is wrong\".\n\nOther evidence that irreducible complexity is not a problem for evolution comes from the field of computer science, which routinely uses computer analogues of the processes of evolution in order to automatically design complex solutions to problems. The results of such genetic algorithms are frequently irreducibly complex since the process, like evolution, both removes non-essential components over time as well as adding new components. The removal of unused components with no essential function, like the natural process where rock underneath a natural arch is removed, can produce irreducibly complex structures without requiring the intervention of a designer. Researchers applying these algorithms automatically produce human-competitive designs—but no human designer is required.\n\nIntelligent design proponents attribute to an intelligent designer those biological structures they believe are irreducibly complex and therefore they say a natural explanation is insufficient to account for them. However, critics view irreducible complexity as a special case of the \"complexity indicates design\" claim, and thus see it as an argument from ignorance and as a God-of-the-gaps argument.\n\nEugenie Scott and Glenn Branch of the National Center for Science Education note that ID arguments from irreducible complexity rest on the false assumption that a lack of knowledge of a natural explanation allows ID proponents to assume an intelligent cause, when the proper response of scientists would be to say that we don't know, and further investigation is needed. Other critics describe Behe as saying that evolutionary explanations are not detailed enough to meet his standards, while at the same time presenting ID as exempt from having to provide any positive evidence at all.\n\nIrreducible complexity is at its core an argument against evolution. If truly irreducible systems are found, the argument goes, then intelligent design must be the correct explanation for their existence. However, this conclusion is based on the assumption that current evolutionary theory and intelligent design are the only two valid models to explain life, a false dilemma.\n\nWhile testifying during the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe conceded that there are no peer-reviewed papers supporting his claims that complex molecular systems, like the bacterial flagellum, the blood-clotting cascade, and the immune system, were intelligently designed nor are there any peer-reviewed articles supporting his argument that certain complex molecular structures are \"irreducibly complex.\"\n\nIn the final ruling of \"Kitzmiller v. Dover Area School District\", Judge Jones specifically singled out Behe and irreducible complexity:\nBULLET::::- \"Professor Behe admitted in \"Reply to My Critics\" that there was a defect in his view of irreducible complexity because, while it purports to be a challenge to natural selection, it does not actually address \"the task facing natural selection.\" and that \"Professor Behe wrote that he hoped to \"repair this defect in future work...\" (Page 73)\nBULLET::::- \"As expert testimony revealed, the qualification on what is meant by \"irreducible complexity\" renders it meaningless as a criticism of evolution. (3:40 (Miller)). In fact, the theory of evolution proffers exaptation as a well-recognized, well-documented explanation for how systems with multiple parts could have evolved through natural means.\" (Page 74)\nBULLET::::- \"By defining irreducible complexity in the way that he has, Professor Behe attempts to exclude the phenomenon of exaptation by definitional fiat, ignoring as he does so abundant evidence which refutes his argument. Notably, the NAS has rejected Professor Behe's claim for irreducible complexity...\" (Page 75)\nBULLET::::- \"As irreducible complexity is only a negative argument against evolution, it is refutable and accordingly testable, unlike ID [Intelligent Design], by showing that there are intermediate structures with selectable functions that could have evolved into the allegedly irreducibly complex systems. (2:15-16 (Miller)). Importantly, however, the fact that the negative argument of irreducible complexity is testable does not make testable the argument for ID. (2:15 (Miller); 5:39 (Pennock)). Professor Behe has applied the concept of irreducible complexity to only a few select systems: (1) the bacterial flagellum; (2) the blood-clotting cascade; and (3) the immune system. Contrary to Professor Behe's assertions with respect to these few biochemical systems among the myriad existing in nature, however, Dr. Miller presented evidence, based upon peer-reviewed studies, that they are not in fact irreducibly complex.\" (Page 76)\nBULLET::::- \"...on cross-examination, Professor Behe was questioned concerning his 1996 claim that science would never find an evolutionary explanation for the immune system. He was presented with fifty-eight peer-reviewed publications, nine books, and several immunology textbook chapters about the evolution of the immune system; however, he simply insisted that this was still not sufficient evidence of evolution, and that it was not \"good enough.\" (23:19 (Behe)).\" (Page 78)\nBULLET::::- \"We therefore find that Professor Behe's claim for irreducible complexity has been refuted in peer-reviewed research papers and has been rejected by the scientific community at large. (17:45-46 (Padian); 3:99 (Miller)). Additionally, even if irreducible complexity had not been rejected, it still does not support ID as it is merely a test for evolution, not design. (2:15, 2:35-40 (Miller); 28:63-66 (Fuller)). We will now consider the purportedly \"positive argument\" for design encompassed in the phrase used numerous times by Professors Behe and Minnich throughout their expert testimony, which is the \"purposeful arrangement of parts.\" Professor Behe summarized the argument as follows: We infer design when we see parts that appear to be arranged for a purpose. The strength of the inference is quantitative; the more parts that are arranged, the more intricately they interact, the stronger is our confidence in design. The appearance of design in aspects of biology is overwhelming. Since nothing other than an intelligent cause has been demonstrated to be able to yield such a strong appearance of design, Darwinian claims notwithstanding, the conclusion that the design seen in life is real design is rationally justified. (18:90-91, 18:109-10 (Behe); 37:50 (Minnich)). As previously indicated, this argument is merely a restatement of the Reverend William Paley's argument applied at the cell level. Minnich, Behe, and Paley reach the same conclusion, that complex organisms must have been designed using the same reasoning, except that Professors Behe and Minnich refuse to identify the designer, whereas Paley inferred from the presence of design that it was God. (1:6- 7 (Miller); 38:44, 57 (Minnich)). Expert testimony revealed that this inductive argument is not scientific and as admitted by Professor Behe, can never be ruled out. (2:40 (Miller); 22:101 (Behe); 3:99 (Miller)).\" (Pages 79–80)\n\n\nBULLET::::- Supportive\nBULLET::::- Michael J. Behe home page\nBULLET::::- About Irreducible Complexity Discovery Institute\nBULLET::::- Behe's Reply to his Critics (pdf)\nBULLET::::- How to Explain Irreducible Complexity -- A Lab Manual Discovery Institute\nBULLET::::- Institute for Creation Research (pdf)\nBULLET::::- Irreducible Complexity: Definition & Evaluation by Craig Rusbult, Ph.D.\nBULLET::::- Irreducible Complexity Revisited (pdf)\n\nBULLET::::- Critical\nBULLET::::- Behe, Biochemistry, and the Invisible Hand\nBULLET::::- Darwin vs. Intelligent Design (again), by H. Allen Orr (review of \"Darwin's Black Box\")\nBULLET::::- Devolution: Why intelligent design isn't (\"The New Yorker\")\nBULLET::::- Does irreducible complexity imply Intelligent Design? by Mark Perakh\nBULLET::::- Evolution of the Eye (Video) Zoologist Dan-Erik Nilsson demonstrates eye evolution through intermediate stages with working model. (PBS)\nBULLET::::- Facilitated Variation\nBULLET::::- Himma, Kenneth Einar. Design Arguments for the Existence of God. \"Internet Encyclopedia of Philosophy\": 2. Contemporary Versions of the Design Argument, a. The Argument from Irreducible Biochemical Complexity\nBULLET::::- \"Kitzmiller vs. Dover\" transcripts\nBULLET::::- Miller, Kenneth R. textbook website\nBULLET::::- Miller's \"The Flagellum Unspun: The Collapse of Irreducible Complexity\"\nBULLET::::- Talk.origins archive (see talk.origins)\nBULLET::::- TalkDesign.org (sister site to talk.origins archive on intelligent design)\nBULLET::::- The bacterial flagellar motor: brilliant evolution or intelligent design? Matt Baker, ABC Science, 7 July 2015\nBULLET::::- Unlocking cell secrets bolsters evolutionists (\"Chicago Tribune\")\n"}
